{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## can we decide between task related and MW ? ############################\n",
    "\n",
    "# only two categorries\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "# Import package/module for data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules for feature engineering and modelling\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# cross validation and hyperparameter tuning\n",
    "from sklearn.model_selection import StratifiedGroupKFold,  GridSearchCV\n",
    "\n",
    "# balancing\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "#feature selection\n",
    "from sklearn import set_config\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_path_awareness = r\"W:\\WCT\\04_Mind-Wandering-Labstudy\\04_Daten\\04_Prepared_data\\00_Julia\\Model Building\\features_with_label_awareness.csv\"\n",
    "read_path = r\"C:\\Users\\Julia\\Desktop\\features_with_labels.csv\"# r\"W:\\WCT\\04_Mind-Wandering-Labstudy\\04_Daten\\04_Prepared_data\\00_Julia\\Model Building\\features_with_labels.csv\"\n",
    "df = pd.read_csv(read_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task-related    631\n",
       "aware           249\n",
       "unaware         147\n",
       "Name: Awareness_all, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[\"Awareness_all\"].unique()\n",
    "df[\"Awareness_all\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "df[\"Awareness_all_new\"] = labelencoder.fit_transform(df[\"Awareness_all\"])\n",
    "df[\"Awareness_all_new\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    631\n",
       "0    249\n",
       "2    147\n",
       "Name: Awareness_all_new, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Awareness_all_new\"].value_counts()\n",
    "# 1 = task related, 0 aware 2 unaware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(0,3)\n",
    "# df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(1,4)\n",
    "# df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(2,1)\n",
    "# df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(3,1)\n",
    "# df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(4, 0)\n",
    "# df[\"Awareness_all_new\"].value_counts()\n",
    "\n",
    "# # 0 task- related\n",
    "# # 1 MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    631\n",
       "0    396\n",
       "Name: Awareness_all_new, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Awareness_all_new\"] =  df[\"Awareness_all_new\"].replace(2,0)\n",
    "df[\"Awareness_all_new\"].value_counts()\n",
    "# 1 task related\n",
    "# 0 MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Awareness_all_cat\"].unique()\n",
    "# # to get only two categories\n",
    "# df[\"Awareness_all_cat\"] =  df[\"Awareness_all_cat\"].replace(3,2)\n",
    "# df[\"Awareness_all_cat\"] =  df[\"Awareness_all_cat\"].replace(1,0)\n",
    "# df[\"Awareness_all_cat\"] =  df[\"Awareness_all_cat\"].replace(2,1)\n",
    "# df[\"Awareness_all_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['task-related' == 1 , 'aware' == 2, 'unaware' == 3 , nan == delete the row]\n",
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        'Fixation Duration Mean [ms]', 'Fixation Duration Max [ms]', 'Fixation Duration Min [ms]', 'Fixation Duration Median [ms]', 'Fixation Duration Std [ms]', 'Fixation Duration Skew [ms]', 'Fixation Duration Quantil 25 [ms]', 'Fixation Duration Quantil 75 [ms]',\n",
    "        'Saccade Duration Mean [ms]', 'Saccade Duration Max [ms]', 'Saccade Duration Min [ms]', 'Saccade Duration Median [ms]', 'Saccade Duration Std [ms]', 'Saccade Duration Skew [ms]', 'Saccade Duration Quantil 25 [ms]', 'Saccade Duration Quantil 75 [ms]', \n",
    "        'Blink Duration Mean [ms]', 'Blink Duration Max [ms]', 'Blink Duration Min [ms]', 'Blink Duration Median [ms]', 'Blink Duration Std [ms]', 'Blink Duration Skew [ms]', 'Blink Duration Quantil 25 [ms]', 'Blink Duration Quantil 75 [ms]', 'Fixation Duration Kurtosis [ms]',\n",
    "        'Saccade Duration Kurtosis [ms]',\n",
    "        'Blink Duration Kurtosis [ms]', \n",
    "        'Fixation Saccade Ratio Mean', 'Fixation Saccade Ratio Max', 'Fixation Saccade Ratio Min', 'Fixation Saccade Ratio Median', 'Fixation Saccade Ratio Std', 'Fixation Saccade Ratio Skew', 'Fixation Saccade Ratio Kurtosis', \n",
    "        'Fixation Number', 'Blink Number', \n",
    "        'Fixation Dispersion X Mean [px]', 'Fixation Dispersion X Max [px]', 'Fixation Dispersion X Min [px]', 'Fixation Dispersion X Median [px]', 'Fixation Dispersion X Std [px]', 'Fixation Dispersion X Skew [px]', 'Fixation Dispersion X Quantil 25 [px]', 'Fixation Dispersion X Quantil 75 [px]', \n",
    "        'Fixation Dispersion Y Mean [px]', 'Fixation Dispersion Y Max [px]', 'Fixation Dispersion Y Min [px]', 'Fixation Dispersion Y Median [px]', 'Fixation Dispersion Y Std [px]', 'Fixation Dispersion Y Skew [px]', 'Fixation Dispersion Y Quantil 25 [px]', 'Fixation Dispersion Y Quantil 75 [px]', 'Fixation Dispersion X Kurtosis [px]', 'Fixation Dispersion Y Kurtosis [px]', \n",
    "        'Saccade Amplitude Mean [°]', 'Saccade Amplitude Max [°]', 'Saccade Amplitude Min [°]', 'Saccade Amplitude Median [°]', 'Saccade Amplitude Std [°]', 'Saccade Amplitude Skew [°]', 'Saccade Amplitude Quantil 25 [°]', 'Saccade Amplitude Quantil 75 [°]', 'Saccade Amplitude Kurtosis [°]',\n",
    "        'Saccade Acceleration Average [°/s²] Mean', 'Saccade Acceleration Average [°/s²] Max', 'Saccade Acceleration Average [°/s²] Min', 'Saccade Acceleration Average [°/s²] Median', 'Saccade Acceleration Average [°/s²] Std', 'Saccade Acceleration Average [°/s²] Skew]', 'Saccade Acceleration Average [°/s²] Quantil 25]', 'Saccade Acceleration Average [°/s²] Quantil 75]',\n",
    "        'Saccade Acceleration Peak [°/s²] Mean', 'Saccade Acceleration Peak [°/s²] Max', 'Saccade Acceleration Peak [°/s²] Min', 'Saccade Acceleration Peak [°/s²] Median', 'Saccade Acceleration Peak [°/s²] Std', 'Saccade Acceleration Peak [°/s²] Skew]', 'Saccade Acceleration Peak [°/s²] Quantil 25]', 'Saccade Acceleration Peak [°/s²] Quantil 75]', 'Saccade Deceleration Peak [°/s²] Mean', \n",
    "        'Saccade Deceleration Peak [°/s²] Max', 'Saccade Deceleration Peak [°/s²] Min', 'Saccade Deceleration Peak [°/s²] Median', 'Saccade Deceleration Peak [°/s²] Std', 'Saccade Deceleration Peak [°/s²] Skew]', 'Saccade Deceleration Peak [°/s²] Quantil 25]', 'Saccade Deceleration Peak [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Average [°/s²] Mean', 'Saccade Velocity Average [°/s²] Max', 'Saccade Velocity Average [°/s²] Min', 'Saccade Velocity Average [°/s²] Median', 'Saccade Velocity Average [°/s²] Std', 'Saccade Velocity Average [°/s²] Skew]', 'Saccade Velocity Average [°/s²] Quantil 25]', 'Saccade Velocity Average [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Peak [°/s²] Mean', 'Saccade Velocity Peak [°/s²] Max', 'Saccade Velocity Peak [°/s²] Min', 'Saccade Velocity Peak [°/s²] Median', 'Saccade Velocity Peak [°/s²] Std', 'Saccade Velocity Peak [°/s²] Skew]', 'Saccade Velocity Peak [°/s²] Quantil 25]', 'Saccade Velocity Peak [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Peak [%] Mean', 'Saccade Velocity Peak [%] Max', 'Saccade Velocity Peak [%] Min', 'Saccade Velocity Peak [%] Median', 'Saccade Velocity Peak [%] Std', 'Saccade Velocity Peak [%] Skew]', 'Saccade Velocity Peak [%] Quantil 25]', 'Saccade Velocity Peak [%] Quantil 75]', \n",
    "        'Saccade Acceleration Average [°/s²] Kurtosis', 'Saccade Acceleration Peak [°/s²] Kurtosis', 'Saccade Deceleration Peak [°/s²] Kurtosis', 'Saccade Velocity Average [°/s²] Kurtosis', 'Saccade Velocity Peak [°/s²] Kurtosis', 'Saccade Velocity Peak [%] Kurtosis', \n",
    "        'Saccade Length Mean [px]', 'Saccade Length Max [px]', 'Saccade Length Min [px]', 'Saccade Length Median [px]', 'Saccade Length Std [px]', 'Saccade Length Skew [px]]', 'Saccade Length Quantil 25 [px]]', 'Saccade Length Quantil 75 [px]]', 'Saccade Length Kurtosis [px]', \n",
    "        'Fixation Average Pupil Diameter [mm] Mean', 'Fixation Average Pupil Diameter [mm] Max', 'Fixation Average Pupil Diameter [mm] Min', 'Fixation Average Pupil Diameter [mm] Median', 'Fixation Average Pupil Diameter [mm] Std', 'Fixation Average Pupil Diameter [mm] Skew', 'Fixation Average Pupil Diameter [mm] Quantil25', 'Fixation Average Pupil Diameter [mm] Quantil75',\n",
    "        'Fixation Average Pupil Diameter [mm] Kurtosis', \n",
    "        'Veregence Angles Mean [rad]', 'Veregence Angles Std [rad]', \n",
    "        'Pupil Distance Mean [px]', 'Pupil Distance Std [px]'\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"Participant\"\n",
    "\n",
    "    TARGET = \"Awareness_all_new\"\n",
    "\n",
    "    X = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    groups = train[GROUPS]\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups = get_X_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### preprocessing with pipleline #####################\n",
    "\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "# Balancing\n",
    "#over = SMOTE(random_state= 4) \n",
    "over = RandomOverSampler(random_state=4)\n",
    "\n",
    "#weighted\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 3, n_estimators = 500, subsample = 1)\n",
    "#model = RandomForestClassifier(random_state=3, class_weight=\"balanced\")\n",
    "#model = SVC(kernel= \"linear\", C = 0.004, gamma = 0.005, class_weight= \"balanced\" )\n",
    "#model = SVC(kernel= \"linear\", C = 10, gamma = 1, class_weight= \"balanced\" )\n",
    "#model = GaussianNB(var_smoothing=  1.5199110829529332e-05) \n",
    "#steps = [('imputer', imputer), ('scaler',scaler), ('model', model)]\n",
    "\n",
    "#classsifier\n",
    "model = MLPClassifier()\n",
    "#classifier getuned\n",
    "#model = GaussianNB(var_smoothing=  1.5199110829529332e-05) #0.002848035868435802)\n",
    "\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 3, n_estimators = 500, subsample = 1)\n",
    "#auch gut\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 15, n_estimators = 220, learning_rate = 0.014, alpha = 0, reg_lambda = 1)\n",
    "\n",
    "# getunet\n",
    "#model = RandomForestClassifier(random_state=3) #, bootstrap = True, max_depth = 50, max_features = 'auto',min_samples_leaf = 6, min_samples_split= 2, n_estimators = 200)\n",
    "\n",
    "#model = SVC(kernel= \"linear\", C = 10, gamma = 1) \n",
    "\n",
    "#model = SVC(kernel = \"rbf\", C = 0.004, gamma = 0.1)\n",
    "#model = SVC(kernel= \"rbf\", C = 0.004, gamma = 0.1) \n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler), ('over', over), ('model', model)]\n",
    "\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  46  32\n",
      "1  46  85\n",
      "f1  score for fold 0:  0.5411764705882353\n",
      "recall for fold 0:  0.5897435897435898\n",
      "precision for fold 0:  0.5\n",
      "('auc for fold 0: ', 0.797723191053846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  34  40\n",
      "1  53  82\n",
      "f1  score for fold 1:  0.422360248447205\n",
      "recall for fold 1:  0.4594594594594595\n",
      "precision for fold 1:  0.39080459770114945\n",
      "('auc for fold 1: ', 0.7665635358474012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  47  28\n",
      "1  58  77\n",
      "f1  score for fold 2:  0.5222222222222223\n",
      "recall for fold 2:  0.6266666666666667\n",
      "precision for fold 2:  0.44761904761904764\n",
      "('auc for fold 2: ', 0.78994708994709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  32  50\n",
      "1  40  84\n",
      "f1  score for fold 3:  0.4155844155844156\n",
      "recall for fold 3:  0.3902439024390244\n",
      "precision for fold 3:  0.4444444444444444\n",
      "('auc for fold 3: ', 0.7492298918810271)\n",
      "    0   1\n",
      "0  48  39\n",
      "1  50  56\n",
      "f1  score for fold 4:  0.5189189189189191\n",
      "recall for fold 4:  0.5517241379310345\n",
      "precision for fold 4:  0.4897959183673469\n",
      "('auc for fold 4: ', 0.6884214642579662)\n",
      "Our mean fold f1 score is 0.4841\n",
      "Our mean fold recall is 0.5236\n",
      "Our mean fold precision is 0.4545\n",
      "Our mean fold auc pr is 0.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##################### prediction without baseline #####################\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "auc_pr_score = []\n",
    "\n",
    "### stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    # sample weights\n",
    "    # sample_weights = class_weight.compute_sample_weight(class_weight = 'balanced',  y = y_train)\n",
    "    # # Fit Model on Train\n",
    "    # pipe.fit(X_train, y_train, **{'model__sample_weight': sample_weights})\n",
    "    # print(pipe)\n",
    "\n",
    "    # Fit Model on Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Calcualte different metrics\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_test, y_pred, pos_label = 0)\n",
    "    precision = precision_score(y_test, y_pred, pos_label = 0)\n",
    "    recall = recall_score(y_test, y_pred, pos_label = 0)\n",
    "\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred)))\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(f\"f1  score for fold {fold}: \", f1)\n",
    "    print(f\"recall for fold {fold}: \", recall)\n",
    "    print(f\"precision for fold {fold}: \", precision)\n",
    "    \n",
    "\n",
    "    # Precision- recall curve\n",
    "    fpr, tpr, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "    # calculate AUC-PR using the precision-recall curve\n",
    "    auc_pr = auc( tpr,fpr) \n",
    "    auc_pr_score.append(auc_pr)\n",
    "\n",
    "    print((f\"auc for fold {fold}: \", auc_pr))\n",
    "   \n",
    "    fold += 1\n",
    "\n",
    "mean_auc = np.mean(auc_pr_score)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "\n",
    "print(f'Our mean fold f1 score is {mean_f1:0.4f}')\n",
    "print(f'Our mean fold recall is {mean_recall:0.4f}')\n",
    "print(f'Our mean fold precision is {mean_precision:0.4f}')\n",
    "print(f'Our mean fold auc pr is {mean_auc:0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__bootstrap': True, 'model__max_depth': 50, 'model__max_features': 'auto', 'model__min_samples_leaf': 6, 'model__min_samples_split': 1, 'model__n_estimators': 100}\n",
      "Pipeline(steps=[('imputer', SimpleImputer(fill_value='missing')),\n",
      "                ('scaler', StandardScaler()), ('over', SMOTE(random_state=4)),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=50, max_features='auto',\n",
      "                                        min_samples_leaf=6, min_samples_split=1,\n",
      "                                        random_state=0))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__bootstrap': False,\n",
       " 'model__max_depth': 50,\n",
       " 'model__max_features': 'auto',\n",
       " 'model__min_samples_leaf': 5,\n",
       " 'model__min_samples_split': 2,\n",
       " 'model__n_estimators': 200}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Grid Search random forrest\n",
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "custom_scorer = make_scorer(f1_score, greater_is_better=True,  pos_label=0)\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "# defining parameter range\n",
    "param_grid = {\n",
    "    'model__bootstrap': [True, False],\n",
    " 'model__max_depth': [50, 25, 6],\n",
    " 'model__max_features': ['auto'],\n",
    " 'model__min_samples_leaf': [4, 5, 6],\n",
    " 'model__min_samples_split': [1, 2, 3],\n",
    " 'model__n_estimators': [200, 100, 150]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, verbose = 1, cv = 5, scoring= custom_scorer)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "TypeError: f1_score() takes 2 positional arguments but 3 were given\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Julia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 0.004, 'model__gamma': 0.005, 'model__kernel': 'linear'}\n",
      "Pipeline(steps=[('imputer', SimpleImputer(fill_value='missing')),\n",
      "                ('scaler', StandardScaler()), ('over', SMOTE(random_state=4)),\n",
      "                ('model', SVC(C=0.004, gamma=0.005, kernel='linear'))])\n"
     ]
    }
   ],
   "source": [
    "############## Grid Search SVC\n",
    "##################### prediction without baseline #####################\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "# defining parameter range\n",
    "param_grid = {'model__C': [0.004,0.1, 1, 10], \n",
    "              'model__gamma':  [0.005, 0.1, 1],\n",
    "              'model__kernel': [\"linear\", \"rbf\"]} \n",
    "  \n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, verbose = 1, cv = 5)#, scoring= f1_score)\n",
    "\n",
    "grid.fit(X, y)\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# {'model__C': 0.004, 'model__gamma': 0.005, 'model__kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 0.1, 'model__gamma': 1, 'model__kernel': 'rbf'}\n",
      "Pipeline(steps=[('imputer', SimpleImputer(fill_value='missing')),\n",
      "                ('scaler', StandardScaler()), ('over', SMOTE(random_state=27)),\n",
      "                ('model', SVC(C=0.1, gamma=1))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49        87\n",
      "           1       0.62      0.85      0.72       106\n",
      "\n",
      "    accuracy                           0.64       193\n",
      "   macro avg       0.65      0.61      0.60       193\n",
      "weighted avg       0.65      0.64      0.61       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# repreditc tto see how the model works\n",
    "grid_predictions = grid.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'model__var_smoothing': 1.5199110829529332e-05}\n",
      "Pipeline(steps=[('imputer', SimpleImputer(fill_value='missing')),\n",
      "                ('scaler', StandardScaler()), ('over', RandomOverSampler()),\n",
      "                ('model', GaussianNB(var_smoothing=1.5199110829529332e-05))])\n"
     ]
    }
   ],
   "source": [
    "### Grid Seach Gaussian naive bayes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "custom_scorer = make_scorer(f1_score, greater_is_better=True,  pos_label=0)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {\n",
    "    #var_smoothing is a stability calculation to widen (or smooth) the curve and therefore account for more samples that are further away from the distribution mean.\n",
    "    'model__var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, verbose = 1, cv = 5, scoring= \"f1_macro\")\n",
    "\n",
    "# muss hier mit trainig data oder mit ganzem X trainiert werden?\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "{'model__colsample_bytree': 0.5, 'model__max_depth': 3, 'model__n_estimators': 500, 'model__subsample': 1}\n",
      "Pipeline(steps=[('imputer', SimpleImputer(fill_value='missing')),\n",
      "                ('scaler', StandardScaler()), ('over', SMOTE(random_state=4)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=0.5, early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               feature_types=None, gamma=...d=None,\n",
      "                               grow_policy=None, importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=3, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=500,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               predictor=None, random_state=42, ...))])\n"
     ]
    }
   ],
   "source": [
    "############################### Grid Search for xgboost\n",
    "\n",
    "# The first way is to directly control model complexity.\n",
    "# This includes max_depth, min_child_weight and gamma.\n",
    "# The second way is to add randomness to make training robust to noise.\n",
    "# This includes subsample and colsample_bytree.\n",
    "# You can also reduce stepsize eta. Remember to increase num_round when you do so.\n",
    "\n",
    "# xgboost -- gridsearchcv\n",
    "# gs_xgb = XGBClassifier(\n",
    "#     eta= 0.3, \n",
    "#     n_estimators= 500,\n",
    "#     gamma= 0,\n",
    "#     max_depth= 6, \n",
    "#     min_child_weight= 1,\n",
    "#     colsample_bytree= 1, \n",
    "#     colsample_bylevel= 1, \n",
    "#     subsample= 1, \n",
    "#     reg_lambda= 1, \n",
    "#     reg_alpha= 0,\n",
    "#     seed= 33\n",
    "# )\n",
    "\n",
    "# max_depth: 3–10\n",
    "# n_estimators: 100 (lots of observations) to 1000 (few observations)\n",
    "# learning_rate: 0.01–0.3\n",
    "# colsample_bytree: 0.5–1\n",
    "# subsample: 0.6–1\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "custom_scorer = make_scorer(f1_score, greater_is_better=True,  pos_label=0)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {\n",
    "    \"model__subsample\": [0.6, 0.8, 1], #np.arange(0.6,1,0.05),\n",
    "    \"model__max_depth\": [3, 6, 10], # np.arange(3,10,1),\n",
    "    \"model__n_estimators\": [1000, 700, 500],\n",
    "    \"model__colsample_bytree\": [0.1,0.5, 1.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid = param_grid, verbose = 1, cv = 5, scoring= custom_scorer)\n",
    "\n",
    "# muss hier mit trainig data oder mit ganzem X trainiert werden?\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### preprocessing with pipleline #####################\n",
    "\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "#over = SMOTE(random_state= 4) #sampling_strategy=0.1 # random_state= 27\n",
    "over = RandomOverSampler()\n",
    "# wieso geth das nicht??\n",
    "model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "#model = GaussianNB()\n",
    "#model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# after gridsearch SVC\n",
    "#model = SVC(kernel= \"linear\", C = 10, gamma = 1, class_weight = \"balanced\") \n",
    "#model = SVC(kernel = \"poly\", C = 0.005, gamma = 0.005, class_weight = \"balanced\")\n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler), ('over', over), ('model', model)] \n",
    "#steps = [('imputer', imputer), ('scaler',scaler), ('model', model)] \n",
    "\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### preprocessing with pipleline #####################\n",
    "\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "over = SMOTE(random_state= 4) #sampling_strategy=0.1 # random_state= 27\n",
    "#over = RandomOverSampler()\n",
    "# wieso geth das nicht??\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "#model = GaussianNB()\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# after gridsearch SVC\n",
    "#model = SVC(kernel= \"linear\", C = 10, gamma = 1, class_weight = \"balanced\") \n",
    "#model = SVC(kernel = \"poly\", C = 0.005, gamma = 0.005, class_weight = \"balanced\")\n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler), ('over', over), ('model', model)] \n",
    "#steps = [('imputer', imputer), ('scaler',scaler), ('model', model)] \n",
    "\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## hyperparamter tuning for random forrest\n",
    "\n",
    "##################### prediction without baseline #####################\n",
    "# for cross- validation\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'model__bootstrap': [True, False],\n",
    " 'model__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'model__max_features': ['auto', 'sqrt'],\n",
    " 'model__min_samples_leaf': [1, 2, 4],\n",
    " 'model__min_samples_split': [2, 5, 10],\n",
    " 'model__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "  \n",
    "grid = GridSearchCV(pipe, param_grid, refit = True, verbose = 3)\n",
    "\n",
    "\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 0:  0.48325358851674644\n",
      "f1  score for fold 0:  0.31645569620253167\n",
      "recall for fold 0:  0.32051282051282054\n",
      "precision for fold 0:  0.3125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1:  0.5789473684210527\n",
      "f1  score for fold 1:  0.42857142857142855\n",
      "recall for fold 1:  0.44594594594594594\n",
      "precision for fold 1:  0.4125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2:  0.5666666666666667\n",
      "f1  score for fold 2:  0.41290322580645167\n",
      "recall for fold 2:  0.4266666666666667\n",
      "precision for fold 2:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3:  0.529126213592233\n",
      "f1  score for fold 3:  0.39751552795031053\n",
      "recall for fold 3:  0.3902439024390244\n",
      "precision for fold 3:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4:  0.47668393782383417\n",
      "f1  score for fold 4:  0.3726708074534162\n",
      "recall for fold 4:  0.3448275862068966\n",
      "precision for fold 4:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 5:  0.5311004784688995\n",
      "f1  score for fold 5:  0.37974683544303806\n",
      "recall for fold 5:  0.38461538461538464\n",
      "precision for fold 5:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 6:  0.5502392344497608\n",
      "f1  score for fold 6:  0.3896103896103896\n",
      "recall for fold 6:  0.40540540540540543\n",
      "precision for fold 6:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 7:  0.5285714285714286\n",
      "f1  score for fold 7:  0.3612903225806451\n",
      "recall for fold 7:  0.37333333333333335\n",
      "precision for fold 7:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 8:  0.5097087378640777\n",
      "f1  score for fold 8:  0.37267080745341613\n",
      "recall for fold 8:  0.36585365853658536\n",
      "precision for fold 8:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 9:  0.45595854922279794\n",
      "f1  score for fold 9:  0.3478260869565218\n",
      "recall for fold 9:  0.3218390804597701\n",
      "precision for fold 9:  0.3783783783783784\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 10:  0.5311004784688995\n",
      "f1  score for fold 10:  0.37974683544303806\n",
      "recall for fold 10:  0.38461538461538464\n",
      "precision for fold 10:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 11:  0.5406698564593302\n",
      "f1  score for fold 11:  0.37662337662337664\n",
      "recall for fold 11:  0.3918918918918919\n",
      "precision for fold 11:  0.3625\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 12:  0.5857142857142857\n",
      "f1  score for fold 12:  0.43870967741935485\n",
      "recall for fold 12:  0.4533333333333333\n",
      "precision for fold 12:  0.425\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 13:  0.5097087378640777\n",
      "f1  score for fold 13:  0.37267080745341613\n",
      "recall for fold 13:  0.36585365853658536\n",
      "precision for fold 13:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 14:  0.5284974093264249\n",
      "f1  score for fold 14:  0.4347826086956522\n",
      "recall for fold 14:  0.40229885057471265\n",
      "precision for fold 14:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 15:  0.5502392344497608\n",
      "f1  score for fold 15:  0.4050632911392405\n",
      "recall for fold 15:  0.41025641025641024\n",
      "precision for fold 15:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 16:  0.5406698564593302\n",
      "f1  score for fold 16:  0.37662337662337664\n",
      "recall for fold 16:  0.3918918918918919\n",
      "precision for fold 16:  0.3625\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 17:  0.5\n",
      "f1  score for fold 17:  0.3225806451612903\n",
      "recall for fold 17:  0.3333333333333333\n",
      "precision for fold 17:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 18:  0.5194174757281553\n",
      "f1  score for fold 18:  0.38509316770186336\n",
      "recall for fold 18:  0.3780487804878049\n",
      "precision for fold 18:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 19:  0.538860103626943\n",
      "f1  score for fold 19:  0.4472049689440994\n",
      "recall for fold 19:  0.41379310344827586\n",
      "precision for fold 19:  0.4864864864864865\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 20:  0.5885167464114832\n",
      "f1  score for fold 20:  0.45569620253164556\n",
      "recall for fold 20:  0.46153846153846156\n",
      "precision for fold 20:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 21:  0.5406698564593302\n",
      "f1  score for fold 21:  0.37662337662337664\n",
      "recall for fold 21:  0.3918918918918919\n",
      "precision for fold 21:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 22:  0.5380952380952381\n",
      "f1  score for fold 22:  0.3741935483870968\n",
      "recall for fold 22:  0.38666666666666666\n",
      "precision for fold 22:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 23:  0.5097087378640777\n",
      "f1  score for fold 23:  0.37267080745341613\n",
      "recall for fold 23:  0.36585365853658536\n",
      "precision for fold 23:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 24:  0.49740932642487046\n",
      "f1  score for fold 24:  0.39751552795031053\n",
      "recall for fold 24:  0.367816091954023\n",
      "precision for fold 24:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 25:  0.5311004784688995\n",
      "f1  score for fold 25:  0.37974683544303806\n",
      "recall for fold 25:  0.38461538461538464\n",
      "precision for fold 25:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 26:  0.5119617224880383\n",
      "f1  score for fold 26:  0.33766233766233766\n",
      "recall for fold 26:  0.35135135135135137\n",
      "precision for fold 26:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 27:  0.5380952380952381\n",
      "f1  score for fold 27:  0.3741935483870968\n",
      "recall for fold 27:  0.38666666666666666\n",
      "precision for fold 27:  0.3625\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 28:  0.5679611650485437\n",
      "f1  score for fold 28:  0.4472049689440994\n",
      "recall for fold 28:  0.43902439024390244\n",
      "precision for fold 28:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 29:  0.5181347150259067\n",
      "f1  score for fold 29:  0.422360248447205\n",
      "recall for fold 29:  0.39080459770114945\n",
      "precision for fold 29:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 30:  0.5215311004784688\n",
      "f1  score for fold 30:  0.36708860759493667\n",
      "recall for fold 30:  0.3717948717948718\n",
      "precision for fold 30:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 31:  0.5598086124401914\n",
      "f1  score for fold 31:  0.40259740259740256\n",
      "recall for fold 31:  0.4189189189189189\n",
      "precision for fold 31:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 32:  0.5380952380952381\n",
      "f1  score for fold 32:  0.3741935483870968\n",
      "recall for fold 32:  0.38666666666666666\n",
      "precision for fold 32:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 33:  0.5388349514563107\n",
      "f1  score for fold 33:  0.40993788819875776\n",
      "recall for fold 33:  0.4024390243902439\n",
      "precision for fold 33:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 34:  0.5077720207253886\n",
      "f1  score for fold 34:  0.40993788819875776\n",
      "recall for fold 34:  0.3793103448275862\n",
      "precision for fold 34:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 35:  0.5406698564593302\n",
      "f1  score for fold 35:  0.3924050632911393\n",
      "recall for fold 35:  0.3974358974358974\n",
      "precision for fold 35:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 36:  0.5406698564593302\n",
      "f1  score for fold 36:  0.37662337662337664\n",
      "recall for fold 36:  0.3918918918918919\n",
      "precision for fold 36:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 37:  0.5190476190476191\n",
      "f1  score for fold 37:  0.34838709677419355\n",
      "recall for fold 37:  0.36\n",
      "precision for fold 37:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 38:  0.558252427184466\n",
      "f1  score for fold 38:  0.43478260869565216\n",
      "recall for fold 38:  0.4268292682926829\n",
      "precision for fold 38:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 39:  0.48704663212435234\n",
      "f1  score for fold 39:  0.3850931677018633\n",
      "recall for fold 39:  0.3563218390804598\n",
      "precision for fold 39:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 40:  0.569377990430622\n",
      "f1  score for fold 40:  0.43037974683544306\n",
      "recall for fold 40:  0.4358974358974359\n",
      "precision for fold 40:  0.425\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 41:  0.5598086124401914\n",
      "f1  score for fold 41:  0.40259740259740256\n",
      "recall for fold 41:  0.4189189189189189\n",
      "precision for fold 41:  0.3875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 42:  0.5761904761904761\n",
      "f1  score for fold 42:  0.4258064516129032\n",
      "recall for fold 42:  0.44\n",
      "precision for fold 42:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 43:  0.5097087378640777\n",
      "f1  score for fold 43:  0.37267080745341613\n",
      "recall for fold 43:  0.36585365853658536\n",
      "precision for fold 43:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 44:  0.538860103626943\n",
      "f1  score for fold 44:  0.4472049689440994\n",
      "recall for fold 44:  0.41379310344827586\n",
      "precision for fold 44:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 45:  0.5215311004784688\n",
      "f1  score for fold 45:  0.36708860759493667\n",
      "recall for fold 45:  0.3717948717948718\n",
      "precision for fold 45:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 46:  0.5502392344497608\n",
      "f1  score for fold 46:  0.3896103896103896\n",
      "recall for fold 46:  0.40540540540540543\n",
      "precision for fold 46:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 47:  0.5380952380952381\n",
      "f1  score for fold 47:  0.3741935483870968\n",
      "recall for fold 47:  0.38666666666666666\n",
      "precision for fold 47:  0.3625\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 48:  0.5679611650485437\n",
      "f1  score for fold 48:  0.4472049689440994\n",
      "recall for fold 48:  0.43902439024390244\n",
      "precision for fold 48:  0.45569620253164556\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 49:  0.5077720207253886\n",
      "f1  score for fold 49:  0.40993788819875776\n",
      "recall for fold 49:  0.3793103448275862\n",
      "precision for fold 49:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 50:  0.5598086124401914\n",
      "f1  score for fold 50:  0.4177215189873418\n",
      "recall for fold 50:  0.4230769230769231\n",
      "precision for fold 50:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 51:  0.5406698564593302\n",
      "f1  score for fold 51:  0.37662337662337664\n",
      "recall for fold 51:  0.3918918918918919\n",
      "precision for fold 51:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 52:  0.5666666666666667\n",
      "f1  score for fold 52:  0.41290322580645167\n",
      "recall for fold 52:  0.4266666666666667\n",
      "precision for fold 52:  0.4\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 53:  0.558252427184466\n",
      "f1  score for fold 53:  0.43478260869565216\n",
      "recall for fold 53:  0.4268292682926829\n",
      "precision for fold 53:  0.4430379746835443\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 54:  0.47668393782383417\n",
      "f1  score for fold 54:  0.3726708074534162\n",
      "recall for fold 54:  0.3448275862068966\n",
      "precision for fold 54:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 55:  0.5311004784688995\n",
      "f1  score for fold 55:  0.37974683544303806\n",
      "recall for fold 55:  0.38461538461538464\n",
      "precision for fold 55:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 56:  0.5215311004784688\n",
      "f1  score for fold 56:  0.3506493506493507\n",
      "recall for fold 56:  0.36486486486486486\n",
      "precision for fold 56:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 57:  0.5380952380952381\n",
      "f1  score for fold 57:  0.3741935483870968\n",
      "recall for fold 57:  0.38666666666666666\n",
      "precision for fold 57:  0.3625\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 58:  0.48058252427184467\n",
      "f1  score for fold 58:  0.33540372670807456\n",
      "recall for fold 58:  0.32926829268292684\n",
      "precision for fold 58:  0.34177215189873417\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 59:  0.49740932642487046\n",
      "f1  score for fold 59:  0.39751552795031053\n",
      "recall for fold 59:  0.367816091954023\n",
      "precision for fold 59:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 60:  0.5311004784688995\n",
      "f1  score for fold 60:  0.37974683544303806\n",
      "recall for fold 60:  0.38461538461538464\n",
      "precision for fold 60:  0.375\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 61:  0.46411483253588515\n",
      "f1  score for fold 61:  0.27272727272727276\n",
      "recall for fold 61:  0.28378378378378377\n",
      "precision for fold 61:  0.2625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 62:  0.5190476190476191\n",
      "f1  score for fold 62:  0.34838709677419355\n",
      "recall for fold 62:  0.36\n",
      "precision for fold 62:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 63:  0.5\n",
      "f1  score for fold 63:  0.3602484472049689\n",
      "recall for fold 63:  0.35365853658536583\n",
      "precision for fold 63:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 64:  0.48704663212435234\n",
      "f1  score for fold 64:  0.3850931677018633\n",
      "recall for fold 64:  0.3563218390804598\n",
      "precision for fold 64:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 65:  0.5119617224880383\n",
      "f1  score for fold 65:  0.3544303797468355\n",
      "recall for fold 65:  0.358974358974359\n",
      "precision for fold 65:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 66:  0.5311004784688995\n",
      "f1  score for fold 66:  0.36363636363636365\n",
      "recall for fold 66:  0.3783783783783784\n",
      "precision for fold 66:  0.35\n",
      "    0   1\n",
      "0  38  37\n",
      "1  42  93\n",
      "Accuracy for fold 67:  0.6238095238095238\n",
      "f1  score for fold 67:  0.49032258064516127\n",
      "recall for fold 67:  0.5066666666666667\n",
      "precision for fold 67:  0.475\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 68:  0.5\n",
      "f1  score for fold 68:  0.3602484472049689\n",
      "recall for fold 68:  0.35365853658536583\n",
      "precision for fold 68:  0.3670886075949367\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 69:  0.538860103626943\n",
      "f1  score for fold 69:  0.4472049689440994\n",
      "recall for fold 69:  0.41379310344827586\n",
      "precision for fold 69:  0.4864864864864865\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 70:  0.48325358851674644\n",
      "f1  score for fold 70:  0.31645569620253167\n",
      "recall for fold 70:  0.32051282051282054\n",
      "precision for fold 70:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 71:  0.5598086124401914\n",
      "f1  score for fold 71:  0.40259740259740256\n",
      "recall for fold 71:  0.4189189189189189\n",
      "precision for fold 71:  0.3875\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 72:  0.4714285714285714\n",
      "f1  score for fold 72:  0.2838709677419355\n",
      "recall for fold 72:  0.29333333333333333\n",
      "precision for fold 72:  0.275\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 73:  0.5194174757281553\n",
      "f1  score for fold 73:  0.38509316770186336\n",
      "recall for fold 73:  0.3780487804878049\n",
      "precision for fold 73:  0.3924050632911392\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 74:  0.47668393782383417\n",
      "f1  score for fold 74:  0.3726708074534162\n",
      "recall for fold 74:  0.3448275862068966\n",
      "precision for fold 74:  0.40540540540540543\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 75:  0.49282296650717705\n",
      "f1  score for fold 75:  0.32911392405063294\n",
      "recall for fold 75:  0.3333333333333333\n",
      "precision for fold 75:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 76:  0.5502392344497608\n",
      "f1  score for fold 76:  0.3896103896103896\n",
      "recall for fold 76:  0.40540540540540543\n",
      "precision for fold 76:  0.375\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 77:  0.4714285714285714\n",
      "f1  score for fold 77:  0.2838709677419355\n",
      "recall for fold 77:  0.29333333333333333\n",
      "precision for fold 77:  0.275\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 78:  0.5388349514563107\n",
      "f1  score for fold 78:  0.40993788819875776\n",
      "recall for fold 78:  0.4024390243902439\n",
      "precision for fold 78:  0.4177215189873418\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 79:  0.46632124352331605\n",
      "f1  score for fold 79:  0.36024844720496896\n",
      "recall for fold 79:  0.3333333333333333\n",
      "precision for fold 79:  0.3918918918918919\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 80:  0.48325358851674644\n",
      "f1  score for fold 80:  0.31645569620253167\n",
      "recall for fold 80:  0.32051282051282054\n",
      "precision for fold 80:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 81:  0.5598086124401914\n",
      "f1  score for fold 81:  0.40259740259740256\n",
      "recall for fold 81:  0.4189189189189189\n",
      "precision for fold 81:  0.3875\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 82:  0.5857142857142857\n",
      "f1  score for fold 82:  0.43870967741935485\n",
      "recall for fold 82:  0.4533333333333333\n",
      "precision for fold 82:  0.425\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 83:  0.5388349514563107\n",
      "f1  score for fold 83:  0.40993788819875776\n",
      "recall for fold 83:  0.4024390243902439\n",
      "precision for fold 83:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 84:  0.5181347150259067\n",
      "f1  score for fold 84:  0.422360248447205\n",
      "recall for fold 84:  0.39080459770114945\n",
      "precision for fold 84:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 85:  0.5023923444976076\n",
      "f1  score for fold 85:  0.34177215189873417\n",
      "recall for fold 85:  0.34615384615384615\n",
      "precision for fold 85:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 86:  0.5119617224880383\n",
      "f1  score for fold 86:  0.33766233766233766\n",
      "recall for fold 86:  0.35135135135135137\n",
      "precision for fold 86:  0.325\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 87:  0.48095238095238096\n",
      "f1  score for fold 87:  0.2967741935483871\n",
      "recall for fold 87:  0.30666666666666664\n",
      "precision for fold 87:  0.2875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 88:  0.5194174757281553\n",
      "f1  score for fold 88:  0.38509316770186336\n",
      "recall for fold 88:  0.3780487804878049\n",
      "precision for fold 88:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 89:  0.538860103626943\n",
      "f1  score for fold 89:  0.4472049689440994\n",
      "recall for fold 89:  0.41379310344827586\n",
      "precision for fold 89:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 90:  0.5311004784688995\n",
      "f1  score for fold 90:  0.37974683544303806\n",
      "recall for fold 90:  0.38461538461538464\n",
      "precision for fold 90:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 91:  0.5023923444976076\n",
      "f1  score for fold 91:  0.3246753246753247\n",
      "recall for fold 91:  0.33783783783783783\n",
      "precision for fold 91:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 92:  0.5380952380952381\n",
      "f1  score for fold 92:  0.3741935483870968\n",
      "recall for fold 92:  0.38666666666666666\n",
      "precision for fold 92:  0.3625\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 93:  0.46116504854368934\n",
      "f1  score for fold 93:  0.31055900621118016\n",
      "recall for fold 93:  0.3048780487804878\n",
      "precision for fold 93:  0.31645569620253167\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 94:  0.49740932642487046\n",
      "f1  score for fold 94:  0.39751552795031053\n",
      "recall for fold 94:  0.367816091954023\n",
      "precision for fold 94:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 95:  0.5119617224880383\n",
      "f1  score for fold 95:  0.3544303797468355\n",
      "recall for fold 95:  0.358974358974359\n",
      "precision for fold 95:  0.35\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 96:  0.49282296650717705\n",
      "f1  score for fold 96:  0.3116883116883117\n",
      "recall for fold 96:  0.32432432432432434\n",
      "precision for fold 96:  0.3\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 97:  0.5571428571428572\n",
      "f1  score for fold 97:  0.4000000000000001\n",
      "recall for fold 97:  0.41333333333333333\n",
      "precision for fold 97:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 98:  0.5485436893203883\n",
      "f1  score for fold 98:  0.42236024844720493\n",
      "recall for fold 98:  0.4146341463414634\n",
      "precision for fold 98:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 99:  0.47668393782383417\n",
      "f1  score for fold 99:  0.3726708074534162\n",
      "recall for fold 99:  0.3448275862068966\n",
      "precision for fold 99:  0.40540540540540543\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 100:  0.47368421052631576\n",
      "f1  score for fold 100:  0.3037974683544304\n",
      "recall for fold 100:  0.3076923076923077\n",
      "precision for fold 100:  0.3\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 101:  0.5406698564593302\n",
      "f1  score for fold 101:  0.37662337662337664\n",
      "recall for fold 101:  0.3918918918918919\n",
      "precision for fold 101:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 102:  0.5190476190476191\n",
      "f1  score for fold 102:  0.34838709677419355\n",
      "recall for fold 102:  0.36\n",
      "precision for fold 102:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 103:  0.48058252427184467\n",
      "f1  score for fold 103:  0.33540372670807456\n",
      "recall for fold 103:  0.32926829268292684\n",
      "precision for fold 103:  0.34177215189873417\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 104:  0.47668393782383417\n",
      "f1  score for fold 104:  0.3726708074534162\n",
      "recall for fold 104:  0.3448275862068966\n",
      "precision for fold 104:  0.40540540540540543\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 105:  0.5502392344497608\n",
      "f1  score for fold 105:  0.4050632911392405\n",
      "recall for fold 105:  0.41025641025641024\n",
      "precision for fold 105:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 106:  0.5406698564593302\n",
      "f1  score for fold 106:  0.37662337662337664\n",
      "recall for fold 106:  0.3918918918918919\n",
      "precision for fold 106:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 107:  0.5380952380952381\n",
      "f1  score for fold 107:  0.3741935483870968\n",
      "recall for fold 107:  0.38666666666666666\n",
      "precision for fold 107:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 108:  0.558252427184466\n",
      "f1  score for fold 108:  0.43478260869565216\n",
      "recall for fold 108:  0.4268292682926829\n",
      "precision for fold 108:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 109:  0.48704663212435234\n",
      "f1  score for fold 109:  0.3850931677018633\n",
      "recall for fold 109:  0.3563218390804598\n",
      "precision for fold 109:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 110:  0.5598086124401914\n",
      "f1  score for fold 110:  0.4177215189873418\n",
      "recall for fold 110:  0.4230769230769231\n",
      "precision for fold 110:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 111:  0.5598086124401914\n",
      "f1  score for fold 111:  0.40259740259740256\n",
      "recall for fold 111:  0.4189189189189189\n",
      "precision for fold 111:  0.3875\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 112:  0.5857142857142857\n",
      "f1  score for fold 112:  0.43870967741935485\n",
      "recall for fold 112:  0.4533333333333333\n",
      "precision for fold 112:  0.425\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 113:  0.470873786407767\n",
      "f1  score for fold 113:  0.3229813664596273\n",
      "recall for fold 113:  0.3170731707317073\n",
      "precision for fold 113:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 114:  0.538860103626943\n",
      "f1  score for fold 114:  0.4472049689440994\n",
      "recall for fold 114:  0.41379310344827586\n",
      "precision for fold 114:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 115:  0.5598086124401914\n",
      "f1  score for fold 115:  0.4177215189873418\n",
      "recall for fold 115:  0.4230769230769231\n",
      "precision for fold 115:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 116:  0.5406698564593302\n",
      "f1  score for fold 116:  0.37662337662337664\n",
      "recall for fold 116:  0.3918918918918919\n",
      "precision for fold 116:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 117:  0.5285714285714286\n",
      "f1  score for fold 117:  0.3612903225806451\n",
      "recall for fold 117:  0.37333333333333335\n",
      "precision for fold 117:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 118:  0.5\n",
      "f1  score for fold 118:  0.3602484472049689\n",
      "recall for fold 118:  0.35365853658536583\n",
      "precision for fold 118:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 119:  0.49740932642487046\n",
      "f1  score for fold 119:  0.39751552795031053\n",
      "recall for fold 119:  0.367816091954023\n",
      "precision for fold 119:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 120:  0.569377990430622\n",
      "f1  score for fold 120:  0.43037974683544306\n",
      "recall for fold 120:  0.4358974358974359\n",
      "precision for fold 120:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 121:  0.5502392344497608\n",
      "f1  score for fold 121:  0.3896103896103896\n",
      "recall for fold 121:  0.40540540540540543\n",
      "precision for fold 121:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 122:  0.5\n",
      "f1  score for fold 122:  0.3225806451612903\n",
      "recall for fold 122:  0.3333333333333333\n",
      "precision for fold 122:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 123:  0.558252427184466\n",
      "f1  score for fold 123:  0.43478260869565216\n",
      "recall for fold 123:  0.4268292682926829\n",
      "precision for fold 123:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 124:  0.5284974093264249\n",
      "f1  score for fold 124:  0.4347826086956522\n",
      "recall for fold 124:  0.40229885057471265\n",
      "precision for fold 124:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 125:  0.5215311004784688\n",
      "f1  score for fold 125:  0.36708860759493667\n",
      "recall for fold 125:  0.3717948717948718\n",
      "precision for fold 125:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 126:  0.5406698564593302\n",
      "f1  score for fold 126:  0.37662337662337664\n",
      "recall for fold 126:  0.3918918918918919\n",
      "precision for fold 126:  0.3625\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 127:  0.4714285714285714\n",
      "f1  score for fold 127:  0.2838709677419355\n",
      "recall for fold 127:  0.29333333333333333\n",
      "precision for fold 127:  0.275\n",
      "    0   1\n",
      "0  20  62\n",
      "1  59  65\n",
      "Accuracy for fold 128:  0.41262135922330095\n",
      "f1  score for fold 128:  0.24844720496894412\n",
      "recall for fold 128:  0.24390243902439024\n",
      "precision for fold 128:  0.25316455696202533\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 129:  0.5492227979274611\n",
      "f1  score for fold 129:  0.45962732919254656\n",
      "recall for fold 129:  0.42528735632183906\n",
      "precision for fold 129:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 130:  0.49282296650717705\n",
      "f1  score for fold 130:  0.32911392405063294\n",
      "recall for fold 130:  0.3333333333333333\n",
      "precision for fold 130:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 131:  0.5502392344497608\n",
      "f1  score for fold 131:  0.3896103896103896\n",
      "recall for fold 131:  0.40540540540540543\n",
      "precision for fold 131:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 132:  0.5476190476190477\n",
      "f1  score for fold 132:  0.38709677419354843\n",
      "recall for fold 132:  0.4\n",
      "precision for fold 132:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 133:  0.529126213592233\n",
      "f1  score for fold 133:  0.39751552795031053\n",
      "recall for fold 133:  0.3902439024390244\n",
      "precision for fold 133:  0.4050632911392405\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 134:  0.5595854922279793\n",
      "f1  score for fold 134:  0.4720496894409938\n",
      "recall for fold 134:  0.4367816091954023\n",
      "precision for fold 134:  0.5135135135135135\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 135:  0.5406698564593302\n",
      "f1  score for fold 135:  0.3924050632911393\n",
      "recall for fold 135:  0.3974358974358974\n",
      "precision for fold 135:  0.3875\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 136:  0.569377990430622\n",
      "f1  score for fold 136:  0.4155844155844156\n",
      "recall for fold 136:  0.43243243243243246\n",
      "precision for fold 136:  0.4\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 137:  0.5\n",
      "f1  score for fold 137:  0.3225806451612903\n",
      "recall for fold 137:  0.3333333333333333\n",
      "precision for fold 137:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 138:  0.5\n",
      "f1  score for fold 138:  0.3602484472049689\n",
      "recall for fold 138:  0.35365853658536583\n",
      "precision for fold 138:  0.3670886075949367\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 139:  0.45595854922279794\n",
      "f1  score for fold 139:  0.3478260869565218\n",
      "recall for fold 139:  0.3218390804597701\n",
      "precision for fold 139:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 140:  0.5406698564593302\n",
      "f1  score for fold 140:  0.3924050632911393\n",
      "recall for fold 140:  0.3974358974358974\n",
      "precision for fold 140:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 141:  0.5215311004784688\n",
      "f1  score for fold 141:  0.3506493506493507\n",
      "recall for fold 141:  0.36486486486486486\n",
      "precision for fold 141:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 142:  0.5\n",
      "f1  score for fold 142:  0.3225806451612903\n",
      "recall for fold 142:  0.3333333333333333\n",
      "precision for fold 142:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 143:  0.5\n",
      "f1  score for fold 143:  0.3602484472049689\n",
      "recall for fold 143:  0.35365853658536583\n",
      "precision for fold 143:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 144:  0.5492227979274611\n",
      "f1  score for fold 144:  0.45962732919254656\n",
      "recall for fold 144:  0.42528735632183906\n",
      "precision for fold 144:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 145:  0.5215311004784688\n",
      "f1  score for fold 145:  0.36708860759493667\n",
      "recall for fold 145:  0.3717948717948718\n",
      "precision for fold 145:  0.3625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 146:  0.5119617224880383\n",
      "f1  score for fold 146:  0.33766233766233766\n",
      "recall for fold 146:  0.35135135135135137\n",
      "precision for fold 146:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 147:  0.5571428571428572\n",
      "f1  score for fold 147:  0.4000000000000001\n",
      "recall for fold 147:  0.41333333333333333\n",
      "precision for fold 147:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 148:  0.5485436893203883\n",
      "f1  score for fold 148:  0.42236024844720493\n",
      "recall for fold 148:  0.4146341463414634\n",
      "precision for fold 148:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 149:  0.5284974093264249\n",
      "f1  score for fold 149:  0.4347826086956522\n",
      "recall for fold 149:  0.40229885057471265\n",
      "precision for fold 149:  0.47297297297297297\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 150:  0.5885167464114832\n",
      "f1  score for fold 150:  0.45569620253164556\n",
      "recall for fold 150:  0.46153846153846156\n",
      "precision for fold 150:  0.45\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 151:  0.5598086124401914\n",
      "f1  score for fold 151:  0.40259740259740256\n",
      "recall for fold 151:  0.4189189189189189\n",
      "precision for fold 151:  0.3875\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 152:  0.5857142857142857\n",
      "f1  score for fold 152:  0.43870967741935485\n",
      "recall for fold 152:  0.4533333333333333\n",
      "precision for fold 152:  0.425\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 153:  0.5388349514563107\n",
      "f1  score for fold 153:  0.40993788819875776\n",
      "recall for fold 153:  0.4024390243902439\n",
      "precision for fold 153:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 154:  0.48704663212435234\n",
      "f1  score for fold 154:  0.3850931677018633\n",
      "recall for fold 154:  0.3563218390804598\n",
      "precision for fold 154:  0.4189189189189189\n",
      "    0   1\n",
      "0  39  39\n",
      "1  41  90\n",
      "Accuracy for fold 155:  0.6172248803827751\n",
      "f1  score for fold 155:  0.49367088607594933\n",
      "recall for fold 155:  0.5\n",
      "precision for fold 155:  0.4875\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 156:  0.5885167464114832\n",
      "f1  score for fold 156:  0.44155844155844154\n",
      "recall for fold 156:  0.4594594594594595\n",
      "precision for fold 156:  0.425\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 157:  0.5095238095238095\n",
      "f1  score for fold 157:  0.335483870967742\n",
      "recall for fold 157:  0.3466666666666667\n",
      "precision for fold 157:  0.325\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 158:  0.587378640776699\n",
      "f1  score for fold 158:  0.4720496894409938\n",
      "recall for fold 158:  0.4634146341463415\n",
      "precision for fold 158:  0.4810126582278481\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 159:  0.5284974093264249\n",
      "f1  score for fold 159:  0.4347826086956522\n",
      "recall for fold 159:  0.40229885057471265\n",
      "precision for fold 159:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 160:  0.5311004784688995\n",
      "f1  score for fold 160:  0.37974683544303806\n",
      "recall for fold 160:  0.38461538461538464\n",
      "precision for fold 160:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 161:  0.5406698564593302\n",
      "f1  score for fold 161:  0.37662337662337664\n",
      "recall for fold 161:  0.3918918918918919\n",
      "precision for fold 161:  0.3625\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 162:  0.5952380952380952\n",
      "f1  score for fold 162:  0.45161290322580644\n",
      "recall for fold 162:  0.4666666666666667\n",
      "precision for fold 162:  0.4375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 163:  0.5679611650485437\n",
      "f1  score for fold 163:  0.4472049689440994\n",
      "recall for fold 163:  0.43902439024390244\n",
      "precision for fold 163:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 164:  0.5284974093264249\n",
      "f1  score for fold 164:  0.4347826086956522\n",
      "recall for fold 164:  0.40229885057471265\n",
      "precision for fold 164:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 165:  0.569377990430622\n",
      "f1  score for fold 165:  0.43037974683544306\n",
      "recall for fold 165:  0.4358974358974359\n",
      "precision for fold 165:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 166:  0.5502392344497608\n",
      "f1  score for fold 166:  0.3896103896103896\n",
      "recall for fold 166:  0.40540540540540543\n",
      "precision for fold 166:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 167:  0.5476190476190477\n",
      "f1  score for fold 167:  0.38709677419354843\n",
      "recall for fold 167:  0.4\n",
      "precision for fold 167:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 168:  0.5485436893203883\n",
      "f1  score for fold 168:  0.42236024844720493\n",
      "recall for fold 168:  0.4146341463414634\n",
      "precision for fold 168:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 169:  0.5492227979274611\n",
      "f1  score for fold 169:  0.45962732919254656\n",
      "recall for fold 169:  0.42528735632183906\n",
      "precision for fold 169:  0.5\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 170:  0.5502392344497608\n",
      "f1  score for fold 170:  0.4050632911392405\n",
      "recall for fold 170:  0.41025641025641024\n",
      "precision for fold 170:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 171:  0.5502392344497608\n",
      "f1  score for fold 171:  0.3896103896103896\n",
      "recall for fold 171:  0.40540540540540543\n",
      "precision for fold 171:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 172:  0.5285714285714286\n",
      "f1  score for fold 172:  0.3612903225806451\n",
      "recall for fold 172:  0.37333333333333335\n",
      "precision for fold 172:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 173:  0.558252427184466\n",
      "f1  score for fold 173:  0.43478260869565216\n",
      "recall for fold 173:  0.4268292682926829\n",
      "precision for fold 173:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 174:  0.48704663212435234\n",
      "f1  score for fold 174:  0.3850931677018633\n",
      "recall for fold 174:  0.3563218390804598\n",
      "precision for fold 174:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 175:  0.5406698564593302\n",
      "f1  score for fold 175:  0.3924050632911393\n",
      "recall for fold 175:  0.3974358974358974\n",
      "precision for fold 175:  0.3875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 176:  0.5023923444976076\n",
      "f1  score for fold 176:  0.3246753246753247\n",
      "recall for fold 176:  0.33783783783783783\n",
      "precision for fold 176:  0.3125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 177:  0.5\n",
      "f1  score for fold 177:  0.3225806451612903\n",
      "recall for fold 177:  0.3333333333333333\n",
      "precision for fold 177:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 178:  0.5097087378640777\n",
      "f1  score for fold 178:  0.37267080745341613\n",
      "recall for fold 178:  0.36585365853658536\n",
      "precision for fold 178:  0.379746835443038\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 179:  0.5595854922279793\n",
      "f1  score for fold 179:  0.4720496894409938\n",
      "recall for fold 179:  0.4367816091954023\n",
      "precision for fold 179:  0.5135135135135135\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 180:  0.5023923444976076\n",
      "f1  score for fold 180:  0.34177215189873417\n",
      "recall for fold 180:  0.34615384615384615\n",
      "precision for fold 180:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 181:  0.5023923444976076\n",
      "f1  score for fold 181:  0.3246753246753247\n",
      "recall for fold 181:  0.33783783783783783\n",
      "precision for fold 181:  0.3125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 182:  0.5285714285714286\n",
      "f1  score for fold 182:  0.3612903225806451\n",
      "recall for fold 182:  0.37333333333333335\n",
      "precision for fold 182:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 183:  0.5\n",
      "f1  score for fold 183:  0.3602484472049689\n",
      "recall for fold 183:  0.35365853658536583\n",
      "precision for fold 183:  0.3670886075949367\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 184:  0.43523316062176165\n",
      "f1  score for fold 184:  0.3229813664596274\n",
      "recall for fold 184:  0.2988505747126437\n",
      "precision for fold 184:  0.35135135135135137\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 185:  0.5311004784688995\n",
      "f1  score for fold 185:  0.37974683544303806\n",
      "recall for fold 185:  0.38461538461538464\n",
      "precision for fold 185:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 186:  0.5119617224880383\n",
      "f1  score for fold 186:  0.33766233766233766\n",
      "recall for fold 186:  0.35135135135135137\n",
      "precision for fold 186:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 187:  0.5190476190476191\n",
      "f1  score for fold 187:  0.34838709677419355\n",
      "recall for fold 187:  0.36\n",
      "precision for fold 187:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 188:  0.5679611650485437\n",
      "f1  score for fold 188:  0.4472049689440994\n",
      "recall for fold 188:  0.43902439024390244\n",
      "precision for fold 188:  0.45569620253164556\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 189:  0.48704663212435234\n",
      "f1  score for fold 189:  0.3850931677018633\n",
      "recall for fold 189:  0.3563218390804598\n",
      "precision for fold 189:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 190:  0.5119617224880383\n",
      "f1  score for fold 190:  0.3544303797468355\n",
      "recall for fold 190:  0.358974358974359\n",
      "precision for fold 190:  0.35\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 191:  0.48325358851674644\n",
      "f1  score for fold 191:  0.29870129870129863\n",
      "recall for fold 191:  0.3108108108108108\n",
      "precision for fold 191:  0.2875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 192:  0.5095238095238095\n",
      "f1  score for fold 192:  0.335483870967742\n",
      "recall for fold 192:  0.3466666666666667\n",
      "precision for fold 192:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 193:  0.5\n",
      "f1  score for fold 193:  0.3602484472049689\n",
      "recall for fold 193:  0.35365853658536583\n",
      "precision for fold 193:  0.3670886075949367\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 194:  0.47668393782383417\n",
      "f1  score for fold 194:  0.3726708074534162\n",
      "recall for fold 194:  0.3448275862068966\n",
      "precision for fold 194:  0.40540540540540543\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 195:  0.47368421052631576\n",
      "f1  score for fold 195:  0.3037974683544304\n",
      "recall for fold 195:  0.3076923076923077\n",
      "precision for fold 195:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 196:  0.5502392344497608\n",
      "f1  score for fold 196:  0.3896103896103896\n",
      "recall for fold 196:  0.40540540540540543\n",
      "precision for fold 196:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 197:  0.5095238095238095\n",
      "f1  score for fold 197:  0.335483870967742\n",
      "recall for fold 197:  0.3466666666666667\n",
      "precision for fold 197:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 198:  0.5\n",
      "f1  score for fold 198:  0.3602484472049689\n",
      "recall for fold 198:  0.35365853658536583\n",
      "precision for fold 198:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 199:  0.5284974093264249\n",
      "f1  score for fold 199:  0.4347826086956522\n",
      "recall for fold 199:  0.40229885057471265\n",
      "precision for fold 199:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 200:  0.5311004784688995\n",
      "f1  score for fold 200:  0.37974683544303806\n",
      "recall for fold 200:  0.38461538461538464\n",
      "precision for fold 200:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 201:  0.5311004784688995\n",
      "f1  score for fold 201:  0.36363636363636365\n",
      "recall for fold 201:  0.3783783783783784\n",
      "precision for fold 201:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 202:  0.5857142857142857\n",
      "f1  score for fold 202:  0.43870967741935485\n",
      "recall for fold 202:  0.4533333333333333\n",
      "precision for fold 202:  0.425\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 203:  0.5194174757281553\n",
      "f1  score for fold 203:  0.38509316770186336\n",
      "recall for fold 203:  0.3780487804878049\n",
      "precision for fold 203:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 204:  0.5492227979274611\n",
      "f1  score for fold 204:  0.45962732919254656\n",
      "recall for fold 204:  0.42528735632183906\n",
      "precision for fold 204:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 205:  0.49282296650717705\n",
      "f1  score for fold 205:  0.32911392405063294\n",
      "recall for fold 205:  0.3333333333333333\n",
      "precision for fold 205:  0.325\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 206:  0.5311004784688995\n",
      "f1  score for fold 206:  0.36363636363636365\n",
      "recall for fold 206:  0.3783783783783784\n",
      "precision for fold 206:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 207:  0.5095238095238095\n",
      "f1  score for fold 207:  0.335483870967742\n",
      "recall for fold 207:  0.3466666666666667\n",
      "precision for fold 207:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 208:  0.529126213592233\n",
      "f1  score for fold 208:  0.39751552795031053\n",
      "recall for fold 208:  0.3902439024390244\n",
      "precision for fold 208:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 209:  0.5181347150259067\n",
      "f1  score for fold 209:  0.422360248447205\n",
      "recall for fold 209:  0.39080459770114945\n",
      "precision for fold 209:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 210:  0.48325358851674644\n",
      "f1  score for fold 210:  0.31645569620253167\n",
      "recall for fold 210:  0.32051282051282054\n",
      "precision for fold 210:  0.3125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 211:  0.5406698564593302\n",
      "f1  score for fold 211:  0.37662337662337664\n",
      "recall for fold 211:  0.3918918918918919\n",
      "precision for fold 211:  0.3625\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 212:  0.6142857142857143\n",
      "f1  score for fold 212:  0.47741935483870973\n",
      "recall for fold 212:  0.49333333333333335\n",
      "precision for fold 212:  0.4625\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 213:  0.5776699029126213\n",
      "f1  score for fold 213:  0.4596273291925466\n",
      "recall for fold 213:  0.45121951219512196\n",
      "precision for fold 213:  0.46835443037974683\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 214:  0.44559585492227977\n",
      "f1  score for fold 214:  0.33540372670807456\n",
      "recall for fold 214:  0.3103448275862069\n",
      "precision for fold 214:  0.36486486486486486\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 215:  0.5406698564593302\n",
      "f1  score for fold 215:  0.3924050632911393\n",
      "recall for fold 215:  0.3974358974358974\n",
      "precision for fold 215:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 216:  0.5598086124401914\n",
      "f1  score for fold 216:  0.40259740259740256\n",
      "recall for fold 216:  0.4189189189189189\n",
      "precision for fold 216:  0.3875\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 217:  0.48095238095238096\n",
      "f1  score for fold 217:  0.2967741935483871\n",
      "recall for fold 217:  0.30666666666666664\n",
      "precision for fold 217:  0.2875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 218:  0.5194174757281553\n",
      "f1  score for fold 218:  0.38509316770186336\n",
      "recall for fold 218:  0.3780487804878049\n",
      "precision for fold 218:  0.3924050632911392\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 219:  0.45595854922279794\n",
      "f1  score for fold 219:  0.3478260869565218\n",
      "recall for fold 219:  0.3218390804597701\n",
      "precision for fold 219:  0.3783783783783784\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 220:  0.5789473684210527\n",
      "f1  score for fold 220:  0.44303797468354433\n",
      "recall for fold 220:  0.44871794871794873\n",
      "precision for fold 220:  0.4375\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 221:  0.6172248803827751\n",
      "f1  score for fold 221:  0.4805194805194805\n",
      "recall for fold 221:  0.5\n",
      "precision for fold 221:  0.4625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 222:  0.5285714285714286\n",
      "f1  score for fold 222:  0.3612903225806451\n",
      "recall for fold 222:  0.37333333333333335\n",
      "precision for fold 222:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 223:  0.5679611650485437\n",
      "f1  score for fold 223:  0.4472049689440994\n",
      "recall for fold 223:  0.43902439024390244\n",
      "precision for fold 223:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 224:  0.5284974093264249\n",
      "f1  score for fold 224:  0.4347826086956522\n",
      "recall for fold 224:  0.40229885057471265\n",
      "precision for fold 224:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 225:  0.49282296650717705\n",
      "f1  score for fold 225:  0.32911392405063294\n",
      "recall for fold 225:  0.3333333333333333\n",
      "precision for fold 225:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 226:  0.5502392344497608\n",
      "f1  score for fold 226:  0.3896103896103896\n",
      "recall for fold 226:  0.40540540540540543\n",
      "precision for fold 226:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 227:  0.5571428571428572\n",
      "f1  score for fold 227:  0.4000000000000001\n",
      "recall for fold 227:  0.41333333333333333\n",
      "precision for fold 227:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 228:  0.5097087378640777\n",
      "f1  score for fold 228:  0.37267080745341613\n",
      "recall for fold 228:  0.36585365853658536\n",
      "precision for fold 228:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 229:  0.48704663212435234\n",
      "f1  score for fold 229:  0.3850931677018633\n",
      "recall for fold 229:  0.3563218390804598\n",
      "precision for fold 229:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 230:  0.5598086124401914\n",
      "f1  score for fold 230:  0.4177215189873418\n",
      "recall for fold 230:  0.4230769230769231\n",
      "precision for fold 230:  0.4125\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 231:  0.569377990430622\n",
      "f1  score for fold 231:  0.4155844155844156\n",
      "recall for fold 231:  0.43243243243243246\n",
      "precision for fold 231:  0.4\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 232:  0.5571428571428572\n",
      "f1  score for fold 232:  0.4000000000000001\n",
      "recall for fold 232:  0.41333333333333333\n",
      "precision for fold 232:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 233:  0.5194174757281553\n",
      "f1  score for fold 233:  0.38509316770186336\n",
      "recall for fold 233:  0.3780487804878049\n",
      "precision for fold 233:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 234:  0.5492227979274611\n",
      "f1  score for fold 234:  0.45962732919254656\n",
      "recall for fold 234:  0.42528735632183906\n",
      "precision for fold 234:  0.5\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 235:  0.5598086124401914\n",
      "f1  score for fold 235:  0.4177215189873418\n",
      "recall for fold 235:  0.4230769230769231\n",
      "precision for fold 235:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 236:  0.5502392344497608\n",
      "f1  score for fold 236:  0.3896103896103896\n",
      "recall for fold 236:  0.40540540540540543\n",
      "precision for fold 236:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 237:  0.5285714285714286\n",
      "f1  score for fold 237:  0.3612903225806451\n",
      "recall for fold 237:  0.37333333333333335\n",
      "precision for fold 237:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 238:  0.5485436893203883\n",
      "f1  score for fold 238:  0.42236024844720493\n",
      "recall for fold 238:  0.4146341463414634\n",
      "precision for fold 238:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 239:  0.5077720207253886\n",
      "f1  score for fold 239:  0.40993788819875776\n",
      "recall for fold 239:  0.3793103448275862\n",
      "precision for fold 239:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 240:  0.5502392344497608\n",
      "f1  score for fold 240:  0.4050632911392405\n",
      "recall for fold 240:  0.41025641025641024\n",
      "precision for fold 240:  0.4\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 241:  0.5215311004784688\n",
      "f1  score for fold 241:  0.3506493506493507\n",
      "recall for fold 241:  0.36486486486486486\n",
      "precision for fold 241:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 242:  0.5190476190476191\n",
      "f1  score for fold 242:  0.34838709677419355\n",
      "recall for fold 242:  0.36\n",
      "precision for fold 242:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 243:  0.529126213592233\n",
      "f1  score for fold 243:  0.39751552795031053\n",
      "recall for fold 243:  0.3902439024390244\n",
      "precision for fold 243:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 244:  0.49740932642487046\n",
      "f1  score for fold 244:  0.39751552795031053\n",
      "recall for fold 244:  0.367816091954023\n",
      "precision for fold 244:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 245:  0.5406698564593302\n",
      "f1  score for fold 245:  0.3924050632911393\n",
      "recall for fold 245:  0.3974358974358974\n",
      "precision for fold 245:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 246:  0.5311004784688995\n",
      "f1  score for fold 246:  0.36363636363636365\n",
      "recall for fold 246:  0.3783783783783784\n",
      "precision for fold 246:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 247:  0.5095238095238095\n",
      "f1  score for fold 247:  0.335483870967742\n",
      "recall for fold 247:  0.3466666666666667\n",
      "precision for fold 247:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 248:  0.5\n",
      "f1  score for fold 248:  0.3602484472049689\n",
      "recall for fold 248:  0.35365853658536583\n",
      "precision for fold 248:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 249:  0.5181347150259067\n",
      "f1  score for fold 249:  0.422360248447205\n",
      "recall for fold 249:  0.39080459770114945\n",
      "precision for fold 249:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 250:  0.49282296650717705\n",
      "f1  score for fold 250:  0.32911392405063294\n",
      "recall for fold 250:  0.3333333333333333\n",
      "precision for fold 250:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 251:  0.5502392344497608\n",
      "f1  score for fold 251:  0.3896103896103896\n",
      "recall for fold 251:  0.40540540540540543\n",
      "precision for fold 251:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 252:  0.5571428571428572\n",
      "f1  score for fold 252:  0.4000000000000001\n",
      "recall for fold 252:  0.41333333333333333\n",
      "precision for fold 252:  0.3875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 253:  0.558252427184466\n",
      "f1  score for fold 253:  0.43478260869565216\n",
      "recall for fold 253:  0.4268292682926829\n",
      "precision for fold 253:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 254:  0.5284974093264249\n",
      "f1  score for fold 254:  0.4347826086956522\n",
      "recall for fold 254:  0.40229885057471265\n",
      "precision for fold 254:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 255:  0.5598086124401914\n",
      "f1  score for fold 255:  0.4177215189873418\n",
      "recall for fold 255:  0.4230769230769231\n",
      "precision for fold 255:  0.4125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 256:  0.5119617224880383\n",
      "f1  score for fold 256:  0.33766233766233766\n",
      "recall for fold 256:  0.35135135135135137\n",
      "precision for fold 256:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 257:  0.5285714285714286\n",
      "f1  score for fold 257:  0.3612903225806451\n",
      "recall for fold 257:  0.37333333333333335\n",
      "precision for fold 257:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 258:  0.558252427184466\n",
      "f1  score for fold 258:  0.43478260869565216\n",
      "recall for fold 258:  0.4268292682926829\n",
      "precision for fold 258:  0.4430379746835443\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 259:  0.5492227979274611\n",
      "f1  score for fold 259:  0.45962732919254656\n",
      "recall for fold 259:  0.42528735632183906\n",
      "precision for fold 259:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 260:  0.49282296650717705\n",
      "f1  score for fold 260:  0.32911392405063294\n",
      "recall for fold 260:  0.3333333333333333\n",
      "precision for fold 260:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 261:  0.5406698564593302\n",
      "f1  score for fold 261:  0.37662337662337664\n",
      "recall for fold 261:  0.3918918918918919\n",
      "precision for fold 261:  0.3625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 262:  0.5571428571428572\n",
      "f1  score for fold 262:  0.4000000000000001\n",
      "recall for fold 262:  0.41333333333333333\n",
      "precision for fold 262:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 263:  0.5388349514563107\n",
      "f1  score for fold 263:  0.40993788819875776\n",
      "recall for fold 263:  0.4024390243902439\n",
      "precision for fold 263:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 264:  0.5077720207253886\n",
      "f1  score for fold 264:  0.40993788819875776\n",
      "recall for fold 264:  0.3793103448275862\n",
      "precision for fold 264:  0.44594594594594594\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 265:  0.48325358851674644\n",
      "f1  score for fold 265:  0.31645569620253167\n",
      "recall for fold 265:  0.32051282051282054\n",
      "precision for fold 265:  0.3125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 266:  0.5311004784688995\n",
      "f1  score for fold 266:  0.36363636363636365\n",
      "recall for fold 266:  0.3783783783783784\n",
      "precision for fold 266:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 267:  0.5571428571428572\n",
      "f1  score for fold 267:  0.4000000000000001\n",
      "recall for fold 267:  0.41333333333333333\n",
      "precision for fold 267:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 268:  0.5097087378640777\n",
      "f1  score for fold 268:  0.37267080745341613\n",
      "recall for fold 268:  0.36585365853658536\n",
      "precision for fold 268:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 269:  0.44559585492227977\n",
      "f1  score for fold 269:  0.33540372670807456\n",
      "recall for fold 269:  0.3103448275862069\n",
      "precision for fold 269:  0.36486486486486486\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 270:  0.5215311004784688\n",
      "f1  score for fold 270:  0.36708860759493667\n",
      "recall for fold 270:  0.3717948717948718\n",
      "precision for fold 270:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 271:  0.49282296650717705\n",
      "f1  score for fold 271:  0.3116883116883117\n",
      "recall for fold 271:  0.32432432432432434\n",
      "precision for fold 271:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 272:  0.5476190476190477\n",
      "f1  score for fold 272:  0.38709677419354843\n",
      "recall for fold 272:  0.4\n",
      "precision for fold 272:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 273:  0.529126213592233\n",
      "f1  score for fold 273:  0.39751552795031053\n",
      "recall for fold 273:  0.3902439024390244\n",
      "precision for fold 273:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 274:  0.538860103626943\n",
      "f1  score for fold 274:  0.4472049689440994\n",
      "recall for fold 274:  0.41379310344827586\n",
      "precision for fold 274:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 275:  0.569377990430622\n",
      "f1  score for fold 275:  0.43037974683544306\n",
      "recall for fold 275:  0.4358974358974359\n",
      "precision for fold 275:  0.425\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 276:  0.5598086124401914\n",
      "f1  score for fold 276:  0.40259740259740256\n",
      "recall for fold 276:  0.4189189189189189\n",
      "precision for fold 276:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 277:  0.5380952380952381\n",
      "f1  score for fold 277:  0.3741935483870968\n",
      "recall for fold 277:  0.38666666666666666\n",
      "precision for fold 277:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 278:  0.49029126213592233\n",
      "f1  score for fold 278:  0.3478260869565218\n",
      "recall for fold 278:  0.34146341463414637\n",
      "precision for fold 278:  0.35443037974683544\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 279:  0.47668393782383417\n",
      "f1  score for fold 279:  0.3726708074534162\n",
      "recall for fold 279:  0.3448275862068966\n",
      "precision for fold 279:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 280:  0.5598086124401914\n",
      "f1  score for fold 280:  0.4177215189873418\n",
      "recall for fold 280:  0.4230769230769231\n",
      "precision for fold 280:  0.4125\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 281:  0.46411483253588515\n",
      "f1  score for fold 281:  0.27272727272727276\n",
      "recall for fold 281:  0.28378378378378377\n",
      "precision for fold 281:  0.2625\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 282:  0.6047619047619047\n",
      "f1  score for fold 282:  0.4645161290322581\n",
      "recall for fold 282:  0.48\n",
      "precision for fold 282:  0.45\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 283:  0.5097087378640777\n",
      "f1  score for fold 283:  0.37267080745341613\n",
      "recall for fold 283:  0.36585365853658536\n",
      "precision for fold 283:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 284:  0.5077720207253886\n",
      "f1  score for fold 284:  0.40993788819875776\n",
      "recall for fold 284:  0.3793103448275862\n",
      "precision for fold 284:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 285:  0.5789473684210527\n",
      "f1  score for fold 285:  0.44303797468354433\n",
      "recall for fold 285:  0.44871794871794873\n",
      "precision for fold 285:  0.4375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 286:  0.49282296650717705\n",
      "f1  score for fold 286:  0.3116883116883117\n",
      "recall for fold 286:  0.32432432432432434\n",
      "precision for fold 286:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 287:  0.5476190476190477\n",
      "f1  score for fold 287:  0.38709677419354843\n",
      "recall for fold 287:  0.4\n",
      "precision for fold 287:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 288:  0.5485436893203883\n",
      "f1  score for fold 288:  0.42236024844720493\n",
      "recall for fold 288:  0.4146341463414634\n",
      "precision for fold 288:  0.43037974683544306\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 289:  0.5595854922279793\n",
      "f1  score for fold 289:  0.4720496894409938\n",
      "recall for fold 289:  0.4367816091954023\n",
      "precision for fold 289:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 290:  0.5598086124401914\n",
      "f1  score for fold 290:  0.4177215189873418\n",
      "recall for fold 290:  0.4230769230769231\n",
      "precision for fold 290:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 291:  0.5502392344497608\n",
      "f1  score for fold 291:  0.3896103896103896\n",
      "recall for fold 291:  0.40540540540540543\n",
      "precision for fold 291:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 292:  0.5\n",
      "f1  score for fold 292:  0.3225806451612903\n",
      "recall for fold 292:  0.3333333333333333\n",
      "precision for fold 292:  0.3125\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 293:  0.5970873786407767\n",
      "f1  score for fold 293:  0.484472049689441\n",
      "recall for fold 293:  0.47560975609756095\n",
      "precision for fold 293:  0.4936708860759494\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 294:  0.538860103626943\n",
      "f1  score for fold 294:  0.4472049689440994\n",
      "recall for fold 294:  0.41379310344827586\n",
      "precision for fold 294:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 295:  0.5215311004784688\n",
      "f1  score for fold 295:  0.36708860759493667\n",
      "recall for fold 295:  0.3717948717948718\n",
      "precision for fold 295:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 296:  0.5311004784688995\n",
      "f1  score for fold 296:  0.36363636363636365\n",
      "recall for fold 296:  0.3783783783783784\n",
      "precision for fold 296:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 297:  0.5380952380952381\n",
      "f1  score for fold 297:  0.3741935483870968\n",
      "recall for fold 297:  0.38666666666666666\n",
      "precision for fold 297:  0.3625\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 298:  0.5776699029126213\n",
      "f1  score for fold 298:  0.4596273291925466\n",
      "recall for fold 298:  0.45121951219512196\n",
      "precision for fold 298:  0.46835443037974683\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 299:  0.49740932642487046\n",
      "f1  score for fold 299:  0.39751552795031053\n",
      "recall for fold 299:  0.367816091954023\n",
      "precision for fold 299:  0.43243243243243246\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 300:  0.5980861244019139\n",
      "f1  score for fold 300:  0.46835443037974683\n",
      "recall for fold 300:  0.47435897435897434\n",
      "precision for fold 300:  0.4625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 301:  0.5119617224880383\n",
      "f1  score for fold 301:  0.33766233766233766\n",
      "recall for fold 301:  0.35135135135135137\n",
      "precision for fold 301:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 302:  0.5190476190476191\n",
      "f1  score for fold 302:  0.34838709677419355\n",
      "recall for fold 302:  0.36\n",
      "precision for fold 302:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 303:  0.5485436893203883\n",
      "f1  score for fold 303:  0.42236024844720493\n",
      "recall for fold 303:  0.4146341463414634\n",
      "precision for fold 303:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 304:  0.538860103626943\n",
      "f1  score for fold 304:  0.4472049689440994\n",
      "recall for fold 304:  0.41379310344827586\n",
      "precision for fold 304:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 305:  0.5502392344497608\n",
      "f1  score for fold 305:  0.4050632911392405\n",
      "recall for fold 305:  0.41025641025641024\n",
      "precision for fold 305:  0.4\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 306:  0.49282296650717705\n",
      "f1  score for fold 306:  0.3116883116883117\n",
      "recall for fold 306:  0.32432432432432434\n",
      "precision for fold 306:  0.3\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 307:  0.48095238095238096\n",
      "f1  score for fold 307:  0.2967741935483871\n",
      "recall for fold 307:  0.30666666666666664\n",
      "precision for fold 307:  0.2875\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 308:  0.48058252427184467\n",
      "f1  score for fold 308:  0.33540372670807456\n",
      "recall for fold 308:  0.32926829268292684\n",
      "precision for fold 308:  0.34177215189873417\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 309:  0.45595854922279794\n",
      "f1  score for fold 309:  0.3478260869565218\n",
      "recall for fold 309:  0.3218390804597701\n",
      "precision for fold 309:  0.3783783783783784\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 310:  0.5023923444976076\n",
      "f1  score for fold 310:  0.34177215189873417\n",
      "recall for fold 310:  0.34615384615384615\n",
      "precision for fold 310:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 311:  0.5406698564593302\n",
      "f1  score for fold 311:  0.37662337662337664\n",
      "recall for fold 311:  0.3918918918918919\n",
      "precision for fold 311:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 312:  0.5095238095238095\n",
      "f1  score for fold 312:  0.335483870967742\n",
      "recall for fold 312:  0.3466666666666667\n",
      "precision for fold 312:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 313:  0.558252427184466\n",
      "f1  score for fold 313:  0.43478260869565216\n",
      "recall for fold 313:  0.4268292682926829\n",
      "precision for fold 313:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 314:  0.5077720207253886\n",
      "f1  score for fold 314:  0.40993788819875776\n",
      "recall for fold 314:  0.3793103448275862\n",
      "precision for fold 314:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 315:  0.5023923444976076\n",
      "f1  score for fold 315:  0.34177215189873417\n",
      "recall for fold 315:  0.34615384615384615\n",
      "precision for fold 315:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 316:  0.5023923444976076\n",
      "f1  score for fold 316:  0.3246753246753247\n",
      "recall for fold 316:  0.33783783783783783\n",
      "precision for fold 316:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 317:  0.5190476190476191\n",
      "f1  score for fold 317:  0.34838709677419355\n",
      "recall for fold 317:  0.36\n",
      "precision for fold 317:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 318:  0.49029126213592233\n",
      "f1  score for fold 318:  0.3478260869565218\n",
      "recall for fold 318:  0.34146341463414637\n",
      "precision for fold 318:  0.35443037974683544\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 319:  0.47668393782383417\n",
      "f1  score for fold 319:  0.3726708074534162\n",
      "recall for fold 319:  0.3448275862068966\n",
      "precision for fold 319:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 320:  0.5598086124401914\n",
      "f1  score for fold 320:  0.4177215189873418\n",
      "recall for fold 320:  0.4230769230769231\n",
      "precision for fold 320:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 321:  0.5502392344497608\n",
      "f1  score for fold 321:  0.3896103896103896\n",
      "recall for fold 321:  0.40540540540540543\n",
      "precision for fold 321:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 322:  0.5095238095238095\n",
      "f1  score for fold 322:  0.335483870967742\n",
      "recall for fold 322:  0.3466666666666667\n",
      "precision for fold 322:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 323:  0.5\n",
      "f1  score for fold 323:  0.3602484472049689\n",
      "recall for fold 323:  0.35365853658536583\n",
      "precision for fold 323:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 324:  0.49740932642487046\n",
      "f1  score for fold 324:  0.39751552795031053\n",
      "recall for fold 324:  0.367816091954023\n",
      "precision for fold 324:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 325:  0.569377990430622\n",
      "f1  score for fold 325:  0.43037974683544306\n",
      "recall for fold 325:  0.4358974358974359\n",
      "precision for fold 325:  0.425\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 326:  0.5789473684210527\n",
      "f1  score for fold 326:  0.42857142857142855\n",
      "recall for fold 326:  0.44594594594594594\n",
      "precision for fold 326:  0.4125\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 327:  0.4714285714285714\n",
      "f1  score for fold 327:  0.2838709677419355\n",
      "recall for fold 327:  0.29333333333333333\n",
      "precision for fold 327:  0.275\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 328:  0.529126213592233\n",
      "f1  score for fold 328:  0.39751552795031053\n",
      "recall for fold 328:  0.3902439024390244\n",
      "precision for fold 328:  0.4050632911392405\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 329:  0.5595854922279793\n",
      "f1  score for fold 329:  0.4720496894409938\n",
      "recall for fold 329:  0.4367816091954023\n",
      "precision for fold 329:  0.5135135135135135\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 330:  0.5406698564593302\n",
      "f1  score for fold 330:  0.3924050632911393\n",
      "recall for fold 330:  0.3974358974358974\n",
      "precision for fold 330:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 331:  0.5119617224880383\n",
      "f1  score for fold 331:  0.33766233766233766\n",
      "recall for fold 331:  0.35135135135135137\n",
      "precision for fold 331:  0.325\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 332:  0.5095238095238095\n",
      "f1  score for fold 332:  0.335483870967742\n",
      "recall for fold 332:  0.3466666666666667\n",
      "precision for fold 332:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 333:  0.529126213592233\n",
      "f1  score for fold 333:  0.39751552795031053\n",
      "recall for fold 333:  0.3902439024390244\n",
      "precision for fold 333:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 334:  0.5181347150259067\n",
      "f1  score for fold 334:  0.422360248447205\n",
      "recall for fold 334:  0.39080459770114945\n",
      "precision for fold 334:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 335:  0.5023923444976076\n",
      "f1  score for fold 335:  0.34177215189873417\n",
      "recall for fold 335:  0.34615384615384615\n",
      "precision for fold 335:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 336:  0.5311004784688995\n",
      "f1  score for fold 336:  0.36363636363636365\n",
      "recall for fold 336:  0.3783783783783784\n",
      "precision for fold 336:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 337:  0.5285714285714286\n",
      "f1  score for fold 337:  0.3612903225806451\n",
      "recall for fold 337:  0.37333333333333335\n",
      "precision for fold 337:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 338:  0.49029126213592233\n",
      "f1  score for fold 338:  0.3478260869565218\n",
      "recall for fold 338:  0.34146341463414637\n",
      "precision for fold 338:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 339:  0.49740932642487046\n",
      "f1  score for fold 339:  0.39751552795031053\n",
      "recall for fold 339:  0.367816091954023\n",
      "precision for fold 339:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 340:  0.5311004784688995\n",
      "f1  score for fold 340:  0.37974683544303806\n",
      "recall for fold 340:  0.38461538461538464\n",
      "precision for fold 340:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 341:  0.569377990430622\n",
      "f1  score for fold 341:  0.4155844155844156\n",
      "recall for fold 341:  0.43243243243243246\n",
      "precision for fold 341:  0.4\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 342:  0.5\n",
      "f1  score for fold 342:  0.3225806451612903\n",
      "recall for fold 342:  0.3333333333333333\n",
      "precision for fold 342:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 343:  0.529126213592233\n",
      "f1  score for fold 343:  0.39751552795031053\n",
      "recall for fold 343:  0.3902439024390244\n",
      "precision for fold 343:  0.4050632911392405\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 344:  0.5803108808290155\n",
      "f1  score for fold 344:  0.49689440993788814\n",
      "recall for fold 344:  0.45977011494252873\n",
      "precision for fold 344:  0.5405405405405406\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 345:  0.5598086124401914\n",
      "f1  score for fold 345:  0.4177215189873418\n",
      "recall for fold 345:  0.4230769230769231\n",
      "precision for fold 345:  0.4125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 346:  0.5789473684210527\n",
      "f1  score for fold 346:  0.42857142857142855\n",
      "recall for fold 346:  0.44594594594594594\n",
      "precision for fold 346:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 347:  0.5285714285714286\n",
      "f1  score for fold 347:  0.3612903225806451\n",
      "recall for fold 347:  0.37333333333333335\n",
      "precision for fold 347:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 348:  0.529126213592233\n",
      "f1  score for fold 348:  0.39751552795031053\n",
      "recall for fold 348:  0.3902439024390244\n",
      "precision for fold 348:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 349:  0.5077720207253886\n",
      "f1  score for fold 349:  0.40993788819875776\n",
      "recall for fold 349:  0.3793103448275862\n",
      "precision for fold 349:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 350:  0.5215311004784688\n",
      "f1  score for fold 350:  0.36708860759493667\n",
      "recall for fold 350:  0.3717948717948718\n",
      "precision for fold 350:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 351:  0.5502392344497608\n",
      "f1  score for fold 351:  0.3896103896103896\n",
      "recall for fold 351:  0.40540540540540543\n",
      "precision for fold 351:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 352:  0.5095238095238095\n",
      "f1  score for fold 352:  0.335483870967742\n",
      "recall for fold 352:  0.3466666666666667\n",
      "precision for fold 352:  0.325\n",
      "    0   1\n",
      "0  41  41\n",
      "1  38  86\n",
      "Accuracy for fold 353:  0.616504854368932\n",
      "f1  score for fold 353:  0.5093167701863354\n",
      "recall for fold 353:  0.5\n",
      "precision for fold 353:  0.5189873417721519\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 354:  0.49740932642487046\n",
      "f1  score for fold 354:  0.39751552795031053\n",
      "recall for fold 354:  0.367816091954023\n",
      "precision for fold 354:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 355:  0.5406698564593302\n",
      "f1  score for fold 355:  0.3924050632911393\n",
      "recall for fold 355:  0.3974358974358974\n",
      "precision for fold 355:  0.3875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 356:  0.5023923444976076\n",
      "f1  score for fold 356:  0.3246753246753247\n",
      "recall for fold 356:  0.33783783783783783\n",
      "precision for fold 356:  0.3125\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 357:  0.5857142857142857\n",
      "f1  score for fold 357:  0.43870967741935485\n",
      "recall for fold 357:  0.4533333333333333\n",
      "precision for fold 357:  0.425\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 358:  0.5388349514563107\n",
      "f1  score for fold 358:  0.40993788819875776\n",
      "recall for fold 358:  0.4024390243902439\n",
      "precision for fold 358:  0.4177215189873418\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 359:  0.45595854922279794\n",
      "f1  score for fold 359:  0.3478260869565218\n",
      "recall for fold 359:  0.3218390804597701\n",
      "precision for fold 359:  0.3783783783783784\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 360:  0.5502392344497608\n",
      "f1  score for fold 360:  0.4050632911392405\n",
      "recall for fold 360:  0.41025641025641024\n",
      "precision for fold 360:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 361:  0.569377990430622\n",
      "f1  score for fold 361:  0.4155844155844156\n",
      "recall for fold 361:  0.43243243243243246\n",
      "precision for fold 361:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 362:  0.5190476190476191\n",
      "f1  score for fold 362:  0.34838709677419355\n",
      "recall for fold 362:  0.36\n",
      "precision for fold 362:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 363:  0.5\n",
      "f1  score for fold 363:  0.3602484472049689\n",
      "recall for fold 363:  0.35365853658536583\n",
      "precision for fold 363:  0.3670886075949367\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 364:  0.45595854922279794\n",
      "f1  score for fold 364:  0.3478260869565218\n",
      "recall for fold 364:  0.3218390804597701\n",
      "precision for fold 364:  0.3783783783783784\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 365:  0.5311004784688995\n",
      "f1  score for fold 365:  0.37974683544303806\n",
      "recall for fold 365:  0.38461538461538464\n",
      "precision for fold 365:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 366:  0.5119617224880383\n",
      "f1  score for fold 366:  0.33766233766233766\n",
      "recall for fold 366:  0.35135135135135137\n",
      "precision for fold 366:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 367:  0.5380952380952381\n",
      "f1  score for fold 367:  0.3741935483870968\n",
      "recall for fold 367:  0.38666666666666666\n",
      "precision for fold 367:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 368:  0.5\n",
      "f1  score for fold 368:  0.3602484472049689\n",
      "recall for fold 368:  0.35365853658536583\n",
      "precision for fold 368:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 369:  0.5077720207253886\n",
      "f1  score for fold 369:  0.40993788819875776\n",
      "recall for fold 369:  0.3793103448275862\n",
      "precision for fold 369:  0.44594594594594594\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 370:  0.6076555023923444\n",
      "f1  score for fold 370:  0.4810126582278481\n",
      "recall for fold 370:  0.48717948717948717\n",
      "precision for fold 370:  0.475\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 371:  0.5598086124401914\n",
      "f1  score for fold 371:  0.40259740259740256\n",
      "recall for fold 371:  0.4189189189189189\n",
      "precision for fold 371:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 372:  0.5380952380952381\n",
      "f1  score for fold 372:  0.3741935483870968\n",
      "recall for fold 372:  0.38666666666666666\n",
      "precision for fold 372:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 373:  0.5485436893203883\n",
      "f1  score for fold 373:  0.42236024844720493\n",
      "recall for fold 373:  0.4146341463414634\n",
      "precision for fold 373:  0.43037974683544306\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 374:  0.6010362694300518\n",
      "f1  score for fold 374:  0.5217391304347826\n",
      "recall for fold 374:  0.4827586206896552\n",
      "precision for fold 374:  0.5675675675675675\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 375:  0.5502392344497608\n",
      "f1  score for fold 375:  0.4050632911392405\n",
      "recall for fold 375:  0.41025641025641024\n",
      "precision for fold 375:  0.4\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 376:  0.5789473684210527\n",
      "f1  score for fold 376:  0.42857142857142855\n",
      "recall for fold 376:  0.44594594594594594\n",
      "precision for fold 376:  0.4125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 377:  0.5571428571428572\n",
      "f1  score for fold 377:  0.4000000000000001\n",
      "recall for fold 377:  0.41333333333333333\n",
      "precision for fold 377:  0.3875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 378:  0.558252427184466\n",
      "f1  score for fold 378:  0.43478260869565216\n",
      "recall for fold 378:  0.4268292682926829\n",
      "precision for fold 378:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 379:  0.5284974093264249\n",
      "f1  score for fold 379:  0.4347826086956522\n",
      "recall for fold 379:  0.40229885057471265\n",
      "precision for fold 379:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 380:  0.5023923444976076\n",
      "f1  score for fold 380:  0.34177215189873417\n",
      "recall for fold 380:  0.34615384615384615\n",
      "precision for fold 380:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 381:  0.5311004784688995\n",
      "f1  score for fold 381:  0.36363636363636365\n",
      "recall for fold 381:  0.3783783783783784\n",
      "precision for fold 381:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 382:  0.5476190476190477\n",
      "f1  score for fold 382:  0.38709677419354843\n",
      "recall for fold 382:  0.4\n",
      "precision for fold 382:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 383:  0.5097087378640777\n",
      "f1  score for fold 383:  0.37267080745341613\n",
      "recall for fold 383:  0.36585365853658536\n",
      "precision for fold 383:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 384:  0.5077720207253886\n",
      "f1  score for fold 384:  0.40993788819875776\n",
      "recall for fold 384:  0.3793103448275862\n",
      "precision for fold 384:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 385:  0.5311004784688995\n",
      "f1  score for fold 385:  0.37974683544303806\n",
      "recall for fold 385:  0.38461538461538464\n",
      "precision for fold 385:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 386:  0.5502392344497608\n",
      "f1  score for fold 386:  0.3896103896103896\n",
      "recall for fold 386:  0.40540540540540543\n",
      "precision for fold 386:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 387:  0.5190476190476191\n",
      "f1  score for fold 387:  0.34838709677419355\n",
      "recall for fold 387:  0.36\n",
      "precision for fold 387:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 388:  0.5679611650485437\n",
      "f1  score for fold 388:  0.4472049689440994\n",
      "recall for fold 388:  0.43902439024390244\n",
      "precision for fold 388:  0.45569620253164556\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 389:  0.46632124352331605\n",
      "f1  score for fold 389:  0.36024844720496896\n",
      "recall for fold 389:  0.3333333333333333\n",
      "precision for fold 389:  0.3918918918918919\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 390:  0.5502392344497608\n",
      "f1  score for fold 390:  0.4050632911392405\n",
      "recall for fold 390:  0.41025641025641024\n",
      "precision for fold 390:  0.4\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 391:  0.5789473684210527\n",
      "f1  score for fold 391:  0.42857142857142855\n",
      "recall for fold 391:  0.44594594594594594\n",
      "precision for fold 391:  0.4125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 392:  0.5095238095238095\n",
      "f1  score for fold 392:  0.335483870967742\n",
      "recall for fold 392:  0.3466666666666667\n",
      "precision for fold 392:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 393:  0.558252427184466\n",
      "f1  score for fold 393:  0.43478260869565216\n",
      "recall for fold 393:  0.4268292682926829\n",
      "precision for fold 393:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 394:  0.5181347150259067\n",
      "f1  score for fold 394:  0.422360248447205\n",
      "recall for fold 394:  0.39080459770114945\n",
      "precision for fold 394:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 395:  0.5502392344497608\n",
      "f1  score for fold 395:  0.4050632911392405\n",
      "recall for fold 395:  0.41025641025641024\n",
      "precision for fold 395:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 396:  0.5406698564593302\n",
      "f1  score for fold 396:  0.37662337662337664\n",
      "recall for fold 396:  0.3918918918918919\n",
      "precision for fold 396:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 397:  0.5285714285714286\n",
      "f1  score for fold 397:  0.3612903225806451\n",
      "recall for fold 397:  0.37333333333333335\n",
      "precision for fold 397:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 398:  0.558252427184466\n",
      "f1  score for fold 398:  0.43478260869565216\n",
      "recall for fold 398:  0.4268292682926829\n",
      "precision for fold 398:  0.4430379746835443\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 399:  0.47668393782383417\n",
      "f1  score for fold 399:  0.3726708074534162\n",
      "recall for fold 399:  0.3448275862068966\n",
      "precision for fold 399:  0.40540540540540543\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 400:  0.569377990430622\n",
      "f1  score for fold 400:  0.43037974683544306\n",
      "recall for fold 400:  0.4358974358974359\n",
      "precision for fold 400:  0.425\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 401:  0.5119617224880383\n",
      "f1  score for fold 401:  0.33766233766233766\n",
      "recall for fold 401:  0.35135135135135137\n",
      "precision for fold 401:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 402:  0.5571428571428572\n",
      "f1  score for fold 402:  0.4000000000000001\n",
      "recall for fold 402:  0.41333333333333333\n",
      "precision for fold 402:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 403:  0.5097087378640777\n",
      "f1  score for fold 403:  0.37267080745341613\n",
      "recall for fold 403:  0.36585365853658536\n",
      "precision for fold 403:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 404:  0.48704663212435234\n",
      "f1  score for fold 404:  0.3850931677018633\n",
      "recall for fold 404:  0.3563218390804598\n",
      "precision for fold 404:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 405:  0.48325358851674644\n",
      "f1  score for fold 405:  0.31645569620253167\n",
      "recall for fold 405:  0.32051282051282054\n",
      "precision for fold 405:  0.3125\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 406:  0.49282296650717705\n",
      "f1  score for fold 406:  0.3116883116883117\n",
      "recall for fold 406:  0.32432432432432434\n",
      "precision for fold 406:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 407:  0.5095238095238095\n",
      "f1  score for fold 407:  0.335483870967742\n",
      "recall for fold 407:  0.3466666666666667\n",
      "precision for fold 407:  0.325\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 408:  0.5970873786407767\n",
      "f1  score for fold 408:  0.484472049689441\n",
      "recall for fold 408:  0.47560975609756095\n",
      "precision for fold 408:  0.4936708860759494\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 409:  0.48704663212435234\n",
      "f1  score for fold 409:  0.3850931677018633\n",
      "recall for fold 409:  0.3563218390804598\n",
      "precision for fold 409:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 410:  0.5502392344497608\n",
      "f1  score for fold 410:  0.4050632911392405\n",
      "recall for fold 410:  0.41025641025641024\n",
      "precision for fold 410:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 411:  0.5311004784688995\n",
      "f1  score for fold 411:  0.36363636363636365\n",
      "recall for fold 411:  0.3783783783783784\n",
      "precision for fold 411:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 412:  0.49047619047619045\n",
      "f1  score for fold 412:  0.3096774193548387\n",
      "recall for fold 412:  0.32\n",
      "precision for fold 412:  0.3\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 413:  0.5388349514563107\n",
      "f1  score for fold 413:  0.40993788819875776\n",
      "recall for fold 413:  0.4024390243902439\n",
      "precision for fold 413:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 414:  0.538860103626943\n",
      "f1  score for fold 414:  0.4472049689440994\n",
      "recall for fold 414:  0.41379310344827586\n",
      "precision for fold 414:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 415:  0.49282296650717705\n",
      "f1  score for fold 415:  0.32911392405063294\n",
      "recall for fold 415:  0.3333333333333333\n",
      "precision for fold 415:  0.325\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 416:  0.569377990430622\n",
      "f1  score for fold 416:  0.4155844155844156\n",
      "recall for fold 416:  0.43243243243243246\n",
      "precision for fold 416:  0.4\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 417:  0.5571428571428572\n",
      "f1  score for fold 417:  0.4000000000000001\n",
      "recall for fold 417:  0.41333333333333333\n",
      "precision for fold 417:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 418:  0.5097087378640777\n",
      "f1  score for fold 418:  0.37267080745341613\n",
      "recall for fold 418:  0.36585365853658536\n",
      "precision for fold 418:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 419:  0.5284974093264249\n",
      "f1  score for fold 419:  0.4347826086956522\n",
      "recall for fold 419:  0.40229885057471265\n",
      "precision for fold 419:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 420:  0.5023923444976076\n",
      "f1  score for fold 420:  0.34177215189873417\n",
      "recall for fold 420:  0.34615384615384615\n",
      "precision for fold 420:  0.3375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 421:  0.569377990430622\n",
      "f1  score for fold 421:  0.4155844155844156\n",
      "recall for fold 421:  0.43243243243243246\n",
      "precision for fold 421:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 422:  0.5190476190476191\n",
      "f1  score for fold 422:  0.34838709677419355\n",
      "recall for fold 422:  0.36\n",
      "precision for fold 422:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 423:  0.49029126213592233\n",
      "f1  score for fold 423:  0.3478260869565218\n",
      "recall for fold 423:  0.34146341463414637\n",
      "precision for fold 423:  0.35443037974683544\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 424:  0.5492227979274611\n",
      "f1  score for fold 424:  0.45962732919254656\n",
      "recall for fold 424:  0.42528735632183906\n",
      "precision for fold 424:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 425:  0.5023923444976076\n",
      "f1  score for fold 425:  0.34177215189873417\n",
      "recall for fold 425:  0.34615384615384615\n",
      "precision for fold 425:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 426:  0.5023923444976076\n",
      "f1  score for fold 426:  0.3246753246753247\n",
      "recall for fold 426:  0.33783783783783783\n",
      "precision for fold 426:  0.3125\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 427:  0.5952380952380952\n",
      "f1  score for fold 427:  0.45161290322580644\n",
      "recall for fold 427:  0.4666666666666667\n",
      "precision for fold 427:  0.4375\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 428:  0.45145631067961167\n",
      "f1  score for fold 428:  0.29813664596273287\n",
      "recall for fold 428:  0.2926829268292683\n",
      "precision for fold 428:  0.3037974683544304\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 429:  0.5284974093264249\n",
      "f1  score for fold 429:  0.4347826086956522\n",
      "recall for fold 429:  0.40229885057471265\n",
      "precision for fold 429:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 430:  0.5502392344497608\n",
      "f1  score for fold 430:  0.4050632911392405\n",
      "recall for fold 430:  0.41025641025641024\n",
      "precision for fold 430:  0.4\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 431:  0.49282296650717705\n",
      "f1  score for fold 431:  0.3116883116883117\n",
      "recall for fold 431:  0.32432432432432434\n",
      "precision for fold 431:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 432:  0.5095238095238095\n",
      "f1  score for fold 432:  0.335483870967742\n",
      "recall for fold 432:  0.3466666666666667\n",
      "precision for fold 432:  0.325\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 433:  0.48058252427184467\n",
      "f1  score for fold 433:  0.33540372670807456\n",
      "recall for fold 433:  0.32926829268292684\n",
      "precision for fold 433:  0.34177215189873417\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 434:  0.5077720207253886\n",
      "f1  score for fold 434:  0.40993788819875776\n",
      "recall for fold 434:  0.3793103448275862\n",
      "precision for fold 434:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 435:  0.5119617224880383\n",
      "f1  score for fold 435:  0.3544303797468355\n",
      "recall for fold 435:  0.358974358974359\n",
      "precision for fold 435:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 436:  0.5598086124401914\n",
      "f1  score for fold 436:  0.40259740259740256\n",
      "recall for fold 436:  0.4189189189189189\n",
      "precision for fold 436:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 437:  0.5476190476190477\n",
      "f1  score for fold 437:  0.38709677419354843\n",
      "recall for fold 437:  0.4\n",
      "precision for fold 437:  0.375\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 438:  0.5776699029126213\n",
      "f1  score for fold 438:  0.4596273291925466\n",
      "recall for fold 438:  0.45121951219512196\n",
      "precision for fold 438:  0.46835443037974683\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 439:  0.47668393782383417\n",
      "f1  score for fold 439:  0.3726708074534162\n",
      "recall for fold 439:  0.3448275862068966\n",
      "precision for fold 439:  0.40540540540540543\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 440:  0.5406698564593302\n",
      "f1  score for fold 440:  0.3924050632911393\n",
      "recall for fold 440:  0.3974358974358974\n",
      "precision for fold 440:  0.3875\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 441:  0.569377990430622\n",
      "f1  score for fold 441:  0.4155844155844156\n",
      "recall for fold 441:  0.43243243243243246\n",
      "precision for fold 441:  0.4\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 442:  0.5857142857142857\n",
      "f1  score for fold 442:  0.43870967741935485\n",
      "recall for fold 442:  0.4533333333333333\n",
      "precision for fold 442:  0.425\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 443:  0.558252427184466\n",
      "f1  score for fold 443:  0.43478260869565216\n",
      "recall for fold 443:  0.4268292682926829\n",
      "precision for fold 443:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 444:  0.46632124352331605\n",
      "f1  score for fold 444:  0.36024844720496896\n",
      "recall for fold 444:  0.3333333333333333\n",
      "precision for fold 444:  0.3918918918918919\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 445:  0.5502392344497608\n",
      "f1  score for fold 445:  0.4050632911392405\n",
      "recall for fold 445:  0.41025641025641024\n",
      "precision for fold 445:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 446:  0.569377990430622\n",
      "f1  score for fold 446:  0.4155844155844156\n",
      "recall for fold 446:  0.43243243243243246\n",
      "precision for fold 446:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 447:  0.5476190476190477\n",
      "f1  score for fold 447:  0.38709677419354843\n",
      "recall for fold 447:  0.4\n",
      "precision for fold 447:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 448:  0.5388349514563107\n",
      "f1  score for fold 448:  0.40993788819875776\n",
      "recall for fold 448:  0.4024390243902439\n",
      "precision for fold 448:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 449:  0.5077720207253886\n",
      "f1  score for fold 449:  0.40993788819875776\n",
      "recall for fold 449:  0.3793103448275862\n",
      "precision for fold 449:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 450:  0.5502392344497608\n",
      "f1  score for fold 450:  0.4050632911392405\n",
      "recall for fold 450:  0.41025641025641024\n",
      "precision for fold 450:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 451:  0.5311004784688995\n",
      "f1  score for fold 451:  0.36363636363636365\n",
      "recall for fold 451:  0.3783783783783784\n",
      "precision for fold 451:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 452:  0.5571428571428572\n",
      "f1  score for fold 452:  0.4000000000000001\n",
      "recall for fold 452:  0.41333333333333333\n",
      "precision for fold 452:  0.3875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 453:  0.5679611650485437\n",
      "f1  score for fold 453:  0.4472049689440994\n",
      "recall for fold 453:  0.43902439024390244\n",
      "precision for fold 453:  0.45569620253164556\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 454:  0.5077720207253886\n",
      "f1  score for fold 454:  0.40993788819875776\n",
      "recall for fold 454:  0.3793103448275862\n",
      "precision for fold 454:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 455:  0.569377990430622\n",
      "f1  score for fold 455:  0.43037974683544306\n",
      "recall for fold 455:  0.4358974358974359\n",
      "precision for fold 455:  0.425\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 456:  0.5789473684210527\n",
      "f1  score for fold 456:  0.42857142857142855\n",
      "recall for fold 456:  0.44594594594594594\n",
      "precision for fold 456:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 457:  0.5380952380952381\n",
      "f1  score for fold 457:  0.3741935483870968\n",
      "recall for fold 457:  0.38666666666666666\n",
      "precision for fold 457:  0.3625\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 458:  0.5970873786407767\n",
      "f1  score for fold 458:  0.484472049689441\n",
      "recall for fold 458:  0.47560975609756095\n",
      "precision for fold 458:  0.4936708860759494\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 459:  0.5181347150259067\n",
      "f1  score for fold 459:  0.422360248447205\n",
      "recall for fold 459:  0.39080459770114945\n",
      "precision for fold 459:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 460:  0.5119617224880383\n",
      "f1  score for fold 460:  0.3544303797468355\n",
      "recall for fold 460:  0.358974358974359\n",
      "precision for fold 460:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 461:  0.569377990430622\n",
      "f1  score for fold 461:  0.4155844155844156\n",
      "recall for fold 461:  0.43243243243243246\n",
      "precision for fold 461:  0.4\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 462:  0.5761904761904761\n",
      "f1  score for fold 462:  0.4258064516129032\n",
      "recall for fold 462:  0.44\n",
      "precision for fold 462:  0.4125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 463:  0.5\n",
      "f1  score for fold 463:  0.3602484472049689\n",
      "recall for fold 463:  0.35365853658536583\n",
      "precision for fold 463:  0.3670886075949367\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 464:  0.42487046632124353\n",
      "f1  score for fold 464:  0.3105590062111801\n",
      "recall for fold 464:  0.28735632183908044\n",
      "precision for fold 464:  0.33783783783783783\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 465:  0.569377990430622\n",
      "f1  score for fold 465:  0.43037974683544306\n",
      "recall for fold 465:  0.4358974358974359\n",
      "precision for fold 465:  0.425\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 466:  0.5119617224880383\n",
      "f1  score for fold 466:  0.33766233766233766\n",
      "recall for fold 466:  0.35135135135135137\n",
      "precision for fold 466:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 467:  0.5285714285714286\n",
      "f1  score for fold 467:  0.3612903225806451\n",
      "recall for fold 467:  0.37333333333333335\n",
      "precision for fold 467:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 468:  0.5776699029126213\n",
      "f1  score for fold 468:  0.4596273291925466\n",
      "recall for fold 468:  0.45121951219512196\n",
      "precision for fold 468:  0.46835443037974683\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 469:  0.47668393782383417\n",
      "f1  score for fold 469:  0.3726708074534162\n",
      "recall for fold 469:  0.3448275862068966\n",
      "precision for fold 469:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 470:  0.5023923444976076\n",
      "f1  score for fold 470:  0.34177215189873417\n",
      "recall for fold 470:  0.34615384615384615\n",
      "precision for fold 470:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 471:  0.5502392344497608\n",
      "f1  score for fold 471:  0.3896103896103896\n",
      "recall for fold 471:  0.40540540540540543\n",
      "precision for fold 471:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 472:  0.5\n",
      "f1  score for fold 472:  0.3225806451612903\n",
      "recall for fold 472:  0.3333333333333333\n",
      "precision for fold 472:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 473:  0.5194174757281553\n",
      "f1  score for fold 473:  0.38509316770186336\n",
      "recall for fold 473:  0.3780487804878049\n",
      "precision for fold 473:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 474:  0.5077720207253886\n",
      "f1  score for fold 474:  0.40993788819875776\n",
      "recall for fold 474:  0.3793103448275862\n",
      "precision for fold 474:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 475:  0.5023923444976076\n",
      "f1  score for fold 475:  0.34177215189873417\n",
      "recall for fold 475:  0.34615384615384615\n",
      "precision for fold 475:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 476:  0.5215311004784688\n",
      "f1  score for fold 476:  0.3506493506493507\n",
      "recall for fold 476:  0.36486486486486486\n",
      "precision for fold 476:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 477:  0.5571428571428572\n",
      "f1  score for fold 477:  0.4000000000000001\n",
      "recall for fold 477:  0.41333333333333333\n",
      "precision for fold 477:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 478:  0.5485436893203883\n",
      "f1  score for fold 478:  0.42236024844720493\n",
      "recall for fold 478:  0.4146341463414634\n",
      "precision for fold 478:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 479:  0.5492227979274611\n",
      "f1  score for fold 479:  0.45962732919254656\n",
      "recall for fold 479:  0.42528735632183906\n",
      "precision for fold 479:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 480:  0.5311004784688995\n",
      "f1  score for fold 480:  0.37974683544303806\n",
      "recall for fold 480:  0.38461538461538464\n",
      "precision for fold 480:  0.375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 481:  0.48325358851674644\n",
      "f1  score for fold 481:  0.29870129870129863\n",
      "recall for fold 481:  0.3108108108108108\n",
      "precision for fold 481:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 482:  0.5285714285714286\n",
      "f1  score for fold 482:  0.3612903225806451\n",
      "recall for fold 482:  0.37333333333333335\n",
      "precision for fold 482:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 483:  0.529126213592233\n",
      "f1  score for fold 483:  0.39751552795031053\n",
      "recall for fold 483:  0.3902439024390244\n",
      "precision for fold 483:  0.4050632911392405\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 484:  0.5595854922279793\n",
      "f1  score for fold 484:  0.4720496894409938\n",
      "recall for fold 484:  0.4367816091954023\n",
      "precision for fold 484:  0.5135135135135135\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 485:  0.48325358851674644\n",
      "f1  score for fold 485:  0.31645569620253167\n",
      "recall for fold 485:  0.32051282051282054\n",
      "precision for fold 485:  0.3125\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 486:  0.6076555023923444\n",
      "f1  score for fold 486:  0.4675324675324675\n",
      "recall for fold 486:  0.4864864864864865\n",
      "precision for fold 486:  0.45\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 487:  0.5\n",
      "f1  score for fold 487:  0.3225806451612903\n",
      "recall for fold 487:  0.3333333333333333\n",
      "precision for fold 487:  0.3125\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 488:  0.46116504854368934\n",
      "f1  score for fold 488:  0.31055900621118016\n",
      "recall for fold 488:  0.3048780487804878\n",
      "precision for fold 488:  0.31645569620253167\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 489:  0.5181347150259067\n",
      "f1  score for fold 489:  0.422360248447205\n",
      "recall for fold 489:  0.39080459770114945\n",
      "precision for fold 489:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 490:  0.5406698564593302\n",
      "f1  score for fold 490:  0.3924050632911393\n",
      "recall for fold 490:  0.3974358974358974\n",
      "precision for fold 490:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 491:  0.49282296650717705\n",
      "f1  score for fold 491:  0.3116883116883117\n",
      "recall for fold 491:  0.32432432432432434\n",
      "precision for fold 491:  0.3\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 492:  0.4523809523809524\n",
      "f1  score for fold 492:  0.2580645161290323\n",
      "recall for fold 492:  0.26666666666666666\n",
      "precision for fold 492:  0.25\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 493:  0.5679611650485437\n",
      "f1  score for fold 493:  0.4472049689440994\n",
      "recall for fold 493:  0.43902439024390244\n",
      "precision for fold 493:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 494:  0.5181347150259067\n",
      "f1  score for fold 494:  0.422360248447205\n",
      "recall for fold 494:  0.39080459770114945\n",
      "precision for fold 494:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 495:  0.5215311004784688\n",
      "f1  score for fold 495:  0.36708860759493667\n",
      "recall for fold 495:  0.3717948717948718\n",
      "precision for fold 495:  0.3625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 496:  0.569377990430622\n",
      "f1  score for fold 496:  0.4155844155844156\n",
      "recall for fold 496:  0.43243243243243246\n",
      "precision for fold 496:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 497:  0.5285714285714286\n",
      "f1  score for fold 497:  0.3612903225806451\n",
      "recall for fold 497:  0.37333333333333335\n",
      "precision for fold 497:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 498:  0.529126213592233\n",
      "f1  score for fold 498:  0.39751552795031053\n",
      "recall for fold 498:  0.3902439024390244\n",
      "precision for fold 498:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 499:  0.49740932642487046\n",
      "f1  score for fold 499:  0.39751552795031053\n",
      "recall for fold 499:  0.367816091954023\n",
      "precision for fold 499:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 500:  0.5119617224880383\n",
      "f1  score for fold 500:  0.3544303797468355\n",
      "recall for fold 500:  0.358974358974359\n",
      "precision for fold 500:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 501:  0.5311004784688995\n",
      "f1  score for fold 501:  0.36363636363636365\n",
      "recall for fold 501:  0.3783783783783784\n",
      "precision for fold 501:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 502:  0.5380952380952381\n",
      "f1  score for fold 502:  0.3741935483870968\n",
      "recall for fold 502:  0.38666666666666666\n",
      "precision for fold 502:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 503:  0.5194174757281553\n",
      "f1  score for fold 503:  0.38509316770186336\n",
      "recall for fold 503:  0.3780487804878049\n",
      "precision for fold 503:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 504:  0.49740932642487046\n",
      "f1  score for fold 504:  0.39751552795031053\n",
      "recall for fold 504:  0.367816091954023\n",
      "precision for fold 504:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 505:  0.5598086124401914\n",
      "f1  score for fold 505:  0.4177215189873418\n",
      "recall for fold 505:  0.4230769230769231\n",
      "precision for fold 505:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 506:  0.5598086124401914\n",
      "f1  score for fold 506:  0.40259740259740256\n",
      "recall for fold 506:  0.4189189189189189\n",
      "precision for fold 506:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 507:  0.5380952380952381\n",
      "f1  score for fold 507:  0.3741935483870968\n",
      "recall for fold 507:  0.38666666666666666\n",
      "precision for fold 507:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 508:  0.5097087378640777\n",
      "f1  score for fold 508:  0.37267080745341613\n",
      "recall for fold 508:  0.36585365853658536\n",
      "precision for fold 508:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 509:  0.5077720207253886\n",
      "f1  score for fold 509:  0.40993788819875776\n",
      "recall for fold 509:  0.3793103448275862\n",
      "precision for fold 509:  0.44594594594594594\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 510:  0.46411483253588515\n",
      "f1  score for fold 510:  0.2911392405063291\n",
      "recall for fold 510:  0.2948717948717949\n",
      "precision for fold 510:  0.2875\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 511:  0.6172248803827751\n",
      "f1  score for fold 511:  0.4805194805194805\n",
      "recall for fold 511:  0.5\n",
      "precision for fold 511:  0.4625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 512:  0.5095238095238095\n",
      "f1  score for fold 512:  0.335483870967742\n",
      "recall for fold 512:  0.3466666666666667\n",
      "precision for fold 512:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 513:  0.5194174757281553\n",
      "f1  score for fold 513:  0.38509316770186336\n",
      "recall for fold 513:  0.3780487804878049\n",
      "precision for fold 513:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 514:  0.5284974093264249\n",
      "f1  score for fold 514:  0.4347826086956522\n",
      "recall for fold 514:  0.40229885057471265\n",
      "precision for fold 514:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 515:  0.5023923444976076\n",
      "f1  score for fold 515:  0.34177215189873417\n",
      "recall for fold 515:  0.34615384615384615\n",
      "precision for fold 515:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 516:  0.5502392344497608\n",
      "f1  score for fold 516:  0.3896103896103896\n",
      "recall for fold 516:  0.40540540540540543\n",
      "precision for fold 516:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 517:  0.5380952380952381\n",
      "f1  score for fold 517:  0.3741935483870968\n",
      "recall for fold 517:  0.38666666666666666\n",
      "precision for fold 517:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 518:  0.5485436893203883\n",
      "f1  score for fold 518:  0.42236024844720493\n",
      "recall for fold 518:  0.4146341463414634\n",
      "precision for fold 518:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 519:  0.5181347150259067\n",
      "f1  score for fold 519:  0.422360248447205\n",
      "recall for fold 519:  0.39080459770114945\n",
      "precision for fold 519:  0.4594594594594595\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 520:  0.5885167464114832\n",
      "f1  score for fold 520:  0.45569620253164556\n",
      "recall for fold 520:  0.46153846153846156\n",
      "precision for fold 520:  0.45\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 521:  0.5215311004784688\n",
      "f1  score for fold 521:  0.3506493506493507\n",
      "recall for fold 521:  0.36486486486486486\n",
      "precision for fold 521:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 522:  0.5190476190476191\n",
      "f1  score for fold 522:  0.34838709677419355\n",
      "recall for fold 522:  0.36\n",
      "precision for fold 522:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 523:  0.5097087378640777\n",
      "f1  score for fold 523:  0.37267080745341613\n",
      "recall for fold 523:  0.36585365853658536\n",
      "precision for fold 523:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 524:  0.5181347150259067\n",
      "f1  score for fold 524:  0.422360248447205\n",
      "recall for fold 524:  0.39080459770114945\n",
      "precision for fold 524:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 525:  0.5406698564593302\n",
      "f1  score for fold 525:  0.3924050632911393\n",
      "recall for fold 525:  0.3974358974358974\n",
      "precision for fold 525:  0.3875\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 526:  0.6076555023923444\n",
      "f1  score for fold 526:  0.4675324675324675\n",
      "recall for fold 526:  0.4864864864864865\n",
      "precision for fold 526:  0.45\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 527:  0.5\n",
      "f1  score for fold 527:  0.3225806451612903\n",
      "recall for fold 527:  0.3333333333333333\n",
      "precision for fold 527:  0.3125\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 528:  0.5776699029126213\n",
      "f1  score for fold 528:  0.4596273291925466\n",
      "recall for fold 528:  0.45121951219512196\n",
      "precision for fold 528:  0.46835443037974683\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 529:  0.5595854922279793\n",
      "f1  score for fold 529:  0.4720496894409938\n",
      "recall for fold 529:  0.4367816091954023\n",
      "precision for fold 529:  0.5135135135135135\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 530:  0.49282296650717705\n",
      "f1  score for fold 530:  0.32911392405063294\n",
      "recall for fold 530:  0.3333333333333333\n",
      "precision for fold 530:  0.325\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 531:  0.49282296650717705\n",
      "f1  score for fold 531:  0.3116883116883117\n",
      "recall for fold 531:  0.32432432432432434\n",
      "precision for fold 531:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 532:  0.5095238095238095\n",
      "f1  score for fold 532:  0.335483870967742\n",
      "recall for fold 532:  0.3466666666666667\n",
      "precision for fold 532:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 533:  0.49029126213592233\n",
      "f1  score for fold 533:  0.3478260869565218\n",
      "recall for fold 533:  0.34146341463414637\n",
      "precision for fold 533:  0.35443037974683544\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 534:  0.5595854922279793\n",
      "f1  score for fold 534:  0.4720496894409938\n",
      "recall for fold 534:  0.4367816091954023\n",
      "precision for fold 534:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 535:  0.5502392344497608\n",
      "f1  score for fold 535:  0.4050632911392405\n",
      "recall for fold 535:  0.41025641025641024\n",
      "precision for fold 535:  0.4\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 536:  0.48325358851674644\n",
      "f1  score for fold 536:  0.29870129870129863\n",
      "recall for fold 536:  0.3108108108108108\n",
      "precision for fold 536:  0.2875\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 537:  0.5666666666666667\n",
      "f1  score for fold 537:  0.41290322580645167\n",
      "recall for fold 537:  0.4266666666666667\n",
      "precision for fold 537:  0.4\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 538:  0.46116504854368934\n",
      "f1  score for fold 538:  0.31055900621118016\n",
      "recall for fold 538:  0.3048780487804878\n",
      "precision for fold 538:  0.31645569620253167\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 539:  0.49740932642487046\n",
      "f1  score for fold 539:  0.39751552795031053\n",
      "recall for fold 539:  0.367816091954023\n",
      "precision for fold 539:  0.43243243243243246\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 540:  0.5885167464114832\n",
      "f1  score for fold 540:  0.45569620253164556\n",
      "recall for fold 540:  0.46153846153846156\n",
      "precision for fold 540:  0.45\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 541:  0.5502392344497608\n",
      "f1  score for fold 541:  0.3896103896103896\n",
      "recall for fold 541:  0.40540540540540543\n",
      "precision for fold 541:  0.375\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 542:  0.5952380952380952\n",
      "f1  score for fold 542:  0.45161290322580644\n",
      "recall for fold 542:  0.4666666666666667\n",
      "precision for fold 542:  0.4375\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 543:  0.45145631067961167\n",
      "f1  score for fold 543:  0.29813664596273287\n",
      "recall for fold 543:  0.2926829268292683\n",
      "precision for fold 543:  0.3037974683544304\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 544:  0.49740932642487046\n",
      "f1  score for fold 544:  0.39751552795031053\n",
      "recall for fold 544:  0.367816091954023\n",
      "precision for fold 544:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 545:  0.5502392344497608\n",
      "f1  score for fold 545:  0.4050632911392405\n",
      "recall for fold 545:  0.41025641025641024\n",
      "precision for fold 545:  0.4\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 546:  0.5215311004784688\n",
      "f1  score for fold 546:  0.3506493506493507\n",
      "recall for fold 546:  0.36486486486486486\n",
      "precision for fold 546:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 547:  0.5\n",
      "f1  score for fold 547:  0.3225806451612903\n",
      "recall for fold 547:  0.3333333333333333\n",
      "precision for fold 547:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 548:  0.558252427184466\n",
      "f1  score for fold 548:  0.43478260869565216\n",
      "recall for fold 548:  0.4268292682926829\n",
      "precision for fold 548:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 549:  0.5077720207253886\n",
      "f1  score for fold 549:  0.40993788819875776\n",
      "recall for fold 549:  0.3793103448275862\n",
      "precision for fold 549:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 550:  0.5311004784688995\n",
      "f1  score for fold 550:  0.37974683544303806\n",
      "recall for fold 550:  0.38461538461538464\n",
      "precision for fold 550:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 551:  0.5215311004784688\n",
      "f1  score for fold 551:  0.3506493506493507\n",
      "recall for fold 551:  0.36486486486486486\n",
      "precision for fold 551:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 552:  0.5571428571428572\n",
      "f1  score for fold 552:  0.4000000000000001\n",
      "recall for fold 552:  0.41333333333333333\n",
      "precision for fold 552:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 553:  0.5\n",
      "f1  score for fold 553:  0.3602484472049689\n",
      "recall for fold 553:  0.35365853658536583\n",
      "precision for fold 553:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 554:  0.5492227979274611\n",
      "f1  score for fold 554:  0.45962732919254656\n",
      "recall for fold 554:  0.42528735632183906\n",
      "precision for fold 554:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 555:  0.5311004784688995\n",
      "f1  score for fold 555:  0.37974683544303806\n",
      "recall for fold 555:  0.38461538461538464\n",
      "precision for fold 555:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 556:  0.5311004784688995\n",
      "f1  score for fold 556:  0.36363636363636365\n",
      "recall for fold 556:  0.3783783783783784\n",
      "precision for fold 556:  0.35\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 557:  0.6142857142857143\n",
      "f1  score for fold 557:  0.47741935483870973\n",
      "recall for fold 557:  0.49333333333333335\n",
      "precision for fold 557:  0.4625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 558:  0.5485436893203883\n",
      "f1  score for fold 558:  0.42236024844720493\n",
      "recall for fold 558:  0.4146341463414634\n",
      "precision for fold 558:  0.43037974683544306\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 559:  0.45595854922279794\n",
      "f1  score for fold 559:  0.3478260869565218\n",
      "recall for fold 559:  0.3218390804597701\n",
      "precision for fold 559:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 560:  0.5406698564593302\n",
      "f1  score for fold 560:  0.3924050632911393\n",
      "recall for fold 560:  0.3974358974358974\n",
      "precision for fold 560:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 561:  0.49282296650717705\n",
      "f1  score for fold 561:  0.3116883116883117\n",
      "recall for fold 561:  0.32432432432432434\n",
      "precision for fold 561:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 562:  0.5\n",
      "f1  score for fold 562:  0.3225806451612903\n",
      "recall for fold 562:  0.3333333333333333\n",
      "precision for fold 562:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 563:  0.558252427184466\n",
      "f1  score for fold 563:  0.43478260869565216\n",
      "recall for fold 563:  0.4268292682926829\n",
      "precision for fold 563:  0.4430379746835443\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 564:  0.5492227979274611\n",
      "f1  score for fold 564:  0.45962732919254656\n",
      "recall for fold 564:  0.42528735632183906\n",
      "precision for fold 564:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 565:  0.5215311004784688\n",
      "f1  score for fold 565:  0.36708860759493667\n",
      "recall for fold 565:  0.3717948717948718\n",
      "precision for fold 565:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 566:  0.5789473684210527\n",
      "f1  score for fold 566:  0.42857142857142855\n",
      "recall for fold 566:  0.44594594594594594\n",
      "precision for fold 566:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 567:  0.5476190476190477\n",
      "f1  score for fold 567:  0.38709677419354843\n",
      "recall for fold 567:  0.4\n",
      "precision for fold 567:  0.375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 568:  0.48058252427184467\n",
      "f1  score for fold 568:  0.33540372670807456\n",
      "recall for fold 568:  0.32926829268292684\n",
      "precision for fold 568:  0.34177215189873417\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 569:  0.5181347150259067\n",
      "f1  score for fold 569:  0.422360248447205\n",
      "recall for fold 569:  0.39080459770114945\n",
      "precision for fold 569:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 570:  0.5119617224880383\n",
      "f1  score for fold 570:  0.3544303797468355\n",
      "recall for fold 570:  0.358974358974359\n",
      "precision for fold 570:  0.35\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 571:  0.5980861244019139\n",
      "f1  score for fold 571:  0.45454545454545453\n",
      "recall for fold 571:  0.47297297297297297\n",
      "precision for fold 571:  0.4375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 572:  0.5\n",
      "f1  score for fold 572:  0.3225806451612903\n",
      "recall for fold 572:  0.3333333333333333\n",
      "precision for fold 572:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 573:  0.5485436893203883\n",
      "f1  score for fold 573:  0.42236024844720493\n",
      "recall for fold 573:  0.4146341463414634\n",
      "precision for fold 573:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 574:  0.5181347150259067\n",
      "f1  score for fold 574:  0.422360248447205\n",
      "recall for fold 574:  0.39080459770114945\n",
      "precision for fold 574:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 575:  0.48325358851674644\n",
      "f1  score for fold 575:  0.31645569620253167\n",
      "recall for fold 575:  0.32051282051282054\n",
      "precision for fold 575:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 576:  0.5598086124401914\n",
      "f1  score for fold 576:  0.40259740259740256\n",
      "recall for fold 576:  0.4189189189189189\n",
      "precision for fold 576:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 577:  0.5\n",
      "f1  score for fold 577:  0.3225806451612903\n",
      "recall for fold 577:  0.3333333333333333\n",
      "precision for fold 577:  0.3125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 578:  0.49029126213592233\n",
      "f1  score for fold 578:  0.3478260869565218\n",
      "recall for fold 578:  0.34146341463414637\n",
      "precision for fold 578:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 579:  0.538860103626943\n",
      "f1  score for fold 579:  0.4472049689440994\n",
      "recall for fold 579:  0.41379310344827586\n",
      "precision for fold 579:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 580:  0.5406698564593302\n",
      "f1  score for fold 580:  0.3924050632911393\n",
      "recall for fold 580:  0.3974358974358974\n",
      "precision for fold 580:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 581:  0.5215311004784688\n",
      "f1  score for fold 581:  0.3506493506493507\n",
      "recall for fold 581:  0.36486486486486486\n",
      "precision for fold 581:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 582:  0.5380952380952381\n",
      "f1  score for fold 582:  0.3741935483870968\n",
      "recall for fold 582:  0.38666666666666666\n",
      "precision for fold 582:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 583:  0.5388349514563107\n",
      "f1  score for fold 583:  0.40993788819875776\n",
      "recall for fold 583:  0.4024390243902439\n",
      "precision for fold 583:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 584:  0.5181347150259067\n",
      "f1  score for fold 584:  0.422360248447205\n",
      "recall for fold 584:  0.39080459770114945\n",
      "precision for fold 584:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 585:  0.5119617224880383\n",
      "f1  score for fold 585:  0.3544303797468355\n",
      "recall for fold 585:  0.358974358974359\n",
      "precision for fold 585:  0.35\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 586:  0.48325358851674644\n",
      "f1  score for fold 586:  0.29870129870129863\n",
      "recall for fold 586:  0.3108108108108108\n",
      "precision for fold 586:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 587:  0.5476190476190477\n",
      "f1  score for fold 587:  0.38709677419354843\n",
      "recall for fold 587:  0.4\n",
      "precision for fold 587:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 588:  0.5679611650485437\n",
      "f1  score for fold 588:  0.4472049689440994\n",
      "recall for fold 588:  0.43902439024390244\n",
      "precision for fold 588:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 589:  0.5181347150259067\n",
      "f1  score for fold 589:  0.422360248447205\n",
      "recall for fold 589:  0.39080459770114945\n",
      "precision for fold 589:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 590:  0.5215311004784688\n",
      "f1  score for fold 590:  0.36708860759493667\n",
      "recall for fold 590:  0.3717948717948718\n",
      "precision for fold 590:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 591:  0.5311004784688995\n",
      "f1  score for fold 591:  0.36363636363636365\n",
      "recall for fold 591:  0.3783783783783784\n",
      "precision for fold 591:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 592:  0.5380952380952381\n",
      "f1  score for fold 592:  0.3741935483870968\n",
      "recall for fold 592:  0.38666666666666666\n",
      "precision for fold 592:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 593:  0.5485436893203883\n",
      "f1  score for fold 593:  0.42236024844720493\n",
      "recall for fold 593:  0.4146341463414634\n",
      "precision for fold 593:  0.43037974683544306\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 594:  0.5595854922279793\n",
      "f1  score for fold 594:  0.4720496894409938\n",
      "recall for fold 594:  0.4367816091954023\n",
      "precision for fold 594:  0.5135135135135135\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 595:  0.5311004784688995\n",
      "f1  score for fold 595:  0.37974683544303806\n",
      "recall for fold 595:  0.38461538461538464\n",
      "precision for fold 595:  0.375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 596:  0.5789473684210527\n",
      "f1  score for fold 596:  0.42857142857142855\n",
      "recall for fold 596:  0.44594594594594594\n",
      "precision for fold 596:  0.4125\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 597:  0.5857142857142857\n",
      "f1  score for fold 597:  0.43870967741935485\n",
      "recall for fold 597:  0.4533333333333333\n",
      "precision for fold 597:  0.425\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 598:  0.48058252427184467\n",
      "f1  score for fold 598:  0.33540372670807456\n",
      "recall for fold 598:  0.32926829268292684\n",
      "precision for fold 598:  0.34177215189873417\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 599:  0.49740932642487046\n",
      "f1  score for fold 599:  0.39751552795031053\n",
      "recall for fold 599:  0.367816091954023\n",
      "precision for fold 599:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 600:  0.49282296650717705\n",
      "f1  score for fold 600:  0.32911392405063294\n",
      "recall for fold 600:  0.3333333333333333\n",
      "precision for fold 600:  0.325\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 601:  0.5885167464114832\n",
      "f1  score for fold 601:  0.44155844155844154\n",
      "recall for fold 601:  0.4594594594594595\n",
      "precision for fold 601:  0.425\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 602:  0.5761904761904761\n",
      "f1  score for fold 602:  0.4258064516129032\n",
      "recall for fold 602:  0.44\n",
      "precision for fold 602:  0.4125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 603:  0.5485436893203883\n",
      "f1  score for fold 603:  0.42236024844720493\n",
      "recall for fold 603:  0.4146341463414634\n",
      "precision for fold 603:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 604:  0.5284974093264249\n",
      "f1  score for fold 604:  0.4347826086956522\n",
      "recall for fold 604:  0.40229885057471265\n",
      "precision for fold 604:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 605:  0.5406698564593302\n",
      "f1  score for fold 605:  0.3924050632911393\n",
      "recall for fold 605:  0.3974358974358974\n",
      "precision for fold 605:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 606:  0.5406698564593302\n",
      "f1  score for fold 606:  0.37662337662337664\n",
      "recall for fold 606:  0.3918918918918919\n",
      "precision for fold 606:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 607:  0.5666666666666667\n",
      "f1  score for fold 607:  0.41290322580645167\n",
      "recall for fold 607:  0.4266666666666667\n",
      "precision for fold 607:  0.4\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 608:  0.5194174757281553\n",
      "f1  score for fold 608:  0.38509316770186336\n",
      "recall for fold 608:  0.3780487804878049\n",
      "precision for fold 608:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 609:  0.49740932642487046\n",
      "f1  score for fold 609:  0.39751552795031053\n",
      "recall for fold 609:  0.367816091954023\n",
      "precision for fold 609:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 610:  0.5502392344497608\n",
      "f1  score for fold 610:  0.4050632911392405\n",
      "recall for fold 610:  0.41025641025641024\n",
      "precision for fold 610:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 611:  0.5598086124401914\n",
      "f1  score for fold 611:  0.40259740259740256\n",
      "recall for fold 611:  0.4189189189189189\n",
      "precision for fold 611:  0.3875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 612:  0.5095238095238095\n",
      "f1  score for fold 612:  0.335483870967742\n",
      "recall for fold 612:  0.3466666666666667\n",
      "precision for fold 612:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 613:  0.5679611650485437\n",
      "f1  score for fold 613:  0.4472049689440994\n",
      "recall for fold 613:  0.43902439024390244\n",
      "precision for fold 613:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 614:  0.5181347150259067\n",
      "f1  score for fold 614:  0.422360248447205\n",
      "recall for fold 614:  0.39080459770114945\n",
      "precision for fold 614:  0.4594594594594595\n",
      "    0   1\n",
      "0  21  57\n",
      "1  59  72\n",
      "Accuracy for fold 615:  0.4449760765550239\n",
      "f1  score for fold 615:  0.26582278481012656\n",
      "recall for fold 615:  0.2692307692307692\n",
      "precision for fold 615:  0.2625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 616:  0.5311004784688995\n",
      "f1  score for fold 616:  0.36363636363636365\n",
      "recall for fold 616:  0.3783783783783784\n",
      "precision for fold 616:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 617:  0.5190476190476191\n",
      "f1  score for fold 617:  0.34838709677419355\n",
      "recall for fold 617:  0.36\n",
      "precision for fold 617:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 618:  0.5097087378640777\n",
      "f1  score for fold 618:  0.37267080745341613\n",
      "recall for fold 618:  0.36585365853658536\n",
      "precision for fold 618:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 619:  0.5284974093264249\n",
      "f1  score for fold 619:  0.4347826086956522\n",
      "recall for fold 619:  0.40229885057471265\n",
      "precision for fold 619:  0.47297297297297297\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 620:  0.45454545454545453\n",
      "f1  score for fold 620:  0.27848101265822783\n",
      "recall for fold 620:  0.28205128205128205\n",
      "precision for fold 620:  0.275\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 621:  0.5789473684210527\n",
      "f1  score for fold 621:  0.42857142857142855\n",
      "recall for fold 621:  0.44594594594594594\n",
      "precision for fold 621:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 622:  0.5476190476190477\n",
      "f1  score for fold 622:  0.38709677419354843\n",
      "recall for fold 622:  0.4\n",
      "precision for fold 622:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 623:  0.5388349514563107\n",
      "f1  score for fold 623:  0.40993788819875776\n",
      "recall for fold 623:  0.4024390243902439\n",
      "precision for fold 623:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 624:  0.49740932642487046\n",
      "f1  score for fold 624:  0.39751552795031053\n",
      "recall for fold 624:  0.367816091954023\n",
      "precision for fold 624:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 625:  0.5406698564593302\n",
      "f1  score for fold 625:  0.3924050632911393\n",
      "recall for fold 625:  0.3974358974358974\n",
      "precision for fold 625:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 626:  0.5406698564593302\n",
      "f1  score for fold 626:  0.37662337662337664\n",
      "recall for fold 626:  0.3918918918918919\n",
      "precision for fold 626:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 627:  0.5380952380952381\n",
      "f1  score for fold 627:  0.3741935483870968\n",
      "recall for fold 627:  0.38666666666666666\n",
      "precision for fold 627:  0.3625\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 628:  0.587378640776699\n",
      "f1  score for fold 628:  0.4720496894409938\n",
      "recall for fold 628:  0.4634146341463415\n",
      "precision for fold 628:  0.4810126582278481\n",
      "    0   1\n",
      "0  24  63\n",
      "1  50  56\n",
      "Accuracy for fold 629:  0.41450777202072536\n",
      "f1  score for fold 629:  0.2981366459627329\n",
      "recall for fold 629:  0.27586206896551724\n",
      "precision for fold 629:  0.32432432432432434\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 630:  0.5311004784688995\n",
      "f1  score for fold 630:  0.37974683544303806\n",
      "recall for fold 630:  0.38461538461538464\n",
      "precision for fold 630:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 631:  0.5023923444976076\n",
      "f1  score for fold 631:  0.3246753246753247\n",
      "recall for fold 631:  0.33783783783783783\n",
      "precision for fold 631:  0.3125\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 632:  0.48095238095238096\n",
      "f1  score for fold 632:  0.2967741935483871\n",
      "recall for fold 632:  0.30666666666666664\n",
      "precision for fold 632:  0.2875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 633:  0.558252427184466\n",
      "f1  score for fold 633:  0.43478260869565216\n",
      "recall for fold 633:  0.4268292682926829\n",
      "precision for fold 633:  0.4430379746835443\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 634:  0.47668393782383417\n",
      "f1  score for fold 634:  0.3726708074534162\n",
      "recall for fold 634:  0.3448275862068966\n",
      "precision for fold 634:  0.40540540540540543\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 635:  0.5406698564593302\n",
      "f1  score for fold 635:  0.3924050632911393\n",
      "recall for fold 635:  0.3974358974358974\n",
      "precision for fold 635:  0.3875\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 636:  0.569377990430622\n",
      "f1  score for fold 636:  0.4155844155844156\n",
      "recall for fold 636:  0.43243243243243246\n",
      "precision for fold 636:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 637:  0.5380952380952381\n",
      "f1  score for fold 637:  0.3741935483870968\n",
      "recall for fold 637:  0.38666666666666666\n",
      "precision for fold 637:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 638:  0.49029126213592233\n",
      "f1  score for fold 638:  0.3478260869565218\n",
      "recall for fold 638:  0.34146341463414637\n",
      "precision for fold 638:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 639:  0.5181347150259067\n",
      "f1  score for fold 639:  0.422360248447205\n",
      "recall for fold 639:  0.39080459770114945\n",
      "precision for fold 639:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 640:  0.5311004784688995\n",
      "f1  score for fold 640:  0.37974683544303806\n",
      "recall for fold 640:  0.38461538461538464\n",
      "precision for fold 640:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 641:  0.5023923444976076\n",
      "f1  score for fold 641:  0.3246753246753247\n",
      "recall for fold 641:  0.33783783783783783\n",
      "precision for fold 641:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 642:  0.5571428571428572\n",
      "f1  score for fold 642:  0.4000000000000001\n",
      "recall for fold 642:  0.41333333333333333\n",
      "precision for fold 642:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 643:  0.529126213592233\n",
      "f1  score for fold 643:  0.39751552795031053\n",
      "recall for fold 643:  0.3902439024390244\n",
      "precision for fold 643:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 644:  0.49740932642487046\n",
      "f1  score for fold 644:  0.39751552795031053\n",
      "recall for fold 644:  0.367816091954023\n",
      "precision for fold 644:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 645:  0.5119617224880383\n",
      "f1  score for fold 645:  0.3544303797468355\n",
      "recall for fold 645:  0.358974358974359\n",
      "precision for fold 645:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 646:  0.5311004784688995\n",
      "f1  score for fold 646:  0.36363636363636365\n",
      "recall for fold 646:  0.3783783783783784\n",
      "precision for fold 646:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 647:  0.5095238095238095\n",
      "f1  score for fold 647:  0.335483870967742\n",
      "recall for fold 647:  0.3466666666666667\n",
      "precision for fold 647:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 648:  0.5388349514563107\n",
      "f1  score for fold 648:  0.40993788819875776\n",
      "recall for fold 648:  0.4024390243902439\n",
      "precision for fold 648:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 649:  0.48704663212435234\n",
      "f1  score for fold 649:  0.3850931677018633\n",
      "recall for fold 649:  0.3563218390804598\n",
      "precision for fold 649:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 650:  0.5119617224880383\n",
      "f1  score for fold 650:  0.3544303797468355\n",
      "recall for fold 650:  0.358974358974359\n",
      "precision for fold 650:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 651:  0.5215311004784688\n",
      "f1  score for fold 651:  0.3506493506493507\n",
      "recall for fold 651:  0.36486486486486486\n",
      "precision for fold 651:  0.3375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 652:  0.48095238095238096\n",
      "f1  score for fold 652:  0.2967741935483871\n",
      "recall for fold 652:  0.30666666666666664\n",
      "precision for fold 652:  0.2875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 653:  0.558252427184466\n",
      "f1  score for fold 653:  0.43478260869565216\n",
      "recall for fold 653:  0.4268292682926829\n",
      "precision for fold 653:  0.4430379746835443\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 654:  0.5595854922279793\n",
      "f1  score for fold 654:  0.4720496894409938\n",
      "recall for fold 654:  0.4367816091954023\n",
      "precision for fold 654:  0.5135135135135135\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 655:  0.5215311004784688\n",
      "f1  score for fold 655:  0.36708860759493667\n",
      "recall for fold 655:  0.3717948717948718\n",
      "precision for fold 655:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 656:  0.5789473684210527\n",
      "f1  score for fold 656:  0.42857142857142855\n",
      "recall for fold 656:  0.44594594594594594\n",
      "precision for fold 656:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 657:  0.5380952380952381\n",
      "f1  score for fold 657:  0.3741935483870968\n",
      "recall for fold 657:  0.38666666666666666\n",
      "precision for fold 657:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 658:  0.5194174757281553\n",
      "f1  score for fold 658:  0.38509316770186336\n",
      "recall for fold 658:  0.3780487804878049\n",
      "precision for fold 658:  0.3924050632911392\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 659:  0.47668393782383417\n",
      "f1  score for fold 659:  0.3726708074534162\n",
      "recall for fold 659:  0.3448275862068966\n",
      "precision for fold 659:  0.40540540540540543\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 660:  0.47368421052631576\n",
      "f1  score for fold 660:  0.3037974683544304\n",
      "recall for fold 660:  0.3076923076923077\n",
      "precision for fold 660:  0.3\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 661:  0.5215311004784688\n",
      "f1  score for fold 661:  0.3506493506493507\n",
      "recall for fold 661:  0.36486486486486486\n",
      "precision for fold 661:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 662:  0.5095238095238095\n",
      "f1  score for fold 662:  0.335483870967742\n",
      "recall for fold 662:  0.3466666666666667\n",
      "precision for fold 662:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 663:  0.5097087378640777\n",
      "f1  score for fold 663:  0.37267080745341613\n",
      "recall for fold 663:  0.36585365853658536\n",
      "precision for fold 663:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 664:  0.49740932642487046\n",
      "f1  score for fold 664:  0.39751552795031053\n",
      "recall for fold 664:  0.367816091954023\n",
      "precision for fold 664:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 665:  0.5119617224880383\n",
      "f1  score for fold 665:  0.3544303797468355\n",
      "recall for fold 665:  0.358974358974359\n",
      "precision for fold 665:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 666:  0.5598086124401914\n",
      "f1  score for fold 666:  0.40259740259740256\n",
      "recall for fold 666:  0.4189189189189189\n",
      "precision for fold 666:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 667:  0.5\n",
      "f1  score for fold 667:  0.3225806451612903\n",
      "recall for fold 667:  0.3333333333333333\n",
      "precision for fold 667:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 668:  0.5485436893203883\n",
      "f1  score for fold 668:  0.42236024844720493\n",
      "recall for fold 668:  0.4146341463414634\n",
      "precision for fold 668:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 669:  0.48704663212435234\n",
      "f1  score for fold 669:  0.3850931677018633\n",
      "recall for fold 669:  0.3563218390804598\n",
      "precision for fold 669:  0.4189189189189189\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 670:  0.49282296650717705\n",
      "f1  score for fold 670:  0.32911392405063294\n",
      "recall for fold 670:  0.3333333333333333\n",
      "precision for fold 670:  0.325\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 671:  0.5885167464114832\n",
      "f1  score for fold 671:  0.44155844155844154\n",
      "recall for fold 671:  0.4594594594594595\n",
      "precision for fold 671:  0.425\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 672:  0.5476190476190477\n",
      "f1  score for fold 672:  0.38709677419354843\n",
      "recall for fold 672:  0.4\n",
      "precision for fold 672:  0.375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 673:  0.46116504854368934\n",
      "f1  score for fold 673:  0.31055900621118016\n",
      "recall for fold 673:  0.3048780487804878\n",
      "precision for fold 673:  0.31645569620253167\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 674:  0.43523316062176165\n",
      "f1  score for fold 674:  0.3229813664596274\n",
      "recall for fold 674:  0.2988505747126437\n",
      "precision for fold 674:  0.35135135135135137\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 675:  0.5406698564593302\n",
      "f1  score for fold 675:  0.3924050632911393\n",
      "recall for fold 675:  0.3974358974358974\n",
      "precision for fold 675:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 676:  0.49282296650717705\n",
      "f1  score for fold 676:  0.3116883116883117\n",
      "recall for fold 676:  0.32432432432432434\n",
      "precision for fold 676:  0.3\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 677:  0.46190476190476193\n",
      "f1  score for fold 677:  0.2709677419354839\n",
      "recall for fold 677:  0.28\n",
      "precision for fold 677:  0.2625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 678:  0.5388349514563107\n",
      "f1  score for fold 678:  0.40993788819875776\n",
      "recall for fold 678:  0.4024390243902439\n",
      "precision for fold 678:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 679:  0.48704663212435234\n",
      "f1  score for fold 679:  0.3850931677018633\n",
      "recall for fold 679:  0.3563218390804598\n",
      "precision for fold 679:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 680:  0.5311004784688995\n",
      "f1  score for fold 680:  0.37974683544303806\n",
      "recall for fold 680:  0.38461538461538464\n",
      "precision for fold 680:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 681:  0.5119617224880383\n",
      "f1  score for fold 681:  0.33766233766233766\n",
      "recall for fold 681:  0.35135135135135137\n",
      "precision for fold 681:  0.325\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 682:  0.5761904761904761\n",
      "f1  score for fold 682:  0.4258064516129032\n",
      "recall for fold 682:  0.44\n",
      "precision for fold 682:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 683:  0.5097087378640777\n",
      "f1  score for fold 683:  0.37267080745341613\n",
      "recall for fold 683:  0.36585365853658536\n",
      "precision for fold 683:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 684:  0.49740932642487046\n",
      "f1  score for fold 684:  0.39751552795031053\n",
      "recall for fold 684:  0.367816091954023\n",
      "precision for fold 684:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 685:  0.5598086124401914\n",
      "f1  score for fold 685:  0.4177215189873418\n",
      "recall for fold 685:  0.4230769230769231\n",
      "precision for fold 685:  0.4125\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 686:  0.49282296650717705\n",
      "f1  score for fold 686:  0.3116883116883117\n",
      "recall for fold 686:  0.32432432432432434\n",
      "precision for fold 686:  0.3\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 687:  0.49047619047619045\n",
      "f1  score for fold 687:  0.3096774193548387\n",
      "recall for fold 687:  0.32\n",
      "precision for fold 687:  0.3\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 688:  0.48058252427184467\n",
      "f1  score for fold 688:  0.33540372670807456\n",
      "recall for fold 688:  0.32926829268292684\n",
      "precision for fold 688:  0.34177215189873417\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 689:  0.5595854922279793\n",
      "f1  score for fold 689:  0.4720496894409938\n",
      "recall for fold 689:  0.4367816091954023\n",
      "precision for fold 689:  0.5135135135135135\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 690:  0.5023923444976076\n",
      "f1  score for fold 690:  0.34177215189873417\n",
      "recall for fold 690:  0.34615384615384615\n",
      "precision for fold 690:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 691:  0.5023923444976076\n",
      "f1  score for fold 691:  0.3246753246753247\n",
      "recall for fold 691:  0.33783783783783783\n",
      "precision for fold 691:  0.3125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 692:  0.5\n",
      "f1  score for fold 692:  0.3225806451612903\n",
      "recall for fold 692:  0.3333333333333333\n",
      "precision for fold 692:  0.3125\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 693:  0.5679611650485437\n",
      "f1  score for fold 693:  0.4472049689440994\n",
      "recall for fold 693:  0.43902439024390244\n",
      "precision for fold 693:  0.45569620253164556\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 694:  0.5492227979274611\n",
      "f1  score for fold 694:  0.45962732919254656\n",
      "recall for fold 694:  0.42528735632183906\n",
      "precision for fold 694:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 695:  0.5406698564593302\n",
      "f1  score for fold 695:  0.3924050632911393\n",
      "recall for fold 695:  0.3974358974358974\n",
      "precision for fold 695:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 696:  0.5215311004784688\n",
      "f1  score for fold 696:  0.3506493506493507\n",
      "recall for fold 696:  0.36486486486486486\n",
      "precision for fold 696:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 697:  0.5\n",
      "f1  score for fold 697:  0.3225806451612903\n",
      "recall for fold 697:  0.3333333333333333\n",
      "precision for fold 697:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 698:  0.5388349514563107\n",
      "f1  score for fold 698:  0.40993788819875776\n",
      "recall for fold 698:  0.4024390243902439\n",
      "precision for fold 698:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 699:  0.5077720207253886\n",
      "f1  score for fold 699:  0.40993788819875776\n",
      "recall for fold 699:  0.3793103448275862\n",
      "precision for fold 699:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 700:  0.5502392344497608\n",
      "f1  score for fold 700:  0.4050632911392405\n",
      "recall for fold 700:  0.41025641025641024\n",
      "precision for fold 700:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 701:  0.5119617224880383\n",
      "f1  score for fold 701:  0.33766233766233766\n",
      "recall for fold 701:  0.35135135135135137\n",
      "precision for fold 701:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 702:  0.5285714285714286\n",
      "f1  score for fold 702:  0.3612903225806451\n",
      "recall for fold 702:  0.37333333333333335\n",
      "precision for fold 702:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 703:  0.5097087378640777\n",
      "f1  score for fold 703:  0.37267080745341613\n",
      "recall for fold 703:  0.36585365853658536\n",
      "precision for fold 703:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 704:  0.5181347150259067\n",
      "f1  score for fold 704:  0.422360248447205\n",
      "recall for fold 704:  0.39080459770114945\n",
      "precision for fold 704:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 705:  0.5406698564593302\n",
      "f1  score for fold 705:  0.3924050632911393\n",
      "recall for fold 705:  0.3974358974358974\n",
      "precision for fold 705:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 706:  0.5502392344497608\n",
      "f1  score for fold 706:  0.3896103896103896\n",
      "recall for fold 706:  0.40540540540540543\n",
      "precision for fold 706:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 707:  0.5190476190476191\n",
      "f1  score for fold 707:  0.34838709677419355\n",
      "recall for fold 707:  0.36\n",
      "precision for fold 707:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 708:  0.5097087378640777\n",
      "f1  score for fold 708:  0.37267080745341613\n",
      "recall for fold 708:  0.36585365853658536\n",
      "precision for fold 708:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 709:  0.45595854922279794\n",
      "f1  score for fold 709:  0.3478260869565218\n",
      "recall for fold 709:  0.3218390804597701\n",
      "precision for fold 709:  0.3783783783783784\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 710:  0.5502392344497608\n",
      "f1  score for fold 710:  0.4050632911392405\n",
      "recall for fold 710:  0.41025641025641024\n",
      "precision for fold 710:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 711:  0.5119617224880383\n",
      "f1  score for fold 711:  0.33766233766233766\n",
      "recall for fold 711:  0.35135135135135137\n",
      "precision for fold 711:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 712:  0.5380952380952381\n",
      "f1  score for fold 712:  0.3741935483870968\n",
      "recall for fold 712:  0.38666666666666666\n",
      "precision for fold 712:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 713:  0.558252427184466\n",
      "f1  score for fold 713:  0.43478260869565216\n",
      "recall for fold 713:  0.4268292682926829\n",
      "precision for fold 713:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 714:  0.538860103626943\n",
      "f1  score for fold 714:  0.4472049689440994\n",
      "recall for fold 714:  0.41379310344827586\n",
      "precision for fold 714:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 715:  0.5406698564593302\n",
      "f1  score for fold 715:  0.3924050632911393\n",
      "recall for fold 715:  0.3974358974358974\n",
      "precision for fold 715:  0.3875\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 716:  0.5789473684210527\n",
      "f1  score for fold 716:  0.42857142857142855\n",
      "recall for fold 716:  0.44594594594594594\n",
      "precision for fold 716:  0.4125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 717:  0.5571428571428572\n",
      "f1  score for fold 717:  0.4000000000000001\n",
      "recall for fold 717:  0.41333333333333333\n",
      "precision for fold 717:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 718:  0.529126213592233\n",
      "f1  score for fold 718:  0.39751552795031053\n",
      "recall for fold 718:  0.3902439024390244\n",
      "precision for fold 718:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 719:  0.5181347150259067\n",
      "f1  score for fold 719:  0.422360248447205\n",
      "recall for fold 719:  0.39080459770114945\n",
      "precision for fold 719:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 720:  0.5215311004784688\n",
      "f1  score for fold 720:  0.36708860759493667\n",
      "recall for fold 720:  0.3717948717948718\n",
      "precision for fold 720:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 721:  0.47368421052631576\n",
      "f1  score for fold 721:  0.28571428571428575\n",
      "recall for fold 721:  0.2972972972972973\n",
      "precision for fold 721:  0.275\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 722:  0.6047619047619047\n",
      "f1  score for fold 722:  0.4645161290322581\n",
      "recall for fold 722:  0.48\n",
      "precision for fold 722:  0.45\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 723:  0.48058252427184467\n",
      "f1  score for fold 723:  0.33540372670807456\n",
      "recall for fold 723:  0.32926829268292684\n",
      "precision for fold 723:  0.34177215189873417\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 724:  0.5492227979274611\n",
      "f1  score for fold 724:  0.45962732919254656\n",
      "recall for fold 724:  0.42528735632183906\n",
      "precision for fold 724:  0.5\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 725:  0.47368421052631576\n",
      "f1  score for fold 725:  0.3037974683544304\n",
      "recall for fold 725:  0.3076923076923077\n",
      "precision for fold 725:  0.3\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 726:  0.5406698564593302\n",
      "f1  score for fold 726:  0.37662337662337664\n",
      "recall for fold 726:  0.3918918918918919\n",
      "precision for fold 726:  0.3625\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 727:  0.48095238095238096\n",
      "f1  score for fold 727:  0.2967741935483871\n",
      "recall for fold 727:  0.30666666666666664\n",
      "precision for fold 727:  0.2875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 728:  0.529126213592233\n",
      "f1  score for fold 728:  0.39751552795031053\n",
      "recall for fold 728:  0.3902439024390244\n",
      "precision for fold 728:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 729:  0.48704663212435234\n",
      "f1  score for fold 729:  0.3850931677018633\n",
      "recall for fold 729:  0.3563218390804598\n",
      "precision for fold 729:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 730:  0.48325358851674644\n",
      "f1  score for fold 730:  0.31645569620253167\n",
      "recall for fold 730:  0.32051282051282054\n",
      "precision for fold 730:  0.3125\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 731:  0.6172248803827751\n",
      "f1  score for fold 731:  0.4805194805194805\n",
      "recall for fold 731:  0.5\n",
      "precision for fold 731:  0.4625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 732:  0.5095238095238095\n",
      "f1  score for fold 732:  0.335483870967742\n",
      "recall for fold 732:  0.3466666666666667\n",
      "precision for fold 732:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 733:  0.529126213592233\n",
      "f1  score for fold 733:  0.39751552795031053\n",
      "recall for fold 733:  0.3902439024390244\n",
      "precision for fold 733:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 734:  0.538860103626943\n",
      "f1  score for fold 734:  0.4472049689440994\n",
      "recall for fold 734:  0.41379310344827586\n",
      "precision for fold 734:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 735:  0.5215311004784688\n",
      "f1  score for fold 735:  0.36708860759493667\n",
      "recall for fold 735:  0.3717948717948718\n",
      "precision for fold 735:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 736:  0.5406698564593302\n",
      "f1  score for fold 736:  0.37662337662337664\n",
      "recall for fold 736:  0.3918918918918919\n",
      "precision for fold 736:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 737:  0.5285714285714286\n",
      "f1  score for fold 737:  0.3612903225806451\n",
      "recall for fold 737:  0.37333333333333335\n",
      "precision for fold 737:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 738:  0.5194174757281553\n",
      "f1  score for fold 738:  0.38509316770186336\n",
      "recall for fold 738:  0.3780487804878049\n",
      "precision for fold 738:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 739:  0.5595854922279793\n",
      "f1  score for fold 739:  0.4720496894409938\n",
      "recall for fold 739:  0.4367816091954023\n",
      "precision for fold 739:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 740:  0.5598086124401914\n",
      "f1  score for fold 740:  0.4177215189873418\n",
      "recall for fold 740:  0.4230769230769231\n",
      "precision for fold 740:  0.4125\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 741:  0.48325358851674644\n",
      "f1  score for fold 741:  0.29870129870129863\n",
      "recall for fold 741:  0.3108108108108108\n",
      "precision for fold 741:  0.2875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 742:  0.5761904761904761\n",
      "f1  score for fold 742:  0.4258064516129032\n",
      "recall for fold 742:  0.44\n",
      "precision for fold 742:  0.4125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 743:  0.5\n",
      "f1  score for fold 743:  0.3602484472049689\n",
      "recall for fold 743:  0.35365853658536583\n",
      "precision for fold 743:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 744:  0.5284974093264249\n",
      "f1  score for fold 744:  0.4347826086956522\n",
      "recall for fold 744:  0.40229885057471265\n",
      "precision for fold 744:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 745:  0.5311004784688995\n",
      "f1  score for fold 745:  0.37974683544303806\n",
      "recall for fold 745:  0.38461538461538464\n",
      "precision for fold 745:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 746:  0.5598086124401914\n",
      "f1  score for fold 746:  0.40259740259740256\n",
      "recall for fold 746:  0.4189189189189189\n",
      "precision for fold 746:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 747:  0.5476190476190477\n",
      "f1  score for fold 747:  0.38709677419354843\n",
      "recall for fold 747:  0.4\n",
      "precision for fold 747:  0.375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 748:  0.48058252427184467\n",
      "f1  score for fold 748:  0.33540372670807456\n",
      "recall for fold 748:  0.32926829268292684\n",
      "precision for fold 748:  0.34177215189873417\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 749:  0.46632124352331605\n",
      "f1  score for fold 749:  0.36024844720496896\n",
      "recall for fold 749:  0.3333333333333333\n",
      "precision for fold 749:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 750:  0.49282296650717705\n",
      "f1  score for fold 750:  0.32911392405063294\n",
      "recall for fold 750:  0.3333333333333333\n",
      "precision for fold 750:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 751:  0.5215311004784688\n",
      "f1  score for fold 751:  0.3506493506493507\n",
      "recall for fold 751:  0.36486486486486486\n",
      "precision for fold 751:  0.3375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 752:  0.48095238095238096\n",
      "f1  score for fold 752:  0.2967741935483871\n",
      "recall for fold 752:  0.30666666666666664\n",
      "precision for fold 752:  0.2875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 753:  0.5485436893203883\n",
      "f1  score for fold 753:  0.42236024844720493\n",
      "recall for fold 753:  0.4146341463414634\n",
      "precision for fold 753:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 754:  0.538860103626943\n",
      "f1  score for fold 754:  0.4472049689440994\n",
      "recall for fold 754:  0.41379310344827586\n",
      "precision for fold 754:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 755:  0.5119617224880383\n",
      "f1  score for fold 755:  0.3544303797468355\n",
      "recall for fold 755:  0.358974358974359\n",
      "precision for fold 755:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 756:  0.5406698564593302\n",
      "f1  score for fold 756:  0.37662337662337664\n",
      "recall for fold 756:  0.3918918918918919\n",
      "precision for fold 756:  0.3625\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 757:  0.5\n",
      "f1  score for fold 757:  0.3225806451612903\n",
      "recall for fold 757:  0.3333333333333333\n",
      "precision for fold 757:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 758:  0.529126213592233\n",
      "f1  score for fold 758:  0.39751552795031053\n",
      "recall for fold 758:  0.3902439024390244\n",
      "precision for fold 758:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 759:  0.48704663212435234\n",
      "f1  score for fold 759:  0.3850931677018633\n",
      "recall for fold 759:  0.3563218390804598\n",
      "precision for fold 759:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 760:  0.5215311004784688\n",
      "f1  score for fold 760:  0.36708860759493667\n",
      "recall for fold 760:  0.3717948717948718\n",
      "precision for fold 760:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 761:  0.5789473684210527\n",
      "f1  score for fold 761:  0.42857142857142855\n",
      "recall for fold 761:  0.44594594594594594\n",
      "precision for fold 761:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 762:  0.5380952380952381\n",
      "f1  score for fold 762:  0.3741935483870968\n",
      "recall for fold 762:  0.38666666666666666\n",
      "precision for fold 762:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 763:  0.558252427184466\n",
      "f1  score for fold 763:  0.43478260869565216\n",
      "recall for fold 763:  0.4268292682926829\n",
      "precision for fold 763:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 764:  0.5284974093264249\n",
      "f1  score for fold 764:  0.4347826086956522\n",
      "recall for fold 764:  0.40229885057471265\n",
      "precision for fold 764:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 765:  0.5311004784688995\n",
      "f1  score for fold 765:  0.37974683544303806\n",
      "recall for fold 765:  0.38461538461538464\n",
      "precision for fold 765:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 766:  0.569377990430622\n",
      "f1  score for fold 766:  0.4155844155844156\n",
      "recall for fold 766:  0.43243243243243246\n",
      "precision for fold 766:  0.4\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 767:  0.6142857142857143\n",
      "f1  score for fold 767:  0.47741935483870973\n",
      "recall for fold 767:  0.49333333333333335\n",
      "precision for fold 767:  0.4625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 768:  0.5097087378640777\n",
      "f1  score for fold 768:  0.37267080745341613\n",
      "recall for fold 768:  0.36585365853658536\n",
      "precision for fold 768:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 769:  0.46632124352331605\n",
      "f1  score for fold 769:  0.36024844720496896\n",
      "recall for fold 769:  0.3333333333333333\n",
      "precision for fold 769:  0.3918918918918919\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 770:  0.5215311004784688\n",
      "f1  score for fold 770:  0.36708860759493667\n",
      "recall for fold 770:  0.3717948717948718\n",
      "precision for fold 770:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 771:  0.5502392344497608\n",
      "f1  score for fold 771:  0.3896103896103896\n",
      "recall for fold 771:  0.40540540540540543\n",
      "precision for fold 771:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 772:  0.5095238095238095\n",
      "f1  score for fold 772:  0.335483870967742\n",
      "recall for fold 772:  0.3466666666666667\n",
      "precision for fold 772:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 773:  0.5679611650485437\n",
      "f1  score for fold 773:  0.4472049689440994\n",
      "recall for fold 773:  0.43902439024390244\n",
      "precision for fold 773:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 774:  0.5284974093264249\n",
      "f1  score for fold 774:  0.4347826086956522\n",
      "recall for fold 774:  0.40229885057471265\n",
      "precision for fold 774:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 775:  0.5119617224880383\n",
      "f1  score for fold 775:  0.3544303797468355\n",
      "recall for fold 775:  0.358974358974359\n",
      "precision for fold 775:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 776:  0.5502392344497608\n",
      "f1  score for fold 776:  0.3896103896103896\n",
      "recall for fold 776:  0.40540540540540543\n",
      "precision for fold 776:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 777:  0.5380952380952381\n",
      "f1  score for fold 777:  0.3741935483870968\n",
      "recall for fold 777:  0.38666666666666666\n",
      "precision for fold 777:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 778:  0.5388349514563107\n",
      "f1  score for fold 778:  0.40993788819875776\n",
      "recall for fold 778:  0.4024390243902439\n",
      "precision for fold 778:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 779:  0.48704663212435234\n",
      "f1  score for fold 779:  0.3850931677018633\n",
      "recall for fold 779:  0.3563218390804598\n",
      "precision for fold 779:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 780:  0.5311004784688995\n",
      "f1  score for fold 780:  0.37974683544303806\n",
      "recall for fold 780:  0.38461538461538464\n",
      "precision for fold 780:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 781:  0.5311004784688995\n",
      "f1  score for fold 781:  0.36363636363636365\n",
      "recall for fold 781:  0.3783783783783784\n",
      "precision for fold 781:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 782:  0.5761904761904761\n",
      "f1  score for fold 782:  0.4258064516129032\n",
      "recall for fold 782:  0.44\n",
      "precision for fold 782:  0.4125\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 783:  0.587378640776699\n",
      "f1  score for fold 783:  0.4720496894409938\n",
      "recall for fold 783:  0.4634146341463415\n",
      "precision for fold 783:  0.4810126582278481\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 784:  0.5284974093264249\n",
      "f1  score for fold 784:  0.4347826086956522\n",
      "recall for fold 784:  0.40229885057471265\n",
      "precision for fold 784:  0.47297297297297297\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 785:  0.47368421052631576\n",
      "f1  score for fold 785:  0.3037974683544304\n",
      "recall for fold 785:  0.3076923076923077\n",
      "precision for fold 785:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 786:  0.5502392344497608\n",
      "f1  score for fold 786:  0.3896103896103896\n",
      "recall for fold 786:  0.40540540540540543\n",
      "precision for fold 786:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 787:  0.5285714285714286\n",
      "f1  score for fold 787:  0.3612903225806451\n",
      "recall for fold 787:  0.37333333333333335\n",
      "precision for fold 787:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 788:  0.558252427184466\n",
      "f1  score for fold 788:  0.43478260869565216\n",
      "recall for fold 788:  0.4268292682926829\n",
      "precision for fold 788:  0.4430379746835443\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 789:  0.45595854922279794\n",
      "f1  score for fold 789:  0.3478260869565218\n",
      "recall for fold 789:  0.3218390804597701\n",
      "precision for fold 789:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 790:  0.5406698564593302\n",
      "f1  score for fold 790:  0.3924050632911393\n",
      "recall for fold 790:  0.3974358974358974\n",
      "precision for fold 790:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 791:  0.5406698564593302\n",
      "f1  score for fold 791:  0.37662337662337664\n",
      "recall for fold 791:  0.3918918918918919\n",
      "precision for fold 791:  0.3625\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 792:  0.5952380952380952\n",
      "f1  score for fold 792:  0.45161290322580644\n",
      "recall for fold 792:  0.4666666666666667\n",
      "precision for fold 792:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 793:  0.5485436893203883\n",
      "f1  score for fold 793:  0.42236024844720493\n",
      "recall for fold 793:  0.4146341463414634\n",
      "precision for fold 793:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 794:  0.49740932642487046\n",
      "f1  score for fold 794:  0.39751552795031053\n",
      "recall for fold 794:  0.367816091954023\n",
      "precision for fold 794:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 795:  0.5311004784688995\n",
      "f1  score for fold 795:  0.37974683544303806\n",
      "recall for fold 795:  0.38461538461538464\n",
      "precision for fold 795:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 796:  0.5502392344497608\n",
      "f1  score for fold 796:  0.3896103896103896\n",
      "recall for fold 796:  0.40540540540540543\n",
      "precision for fold 796:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 797:  0.5476190476190477\n",
      "f1  score for fold 797:  0.38709677419354843\n",
      "recall for fold 797:  0.4\n",
      "precision for fold 797:  0.375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 798:  0.5\n",
      "f1  score for fold 798:  0.3602484472049689\n",
      "recall for fold 798:  0.35365853658536583\n",
      "precision for fold 798:  0.3670886075949367\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 799:  0.43523316062176165\n",
      "f1  score for fold 799:  0.3229813664596274\n",
      "recall for fold 799:  0.2988505747126437\n",
      "precision for fold 799:  0.35135135135135137\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 800:  0.47368421052631576\n",
      "f1  score for fold 800:  0.3037974683544304\n",
      "recall for fold 800:  0.3076923076923077\n",
      "precision for fold 800:  0.3\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 801:  0.49282296650717705\n",
      "f1  score for fold 801:  0.3116883116883117\n",
      "recall for fold 801:  0.32432432432432434\n",
      "precision for fold 801:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 802:  0.5095238095238095\n",
      "f1  score for fold 802:  0.335483870967742\n",
      "recall for fold 802:  0.3466666666666667\n",
      "precision for fold 802:  0.325\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 803:  0.441747572815534\n",
      "f1  score for fold 803:  0.28571428571428575\n",
      "recall for fold 803:  0.2804878048780488\n",
      "precision for fold 803:  0.2911392405063291\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 804:  0.538860103626943\n",
      "f1  score for fold 804:  0.4472049689440994\n",
      "recall for fold 804:  0.41379310344827586\n",
      "precision for fold 804:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 805:  0.5406698564593302\n",
      "f1  score for fold 805:  0.3924050632911393\n",
      "recall for fold 805:  0.3974358974358974\n",
      "precision for fold 805:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 806:  0.5311004784688995\n",
      "f1  score for fold 806:  0.36363636363636365\n",
      "recall for fold 806:  0.3783783783783784\n",
      "precision for fold 806:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 807:  0.5476190476190477\n",
      "f1  score for fold 807:  0.38709677419354843\n",
      "recall for fold 807:  0.4\n",
      "precision for fold 807:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 808:  0.470873786407767\n",
      "f1  score for fold 808:  0.3229813664596273\n",
      "recall for fold 808:  0.3170731707317073\n",
      "precision for fold 808:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 809:  0.538860103626943\n",
      "f1  score for fold 809:  0.4472049689440994\n",
      "recall for fold 809:  0.41379310344827586\n",
      "precision for fold 809:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 810:  0.569377990430622\n",
      "f1  score for fold 810:  0.43037974683544306\n",
      "recall for fold 810:  0.4358974358974359\n",
      "precision for fold 810:  0.425\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 811:  0.49282296650717705\n",
      "f1  score for fold 811:  0.3116883116883117\n",
      "recall for fold 811:  0.32432432432432434\n",
      "precision for fold 811:  0.3\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 812:  0.5285714285714286\n",
      "f1  score for fold 812:  0.3612903225806451\n",
      "recall for fold 812:  0.37333333333333335\n",
      "precision for fold 812:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 813:  0.5194174757281553\n",
      "f1  score for fold 813:  0.38509316770186336\n",
      "recall for fold 813:  0.3780487804878049\n",
      "precision for fold 813:  0.3924050632911392\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 814:  0.45595854922279794\n",
      "f1  score for fold 814:  0.3478260869565218\n",
      "recall for fold 814:  0.3218390804597701\n",
      "precision for fold 814:  0.3783783783783784\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 815:  0.5598086124401914\n",
      "f1  score for fold 815:  0.4177215189873418\n",
      "recall for fold 815:  0.4230769230769231\n",
      "precision for fold 815:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 816:  0.5502392344497608\n",
      "f1  score for fold 816:  0.3896103896103896\n",
      "recall for fold 816:  0.40540540540540543\n",
      "precision for fold 816:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 817:  0.5571428571428572\n",
      "f1  score for fold 817:  0.4000000000000001\n",
      "recall for fold 817:  0.41333333333333333\n",
      "precision for fold 817:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 818:  0.5097087378640777\n",
      "f1  score for fold 818:  0.37267080745341613\n",
      "recall for fold 818:  0.36585365853658536\n",
      "precision for fold 818:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 819:  0.49740932642487046\n",
      "f1  score for fold 819:  0.39751552795031053\n",
      "recall for fold 819:  0.367816091954023\n",
      "precision for fold 819:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 820:  0.5311004784688995\n",
      "f1  score for fold 820:  0.37974683544303806\n",
      "recall for fold 820:  0.38461538461538464\n",
      "precision for fold 820:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 821:  0.5215311004784688\n",
      "f1  score for fold 821:  0.3506493506493507\n",
      "recall for fold 821:  0.36486486486486486\n",
      "precision for fold 821:  0.3375\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 822:  0.6142857142857143\n",
      "f1  score for fold 822:  0.47741935483870973\n",
      "recall for fold 822:  0.49333333333333335\n",
      "precision for fold 822:  0.4625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 823:  0.5194174757281553\n",
      "f1  score for fold 823:  0.38509316770186336\n",
      "recall for fold 823:  0.3780487804878049\n",
      "precision for fold 823:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 824:  0.49740932642487046\n",
      "f1  score for fold 824:  0.39751552795031053\n",
      "recall for fold 824:  0.367816091954023\n",
      "precision for fold 824:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 825:  0.5119617224880383\n",
      "f1  score for fold 825:  0.3544303797468355\n",
      "recall for fold 825:  0.358974358974359\n",
      "precision for fold 825:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 826:  0.5311004784688995\n",
      "f1  score for fold 826:  0.36363636363636365\n",
      "recall for fold 826:  0.3783783783783784\n",
      "precision for fold 826:  0.35\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 827:  0.5666666666666667\n",
      "f1  score for fold 827:  0.41290322580645167\n",
      "recall for fold 827:  0.4266666666666667\n",
      "precision for fold 827:  0.4\n",
      "    0   1\n",
      "0  41  41\n",
      "1  38  86\n",
      "Accuracy for fold 828:  0.616504854368932\n",
      "f1  score for fold 828:  0.5093167701863354\n",
      "recall for fold 828:  0.5\n",
      "precision for fold 828:  0.5189873417721519\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 829:  0.5284974093264249\n",
      "f1  score for fold 829:  0.4347826086956522\n",
      "recall for fold 829:  0.40229885057471265\n",
      "precision for fold 829:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 830:  0.5406698564593302\n",
      "f1  score for fold 830:  0.3924050632911393\n",
      "recall for fold 830:  0.3974358974358974\n",
      "precision for fold 830:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 831:  0.5311004784688995\n",
      "f1  score for fold 831:  0.36363636363636365\n",
      "recall for fold 831:  0.3783783783783784\n",
      "precision for fold 831:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 832:  0.5190476190476191\n",
      "f1  score for fold 832:  0.34838709677419355\n",
      "recall for fold 832:  0.36\n",
      "precision for fold 832:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 833:  0.5097087378640777\n",
      "f1  score for fold 833:  0.37267080745341613\n",
      "recall for fold 833:  0.36585365853658536\n",
      "precision for fold 833:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 834:  0.5284974093264249\n",
      "f1  score for fold 834:  0.4347826086956522\n",
      "recall for fold 834:  0.40229885057471265\n",
      "precision for fold 834:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 835:  0.5119617224880383\n",
      "f1  score for fold 835:  0.3544303797468355\n",
      "recall for fold 835:  0.358974358974359\n",
      "precision for fold 835:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 836:  0.5119617224880383\n",
      "f1  score for fold 836:  0.33766233766233766\n",
      "recall for fold 836:  0.35135135135135137\n",
      "precision for fold 836:  0.325\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 837:  0.48095238095238096\n",
      "f1  score for fold 837:  0.2967741935483871\n",
      "recall for fold 837:  0.30666666666666664\n",
      "precision for fold 837:  0.2875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 838:  0.5\n",
      "f1  score for fold 838:  0.3602484472049689\n",
      "recall for fold 838:  0.35365853658536583\n",
      "precision for fold 838:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 839:  0.48704663212435234\n",
      "f1  score for fold 839:  0.3850931677018633\n",
      "recall for fold 839:  0.3563218390804598\n",
      "precision for fold 839:  0.4189189189189189\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 840:  0.5789473684210527\n",
      "f1  score for fold 840:  0.44303797468354433\n",
      "recall for fold 840:  0.44871794871794873\n",
      "precision for fold 840:  0.4375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 841:  0.5023923444976076\n",
      "f1  score for fold 841:  0.3246753246753247\n",
      "recall for fold 841:  0.33783783783783783\n",
      "precision for fold 841:  0.3125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 842:  0.49047619047619045\n",
      "f1  score for fold 842:  0.3096774193548387\n",
      "recall for fold 842:  0.32\n",
      "precision for fold 842:  0.3\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 843:  0.5194174757281553\n",
      "f1  score for fold 843:  0.38509316770186336\n",
      "recall for fold 843:  0.3780487804878049\n",
      "precision for fold 843:  0.3924050632911392\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 844:  0.42487046632124353\n",
      "f1  score for fold 844:  0.3105590062111801\n",
      "recall for fold 844:  0.28735632183908044\n",
      "precision for fold 844:  0.33783783783783783\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 845:  0.5119617224880383\n",
      "f1  score for fold 845:  0.3544303797468355\n",
      "recall for fold 845:  0.358974358974359\n",
      "precision for fold 845:  0.35\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 846:  0.5789473684210527\n",
      "f1  score for fold 846:  0.42857142857142855\n",
      "recall for fold 846:  0.44594594594594594\n",
      "precision for fold 846:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 847:  0.5285714285714286\n",
      "f1  score for fold 847:  0.3612903225806451\n",
      "recall for fold 847:  0.37333333333333335\n",
      "precision for fold 847:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 848:  0.558252427184466\n",
      "f1  score for fold 848:  0.43478260869565216\n",
      "recall for fold 848:  0.4268292682926829\n",
      "precision for fold 848:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 849:  0.48704663212435234\n",
      "f1  score for fold 849:  0.3850931677018633\n",
      "recall for fold 849:  0.3563218390804598\n",
      "precision for fold 849:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 850:  0.569377990430622\n",
      "f1  score for fold 850:  0.43037974683544306\n",
      "recall for fold 850:  0.4358974358974359\n",
      "precision for fold 850:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 851:  0.5023923444976076\n",
      "f1  score for fold 851:  0.3246753246753247\n",
      "recall for fold 851:  0.33783783783783783\n",
      "precision for fold 851:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 852:  0.5571428571428572\n",
      "f1  score for fold 852:  0.4000000000000001\n",
      "recall for fold 852:  0.41333333333333333\n",
      "precision for fold 852:  0.3875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 853:  0.49029126213592233\n",
      "f1  score for fold 853:  0.3478260869565218\n",
      "recall for fold 853:  0.34146341463414637\n",
      "precision for fold 853:  0.35443037974683544\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 854:  0.5492227979274611\n",
      "f1  score for fold 854:  0.45962732919254656\n",
      "recall for fold 854:  0.42528735632183906\n",
      "precision for fold 854:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 855:  0.5215311004784688\n",
      "f1  score for fold 855:  0.36708860759493667\n",
      "recall for fold 855:  0.3717948717948718\n",
      "precision for fold 855:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 856:  0.5502392344497608\n",
      "f1  score for fold 856:  0.3896103896103896\n",
      "recall for fold 856:  0.40540540540540543\n",
      "precision for fold 856:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 857:  0.5190476190476191\n",
      "f1  score for fold 857:  0.34838709677419355\n",
      "recall for fold 857:  0.36\n",
      "precision for fold 857:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 858:  0.529126213592233\n",
      "f1  score for fold 858:  0.39751552795031053\n",
      "recall for fold 858:  0.3902439024390244\n",
      "precision for fold 858:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 859:  0.47668393782383417\n",
      "f1  score for fold 859:  0.3726708074534162\n",
      "recall for fold 859:  0.3448275862068966\n",
      "precision for fold 859:  0.40540540540540543\n",
      "    0   1\n",
      "0  20  58\n",
      "1  60  71\n",
      "Accuracy for fold 860:  0.4354066985645933\n",
      "f1  score for fold 860:  0.2531645569620253\n",
      "recall for fold 860:  0.2564102564102564\n",
      "precision for fold 860:  0.25\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 861:  0.569377990430622\n",
      "f1  score for fold 861:  0.4155844155844156\n",
      "recall for fold 861:  0.43243243243243246\n",
      "precision for fold 861:  0.4\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 862:  0.5666666666666667\n",
      "f1  score for fold 862:  0.41290322580645167\n",
      "recall for fold 862:  0.4266666666666667\n",
      "precision for fold 862:  0.4\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 863:  0.46116504854368934\n",
      "f1  score for fold 863:  0.31055900621118016\n",
      "recall for fold 863:  0.3048780487804878\n",
      "precision for fold 863:  0.31645569620253167\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 864:  0.46632124352331605\n",
      "f1  score for fold 864:  0.36024844720496896\n",
      "recall for fold 864:  0.3333333333333333\n",
      "precision for fold 864:  0.3918918918918919\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 865:  0.5980861244019139\n",
      "f1  score for fold 865:  0.46835443037974683\n",
      "recall for fold 865:  0.47435897435897434\n",
      "precision for fold 865:  0.4625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 866:  0.569377990430622\n",
      "f1  score for fold 866:  0.4155844155844156\n",
      "recall for fold 866:  0.43243243243243246\n",
      "precision for fold 866:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 867:  0.5380952380952381\n",
      "f1  score for fold 867:  0.3741935483870968\n",
      "recall for fold 867:  0.38666666666666666\n",
      "precision for fold 867:  0.3625\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 868:  0.45145631067961167\n",
      "f1  score for fold 868:  0.29813664596273287\n",
      "recall for fold 868:  0.2926829268292683\n",
      "precision for fold 868:  0.3037974683544304\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 869:  0.46632124352331605\n",
      "f1  score for fold 869:  0.36024844720496896\n",
      "recall for fold 869:  0.3333333333333333\n",
      "precision for fold 869:  0.3918918918918919\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 870:  0.5311004784688995\n",
      "f1  score for fold 870:  0.37974683544303806\n",
      "recall for fold 870:  0.38461538461538464\n",
      "precision for fold 870:  0.375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 871:  0.48325358851674644\n",
      "f1  score for fold 871:  0.29870129870129863\n",
      "recall for fold 871:  0.3108108108108108\n",
      "precision for fold 871:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 872:  0.5285714285714286\n",
      "f1  score for fold 872:  0.3612903225806451\n",
      "recall for fold 872:  0.37333333333333335\n",
      "precision for fold 872:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 873:  0.5\n",
      "f1  score for fold 873:  0.3602484472049689\n",
      "recall for fold 873:  0.35365853658536583\n",
      "precision for fold 873:  0.3670886075949367\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 874:  0.46632124352331605\n",
      "f1  score for fold 874:  0.36024844720496896\n",
      "recall for fold 874:  0.3333333333333333\n",
      "precision for fold 874:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 875:  0.49282296650717705\n",
      "f1  score for fold 875:  0.32911392405063294\n",
      "recall for fold 875:  0.3333333333333333\n",
      "precision for fold 875:  0.325\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 876:  0.5119617224880383\n",
      "f1  score for fold 876:  0.33766233766233766\n",
      "recall for fold 876:  0.35135135135135137\n",
      "precision for fold 876:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 877:  0.5571428571428572\n",
      "f1  score for fold 877:  0.4000000000000001\n",
      "recall for fold 877:  0.41333333333333333\n",
      "precision for fold 877:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 878:  0.5485436893203883\n",
      "f1  score for fold 878:  0.42236024844720493\n",
      "recall for fold 878:  0.4146341463414634\n",
      "precision for fold 878:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 879:  0.49740932642487046\n",
      "f1  score for fold 879:  0.39751552795031053\n",
      "recall for fold 879:  0.367816091954023\n",
      "precision for fold 879:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 880:  0.49282296650717705\n",
      "f1  score for fold 880:  0.32911392405063294\n",
      "recall for fold 880:  0.3333333333333333\n",
      "precision for fold 880:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 881:  0.5406698564593302\n",
      "f1  score for fold 881:  0.37662337662337664\n",
      "recall for fold 881:  0.3918918918918919\n",
      "precision for fold 881:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 882:  0.5190476190476191\n",
      "f1  score for fold 882:  0.34838709677419355\n",
      "recall for fold 882:  0.36\n",
      "precision for fold 882:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 883:  0.558252427184466\n",
      "f1  score for fold 883:  0.43478260869565216\n",
      "recall for fold 883:  0.4268292682926829\n",
      "precision for fold 883:  0.4430379746835443\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 884:  0.5595854922279793\n",
      "f1  score for fold 884:  0.4720496894409938\n",
      "recall for fold 884:  0.4367816091954023\n",
      "precision for fold 884:  0.5135135135135135\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 885:  0.5119617224880383\n",
      "f1  score for fold 885:  0.3544303797468355\n",
      "recall for fold 885:  0.358974358974359\n",
      "precision for fold 885:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 886:  0.5311004784688995\n",
      "f1  score for fold 886:  0.36363636363636365\n",
      "recall for fold 886:  0.3783783783783784\n",
      "precision for fold 886:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 887:  0.49047619047619045\n",
      "f1  score for fold 887:  0.3096774193548387\n",
      "recall for fold 887:  0.32\n",
      "precision for fold 887:  0.3\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 888:  0.49029126213592233\n",
      "f1  score for fold 888:  0.3478260869565218\n",
      "recall for fold 888:  0.34146341463414637\n",
      "precision for fold 888:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 889:  0.5077720207253886\n",
      "f1  score for fold 889:  0.40993788819875776\n",
      "recall for fold 889:  0.3793103448275862\n",
      "precision for fold 889:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 890:  0.47368421052631576\n",
      "f1  score for fold 890:  0.3037974683544304\n",
      "recall for fold 890:  0.3076923076923077\n",
      "precision for fold 890:  0.3\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 891:  0.5406698564593302\n",
      "f1  score for fold 891:  0.37662337662337664\n",
      "recall for fold 891:  0.3918918918918919\n",
      "precision for fold 891:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 892:  0.5095238095238095\n",
      "f1  score for fold 892:  0.335483870967742\n",
      "recall for fold 892:  0.3466666666666667\n",
      "precision for fold 892:  0.325\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 893:  0.48058252427184467\n",
      "f1  score for fold 893:  0.33540372670807456\n",
      "recall for fold 893:  0.32926829268292684\n",
      "precision for fold 893:  0.34177215189873417\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 894:  0.44559585492227977\n",
      "f1  score for fold 894:  0.33540372670807456\n",
      "recall for fold 894:  0.3103448275862069\n",
      "precision for fold 894:  0.36486486486486486\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 895:  0.48325358851674644\n",
      "f1  score for fold 895:  0.31645569620253167\n",
      "recall for fold 895:  0.32051282051282054\n",
      "precision for fold 895:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 896:  0.5215311004784688\n",
      "f1  score for fold 896:  0.3506493506493507\n",
      "recall for fold 896:  0.36486486486486486\n",
      "precision for fold 896:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 897:  0.5285714285714286\n",
      "f1  score for fold 897:  0.3612903225806451\n",
      "recall for fold 897:  0.37333333333333335\n",
      "precision for fold 897:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 898:  0.5194174757281553\n",
      "f1  score for fold 898:  0.38509316770186336\n",
      "recall for fold 898:  0.3780487804878049\n",
      "precision for fold 898:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 899:  0.5077720207253886\n",
      "f1  score for fold 899:  0.40993788819875776\n",
      "recall for fold 899:  0.3793103448275862\n",
      "precision for fold 899:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 900:  0.5502392344497608\n",
      "f1  score for fold 900:  0.4050632911392405\n",
      "recall for fold 900:  0.41025641025641024\n",
      "precision for fold 900:  0.4\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 901:  0.49282296650717705\n",
      "f1  score for fold 901:  0.3116883116883117\n",
      "recall for fold 901:  0.32432432432432434\n",
      "precision for fold 901:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 902:  0.5\n",
      "f1  score for fold 902:  0.3225806451612903\n",
      "recall for fold 902:  0.3333333333333333\n",
      "precision for fold 902:  0.3125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 903:  0.48058252427184467\n",
      "f1  score for fold 903:  0.33540372670807456\n",
      "recall for fold 903:  0.32926829268292684\n",
      "precision for fold 903:  0.34177215189873417\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 904:  0.47668393782383417\n",
      "f1  score for fold 904:  0.3726708074534162\n",
      "recall for fold 904:  0.3448275862068966\n",
      "precision for fold 904:  0.40540540540540543\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 905:  0.569377990430622\n",
      "f1  score for fold 905:  0.43037974683544306\n",
      "recall for fold 905:  0.4358974358974359\n",
      "precision for fold 905:  0.425\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 906:  0.5598086124401914\n",
      "f1  score for fold 906:  0.40259740259740256\n",
      "recall for fold 906:  0.4189189189189189\n",
      "precision for fold 906:  0.3875\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 907:  0.5952380952380952\n",
      "f1  score for fold 907:  0.45161290322580644\n",
      "recall for fold 907:  0.4666666666666667\n",
      "precision for fold 907:  0.4375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 908:  0.5194174757281553\n",
      "f1  score for fold 908:  0.38509316770186336\n",
      "recall for fold 908:  0.3780487804878049\n",
      "precision for fold 908:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 909:  0.5595854922279793\n",
      "f1  score for fold 909:  0.4720496894409938\n",
      "recall for fold 909:  0.4367816091954023\n",
      "precision for fold 909:  0.5135135135135135\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 910:  0.5215311004784688\n",
      "f1  score for fold 910:  0.36708860759493667\n",
      "recall for fold 910:  0.3717948717948718\n",
      "precision for fold 910:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 911:  0.49282296650717705\n",
      "f1  score for fold 911:  0.3116883116883117\n",
      "recall for fold 911:  0.32432432432432434\n",
      "precision for fold 911:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 912:  0.5476190476190477\n",
      "f1  score for fold 912:  0.38709677419354843\n",
      "recall for fold 912:  0.4\n",
      "precision for fold 912:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 913:  0.5194174757281553\n",
      "f1  score for fold 913:  0.38509316770186336\n",
      "recall for fold 913:  0.3780487804878049\n",
      "precision for fold 913:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 914:  0.5077720207253886\n",
      "f1  score for fold 914:  0.40993788819875776\n",
      "recall for fold 914:  0.3793103448275862\n",
      "precision for fold 914:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 915:  0.569377990430622\n",
      "f1  score for fold 915:  0.43037974683544306\n",
      "recall for fold 915:  0.4358974358974359\n",
      "precision for fold 915:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 916:  0.5502392344497608\n",
      "f1  score for fold 916:  0.3896103896103896\n",
      "recall for fold 916:  0.40540540540540543\n",
      "precision for fold 916:  0.375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 917:  0.49047619047619045\n",
      "f1  score for fold 917:  0.3096774193548387\n",
      "recall for fold 917:  0.32\n",
      "precision for fold 917:  0.3\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 918:  0.5485436893203883\n",
      "f1  score for fold 918:  0.42236024844720493\n",
      "recall for fold 918:  0.4146341463414634\n",
      "precision for fold 918:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 919:  0.49740932642487046\n",
      "f1  score for fold 919:  0.39751552795031053\n",
      "recall for fold 919:  0.367816091954023\n",
      "precision for fold 919:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 920:  0.5023923444976076\n",
      "f1  score for fold 920:  0.34177215189873417\n",
      "recall for fold 920:  0.34615384615384615\n",
      "precision for fold 920:  0.3375\n",
      "    0   1\n",
      "0  38  36\n",
      "1  42  93\n",
      "Accuracy for fold 921:  0.6267942583732058\n",
      "f1  score for fold 921:  0.4935064935064935\n",
      "recall for fold 921:  0.5135135135135135\n",
      "precision for fold 921:  0.475\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 922:  0.5571428571428572\n",
      "f1  score for fold 922:  0.4000000000000001\n",
      "recall for fold 922:  0.41333333333333333\n",
      "precision for fold 922:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 923:  0.529126213592233\n",
      "f1  score for fold 923:  0.39751552795031053\n",
      "recall for fold 923:  0.3902439024390244\n",
      "precision for fold 923:  0.4050632911392405\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 924:  0.5492227979274611\n",
      "f1  score for fold 924:  0.45962732919254656\n",
      "recall for fold 924:  0.42528735632183906\n",
      "precision for fold 924:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 925:  0.49282296650717705\n",
      "f1  score for fold 925:  0.32911392405063294\n",
      "recall for fold 925:  0.3333333333333333\n",
      "precision for fold 925:  0.325\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 926:  0.48325358851674644\n",
      "f1  score for fold 926:  0.29870129870129863\n",
      "recall for fold 926:  0.3108108108108108\n",
      "precision for fold 926:  0.2875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 927:  0.5761904761904761\n",
      "f1  score for fold 927:  0.4258064516129032\n",
      "recall for fold 927:  0.44\n",
      "precision for fold 927:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 928:  0.5194174757281553\n",
      "f1  score for fold 928:  0.38509316770186336\n",
      "recall for fold 928:  0.3780487804878049\n",
      "precision for fold 928:  0.3924050632911392\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 929:  0.43523316062176165\n",
      "f1  score for fold 929:  0.3229813664596274\n",
      "recall for fold 929:  0.2988505747126437\n",
      "precision for fold 929:  0.35135135135135137\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 930:  0.5598086124401914\n",
      "f1  score for fold 930:  0.4177215189873418\n",
      "recall for fold 930:  0.4230769230769231\n",
      "precision for fold 930:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 931:  0.5502392344497608\n",
      "f1  score for fold 931:  0.3896103896103896\n",
      "recall for fold 931:  0.40540540540540543\n",
      "precision for fold 931:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 932:  0.5285714285714286\n",
      "f1  score for fold 932:  0.3612903225806451\n",
      "recall for fold 932:  0.37333333333333335\n",
      "precision for fold 932:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 933:  0.49029126213592233\n",
      "f1  score for fold 933:  0.3478260869565218\n",
      "recall for fold 933:  0.34146341463414637\n",
      "precision for fold 933:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 934:  0.5181347150259067\n",
      "f1  score for fold 934:  0.422360248447205\n",
      "recall for fold 934:  0.39080459770114945\n",
      "precision for fold 934:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 935:  0.5215311004784688\n",
      "f1  score for fold 935:  0.36708860759493667\n",
      "recall for fold 935:  0.3717948717948718\n",
      "precision for fold 935:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 936:  0.49282296650717705\n",
      "f1  score for fold 936:  0.3116883116883117\n",
      "recall for fold 936:  0.32432432432432434\n",
      "precision for fold 936:  0.3\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 937:  0.5952380952380952\n",
      "f1  score for fold 937:  0.45161290322580644\n",
      "recall for fold 937:  0.4666666666666667\n",
      "precision for fold 937:  0.4375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 938:  0.5194174757281553\n",
      "f1  score for fold 938:  0.38509316770186336\n",
      "recall for fold 938:  0.3780487804878049\n",
      "precision for fold 938:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 939:  0.5284974093264249\n",
      "f1  score for fold 939:  0.4347826086956522\n",
      "recall for fold 939:  0.40229885057471265\n",
      "precision for fold 939:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 940:  0.5502392344497608\n",
      "f1  score for fold 940:  0.4050632911392405\n",
      "recall for fold 940:  0.41025641025641024\n",
      "precision for fold 940:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 941:  0.5311004784688995\n",
      "f1  score for fold 941:  0.36363636363636365\n",
      "recall for fold 941:  0.3783783783783784\n",
      "precision for fold 941:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 942:  0.5285714285714286\n",
      "f1  score for fold 942:  0.3612903225806451\n",
      "recall for fold 942:  0.37333333333333335\n",
      "precision for fold 942:  0.35\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 943:  0.46116504854368934\n",
      "f1  score for fold 943:  0.31055900621118016\n",
      "recall for fold 943:  0.3048780487804878\n",
      "precision for fold 943:  0.31645569620253167\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 944:  0.49740932642487046\n",
      "f1  score for fold 944:  0.39751552795031053\n",
      "recall for fold 944:  0.367816091954023\n",
      "precision for fold 944:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 945:  0.5119617224880383\n",
      "f1  score for fold 945:  0.3544303797468355\n",
      "recall for fold 945:  0.358974358974359\n",
      "precision for fold 945:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 946:  0.5502392344497608\n",
      "f1  score for fold 946:  0.3896103896103896\n",
      "recall for fold 946:  0.40540540540540543\n",
      "precision for fold 946:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 947:  0.5476190476190477\n",
      "f1  score for fold 947:  0.38709677419354843\n",
      "recall for fold 947:  0.4\n",
      "precision for fold 947:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 948:  0.470873786407767\n",
      "f1  score for fold 948:  0.3229813664596273\n",
      "recall for fold 948:  0.3170731707317073\n",
      "precision for fold 948:  0.3291139240506329\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 949:  0.5284974093264249\n",
      "f1  score for fold 949:  0.4347826086956522\n",
      "recall for fold 949:  0.40229885057471265\n",
      "precision for fold 949:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 950:  0.49282296650717705\n",
      "f1  score for fold 950:  0.32911392405063294\n",
      "recall for fold 950:  0.3333333333333333\n",
      "precision for fold 950:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 951:  0.5406698564593302\n",
      "f1  score for fold 951:  0.37662337662337664\n",
      "recall for fold 951:  0.3918918918918919\n",
      "precision for fold 951:  0.3625\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 952:  0.4714285714285714\n",
      "f1  score for fold 952:  0.2838709677419355\n",
      "recall for fold 952:  0.29333333333333333\n",
      "precision for fold 952:  0.275\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 953:  0.5\n",
      "f1  score for fold 953:  0.3602484472049689\n",
      "recall for fold 953:  0.35365853658536583\n",
      "precision for fold 953:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 954:  0.5181347150259067\n",
      "f1  score for fold 954:  0.422360248447205\n",
      "recall for fold 954:  0.39080459770114945\n",
      "precision for fold 954:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 955:  0.5023923444976076\n",
      "f1  score for fold 955:  0.34177215189873417\n",
      "recall for fold 955:  0.34615384615384615\n",
      "precision for fold 955:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 956:  0.5215311004784688\n",
      "f1  score for fold 956:  0.3506493506493507\n",
      "recall for fold 956:  0.36486486486486486\n",
      "precision for fold 956:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 957:  0.5190476190476191\n",
      "f1  score for fold 957:  0.34838709677419355\n",
      "recall for fold 957:  0.36\n",
      "precision for fold 957:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 958:  0.5097087378640777\n",
      "f1  score for fold 958:  0.37267080745341613\n",
      "recall for fold 958:  0.36585365853658536\n",
      "precision for fold 958:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 959:  0.5181347150259067\n",
      "f1  score for fold 959:  0.422360248447205\n",
      "recall for fold 959:  0.39080459770114945\n",
      "precision for fold 959:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 960:  0.48325358851674644\n",
      "f1  score for fold 960:  0.31645569620253167\n",
      "recall for fold 960:  0.32051282051282054\n",
      "precision for fold 960:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 961:  0.5215311004784688\n",
      "f1  score for fold 961:  0.3506493506493507\n",
      "recall for fold 961:  0.36486486486486486\n",
      "precision for fold 961:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 962:  0.5571428571428572\n",
      "f1  score for fold 962:  0.4000000000000001\n",
      "recall for fold 962:  0.41333333333333333\n",
      "precision for fold 962:  0.3875\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 963:  0.587378640776699\n",
      "f1  score for fold 963:  0.4720496894409938\n",
      "recall for fold 963:  0.4634146341463415\n",
      "precision for fold 963:  0.4810126582278481\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 964:  0.5492227979274611\n",
      "f1  score for fold 964:  0.45962732919254656\n",
      "recall for fold 964:  0.42528735632183906\n",
      "precision for fold 964:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 965:  0.5215311004784688\n",
      "f1  score for fold 965:  0.36708860759493667\n",
      "recall for fold 965:  0.3717948717948718\n",
      "precision for fold 965:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 966:  0.5215311004784688\n",
      "f1  score for fold 966:  0.3506493506493507\n",
      "recall for fold 966:  0.36486486486486486\n",
      "precision for fold 966:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 967:  0.5190476190476191\n",
      "f1  score for fold 967:  0.34838709677419355\n",
      "recall for fold 967:  0.36\n",
      "precision for fold 967:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 968:  0.5\n",
      "f1  score for fold 968:  0.3602484472049689\n",
      "recall for fold 968:  0.35365853658536583\n",
      "precision for fold 968:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 969:  0.5077720207253886\n",
      "f1  score for fold 969:  0.40993788819875776\n",
      "recall for fold 969:  0.3793103448275862\n",
      "precision for fold 969:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 970:  0.5598086124401914\n",
      "f1  score for fold 970:  0.4177215189873418\n",
      "recall for fold 970:  0.4230769230769231\n",
      "precision for fold 970:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 971:  0.5215311004784688\n",
      "f1  score for fold 971:  0.3506493506493507\n",
      "recall for fold 971:  0.36486486486486486\n",
      "precision for fold 971:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 972:  0.5285714285714286\n",
      "f1  score for fold 972:  0.3612903225806451\n",
      "recall for fold 972:  0.37333333333333335\n",
      "precision for fold 972:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 973:  0.48058252427184467\n",
      "f1  score for fold 973:  0.33540372670807456\n",
      "recall for fold 973:  0.32926829268292684\n",
      "precision for fold 973:  0.34177215189873417\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 974:  0.45595854922279794\n",
      "f1  score for fold 974:  0.3478260869565218\n",
      "recall for fold 974:  0.3218390804597701\n",
      "precision for fold 974:  0.3783783783783784\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 975:  0.5885167464114832\n",
      "f1  score for fold 975:  0.45569620253164556\n",
      "recall for fold 975:  0.46153846153846156\n",
      "precision for fold 975:  0.45\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 976:  0.5215311004784688\n",
      "f1  score for fold 976:  0.3506493506493507\n",
      "recall for fold 976:  0.36486486486486486\n",
      "precision for fold 976:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 977:  0.5285714285714286\n",
      "f1  score for fold 977:  0.3612903225806451\n",
      "recall for fold 977:  0.37333333333333335\n",
      "precision for fold 977:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 978:  0.5194174757281553\n",
      "f1  score for fold 978:  0.38509316770186336\n",
      "recall for fold 978:  0.3780487804878049\n",
      "precision for fold 978:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 979:  0.5077720207253886\n",
      "f1  score for fold 979:  0.40993788819875776\n",
      "recall for fold 979:  0.3793103448275862\n",
      "precision for fold 979:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 980:  0.5406698564593302\n",
      "f1  score for fold 980:  0.3924050632911393\n",
      "recall for fold 980:  0.3974358974358974\n",
      "precision for fold 980:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 981:  0.5502392344497608\n",
      "f1  score for fold 981:  0.3896103896103896\n",
      "recall for fold 981:  0.40540540540540543\n",
      "precision for fold 981:  0.375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 982:  0.5857142857142857\n",
      "f1  score for fold 982:  0.43870967741935485\n",
      "recall for fold 982:  0.4533333333333333\n",
      "precision for fold 982:  0.425\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 983:  0.587378640776699\n",
      "f1  score for fold 983:  0.4720496894409938\n",
      "recall for fold 983:  0.4634146341463415\n",
      "precision for fold 983:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 984:  0.49740932642487046\n",
      "f1  score for fold 984:  0.39751552795031053\n",
      "recall for fold 984:  0.367816091954023\n",
      "precision for fold 984:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 985:  0.5406698564593302\n",
      "f1  score for fold 985:  0.3924050632911393\n",
      "recall for fold 985:  0.3974358974358974\n",
      "precision for fold 985:  0.3875\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 986:  0.46411483253588515\n",
      "f1  score for fold 986:  0.27272727272727276\n",
      "recall for fold 986:  0.28378378378378377\n",
      "precision for fold 986:  0.2625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 987:  0.5380952380952381\n",
      "f1  score for fold 987:  0.3741935483870968\n",
      "recall for fold 987:  0.38666666666666666\n",
      "precision for fold 987:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 988:  0.5\n",
      "f1  score for fold 988:  0.3602484472049689\n",
      "recall for fold 988:  0.35365853658536583\n",
      "precision for fold 988:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 989:  0.5077720207253886\n",
      "f1  score for fold 989:  0.40993788819875776\n",
      "recall for fold 989:  0.3793103448275862\n",
      "precision for fold 989:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 990:  0.5215311004784688\n",
      "f1  score for fold 990:  0.36708860759493667\n",
      "recall for fold 990:  0.3717948717948718\n",
      "precision for fold 990:  0.3625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 991:  0.569377990430622\n",
      "f1  score for fold 991:  0.4155844155844156\n",
      "recall for fold 991:  0.43243243243243246\n",
      "precision for fold 991:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 992:  0.5095238095238095\n",
      "f1  score for fold 992:  0.335483870967742\n",
      "recall for fold 992:  0.3466666666666667\n",
      "precision for fold 992:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 993:  0.5485436893203883\n",
      "f1  score for fold 993:  0.42236024844720493\n",
      "recall for fold 993:  0.4146341463414634\n",
      "precision for fold 993:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 994:  0.5077720207253886\n",
      "f1  score for fold 994:  0.40993788819875776\n",
      "recall for fold 994:  0.3793103448275862\n",
      "precision for fold 994:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 995:  0.5119617224880383\n",
      "f1  score for fold 995:  0.3544303797468355\n",
      "recall for fold 995:  0.358974358974359\n",
      "precision for fold 995:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 996:  0.5502392344497608\n",
      "f1  score for fold 996:  0.3896103896103896\n",
      "recall for fold 996:  0.40540540540540543\n",
      "precision for fold 996:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 997:  0.5095238095238095\n",
      "f1  score for fold 997:  0.335483870967742\n",
      "recall for fold 997:  0.3466666666666667\n",
      "precision for fold 997:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 998:  0.5485436893203883\n",
      "f1  score for fold 998:  0.42236024844720493\n",
      "recall for fold 998:  0.4146341463414634\n",
      "precision for fold 998:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 999:  0.5077720207253886\n",
      "f1  score for fold 999:  0.40993788819875776\n",
      "recall for fold 999:  0.3793103448275862\n",
      "precision for fold 999:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1000:  0.5119617224880383\n",
      "f1  score for fold 1000:  0.3544303797468355\n",
      "recall for fold 1000:  0.358974358974359\n",
      "precision for fold 1000:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1001:  0.5119617224880383\n",
      "f1  score for fold 1001:  0.33766233766233766\n",
      "recall for fold 1001:  0.35135135135135137\n",
      "precision for fold 1001:  0.325\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1002:  0.5666666666666667\n",
      "f1  score for fold 1002:  0.41290322580645167\n",
      "recall for fold 1002:  0.4266666666666667\n",
      "precision for fold 1002:  0.4\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1003:  0.470873786407767\n",
      "f1  score for fold 1003:  0.3229813664596273\n",
      "recall for fold 1003:  0.3170731707317073\n",
      "precision for fold 1003:  0.3291139240506329\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1004:  0.47668393782383417\n",
      "f1  score for fold 1004:  0.3726708074534162\n",
      "recall for fold 1004:  0.3448275862068966\n",
      "precision for fold 1004:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1005:  0.5023923444976076\n",
      "f1  score for fold 1005:  0.34177215189873417\n",
      "recall for fold 1005:  0.34615384615384615\n",
      "precision for fold 1005:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1006:  0.5598086124401914\n",
      "f1  score for fold 1006:  0.40259740259740256\n",
      "recall for fold 1006:  0.4189189189189189\n",
      "precision for fold 1006:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1007:  0.5380952380952381\n",
      "f1  score for fold 1007:  0.3741935483870968\n",
      "recall for fold 1007:  0.38666666666666666\n",
      "precision for fold 1007:  0.3625\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 1008:  0.45145631067961167\n",
      "f1  score for fold 1008:  0.29813664596273287\n",
      "recall for fold 1008:  0.2926829268292683\n",
      "precision for fold 1008:  0.3037974683544304\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 1009:  0.42487046632124353\n",
      "f1  score for fold 1009:  0.3105590062111801\n",
      "recall for fold 1009:  0.28735632183908044\n",
      "precision for fold 1009:  0.33783783783783783\n",
      "    0   1\n",
      "0  21  57\n",
      "1  59  72\n",
      "Accuracy for fold 1010:  0.4449760765550239\n",
      "f1  score for fold 1010:  0.26582278481012656\n",
      "recall for fold 1010:  0.2692307692307692\n",
      "precision for fold 1010:  0.2625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1011:  0.5215311004784688\n",
      "f1  score for fold 1011:  0.3506493506493507\n",
      "recall for fold 1011:  0.36486486486486486\n",
      "precision for fold 1011:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1012:  0.49047619047619045\n",
      "f1  score for fold 1012:  0.3096774193548387\n",
      "recall for fold 1012:  0.32\n",
      "precision for fold 1012:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1013:  0.5\n",
      "f1  score for fold 1013:  0.3602484472049689\n",
      "recall for fold 1013:  0.35365853658536583\n",
      "precision for fold 1013:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1014:  0.48704663212435234\n",
      "f1  score for fold 1014:  0.3850931677018633\n",
      "recall for fold 1014:  0.3563218390804598\n",
      "precision for fold 1014:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1015:  0.5215311004784688\n",
      "f1  score for fold 1015:  0.36708860759493667\n",
      "recall for fold 1015:  0.3717948717948718\n",
      "precision for fold 1015:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1016:  0.5311004784688995\n",
      "f1  score for fold 1016:  0.36363636363636365\n",
      "recall for fold 1016:  0.3783783783783784\n",
      "precision for fold 1016:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1017:  0.5095238095238095\n",
      "f1  score for fold 1017:  0.335483870967742\n",
      "recall for fold 1017:  0.3466666666666667\n",
      "precision for fold 1017:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1018:  0.558252427184466\n",
      "f1  score for fold 1018:  0.43478260869565216\n",
      "recall for fold 1018:  0.4268292682926829\n",
      "precision for fold 1018:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1019:  0.538860103626943\n",
      "f1  score for fold 1019:  0.4472049689440994\n",
      "recall for fold 1019:  0.41379310344827586\n",
      "precision for fold 1019:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1020:  0.5311004784688995\n",
      "f1  score for fold 1020:  0.37974683544303806\n",
      "recall for fold 1020:  0.38461538461538464\n",
      "precision for fold 1020:  0.375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1021:  0.49282296650717705\n",
      "f1  score for fold 1021:  0.3116883116883117\n",
      "recall for fold 1021:  0.32432432432432434\n",
      "precision for fold 1021:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1022:  0.5095238095238095\n",
      "f1  score for fold 1022:  0.335483870967742\n",
      "recall for fold 1022:  0.3466666666666667\n",
      "precision for fold 1022:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1023:  0.529126213592233\n",
      "f1  score for fold 1023:  0.39751552795031053\n",
      "recall for fold 1023:  0.3902439024390244\n",
      "precision for fold 1023:  0.4050632911392405\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 1024:  0.42487046632124353\n",
      "f1  score for fold 1024:  0.3105590062111801\n",
      "recall for fold 1024:  0.28735632183908044\n",
      "precision for fold 1024:  0.33783783783783783\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1025:  0.5311004784688995\n",
      "f1  score for fold 1025:  0.37974683544303806\n",
      "recall for fold 1025:  0.38461538461538464\n",
      "precision for fold 1025:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1026:  0.569377990430622\n",
      "f1  score for fold 1026:  0.4155844155844156\n",
      "recall for fold 1026:  0.43243243243243246\n",
      "precision for fold 1026:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1027:  0.5190476190476191\n",
      "f1  score for fold 1027:  0.34838709677419355\n",
      "recall for fold 1027:  0.36\n",
      "precision for fold 1027:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1028:  0.558252427184466\n",
      "f1  score for fold 1028:  0.43478260869565216\n",
      "recall for fold 1028:  0.4268292682926829\n",
      "precision for fold 1028:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1029:  0.5181347150259067\n",
      "f1  score for fold 1029:  0.422360248447205\n",
      "recall for fold 1029:  0.39080459770114945\n",
      "precision for fold 1029:  0.4594594594594595\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 1030:  0.46411483253588515\n",
      "f1  score for fold 1030:  0.2911392405063291\n",
      "recall for fold 1030:  0.2948717948717949\n",
      "precision for fold 1030:  0.2875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1031:  0.5119617224880383\n",
      "f1  score for fold 1031:  0.33766233766233766\n",
      "recall for fold 1031:  0.35135135135135137\n",
      "precision for fold 1031:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1032:  0.5476190476190477\n",
      "f1  score for fold 1032:  0.38709677419354843\n",
      "recall for fold 1032:  0.4\n",
      "precision for fold 1032:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1033:  0.5388349514563107\n",
      "f1  score for fold 1033:  0.40993788819875776\n",
      "recall for fold 1033:  0.4024390243902439\n",
      "precision for fold 1033:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1034:  0.5077720207253886\n",
      "f1  score for fold 1034:  0.40993788819875776\n",
      "recall for fold 1034:  0.3793103448275862\n",
      "precision for fold 1034:  0.44594594594594594\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 1035:  0.5980861244019139\n",
      "f1  score for fold 1035:  0.46835443037974683\n",
      "recall for fold 1035:  0.47435897435897434\n",
      "precision for fold 1035:  0.4625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1036:  0.5502392344497608\n",
      "f1  score for fold 1036:  0.3896103896103896\n",
      "recall for fold 1036:  0.40540540540540543\n",
      "precision for fold 1036:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1037:  0.5380952380952381\n",
      "f1  score for fold 1037:  0.3741935483870968\n",
      "recall for fold 1037:  0.38666666666666666\n",
      "precision for fold 1037:  0.3625\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1038:  0.5679611650485437\n",
      "f1  score for fold 1038:  0.4472049689440994\n",
      "recall for fold 1038:  0.43902439024390244\n",
      "precision for fold 1038:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1039:  0.49740932642487046\n",
      "f1  score for fold 1039:  0.39751552795031053\n",
      "recall for fold 1039:  0.367816091954023\n",
      "precision for fold 1039:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1040:  0.5023923444976076\n",
      "f1  score for fold 1040:  0.34177215189873417\n",
      "recall for fold 1040:  0.34615384615384615\n",
      "precision for fold 1040:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1041:  0.5406698564593302\n",
      "f1  score for fold 1041:  0.37662337662337664\n",
      "recall for fold 1041:  0.3918918918918919\n",
      "precision for fold 1041:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1042:  0.5476190476190477\n",
      "f1  score for fold 1042:  0.38709677419354843\n",
      "recall for fold 1042:  0.4\n",
      "precision for fold 1042:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1043:  0.5679611650485437\n",
      "f1  score for fold 1043:  0.4472049689440994\n",
      "recall for fold 1043:  0.43902439024390244\n",
      "precision for fold 1043:  0.45569620253164556\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1044:  0.48704663212435234\n",
      "f1  score for fold 1044:  0.3850931677018633\n",
      "recall for fold 1044:  0.3563218390804598\n",
      "precision for fold 1044:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1045:  0.5406698564593302\n",
      "f1  score for fold 1045:  0.3924050632911393\n",
      "recall for fold 1045:  0.3974358974358974\n",
      "precision for fold 1045:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1046:  0.49282296650717705\n",
      "f1  score for fold 1046:  0.3116883116883117\n",
      "recall for fold 1046:  0.32432432432432434\n",
      "precision for fold 1046:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1047:  0.5476190476190477\n",
      "f1  score for fold 1047:  0.38709677419354843\n",
      "recall for fold 1047:  0.4\n",
      "precision for fold 1047:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1048:  0.5388349514563107\n",
      "f1  score for fold 1048:  0.40993788819875776\n",
      "recall for fold 1048:  0.4024390243902439\n",
      "precision for fold 1048:  0.4177215189873418\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1049:  0.5492227979274611\n",
      "f1  score for fold 1049:  0.45962732919254656\n",
      "recall for fold 1049:  0.42528735632183906\n",
      "precision for fold 1049:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1050:  0.49282296650717705\n",
      "f1  score for fold 1050:  0.32911392405063294\n",
      "recall for fold 1050:  0.3333333333333333\n",
      "precision for fold 1050:  0.325\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1051:  0.5598086124401914\n",
      "f1  score for fold 1051:  0.40259740259740256\n",
      "recall for fold 1051:  0.4189189189189189\n",
      "precision for fold 1051:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1052:  0.5190476190476191\n",
      "f1  score for fold 1052:  0.34838709677419355\n",
      "recall for fold 1052:  0.36\n",
      "precision for fold 1052:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1053:  0.529126213592233\n",
      "f1  score for fold 1053:  0.39751552795031053\n",
      "recall for fold 1053:  0.3902439024390244\n",
      "precision for fold 1053:  0.4050632911392405\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1054:  0.5595854922279793\n",
      "f1  score for fold 1054:  0.4720496894409938\n",
      "recall for fold 1054:  0.4367816091954023\n",
      "precision for fold 1054:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1055:  0.5502392344497608\n",
      "f1  score for fold 1055:  0.4050632911392405\n",
      "recall for fold 1055:  0.41025641025641024\n",
      "precision for fold 1055:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1056:  0.569377990430622\n",
      "f1  score for fold 1056:  0.4155844155844156\n",
      "recall for fold 1056:  0.43243243243243246\n",
      "precision for fold 1056:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1057:  0.5285714285714286\n",
      "f1  score for fold 1057:  0.3612903225806451\n",
      "recall for fold 1057:  0.37333333333333335\n",
      "precision for fold 1057:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1058:  0.558252427184466\n",
      "f1  score for fold 1058:  0.43478260869565216\n",
      "recall for fold 1058:  0.4268292682926829\n",
      "precision for fold 1058:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1059:  0.538860103626943\n",
      "f1  score for fold 1059:  0.4472049689440994\n",
      "recall for fold 1059:  0.41379310344827586\n",
      "precision for fold 1059:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1060:  0.5406698564593302\n",
      "f1  score for fold 1060:  0.3924050632911393\n",
      "recall for fold 1060:  0.3974358974358974\n",
      "precision for fold 1060:  0.3875\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1061:  0.5980861244019139\n",
      "f1  score for fold 1061:  0.45454545454545453\n",
      "recall for fold 1061:  0.47297297297297297\n",
      "precision for fold 1061:  0.4375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1062:  0.48095238095238096\n",
      "f1  score for fold 1062:  0.2967741935483871\n",
      "recall for fold 1062:  0.30666666666666664\n",
      "precision for fold 1062:  0.2875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1063:  0.558252427184466\n",
      "f1  score for fold 1063:  0.43478260869565216\n",
      "recall for fold 1063:  0.4268292682926829\n",
      "precision for fold 1063:  0.4430379746835443\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1064:  0.45595854922279794\n",
      "f1  score for fold 1064:  0.3478260869565218\n",
      "recall for fold 1064:  0.3218390804597701\n",
      "precision for fold 1064:  0.3783783783783784\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1065:  0.5023923444976076\n",
      "f1  score for fold 1065:  0.34177215189873417\n",
      "recall for fold 1065:  0.34615384615384615\n",
      "precision for fold 1065:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1066:  0.5598086124401914\n",
      "f1  score for fold 1066:  0.40259740259740256\n",
      "recall for fold 1066:  0.4189189189189189\n",
      "precision for fold 1066:  0.3875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1067:  0.5095238095238095\n",
      "f1  score for fold 1067:  0.335483870967742\n",
      "recall for fold 1067:  0.3466666666666667\n",
      "precision for fold 1067:  0.325\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 1068:  0.5776699029126213\n",
      "f1  score for fold 1068:  0.4596273291925466\n",
      "recall for fold 1068:  0.45121951219512196\n",
      "precision for fold 1068:  0.46835443037974683\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1069:  0.48704663212435234\n",
      "f1  score for fold 1069:  0.3850931677018633\n",
      "recall for fold 1069:  0.3563218390804598\n",
      "precision for fold 1069:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1070:  0.5215311004784688\n",
      "f1  score for fold 1070:  0.36708860759493667\n",
      "recall for fold 1070:  0.3717948717948718\n",
      "precision for fold 1070:  0.3625\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1071:  0.5980861244019139\n",
      "f1  score for fold 1071:  0.45454545454545453\n",
      "recall for fold 1071:  0.47297297297297297\n",
      "precision for fold 1071:  0.4375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1072:  0.5095238095238095\n",
      "f1  score for fold 1072:  0.335483870967742\n",
      "recall for fold 1072:  0.3466666666666667\n",
      "precision for fold 1072:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1073:  0.5485436893203883\n",
      "f1  score for fold 1073:  0.42236024844720493\n",
      "recall for fold 1073:  0.4146341463414634\n",
      "precision for fold 1073:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1074:  0.5284974093264249\n",
      "f1  score for fold 1074:  0.4347826086956522\n",
      "recall for fold 1074:  0.40229885057471265\n",
      "precision for fold 1074:  0.47297297297297297\n",
      "    0   1\n",
      "0  39  39\n",
      "1  41  90\n",
      "Accuracy for fold 1075:  0.6172248803827751\n",
      "f1  score for fold 1075:  0.49367088607594933\n",
      "recall for fold 1075:  0.5\n",
      "precision for fold 1075:  0.4875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1076:  0.5119617224880383\n",
      "f1  score for fold 1076:  0.33766233766233766\n",
      "recall for fold 1076:  0.35135135135135137\n",
      "precision for fold 1076:  0.325\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1077:  0.5\n",
      "f1  score for fold 1077:  0.3225806451612903\n",
      "recall for fold 1077:  0.3333333333333333\n",
      "precision for fold 1077:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1078:  0.529126213592233\n",
      "f1  score for fold 1078:  0.39751552795031053\n",
      "recall for fold 1078:  0.3902439024390244\n",
      "precision for fold 1078:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1079:  0.49740932642487046\n",
      "f1  score for fold 1079:  0.39751552795031053\n",
      "recall for fold 1079:  0.367816091954023\n",
      "precision for fold 1079:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1080:  0.5406698564593302\n",
      "f1  score for fold 1080:  0.3924050632911393\n",
      "recall for fold 1080:  0.3974358974358974\n",
      "precision for fold 1080:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1081:  0.5311004784688995\n",
      "f1  score for fold 1081:  0.36363636363636365\n",
      "recall for fold 1081:  0.3783783783783784\n",
      "precision for fold 1081:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1082:  0.5095238095238095\n",
      "f1  score for fold 1082:  0.335483870967742\n",
      "recall for fold 1082:  0.3466666666666667\n",
      "precision for fold 1082:  0.325\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 1083:  0.5970873786407767\n",
      "f1  score for fold 1083:  0.484472049689441\n",
      "recall for fold 1083:  0.47560975609756095\n",
      "precision for fold 1083:  0.4936708860759494\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1084:  0.5699481865284974\n",
      "f1  score for fold 1084:  0.48447204968944096\n",
      "recall for fold 1084:  0.4482758620689655\n",
      "precision for fold 1084:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1085:  0.5502392344497608\n",
      "f1  score for fold 1085:  0.4050632911392405\n",
      "recall for fold 1085:  0.41025641025641024\n",
      "precision for fold 1085:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1086:  0.5023923444976076\n",
      "f1  score for fold 1086:  0.3246753246753247\n",
      "recall for fold 1086:  0.33783783783783783\n",
      "precision for fold 1086:  0.3125\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1087:  0.5761904761904761\n",
      "f1  score for fold 1087:  0.4258064516129032\n",
      "recall for fold 1087:  0.44\n",
      "precision for fold 1087:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1088:  0.5194174757281553\n",
      "f1  score for fold 1088:  0.38509316770186336\n",
      "recall for fold 1088:  0.3780487804878049\n",
      "precision for fold 1088:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1089:  0.5284974093264249\n",
      "f1  score for fold 1089:  0.4347826086956522\n",
      "recall for fold 1089:  0.40229885057471265\n",
      "precision for fold 1089:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1090:  0.5215311004784688\n",
      "f1  score for fold 1090:  0.36708860759493667\n",
      "recall for fold 1090:  0.3717948717948718\n",
      "precision for fold 1090:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1091:  0.5215311004784688\n",
      "f1  score for fold 1091:  0.3506493506493507\n",
      "recall for fold 1091:  0.36486486486486486\n",
      "precision for fold 1091:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1092:  0.5666666666666667\n",
      "f1  score for fold 1092:  0.41290322580645167\n",
      "recall for fold 1092:  0.4266666666666667\n",
      "precision for fold 1092:  0.4\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 1093:  0.587378640776699\n",
      "f1  score for fold 1093:  0.4720496894409938\n",
      "recall for fold 1093:  0.4634146341463415\n",
      "precision for fold 1093:  0.4810126582278481\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1094:  0.46632124352331605\n",
      "f1  score for fold 1094:  0.36024844720496896\n",
      "recall for fold 1094:  0.3333333333333333\n",
      "precision for fold 1094:  0.3918918918918919\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1095:  0.5598086124401914\n",
      "f1  score for fold 1095:  0.4177215189873418\n",
      "recall for fold 1095:  0.4230769230769231\n",
      "precision for fold 1095:  0.4125\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1096:  0.48325358851674644\n",
      "f1  score for fold 1096:  0.29870129870129863\n",
      "recall for fold 1096:  0.3108108108108108\n",
      "precision for fold 1096:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1097:  0.5571428571428572\n",
      "f1  score for fold 1097:  0.4000000000000001\n",
      "recall for fold 1097:  0.41333333333333333\n",
      "precision for fold 1097:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1098:  0.5\n",
      "f1  score for fold 1098:  0.3602484472049689\n",
      "recall for fold 1098:  0.35365853658536583\n",
      "precision for fold 1098:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1099:  0.5492227979274611\n",
      "f1  score for fold 1099:  0.45962732919254656\n",
      "recall for fold 1099:  0.42528735632183906\n",
      "precision for fold 1099:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1100:  0.5215311004784688\n",
      "f1  score for fold 1100:  0.36708860759493667\n",
      "recall for fold 1100:  0.3717948717948718\n",
      "precision for fold 1100:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1101:  0.49282296650717705\n",
      "f1  score for fold 1101:  0.3116883116883117\n",
      "recall for fold 1101:  0.32432432432432434\n",
      "precision for fold 1101:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1102:  0.5\n",
      "f1  score for fold 1102:  0.3225806451612903\n",
      "recall for fold 1102:  0.3333333333333333\n",
      "precision for fold 1102:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1103:  0.5485436893203883\n",
      "f1  score for fold 1103:  0.42236024844720493\n",
      "recall for fold 1103:  0.4146341463414634\n",
      "precision for fold 1103:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1104:  0.49740932642487046\n",
      "f1  score for fold 1104:  0.39751552795031053\n",
      "recall for fold 1104:  0.367816091954023\n",
      "precision for fold 1104:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1105:  0.5406698564593302\n",
      "f1  score for fold 1105:  0.3924050632911393\n",
      "recall for fold 1105:  0.3974358974358974\n",
      "precision for fold 1105:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1106:  0.5406698564593302\n",
      "f1  score for fold 1106:  0.37662337662337664\n",
      "recall for fold 1106:  0.3918918918918919\n",
      "precision for fold 1106:  0.3625\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 1107:  0.4523809523809524\n",
      "f1  score for fold 1107:  0.2580645161290323\n",
      "recall for fold 1107:  0.26666666666666666\n",
      "precision for fold 1107:  0.25\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1108:  0.5388349514563107\n",
      "f1  score for fold 1108:  0.40993788819875776\n",
      "recall for fold 1108:  0.4024390243902439\n",
      "precision for fold 1108:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1109:  0.5284974093264249\n",
      "f1  score for fold 1109:  0.4347826086956522\n",
      "recall for fold 1109:  0.40229885057471265\n",
      "precision for fold 1109:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1110:  0.5215311004784688\n",
      "f1  score for fold 1110:  0.36708860759493667\n",
      "recall for fold 1110:  0.3717948717948718\n",
      "precision for fold 1110:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1111:  0.5406698564593302\n",
      "f1  score for fold 1111:  0.37662337662337664\n",
      "recall for fold 1111:  0.3918918918918919\n",
      "precision for fold 1111:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1112:  0.5380952380952381\n",
      "f1  score for fold 1112:  0.3741935483870968\n",
      "recall for fold 1112:  0.38666666666666666\n",
      "precision for fold 1112:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1113:  0.49029126213592233\n",
      "f1  score for fold 1113:  0.3478260869565218\n",
      "recall for fold 1113:  0.34146341463414637\n",
      "precision for fold 1113:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1114:  0.49740932642487046\n",
      "f1  score for fold 1114:  0.39751552795031053\n",
      "recall for fold 1114:  0.367816091954023\n",
      "precision for fold 1114:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1115:  0.5406698564593302\n",
      "f1  score for fold 1115:  0.3924050632911393\n",
      "recall for fold 1115:  0.3974358974358974\n",
      "precision for fold 1115:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1116:  0.5406698564593302\n",
      "f1  score for fold 1116:  0.37662337662337664\n",
      "recall for fold 1116:  0.3918918918918919\n",
      "precision for fold 1116:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1117:  0.5380952380952381\n",
      "f1  score for fold 1117:  0.3741935483870968\n",
      "recall for fold 1117:  0.38666666666666666\n",
      "precision for fold 1117:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1118:  0.5194174757281553\n",
      "f1  score for fold 1118:  0.38509316770186336\n",
      "recall for fold 1118:  0.3780487804878049\n",
      "precision for fold 1118:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1119:  0.538860103626943\n",
      "f1  score for fold 1119:  0.4472049689440994\n",
      "recall for fold 1119:  0.41379310344827586\n",
      "precision for fold 1119:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1120:  0.5598086124401914\n",
      "f1  score for fold 1120:  0.4177215189873418\n",
      "recall for fold 1120:  0.4230769230769231\n",
      "precision for fold 1120:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1121:  0.5598086124401914\n",
      "f1  score for fold 1121:  0.40259740259740256\n",
      "recall for fold 1121:  0.4189189189189189\n",
      "precision for fold 1121:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1122:  0.5380952380952381\n",
      "f1  score for fold 1122:  0.3741935483870968\n",
      "recall for fold 1122:  0.38666666666666666\n",
      "precision for fold 1122:  0.3625\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 1123:  0.441747572815534\n",
      "f1  score for fold 1123:  0.28571428571428575\n",
      "recall for fold 1123:  0.2804878048780488\n",
      "precision for fold 1123:  0.2911392405063291\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1124:  0.5077720207253886\n",
      "f1  score for fold 1124:  0.40993788819875776\n",
      "recall for fold 1124:  0.3793103448275862\n",
      "precision for fold 1124:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1125:  0.5502392344497608\n",
      "f1  score for fold 1125:  0.4050632911392405\n",
      "recall for fold 1125:  0.41025641025641024\n",
      "precision for fold 1125:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1126:  0.5311004784688995\n",
      "f1  score for fold 1126:  0.36363636363636365\n",
      "recall for fold 1126:  0.3783783783783784\n",
      "precision for fold 1126:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1127:  0.5285714285714286\n",
      "f1  score for fold 1127:  0.3612903225806451\n",
      "recall for fold 1127:  0.37333333333333335\n",
      "precision for fold 1127:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1128:  0.5485436893203883\n",
      "f1  score for fold 1128:  0.42236024844720493\n",
      "recall for fold 1128:  0.4146341463414634\n",
      "precision for fold 1128:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1129:  0.47668393782383417\n",
      "f1  score for fold 1129:  0.3726708074534162\n",
      "recall for fold 1129:  0.3448275862068966\n",
      "precision for fold 1129:  0.40540540540540543\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1130:  0.569377990430622\n",
      "f1  score for fold 1130:  0.43037974683544306\n",
      "recall for fold 1130:  0.4358974358974359\n",
      "precision for fold 1130:  0.425\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 1131:  0.6076555023923444\n",
      "f1  score for fold 1131:  0.4675324675324675\n",
      "recall for fold 1131:  0.4864864864864865\n",
      "precision for fold 1131:  0.45\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1132:  0.5285714285714286\n",
      "f1  score for fold 1132:  0.3612903225806451\n",
      "recall for fold 1132:  0.37333333333333335\n",
      "precision for fold 1132:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1133:  0.5485436893203883\n",
      "f1  score for fold 1133:  0.42236024844720493\n",
      "recall for fold 1133:  0.4146341463414634\n",
      "precision for fold 1133:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1134:  0.47668393782383417\n",
      "f1  score for fold 1134:  0.3726708074534162\n",
      "recall for fold 1134:  0.3448275862068966\n",
      "precision for fold 1134:  0.40540540540540543\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 1135:  0.47368421052631576\n",
      "f1  score for fold 1135:  0.3037974683544304\n",
      "recall for fold 1135:  0.3076923076923077\n",
      "precision for fold 1135:  0.3\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1136:  0.5980861244019139\n",
      "f1  score for fold 1136:  0.45454545454545453\n",
      "recall for fold 1136:  0.47297297297297297\n",
      "precision for fold 1136:  0.4375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1137:  0.5761904761904761\n",
      "f1  score for fold 1137:  0.4258064516129032\n",
      "recall for fold 1137:  0.44\n",
      "precision for fold 1137:  0.4125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1138:  0.5388349514563107\n",
      "f1  score for fold 1138:  0.40993788819875776\n",
      "recall for fold 1138:  0.4024390243902439\n",
      "precision for fold 1138:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1139:  0.48704663212435234\n",
      "f1  score for fold 1139:  0.3850931677018633\n",
      "recall for fold 1139:  0.3563218390804598\n",
      "precision for fold 1139:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1140:  0.569377990430622\n",
      "f1  score for fold 1140:  0.43037974683544306\n",
      "recall for fold 1140:  0.4358974358974359\n",
      "precision for fold 1140:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1141:  0.5215311004784688\n",
      "f1  score for fold 1141:  0.3506493506493507\n",
      "recall for fold 1141:  0.36486486486486486\n",
      "precision for fold 1141:  0.3375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1142:  0.5761904761904761\n",
      "f1  score for fold 1142:  0.4258064516129032\n",
      "recall for fold 1142:  0.44\n",
      "precision for fold 1142:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1143:  0.5194174757281553\n",
      "f1  score for fold 1143:  0.38509316770186336\n",
      "recall for fold 1143:  0.3780487804878049\n",
      "precision for fold 1143:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1144:  0.5181347150259067\n",
      "f1  score for fold 1144:  0.422360248447205\n",
      "recall for fold 1144:  0.39080459770114945\n",
      "precision for fold 1144:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1145:  0.5502392344497608\n",
      "f1  score for fold 1145:  0.4050632911392405\n",
      "recall for fold 1145:  0.41025641025641024\n",
      "precision for fold 1145:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1146:  0.5119617224880383\n",
      "f1  score for fold 1146:  0.33766233766233766\n",
      "recall for fold 1146:  0.35135135135135137\n",
      "precision for fold 1146:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1147:  0.5476190476190477\n",
      "f1  score for fold 1147:  0.38709677419354843\n",
      "recall for fold 1147:  0.4\n",
      "precision for fold 1147:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1148:  0.5097087378640777\n",
      "f1  score for fold 1148:  0.37267080745341613\n",
      "recall for fold 1148:  0.36585365853658536\n",
      "precision for fold 1148:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1149:  0.45595854922279794\n",
      "f1  score for fold 1149:  0.3478260869565218\n",
      "recall for fold 1149:  0.3218390804597701\n",
      "precision for fold 1149:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1150:  0.5215311004784688\n",
      "f1  score for fold 1150:  0.36708860759493667\n",
      "recall for fold 1150:  0.3717948717948718\n",
      "precision for fold 1150:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1151:  0.5502392344497608\n",
      "f1  score for fold 1151:  0.3896103896103896\n",
      "recall for fold 1151:  0.40540540540540543\n",
      "precision for fold 1151:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1152:  0.5476190476190477\n",
      "f1  score for fold 1152:  0.38709677419354843\n",
      "recall for fold 1152:  0.4\n",
      "precision for fold 1152:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1153:  0.5097087378640777\n",
      "f1  score for fold 1153:  0.37267080745341613\n",
      "recall for fold 1153:  0.36585365853658536\n",
      "precision for fold 1153:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1154:  0.5077720207253886\n",
      "f1  score for fold 1154:  0.40993788819875776\n",
      "recall for fold 1154:  0.3793103448275862\n",
      "precision for fold 1154:  0.44594594594594594\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1155:  0.49282296650717705\n",
      "f1  score for fold 1155:  0.32911392405063294\n",
      "recall for fold 1155:  0.3333333333333333\n",
      "precision for fold 1155:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1156:  0.5215311004784688\n",
      "f1  score for fold 1156:  0.3506493506493507\n",
      "recall for fold 1156:  0.36486486486486486\n",
      "precision for fold 1156:  0.3375\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 1157:  0.4714285714285714\n",
      "f1  score for fold 1157:  0.2838709677419355\n",
      "recall for fold 1157:  0.29333333333333333\n",
      "precision for fold 1157:  0.275\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1158:  0.5097087378640777\n",
      "f1  score for fold 1158:  0.37267080745341613\n",
      "recall for fold 1158:  0.36585365853658536\n",
      "precision for fold 1158:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1159:  0.49740932642487046\n",
      "f1  score for fold 1159:  0.39751552795031053\n",
      "recall for fold 1159:  0.367816091954023\n",
      "precision for fold 1159:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1160:  0.5119617224880383\n",
      "f1  score for fold 1160:  0.3544303797468355\n",
      "recall for fold 1160:  0.358974358974359\n",
      "precision for fold 1160:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1161:  0.5406698564593302\n",
      "f1  score for fold 1161:  0.37662337662337664\n",
      "recall for fold 1161:  0.3918918918918919\n",
      "precision for fold 1161:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1162:  0.5190476190476191\n",
      "f1  score for fold 1162:  0.34838709677419355\n",
      "recall for fold 1162:  0.36\n",
      "precision for fold 1162:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1163:  0.5097087378640777\n",
      "f1  score for fold 1163:  0.37267080745341613\n",
      "recall for fold 1163:  0.36585365853658536\n",
      "precision for fold 1163:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1164:  0.48704663212435234\n",
      "f1  score for fold 1164:  0.3850931677018633\n",
      "recall for fold 1164:  0.3563218390804598\n",
      "precision for fold 1164:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1165:  0.5598086124401914\n",
      "f1  score for fold 1165:  0.4177215189873418\n",
      "recall for fold 1165:  0.4230769230769231\n",
      "precision for fold 1165:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1166:  0.5598086124401914\n",
      "f1  score for fold 1166:  0.40259740259740256\n",
      "recall for fold 1166:  0.4189189189189189\n",
      "precision for fold 1166:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1167:  0.5190476190476191\n",
      "f1  score for fold 1167:  0.34838709677419355\n",
      "recall for fold 1167:  0.36\n",
      "precision for fold 1167:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1168:  0.48058252427184467\n",
      "f1  score for fold 1168:  0.33540372670807456\n",
      "recall for fold 1168:  0.32926829268292684\n",
      "precision for fold 1168:  0.34177215189873417\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1169:  0.48704663212435234\n",
      "f1  score for fold 1169:  0.3850931677018633\n",
      "recall for fold 1169:  0.3563218390804598\n",
      "precision for fold 1169:  0.4189189189189189\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1170:  0.5023923444976076\n",
      "f1  score for fold 1170:  0.34177215189873417\n",
      "recall for fold 1170:  0.34615384615384615\n",
      "precision for fold 1170:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1171:  0.5119617224880383\n",
      "f1  score for fold 1171:  0.33766233766233766\n",
      "recall for fold 1171:  0.35135135135135137\n",
      "precision for fold 1171:  0.325\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1172:  0.5\n",
      "f1  score for fold 1172:  0.3225806451612903\n",
      "recall for fold 1172:  0.3333333333333333\n",
      "precision for fold 1172:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1173:  0.5485436893203883\n",
      "f1  score for fold 1173:  0.42236024844720493\n",
      "recall for fold 1173:  0.4146341463414634\n",
      "precision for fold 1173:  0.43037974683544306\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1174:  0.5595854922279793\n",
      "f1  score for fold 1174:  0.4720496894409938\n",
      "recall for fold 1174:  0.4367816091954023\n",
      "precision for fold 1174:  0.5135135135135135\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 1175:  0.47368421052631576\n",
      "f1  score for fold 1175:  0.3037974683544304\n",
      "recall for fold 1175:  0.3076923076923077\n",
      "precision for fold 1175:  0.3\n",
      "    0   1\n",
      "0  18  56\n",
      "1  62  73\n",
      "Accuracy for fold 1176:  0.4354066985645933\n",
      "f1  score for fold 1176:  0.23376623376623376\n",
      "recall for fold 1176:  0.24324324324324326\n",
      "precision for fold 1176:  0.225\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1177:  0.5095238095238095\n",
      "f1  score for fold 1177:  0.335483870967742\n",
      "recall for fold 1177:  0.3466666666666667\n",
      "precision for fold 1177:  0.325\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 1178:  0.587378640776699\n",
      "f1  score for fold 1178:  0.4720496894409938\n",
      "recall for fold 1178:  0.4634146341463415\n",
      "precision for fold 1178:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1179:  0.49740932642487046\n",
      "f1  score for fold 1179:  0.39751552795031053\n",
      "recall for fold 1179:  0.367816091954023\n",
      "precision for fold 1179:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1180:  0.5311004784688995\n",
      "f1  score for fold 1180:  0.37974683544303806\n",
      "recall for fold 1180:  0.38461538461538464\n",
      "precision for fold 1180:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1181:  0.5119617224880383\n",
      "f1  score for fold 1181:  0.33766233766233766\n",
      "recall for fold 1181:  0.35135135135135137\n",
      "precision for fold 1181:  0.325\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1182:  0.5952380952380952\n",
      "f1  score for fold 1182:  0.45161290322580644\n",
      "recall for fold 1182:  0.4666666666666667\n",
      "precision for fold 1182:  0.4375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1183:  0.5194174757281553\n",
      "f1  score for fold 1183:  0.38509316770186336\n",
      "recall for fold 1183:  0.3780487804878049\n",
      "precision for fold 1183:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1184:  0.5077720207253886\n",
      "f1  score for fold 1184:  0.40993788819875776\n",
      "recall for fold 1184:  0.3793103448275862\n",
      "precision for fold 1184:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1185:  0.5789473684210527\n",
      "f1  score for fold 1185:  0.44303797468354433\n",
      "recall for fold 1185:  0.44871794871794873\n",
      "precision for fold 1185:  0.4375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1186:  0.5502392344497608\n",
      "f1  score for fold 1186:  0.3896103896103896\n",
      "recall for fold 1186:  0.40540540540540543\n",
      "precision for fold 1186:  0.375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1187:  0.49047619047619045\n",
      "f1  score for fold 1187:  0.3096774193548387\n",
      "recall for fold 1187:  0.32\n",
      "precision for fold 1187:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1188:  0.5\n",
      "f1  score for fold 1188:  0.3602484472049689\n",
      "recall for fold 1188:  0.35365853658536583\n",
      "precision for fold 1188:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1189:  0.49740932642487046\n",
      "f1  score for fold 1189:  0.39751552795031053\n",
      "recall for fold 1189:  0.367816091954023\n",
      "precision for fold 1189:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1190:  0.5598086124401914\n",
      "f1  score for fold 1190:  0.4177215189873418\n",
      "recall for fold 1190:  0.4230769230769231\n",
      "precision for fold 1190:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1191:  0.5311004784688995\n",
      "f1  score for fold 1191:  0.36363636363636365\n",
      "recall for fold 1191:  0.3783783783783784\n",
      "precision for fold 1191:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1192:  0.5476190476190477\n",
      "f1  score for fold 1192:  0.38709677419354843\n",
      "recall for fold 1192:  0.4\n",
      "precision for fold 1192:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1193:  0.5194174757281553\n",
      "f1  score for fold 1193:  0.38509316770186336\n",
      "recall for fold 1193:  0.3780487804878049\n",
      "precision for fold 1193:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1194:  0.5181347150259067\n",
      "f1  score for fold 1194:  0.422360248447205\n",
      "recall for fold 1194:  0.39080459770114945\n",
      "precision for fold 1194:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1195:  0.5215311004784688\n",
      "f1  score for fold 1195:  0.36708860759493667\n",
      "recall for fold 1195:  0.3717948717948718\n",
      "precision for fold 1195:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1196:  0.5502392344497608\n",
      "f1  score for fold 1196:  0.3896103896103896\n",
      "recall for fold 1196:  0.40540540540540543\n",
      "precision for fold 1196:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1197:  0.5380952380952381\n",
      "f1  score for fold 1197:  0.3741935483870968\n",
      "recall for fold 1197:  0.38666666666666666\n",
      "precision for fold 1197:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1198:  0.470873786407767\n",
      "f1  score for fold 1198:  0.3229813664596273\n",
      "recall for fold 1198:  0.3170731707317073\n",
      "precision for fold 1198:  0.3291139240506329\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1199:  0.47668393782383417\n",
      "f1  score for fold 1199:  0.3726708074534162\n",
      "recall for fold 1199:  0.3448275862068966\n",
      "precision for fold 1199:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1200:  0.5311004784688995\n",
      "f1  score for fold 1200:  0.37974683544303806\n",
      "recall for fold 1200:  0.38461538461538464\n",
      "precision for fold 1200:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1201:  0.5502392344497608\n",
      "f1  score for fold 1201:  0.3896103896103896\n",
      "recall for fold 1201:  0.40540540540540543\n",
      "precision for fold 1201:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1202:  0.5190476190476191\n",
      "f1  score for fold 1202:  0.34838709677419355\n",
      "recall for fold 1202:  0.36\n",
      "precision for fold 1202:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1203:  0.48058252427184467\n",
      "f1  score for fold 1203:  0.33540372670807456\n",
      "recall for fold 1203:  0.32926829268292684\n",
      "precision for fold 1203:  0.34177215189873417\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1204:  0.538860103626943\n",
      "f1  score for fold 1204:  0.4472049689440994\n",
      "recall for fold 1204:  0.41379310344827586\n",
      "precision for fold 1204:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1205:  0.5311004784688995\n",
      "f1  score for fold 1205:  0.37974683544303806\n",
      "recall for fold 1205:  0.38461538461538464\n",
      "precision for fold 1205:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1206:  0.5311004784688995\n",
      "f1  score for fold 1206:  0.36363636363636365\n",
      "recall for fold 1206:  0.3783783783783784\n",
      "precision for fold 1206:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1207:  0.5571428571428572\n",
      "f1  score for fold 1207:  0.4000000000000001\n",
      "recall for fold 1207:  0.41333333333333333\n",
      "precision for fold 1207:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1208:  0.529126213592233\n",
      "f1  score for fold 1208:  0.39751552795031053\n",
      "recall for fold 1208:  0.3902439024390244\n",
      "precision for fold 1208:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1209:  0.5181347150259067\n",
      "f1  score for fold 1209:  0.422360248447205\n",
      "recall for fold 1209:  0.39080459770114945\n",
      "precision for fold 1209:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1210:  0.48325358851674644\n",
      "f1  score for fold 1210:  0.31645569620253167\n",
      "recall for fold 1210:  0.32051282051282054\n",
      "precision for fold 1210:  0.3125\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1211:  0.48325358851674644\n",
      "f1  score for fold 1211:  0.29870129870129863\n",
      "recall for fold 1211:  0.3108108108108108\n",
      "precision for fold 1211:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1212:  0.5285714285714286\n",
      "f1  score for fold 1212:  0.3612903225806451\n",
      "recall for fold 1212:  0.37333333333333335\n",
      "precision for fold 1212:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1213:  0.5097087378640777\n",
      "f1  score for fold 1213:  0.37267080745341613\n",
      "recall for fold 1213:  0.36585365853658536\n",
      "precision for fold 1213:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1214:  0.5181347150259067\n",
      "f1  score for fold 1214:  0.422360248447205\n",
      "recall for fold 1214:  0.39080459770114945\n",
      "precision for fold 1214:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1215:  0.5311004784688995\n",
      "f1  score for fold 1215:  0.37974683544303806\n",
      "recall for fold 1215:  0.38461538461538464\n",
      "precision for fold 1215:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1216:  0.5502392344497608\n",
      "f1  score for fold 1216:  0.3896103896103896\n",
      "recall for fold 1216:  0.40540540540540543\n",
      "precision for fold 1216:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1217:  0.5666666666666667\n",
      "f1  score for fold 1217:  0.41290322580645167\n",
      "recall for fold 1217:  0.4266666666666667\n",
      "precision for fold 1217:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1218:  0.5097087378640777\n",
      "f1  score for fold 1218:  0.37267080745341613\n",
      "recall for fold 1218:  0.36585365853658536\n",
      "precision for fold 1218:  0.379746835443038\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1219:  0.5492227979274611\n",
      "f1  score for fold 1219:  0.45962732919254656\n",
      "recall for fold 1219:  0.42528735632183906\n",
      "precision for fold 1219:  0.5\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1220:  0.5598086124401914\n",
      "f1  score for fold 1220:  0.4177215189873418\n",
      "recall for fold 1220:  0.4230769230769231\n",
      "precision for fold 1220:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1221:  0.5215311004784688\n",
      "f1  score for fold 1221:  0.3506493506493507\n",
      "recall for fold 1221:  0.36486486486486486\n",
      "precision for fold 1221:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1222:  0.5666666666666667\n",
      "f1  score for fold 1222:  0.41290322580645167\n",
      "recall for fold 1222:  0.4266666666666667\n",
      "precision for fold 1222:  0.4\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1223:  0.5194174757281553\n",
      "f1  score for fold 1223:  0.38509316770186336\n",
      "recall for fold 1223:  0.3780487804878049\n",
      "precision for fold 1223:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1224:  0.48704663212435234\n",
      "f1  score for fold 1224:  0.3850931677018633\n",
      "recall for fold 1224:  0.3563218390804598\n",
      "precision for fold 1224:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1225:  0.5215311004784688\n",
      "f1  score for fold 1225:  0.36708860759493667\n",
      "recall for fold 1225:  0.3717948717948718\n",
      "precision for fold 1225:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1226:  0.5215311004784688\n",
      "f1  score for fold 1226:  0.3506493506493507\n",
      "recall for fold 1226:  0.36486486486486486\n",
      "precision for fold 1226:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1227:  0.5190476190476191\n",
      "f1  score for fold 1227:  0.34838709677419355\n",
      "recall for fold 1227:  0.36\n",
      "precision for fold 1227:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1228:  0.5388349514563107\n",
      "f1  score for fold 1228:  0.40993788819875776\n",
      "recall for fold 1228:  0.4024390243902439\n",
      "precision for fold 1228:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1229:  0.48704663212435234\n",
      "f1  score for fold 1229:  0.3850931677018633\n",
      "recall for fold 1229:  0.3563218390804598\n",
      "precision for fold 1229:  0.4189189189189189\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 1230:  0.5885167464114832\n",
      "f1  score for fold 1230:  0.45569620253164556\n",
      "recall for fold 1230:  0.46153846153846156\n",
      "precision for fold 1230:  0.45\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1231:  0.5119617224880383\n",
      "f1  score for fold 1231:  0.33766233766233766\n",
      "recall for fold 1231:  0.35135135135135137\n",
      "precision for fold 1231:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1232:  0.5285714285714286\n",
      "f1  score for fold 1232:  0.3612903225806451\n",
      "recall for fold 1232:  0.37333333333333335\n",
      "precision for fold 1232:  0.35\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 1233:  0.5970873786407767\n",
      "f1  score for fold 1233:  0.484472049689441\n",
      "recall for fold 1233:  0.47560975609756095\n",
      "precision for fold 1233:  0.4936708860759494\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1234:  0.46632124352331605\n",
      "f1  score for fold 1234:  0.36024844720496896\n",
      "recall for fold 1234:  0.3333333333333333\n",
      "precision for fold 1234:  0.3918918918918919\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1235:  0.48325358851674644\n",
      "f1  score for fold 1235:  0.31645569620253167\n",
      "recall for fold 1235:  0.32051282051282054\n",
      "precision for fold 1235:  0.3125\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1236:  0.569377990430622\n",
      "f1  score for fold 1236:  0.4155844155844156\n",
      "recall for fold 1236:  0.43243243243243246\n",
      "precision for fold 1236:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1237:  0.5285714285714286\n",
      "f1  score for fold 1237:  0.3612903225806451\n",
      "recall for fold 1237:  0.37333333333333335\n",
      "precision for fold 1237:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1238:  0.5485436893203883\n",
      "f1  score for fold 1238:  0.42236024844720493\n",
      "recall for fold 1238:  0.4146341463414634\n",
      "precision for fold 1238:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1239:  0.5181347150259067\n",
      "f1  score for fold 1239:  0.422360248447205\n",
      "recall for fold 1239:  0.39080459770114945\n",
      "precision for fold 1239:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1240:  0.5215311004784688\n",
      "f1  score for fold 1240:  0.36708860759493667\n",
      "recall for fold 1240:  0.3717948717948718\n",
      "precision for fold 1240:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1241:  0.5502392344497608\n",
      "f1  score for fold 1241:  0.3896103896103896\n",
      "recall for fold 1241:  0.40540540540540543\n",
      "precision for fold 1241:  0.375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1242:  0.5857142857142857\n",
      "f1  score for fold 1242:  0.43870967741935485\n",
      "recall for fold 1242:  0.4533333333333333\n",
      "precision for fold 1242:  0.425\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1243:  0.48058252427184467\n",
      "f1  score for fold 1243:  0.33540372670807456\n",
      "recall for fold 1243:  0.32926829268292684\n",
      "precision for fold 1243:  0.34177215189873417\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1244:  0.538860103626943\n",
      "f1  score for fold 1244:  0.4472049689440994\n",
      "recall for fold 1244:  0.41379310344827586\n",
      "precision for fold 1244:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1245:  0.5311004784688995\n",
      "f1  score for fold 1245:  0.37974683544303806\n",
      "recall for fold 1245:  0.38461538461538464\n",
      "precision for fold 1245:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1246:  0.5598086124401914\n",
      "f1  score for fold 1246:  0.40259740259740256\n",
      "recall for fold 1246:  0.4189189189189189\n",
      "precision for fold 1246:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1247:  0.5285714285714286\n",
      "f1  score for fold 1247:  0.3612903225806451\n",
      "recall for fold 1247:  0.37333333333333335\n",
      "precision for fold 1247:  0.35\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1248:  0.46116504854368934\n",
      "f1  score for fold 1248:  0.31055900621118016\n",
      "recall for fold 1248:  0.3048780487804878\n",
      "precision for fold 1248:  0.31645569620253167\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1249:  0.5699481865284974\n",
      "f1  score for fold 1249:  0.48447204968944096\n",
      "recall for fold 1249:  0.4482758620689655\n",
      "precision for fold 1249:  0.527027027027027\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1250:  0.5023923444976076\n",
      "f1  score for fold 1250:  0.34177215189873417\n",
      "recall for fold 1250:  0.34615384615384615\n",
      "precision for fold 1250:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1251:  0.5502392344497608\n",
      "f1  score for fold 1251:  0.3896103896103896\n",
      "recall for fold 1251:  0.40540540540540543\n",
      "precision for fold 1251:  0.375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1252:  0.48095238095238096\n",
      "f1  score for fold 1252:  0.2967741935483871\n",
      "recall for fold 1252:  0.30666666666666664\n",
      "precision for fold 1252:  0.2875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1253:  0.5194174757281553\n",
      "f1  score for fold 1253:  0.38509316770186336\n",
      "recall for fold 1253:  0.3780487804878049\n",
      "precision for fold 1253:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1254:  0.538860103626943\n",
      "f1  score for fold 1254:  0.4472049689440994\n",
      "recall for fold 1254:  0.41379310344827586\n",
      "precision for fold 1254:  0.4864864864864865\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 1255:  0.5885167464114832\n",
      "f1  score for fold 1255:  0.45569620253164556\n",
      "recall for fold 1255:  0.46153846153846156\n",
      "precision for fold 1255:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1256:  0.5406698564593302\n",
      "f1  score for fold 1256:  0.37662337662337664\n",
      "recall for fold 1256:  0.3918918918918919\n",
      "precision for fold 1256:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1257:  0.5666666666666667\n",
      "f1  score for fold 1257:  0.41290322580645167\n",
      "recall for fold 1257:  0.4266666666666667\n",
      "precision for fold 1257:  0.4\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1258:  0.5\n",
      "f1  score for fold 1258:  0.3602484472049689\n",
      "recall for fold 1258:  0.35365853658536583\n",
      "precision for fold 1258:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1259:  0.49740932642487046\n",
      "f1  score for fold 1259:  0.39751552795031053\n",
      "recall for fold 1259:  0.367816091954023\n",
      "precision for fold 1259:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1260:  0.5502392344497608\n",
      "f1  score for fold 1260:  0.4050632911392405\n",
      "recall for fold 1260:  0.41025641025641024\n",
      "precision for fold 1260:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1261:  0.5502392344497608\n",
      "f1  score for fold 1261:  0.3896103896103896\n",
      "recall for fold 1261:  0.40540540540540543\n",
      "precision for fold 1261:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1262:  0.5\n",
      "f1  score for fold 1262:  0.3225806451612903\n",
      "recall for fold 1262:  0.3333333333333333\n",
      "precision for fold 1262:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1263:  0.5\n",
      "f1  score for fold 1263:  0.3602484472049689\n",
      "recall for fold 1263:  0.35365853658536583\n",
      "precision for fold 1263:  0.3670886075949367\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1264:  0.5699481865284974\n",
      "f1  score for fold 1264:  0.48447204968944096\n",
      "recall for fold 1264:  0.4482758620689655\n",
      "precision for fold 1264:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1265:  0.5502392344497608\n",
      "f1  score for fold 1265:  0.4050632911392405\n",
      "recall for fold 1265:  0.41025641025641024\n",
      "precision for fold 1265:  0.4\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 1266:  0.5885167464114832\n",
      "f1  score for fold 1266:  0.44155844155844154\n",
      "recall for fold 1266:  0.4594594594594595\n",
      "precision for fold 1266:  0.425\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1267:  0.5190476190476191\n",
      "f1  score for fold 1267:  0.34838709677419355\n",
      "recall for fold 1267:  0.36\n",
      "precision for fold 1267:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1268:  0.529126213592233\n",
      "f1  score for fold 1268:  0.39751552795031053\n",
      "recall for fold 1268:  0.3902439024390244\n",
      "precision for fold 1268:  0.4050632911392405\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1269:  0.46632124352331605\n",
      "f1  score for fold 1269:  0.36024844720496896\n",
      "recall for fold 1269:  0.3333333333333333\n",
      "precision for fold 1269:  0.3918918918918919\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1270:  0.5406698564593302\n",
      "f1  score for fold 1270:  0.3924050632911393\n",
      "recall for fold 1270:  0.3974358974358974\n",
      "precision for fold 1270:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1271:  0.5598086124401914\n",
      "f1  score for fold 1271:  0.40259740259740256\n",
      "recall for fold 1271:  0.4189189189189189\n",
      "precision for fold 1271:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1272:  0.49047619047619045\n",
      "f1  score for fold 1272:  0.3096774193548387\n",
      "recall for fold 1272:  0.32\n",
      "precision for fold 1272:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1273:  0.5097087378640777\n",
      "f1  score for fold 1273:  0.37267080745341613\n",
      "recall for fold 1273:  0.36585365853658536\n",
      "precision for fold 1273:  0.379746835443038\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1274:  0.5595854922279793\n",
      "f1  score for fold 1274:  0.4720496894409938\n",
      "recall for fold 1274:  0.4367816091954023\n",
      "precision for fold 1274:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1275:  0.5598086124401914\n",
      "f1  score for fold 1275:  0.4177215189873418\n",
      "recall for fold 1275:  0.4230769230769231\n",
      "precision for fold 1275:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1276:  0.5598086124401914\n",
      "f1  score for fold 1276:  0.40259740259740256\n",
      "recall for fold 1276:  0.4189189189189189\n",
      "precision for fold 1276:  0.3875\n",
      "    0   1\n",
      "0  39  36\n",
      "1  41  94\n",
      "Accuracy for fold 1277:  0.6333333333333333\n",
      "f1  score for fold 1277:  0.5032258064516129\n",
      "recall for fold 1277:  0.52\n",
      "precision for fold 1277:  0.4875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1278:  0.49029126213592233\n",
      "f1  score for fold 1278:  0.3478260869565218\n",
      "recall for fold 1278:  0.34146341463414637\n",
      "precision for fold 1278:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1279:  0.538860103626943\n",
      "f1  score for fold 1279:  0.4472049689440994\n",
      "recall for fold 1279:  0.41379310344827586\n",
      "precision for fold 1279:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1280:  0.5311004784688995\n",
      "f1  score for fold 1280:  0.37974683544303806\n",
      "recall for fold 1280:  0.38461538461538464\n",
      "precision for fold 1280:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1281:  0.5311004784688995\n",
      "f1  score for fold 1281:  0.36363636363636365\n",
      "recall for fold 1281:  0.3783783783783784\n",
      "precision for fold 1281:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1282:  0.5\n",
      "f1  score for fold 1282:  0.3225806451612903\n",
      "recall for fold 1282:  0.3333333333333333\n",
      "precision for fold 1282:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1283:  0.5388349514563107\n",
      "f1  score for fold 1283:  0.40993788819875776\n",
      "recall for fold 1283:  0.4024390243902439\n",
      "precision for fold 1283:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1284:  0.5284974093264249\n",
      "f1  score for fold 1284:  0.4347826086956522\n",
      "recall for fold 1284:  0.40229885057471265\n",
      "precision for fold 1284:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1285:  0.5215311004784688\n",
      "f1  score for fold 1285:  0.36708860759493667\n",
      "recall for fold 1285:  0.3717948717948718\n",
      "precision for fold 1285:  0.3625\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1286:  0.5980861244019139\n",
      "f1  score for fold 1286:  0.45454545454545453\n",
      "recall for fold 1286:  0.47297297297297297\n",
      "precision for fold 1286:  0.4375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1287:  0.5761904761904761\n",
      "f1  score for fold 1287:  0.4258064516129032\n",
      "recall for fold 1287:  0.44\n",
      "precision for fold 1287:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1288:  0.5097087378640777\n",
      "f1  score for fold 1288:  0.37267080745341613\n",
      "recall for fold 1288:  0.36585365853658536\n",
      "precision for fold 1288:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1289:  0.5181347150259067\n",
      "f1  score for fold 1289:  0.422360248447205\n",
      "recall for fold 1289:  0.39080459770114945\n",
      "precision for fold 1289:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1290:  0.5311004784688995\n",
      "f1  score for fold 1290:  0.37974683544303806\n",
      "recall for fold 1290:  0.38461538461538464\n",
      "precision for fold 1290:  0.375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1291:  0.49282296650717705\n",
      "f1  score for fold 1291:  0.3116883116883117\n",
      "recall for fold 1291:  0.32432432432432434\n",
      "precision for fold 1291:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1292:  0.5476190476190477\n",
      "f1  score for fold 1292:  0.38709677419354843\n",
      "recall for fold 1292:  0.4\n",
      "precision for fold 1292:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1293:  0.558252427184466\n",
      "f1  score for fold 1293:  0.43478260869565216\n",
      "recall for fold 1293:  0.4268292682926829\n",
      "precision for fold 1293:  0.4430379746835443\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1294:  0.45595854922279794\n",
      "f1  score for fold 1294:  0.3478260869565218\n",
      "recall for fold 1294:  0.3218390804597701\n",
      "precision for fold 1294:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1295:  0.5215311004784688\n",
      "f1  score for fold 1295:  0.36708860759493667\n",
      "recall for fold 1295:  0.3717948717948718\n",
      "precision for fold 1295:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1296:  0.5598086124401914\n",
      "f1  score for fold 1296:  0.40259740259740256\n",
      "recall for fold 1296:  0.4189189189189189\n",
      "precision for fold 1296:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1297:  0.5190476190476191\n",
      "f1  score for fold 1297:  0.34838709677419355\n",
      "recall for fold 1297:  0.36\n",
      "precision for fold 1297:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1298:  0.5\n",
      "f1  score for fold 1298:  0.3602484472049689\n",
      "recall for fold 1298:  0.35365853658536583\n",
      "precision for fold 1298:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1299:  0.48704663212435234\n",
      "f1  score for fold 1299:  0.3850931677018633\n",
      "recall for fold 1299:  0.3563218390804598\n",
      "precision for fold 1299:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1300:  0.5311004784688995\n",
      "f1  score for fold 1300:  0.37974683544303806\n",
      "recall for fold 1300:  0.38461538461538464\n",
      "precision for fold 1300:  0.375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1301:  0.48325358851674644\n",
      "f1  score for fold 1301:  0.29870129870129863\n",
      "recall for fold 1301:  0.3108108108108108\n",
      "precision for fold 1301:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1302:  0.5571428571428572\n",
      "f1  score for fold 1302:  0.4000000000000001\n",
      "recall for fold 1302:  0.41333333333333333\n",
      "precision for fold 1302:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1303:  0.5485436893203883\n",
      "f1  score for fold 1303:  0.42236024844720493\n",
      "recall for fold 1303:  0.4146341463414634\n",
      "precision for fold 1303:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1304:  0.48704663212435234\n",
      "f1  score for fold 1304:  0.3850931677018633\n",
      "recall for fold 1304:  0.3563218390804598\n",
      "precision for fold 1304:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1305:  0.5311004784688995\n",
      "f1  score for fold 1305:  0.37974683544303806\n",
      "recall for fold 1305:  0.38461538461538464\n",
      "precision for fold 1305:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1306:  0.5502392344497608\n",
      "f1  score for fold 1306:  0.3896103896103896\n",
      "recall for fold 1306:  0.40540540540540543\n",
      "precision for fold 1306:  0.375\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 1307:  0.6047619047619047\n",
      "f1  score for fold 1307:  0.4645161290322581\n",
      "recall for fold 1307:  0.48\n",
      "precision for fold 1307:  0.45\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1308:  0.5\n",
      "f1  score for fold 1308:  0.3602484472049689\n",
      "recall for fold 1308:  0.35365853658536583\n",
      "precision for fold 1308:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1309:  0.5492227979274611\n",
      "f1  score for fold 1309:  0.45962732919254656\n",
      "recall for fold 1309:  0.42528735632183906\n",
      "precision for fold 1309:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1310:  0.49282296650717705\n",
      "f1  score for fold 1310:  0.32911392405063294\n",
      "recall for fold 1310:  0.3333333333333333\n",
      "precision for fold 1310:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1311:  0.5406698564593302\n",
      "f1  score for fold 1311:  0.37662337662337664\n",
      "recall for fold 1311:  0.3918918918918919\n",
      "precision for fold 1311:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1312:  0.49047619047619045\n",
      "f1  score for fold 1312:  0.3096774193548387\n",
      "recall for fold 1312:  0.32\n",
      "precision for fold 1312:  0.3\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1313:  0.5388349514563107\n",
      "f1  score for fold 1313:  0.40993788819875776\n",
      "recall for fold 1313:  0.4024390243902439\n",
      "precision for fold 1313:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1314:  0.5181347150259067\n",
      "f1  score for fold 1314:  0.422360248447205\n",
      "recall for fold 1314:  0.39080459770114945\n",
      "precision for fold 1314:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1315:  0.5119617224880383\n",
      "f1  score for fold 1315:  0.3544303797468355\n",
      "recall for fold 1315:  0.358974358974359\n",
      "precision for fold 1315:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1316:  0.5406698564593302\n",
      "f1  score for fold 1316:  0.37662337662337664\n",
      "recall for fold 1316:  0.3918918918918919\n",
      "precision for fold 1316:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1317:  0.5285714285714286\n",
      "f1  score for fold 1317:  0.3612903225806451\n",
      "recall for fold 1317:  0.37333333333333335\n",
      "precision for fold 1317:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1318:  0.49029126213592233\n",
      "f1  score for fold 1318:  0.3478260869565218\n",
      "recall for fold 1318:  0.34146341463414637\n",
      "precision for fold 1318:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1319:  0.48704663212435234\n",
      "f1  score for fold 1319:  0.3850931677018633\n",
      "recall for fold 1319:  0.3563218390804598\n",
      "precision for fold 1319:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1320:  0.48325358851674644\n",
      "f1  score for fold 1320:  0.31645569620253167\n",
      "recall for fold 1320:  0.32051282051282054\n",
      "precision for fold 1320:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1321:  0.5215311004784688\n",
      "f1  score for fold 1321:  0.3506493506493507\n",
      "recall for fold 1321:  0.36486486486486486\n",
      "precision for fold 1321:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1322:  0.5476190476190477\n",
      "f1  score for fold 1322:  0.38709677419354843\n",
      "recall for fold 1322:  0.4\n",
      "precision for fold 1322:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1323:  0.49029126213592233\n",
      "f1  score for fold 1323:  0.3478260869565218\n",
      "recall for fold 1323:  0.34146341463414637\n",
      "precision for fold 1323:  0.35443037974683544\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1324:  0.5492227979274611\n",
      "f1  score for fold 1324:  0.45962732919254656\n",
      "recall for fold 1324:  0.42528735632183906\n",
      "precision for fold 1324:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1325:  0.5406698564593302\n",
      "f1  score for fold 1325:  0.3924050632911393\n",
      "recall for fold 1325:  0.3974358974358974\n",
      "precision for fold 1325:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1326:  0.5215311004784688\n",
      "f1  score for fold 1326:  0.3506493506493507\n",
      "recall for fold 1326:  0.36486486486486486\n",
      "precision for fold 1326:  0.3375\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 1327:  0.6142857142857143\n",
      "f1  score for fold 1327:  0.47741935483870973\n",
      "recall for fold 1327:  0.49333333333333335\n",
      "precision for fold 1327:  0.4625\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 1328:  0.5776699029126213\n",
      "f1  score for fold 1328:  0.4596273291925466\n",
      "recall for fold 1328:  0.45121951219512196\n",
      "precision for fold 1328:  0.46835443037974683\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1329:  0.48704663212435234\n",
      "f1  score for fold 1329:  0.3850931677018633\n",
      "recall for fold 1329:  0.3563218390804598\n",
      "precision for fold 1329:  0.4189189189189189\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1330:  0.5023923444976076\n",
      "f1  score for fold 1330:  0.34177215189873417\n",
      "recall for fold 1330:  0.34615384615384615\n",
      "precision for fold 1330:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1331:  0.5406698564593302\n",
      "f1  score for fold 1331:  0.37662337662337664\n",
      "recall for fold 1331:  0.3918918918918919\n",
      "precision for fold 1331:  0.3625\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1332:  0.48095238095238096\n",
      "f1  score for fold 1332:  0.2967741935483871\n",
      "recall for fold 1332:  0.30666666666666664\n",
      "precision for fold 1332:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1333:  0.5388349514563107\n",
      "f1  score for fold 1333:  0.40993788819875776\n",
      "recall for fold 1333:  0.4024390243902439\n",
      "precision for fold 1333:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1334:  0.5077720207253886\n",
      "f1  score for fold 1334:  0.40993788819875776\n",
      "recall for fold 1334:  0.3793103448275862\n",
      "precision for fold 1334:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1335:  0.5119617224880383\n",
      "f1  score for fold 1335:  0.3544303797468355\n",
      "recall for fold 1335:  0.358974358974359\n",
      "precision for fold 1335:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1336:  0.5311004784688995\n",
      "f1  score for fold 1336:  0.36363636363636365\n",
      "recall for fold 1336:  0.3783783783783784\n",
      "precision for fold 1336:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1337:  0.5857142857142857\n",
      "f1  score for fold 1337:  0.43870967741935485\n",
      "recall for fold 1337:  0.4533333333333333\n",
      "precision for fold 1337:  0.425\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1338:  0.48058252427184467\n",
      "f1  score for fold 1338:  0.33540372670807456\n",
      "recall for fold 1338:  0.32926829268292684\n",
      "precision for fold 1338:  0.34177215189873417\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1339:  0.5595854922279793\n",
      "f1  score for fold 1339:  0.4720496894409938\n",
      "recall for fold 1339:  0.4367816091954023\n",
      "precision for fold 1339:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1340:  0.5598086124401914\n",
      "f1  score for fold 1340:  0.4177215189873418\n",
      "recall for fold 1340:  0.4230769230769231\n",
      "precision for fold 1340:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1341:  0.5311004784688995\n",
      "f1  score for fold 1341:  0.36363636363636365\n",
      "recall for fold 1341:  0.3783783783783784\n",
      "precision for fold 1341:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1342:  0.5095238095238095\n",
      "f1  score for fold 1342:  0.335483870967742\n",
      "recall for fold 1342:  0.3466666666666667\n",
      "precision for fold 1342:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1343:  0.5194174757281553\n",
      "f1  score for fold 1343:  0.38509316770186336\n",
      "recall for fold 1343:  0.3780487804878049\n",
      "precision for fold 1343:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1344:  0.48704663212435234\n",
      "f1  score for fold 1344:  0.3850931677018633\n",
      "recall for fold 1344:  0.3563218390804598\n",
      "precision for fold 1344:  0.4189189189189189\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1345:  0.49282296650717705\n",
      "f1  score for fold 1345:  0.32911392405063294\n",
      "recall for fold 1345:  0.3333333333333333\n",
      "precision for fold 1345:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1346:  0.5406698564593302\n",
      "f1  score for fold 1346:  0.37662337662337664\n",
      "recall for fold 1346:  0.3918918918918919\n",
      "precision for fold 1346:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1347:  0.5285714285714286\n",
      "f1  score for fold 1347:  0.3612903225806451\n",
      "recall for fold 1347:  0.37333333333333335\n",
      "precision for fold 1347:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1348:  0.5097087378640777\n",
      "f1  score for fold 1348:  0.37267080745341613\n",
      "recall for fold 1348:  0.36585365853658536\n",
      "precision for fold 1348:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1349:  0.5181347150259067\n",
      "f1  score for fold 1349:  0.422360248447205\n",
      "recall for fold 1349:  0.39080459770114945\n",
      "precision for fold 1349:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1350:  0.5598086124401914\n",
      "f1  score for fold 1350:  0.4177215189873418\n",
      "recall for fold 1350:  0.4230769230769231\n",
      "precision for fold 1350:  0.4125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1351:  0.5023923444976076\n",
      "f1  score for fold 1351:  0.3246753246753247\n",
      "recall for fold 1351:  0.33783783783783783\n",
      "precision for fold 1351:  0.3125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1352:  0.5476190476190477\n",
      "f1  score for fold 1352:  0.38709677419354843\n",
      "recall for fold 1352:  0.4\n",
      "precision for fold 1352:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1353:  0.5679611650485437\n",
      "f1  score for fold 1353:  0.4472049689440994\n",
      "recall for fold 1353:  0.43902439024390244\n",
      "precision for fold 1353:  0.45569620253164556\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1354:  0.5077720207253886\n",
      "f1  score for fold 1354:  0.40993788819875776\n",
      "recall for fold 1354:  0.3793103448275862\n",
      "precision for fold 1354:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1355:  0.569377990430622\n",
      "f1  score for fold 1355:  0.43037974683544306\n",
      "recall for fold 1355:  0.4358974358974359\n",
      "precision for fold 1355:  0.425\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1356:  0.48325358851674644\n",
      "f1  score for fold 1356:  0.29870129870129863\n",
      "recall for fold 1356:  0.3108108108108108\n",
      "precision for fold 1356:  0.2875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1357:  0.5\n",
      "f1  score for fold 1357:  0.3225806451612903\n",
      "recall for fold 1357:  0.3333333333333333\n",
      "precision for fold 1357:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1358:  0.5097087378640777\n",
      "f1  score for fold 1358:  0.37267080745341613\n",
      "recall for fold 1358:  0.36585365853658536\n",
      "precision for fold 1358:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1359:  0.5181347150259067\n",
      "f1  score for fold 1359:  0.422360248447205\n",
      "recall for fold 1359:  0.39080459770114945\n",
      "precision for fold 1359:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1360:  0.5311004784688995\n",
      "f1  score for fold 1360:  0.37974683544303806\n",
      "recall for fold 1360:  0.38461538461538464\n",
      "precision for fold 1360:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1361:  0.5598086124401914\n",
      "f1  score for fold 1361:  0.40259740259740256\n",
      "recall for fold 1361:  0.4189189189189189\n",
      "precision for fold 1361:  0.3875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1362:  0.5095238095238095\n",
      "f1  score for fold 1362:  0.335483870967742\n",
      "recall for fold 1362:  0.3466666666666667\n",
      "precision for fold 1362:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1363:  0.558252427184466\n",
      "f1  score for fold 1363:  0.43478260869565216\n",
      "recall for fold 1363:  0.4268292682926829\n",
      "precision for fold 1363:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1364:  0.5181347150259067\n",
      "f1  score for fold 1364:  0.422360248447205\n",
      "recall for fold 1364:  0.39080459770114945\n",
      "precision for fold 1364:  0.4594594594594595\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 1365:  0.47368421052631576\n",
      "f1  score for fold 1365:  0.3037974683544304\n",
      "recall for fold 1365:  0.3076923076923077\n",
      "precision for fold 1365:  0.3\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1366:  0.5406698564593302\n",
      "f1  score for fold 1366:  0.37662337662337664\n",
      "recall for fold 1366:  0.3918918918918919\n",
      "precision for fold 1366:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1367:  0.5095238095238095\n",
      "f1  score for fold 1367:  0.335483870967742\n",
      "recall for fold 1367:  0.3466666666666667\n",
      "precision for fold 1367:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1368:  0.49029126213592233\n",
      "f1  score for fold 1368:  0.3478260869565218\n",
      "recall for fold 1368:  0.34146341463414637\n",
      "precision for fold 1368:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1369:  0.48704663212435234\n",
      "f1  score for fold 1369:  0.3850931677018633\n",
      "recall for fold 1369:  0.3563218390804598\n",
      "precision for fold 1369:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1370:  0.569377990430622\n",
      "f1  score for fold 1370:  0.43037974683544306\n",
      "recall for fold 1370:  0.4358974358974359\n",
      "precision for fold 1370:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1371:  0.5023923444976076\n",
      "f1  score for fold 1371:  0.3246753246753247\n",
      "recall for fold 1371:  0.33783783783783783\n",
      "precision for fold 1371:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1372:  0.5095238095238095\n",
      "f1  score for fold 1372:  0.335483870967742\n",
      "recall for fold 1372:  0.3466666666666667\n",
      "precision for fold 1372:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1373:  0.529126213592233\n",
      "f1  score for fold 1373:  0.39751552795031053\n",
      "recall for fold 1373:  0.3902439024390244\n",
      "precision for fold 1373:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1374:  0.538860103626943\n",
      "f1  score for fold 1374:  0.4472049689440994\n",
      "recall for fold 1374:  0.41379310344827586\n",
      "precision for fold 1374:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1375:  0.5598086124401914\n",
      "f1  score for fold 1375:  0.4177215189873418\n",
      "recall for fold 1375:  0.4230769230769231\n",
      "precision for fold 1375:  0.4125\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1376:  0.569377990430622\n",
      "f1  score for fold 1376:  0.4155844155844156\n",
      "recall for fold 1376:  0.43243243243243246\n",
      "precision for fold 1376:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1377:  0.5190476190476191\n",
      "f1  score for fold 1377:  0.34838709677419355\n",
      "recall for fold 1377:  0.36\n",
      "precision for fold 1377:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1378:  0.49029126213592233\n",
      "f1  score for fold 1378:  0.3478260869565218\n",
      "recall for fold 1378:  0.34146341463414637\n",
      "precision for fold 1378:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1379:  0.5181347150259067\n",
      "f1  score for fold 1379:  0.422360248447205\n",
      "recall for fold 1379:  0.39080459770114945\n",
      "precision for fold 1379:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1380:  0.5311004784688995\n",
      "f1  score for fold 1380:  0.37974683544303806\n",
      "recall for fold 1380:  0.38461538461538464\n",
      "precision for fold 1380:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1381:  0.5023923444976076\n",
      "f1  score for fold 1381:  0.3246753246753247\n",
      "recall for fold 1381:  0.33783783783783783\n",
      "precision for fold 1381:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1382:  0.5095238095238095\n",
      "f1  score for fold 1382:  0.335483870967742\n",
      "recall for fold 1382:  0.3466666666666667\n",
      "precision for fold 1382:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1383:  0.5388349514563107\n",
      "f1  score for fold 1383:  0.40993788819875776\n",
      "recall for fold 1383:  0.4024390243902439\n",
      "precision for fold 1383:  0.4177215189873418\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1384:  0.5699481865284974\n",
      "f1  score for fold 1384:  0.48447204968944096\n",
      "recall for fold 1384:  0.4482758620689655\n",
      "precision for fold 1384:  0.527027027027027\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1385:  0.48325358851674644\n",
      "f1  score for fold 1385:  0.31645569620253167\n",
      "recall for fold 1385:  0.32051282051282054\n",
      "precision for fold 1385:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1386:  0.5598086124401914\n",
      "f1  score for fold 1386:  0.40259740259740256\n",
      "recall for fold 1386:  0.4189189189189189\n",
      "precision for fold 1386:  0.3875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1387:  0.5571428571428572\n",
      "f1  score for fold 1387:  0.4000000000000001\n",
      "recall for fold 1387:  0.41333333333333333\n",
      "precision for fold 1387:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1388:  0.5097087378640777\n",
      "f1  score for fold 1388:  0.37267080745341613\n",
      "recall for fold 1388:  0.36585365853658536\n",
      "precision for fold 1388:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1389:  0.44559585492227977\n",
      "f1  score for fold 1389:  0.33540372670807456\n",
      "recall for fold 1389:  0.3103448275862069\n",
      "precision for fold 1389:  0.36486486486486486\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1390:  0.5215311004784688\n",
      "f1  score for fold 1390:  0.36708860759493667\n",
      "recall for fold 1390:  0.3717948717948718\n",
      "precision for fold 1390:  0.3625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1391:  0.5119617224880383\n",
      "f1  score for fold 1391:  0.33766233766233766\n",
      "recall for fold 1391:  0.35135135135135137\n",
      "precision for fold 1391:  0.325\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1392:  0.5\n",
      "f1  score for fold 1392:  0.3225806451612903\n",
      "recall for fold 1392:  0.3333333333333333\n",
      "precision for fold 1392:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1393:  0.5097087378640777\n",
      "f1  score for fold 1393:  0.37267080745341613\n",
      "recall for fold 1393:  0.36585365853658536\n",
      "precision for fold 1393:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1394:  0.538860103626943\n",
      "f1  score for fold 1394:  0.4472049689440994\n",
      "recall for fold 1394:  0.41379310344827586\n",
      "precision for fold 1394:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1395:  0.5406698564593302\n",
      "f1  score for fold 1395:  0.3924050632911393\n",
      "recall for fold 1395:  0.3974358974358974\n",
      "precision for fold 1395:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1396:  0.5311004784688995\n",
      "f1  score for fold 1396:  0.36363636363636365\n",
      "recall for fold 1396:  0.3783783783783784\n",
      "precision for fold 1396:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1397:  0.5571428571428572\n",
      "f1  score for fold 1397:  0.4000000000000001\n",
      "recall for fold 1397:  0.41333333333333333\n",
      "precision for fold 1397:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1398:  0.5\n",
      "f1  score for fold 1398:  0.3602484472049689\n",
      "recall for fold 1398:  0.35365853658536583\n",
      "precision for fold 1398:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1399:  0.5284974093264249\n",
      "f1  score for fold 1399:  0.4347826086956522\n",
      "recall for fold 1399:  0.40229885057471265\n",
      "precision for fold 1399:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1400:  0.5119617224880383\n",
      "f1  score for fold 1400:  0.3544303797468355\n",
      "recall for fold 1400:  0.358974358974359\n",
      "precision for fold 1400:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1401:  0.5502392344497608\n",
      "f1  score for fold 1401:  0.3896103896103896\n",
      "recall for fold 1401:  0.40540540540540543\n",
      "precision for fold 1401:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1402:  0.5571428571428572\n",
      "f1  score for fold 1402:  0.4000000000000001\n",
      "recall for fold 1402:  0.41333333333333333\n",
      "precision for fold 1402:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1403:  0.5485436893203883\n",
      "f1  score for fold 1403:  0.42236024844720493\n",
      "recall for fold 1403:  0.4146341463414634\n",
      "precision for fold 1403:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1404:  0.49740932642487046\n",
      "f1  score for fold 1404:  0.39751552795031053\n",
      "recall for fold 1404:  0.367816091954023\n",
      "precision for fold 1404:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1405:  0.5215311004784688\n",
      "f1  score for fold 1405:  0.36708860759493667\n",
      "recall for fold 1405:  0.3717948717948718\n",
      "precision for fold 1405:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1406:  0.5311004784688995\n",
      "f1  score for fold 1406:  0.36363636363636365\n",
      "recall for fold 1406:  0.3783783783783784\n",
      "precision for fold 1406:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1407:  0.5380952380952381\n",
      "f1  score for fold 1407:  0.3741935483870968\n",
      "recall for fold 1407:  0.38666666666666666\n",
      "precision for fold 1407:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1408:  0.5097087378640777\n",
      "f1  score for fold 1408:  0.37267080745341613\n",
      "recall for fold 1408:  0.36585365853658536\n",
      "precision for fold 1408:  0.379746835443038\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1409:  0.5492227979274611\n",
      "f1  score for fold 1409:  0.45962732919254656\n",
      "recall for fold 1409:  0.42528735632183906\n",
      "precision for fold 1409:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1410:  0.5311004784688995\n",
      "f1  score for fold 1410:  0.37974683544303806\n",
      "recall for fold 1410:  0.38461538461538464\n",
      "precision for fold 1410:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1411:  0.5023923444976076\n",
      "f1  score for fold 1411:  0.3246753246753247\n",
      "recall for fold 1411:  0.33783783783783783\n",
      "precision for fold 1411:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1412:  0.5095238095238095\n",
      "f1  score for fold 1412:  0.335483870967742\n",
      "recall for fold 1412:  0.3466666666666667\n",
      "precision for fold 1412:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1413:  0.5388349514563107\n",
      "f1  score for fold 1413:  0.40993788819875776\n",
      "recall for fold 1413:  0.4024390243902439\n",
      "precision for fold 1413:  0.4177215189873418\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1414:  0.44559585492227977\n",
      "f1  score for fold 1414:  0.33540372670807456\n",
      "recall for fold 1414:  0.3103448275862069\n",
      "precision for fold 1414:  0.36486486486486486\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1415:  0.5406698564593302\n",
      "f1  score for fold 1415:  0.3924050632911393\n",
      "recall for fold 1415:  0.3974358974358974\n",
      "precision for fold 1415:  0.3875\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 1416:  0.6172248803827751\n",
      "f1  score for fold 1416:  0.4805194805194805\n",
      "recall for fold 1416:  0.5\n",
      "precision for fold 1416:  0.4625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1417:  0.5666666666666667\n",
      "f1  score for fold 1417:  0.41290322580645167\n",
      "recall for fold 1417:  0.4266666666666667\n",
      "precision for fold 1417:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1418:  0.529126213592233\n",
      "f1  score for fold 1418:  0.39751552795031053\n",
      "recall for fold 1418:  0.3902439024390244\n",
      "precision for fold 1418:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1419:  0.5181347150259067\n",
      "f1  score for fold 1419:  0.422360248447205\n",
      "recall for fold 1419:  0.39080459770114945\n",
      "precision for fold 1419:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1420:  0.49282296650717705\n",
      "f1  score for fold 1420:  0.32911392405063294\n",
      "recall for fold 1420:  0.3333333333333333\n",
      "precision for fold 1420:  0.325\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1421:  0.569377990430622\n",
      "f1  score for fold 1421:  0.4155844155844156\n",
      "recall for fold 1421:  0.43243243243243246\n",
      "precision for fold 1421:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1422:  0.5380952380952381\n",
      "f1  score for fold 1422:  0.3741935483870968\n",
      "recall for fold 1422:  0.38666666666666666\n",
      "precision for fold 1422:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1423:  0.5\n",
      "f1  score for fold 1423:  0.3602484472049689\n",
      "recall for fold 1423:  0.35365853658536583\n",
      "precision for fold 1423:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1424:  0.5077720207253886\n",
      "f1  score for fold 1424:  0.40993788819875776\n",
      "recall for fold 1424:  0.3793103448275862\n",
      "precision for fold 1424:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1425:  0.5119617224880383\n",
      "f1  score for fold 1425:  0.3544303797468355\n",
      "recall for fold 1425:  0.358974358974359\n",
      "precision for fold 1425:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1426:  0.5502392344497608\n",
      "f1  score for fold 1426:  0.3896103896103896\n",
      "recall for fold 1426:  0.40540540540540543\n",
      "precision for fold 1426:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1427:  0.5\n",
      "f1  score for fold 1427:  0.3225806451612903\n",
      "recall for fold 1427:  0.3333333333333333\n",
      "precision for fold 1427:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1428:  0.5485436893203883\n",
      "f1  score for fold 1428:  0.42236024844720493\n",
      "recall for fold 1428:  0.4146341463414634\n",
      "precision for fold 1428:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1429:  0.5492227979274611\n",
      "f1  score for fold 1429:  0.45962732919254656\n",
      "recall for fold 1429:  0.42528735632183906\n",
      "precision for fold 1429:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1430:  0.5406698564593302\n",
      "f1  score for fold 1430:  0.3924050632911393\n",
      "recall for fold 1430:  0.3974358974358974\n",
      "precision for fold 1430:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1431:  0.49282296650717705\n",
      "f1  score for fold 1431:  0.3116883116883117\n",
      "recall for fold 1431:  0.32432432432432434\n",
      "precision for fold 1431:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1432:  0.5\n",
      "f1  score for fold 1432:  0.3225806451612903\n",
      "recall for fold 1432:  0.3333333333333333\n",
      "precision for fold 1432:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1433:  0.5097087378640777\n",
      "f1  score for fold 1433:  0.37267080745341613\n",
      "recall for fold 1433:  0.36585365853658536\n",
      "precision for fold 1433:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1434:  0.5284974093264249\n",
      "f1  score for fold 1434:  0.4347826086956522\n",
      "recall for fold 1434:  0.40229885057471265\n",
      "precision for fold 1434:  0.47297297297297297\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 1435:  0.46411483253588515\n",
      "f1  score for fold 1435:  0.2911392405063291\n",
      "recall for fold 1435:  0.2948717948717949\n",
      "precision for fold 1435:  0.2875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1436:  0.5023923444976076\n",
      "f1  score for fold 1436:  0.3246753246753247\n",
      "recall for fold 1436:  0.33783783783783783\n",
      "precision for fold 1436:  0.3125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1437:  0.5285714285714286\n",
      "f1  score for fold 1437:  0.3612903225806451\n",
      "recall for fold 1437:  0.37333333333333335\n",
      "precision for fold 1437:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1438:  0.5388349514563107\n",
      "f1  score for fold 1438:  0.40993788819875776\n",
      "recall for fold 1438:  0.4024390243902439\n",
      "precision for fold 1438:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1439:  0.5077720207253886\n",
      "f1  score for fold 1439:  0.40993788819875776\n",
      "recall for fold 1439:  0.3793103448275862\n",
      "precision for fold 1439:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1440:  0.5598086124401914\n",
      "f1  score for fold 1440:  0.4177215189873418\n",
      "recall for fold 1440:  0.4230769230769231\n",
      "precision for fold 1440:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1441:  0.5406698564593302\n",
      "f1  score for fold 1441:  0.37662337662337664\n",
      "recall for fold 1441:  0.3918918918918919\n",
      "precision for fold 1441:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1442:  0.5380952380952381\n",
      "f1  score for fold 1442:  0.3741935483870968\n",
      "recall for fold 1442:  0.38666666666666666\n",
      "precision for fold 1442:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1443:  0.5\n",
      "f1  score for fold 1443:  0.3602484472049689\n",
      "recall for fold 1443:  0.35365853658536583\n",
      "precision for fold 1443:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1444:  0.49740932642487046\n",
      "f1  score for fold 1444:  0.39751552795031053\n",
      "recall for fold 1444:  0.367816091954023\n",
      "precision for fold 1444:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1445:  0.5502392344497608\n",
      "f1  score for fold 1445:  0.4050632911392405\n",
      "recall for fold 1445:  0.41025641025641024\n",
      "precision for fold 1445:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1446:  0.5598086124401914\n",
      "f1  score for fold 1446:  0.40259740259740256\n",
      "recall for fold 1446:  0.4189189189189189\n",
      "precision for fold 1446:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1447:  0.5\n",
      "f1  score for fold 1447:  0.3225806451612903\n",
      "recall for fold 1447:  0.3333333333333333\n",
      "precision for fold 1447:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1448:  0.5485436893203883\n",
      "f1  score for fold 1448:  0.42236024844720493\n",
      "recall for fold 1448:  0.4146341463414634\n",
      "precision for fold 1448:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1449:  0.48704663212435234\n",
      "f1  score for fold 1449:  0.3850931677018633\n",
      "recall for fold 1449:  0.3563218390804598\n",
      "precision for fold 1449:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1450:  0.5502392344497608\n",
      "f1  score for fold 1450:  0.4050632911392405\n",
      "recall for fold 1450:  0.41025641025641024\n",
      "precision for fold 1450:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1451:  0.5502392344497608\n",
      "f1  score for fold 1451:  0.3896103896103896\n",
      "recall for fold 1451:  0.40540540540540543\n",
      "precision for fold 1451:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1452:  0.5476190476190477\n",
      "f1  score for fold 1452:  0.38709677419354843\n",
      "recall for fold 1452:  0.4\n",
      "precision for fold 1452:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1453:  0.5679611650485437\n",
      "f1  score for fold 1453:  0.4472049689440994\n",
      "recall for fold 1453:  0.43902439024390244\n",
      "precision for fold 1453:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1454:  0.49740932642487046\n",
      "f1  score for fold 1454:  0.39751552795031053\n",
      "recall for fold 1454:  0.367816091954023\n",
      "precision for fold 1454:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1455:  0.5023923444976076\n",
      "f1  score for fold 1455:  0.34177215189873417\n",
      "recall for fold 1455:  0.34615384615384615\n",
      "precision for fold 1455:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1456:  0.5502392344497608\n",
      "f1  score for fold 1456:  0.3896103896103896\n",
      "recall for fold 1456:  0.40540540540540543\n",
      "precision for fold 1456:  0.375\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1457:  0.5952380952380952\n",
      "f1  score for fold 1457:  0.45161290322580644\n",
      "recall for fold 1457:  0.4666666666666667\n",
      "precision for fold 1457:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1458:  0.5485436893203883\n",
      "f1  score for fold 1458:  0.42236024844720493\n",
      "recall for fold 1458:  0.4146341463414634\n",
      "precision for fold 1458:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1459:  0.48704663212435234\n",
      "f1  score for fold 1459:  0.3850931677018633\n",
      "recall for fold 1459:  0.3563218390804598\n",
      "precision for fold 1459:  0.4189189189189189\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 1460:  0.46411483253588515\n",
      "f1  score for fold 1460:  0.2911392405063291\n",
      "recall for fold 1460:  0.2948717948717949\n",
      "precision for fold 1460:  0.2875\n",
      "    0   1\n",
      "0  20  54\n",
      "1  60  75\n",
      "Accuracy for fold 1461:  0.45454545454545453\n",
      "f1  score for fold 1461:  0.25974025974025977\n",
      "recall for fold 1461:  0.2702702702702703\n",
      "precision for fold 1461:  0.25\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 1462:  0.6047619047619047\n",
      "f1  score for fold 1462:  0.4645161290322581\n",
      "recall for fold 1462:  0.48\n",
      "precision for fold 1462:  0.45\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1463:  0.5097087378640777\n",
      "f1  score for fold 1463:  0.37267080745341613\n",
      "recall for fold 1463:  0.36585365853658536\n",
      "precision for fold 1463:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1464:  0.44559585492227977\n",
      "f1  score for fold 1464:  0.33540372670807456\n",
      "recall for fold 1464:  0.3103448275862069\n",
      "precision for fold 1464:  0.36486486486486486\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1465:  0.5502392344497608\n",
      "f1  score for fold 1465:  0.4050632911392405\n",
      "recall for fold 1465:  0.41025641025641024\n",
      "precision for fold 1465:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1466:  0.5502392344497608\n",
      "f1  score for fold 1466:  0.3896103896103896\n",
      "recall for fold 1466:  0.40540540540540543\n",
      "precision for fold 1466:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1467:  0.5\n",
      "f1  score for fold 1467:  0.3225806451612903\n",
      "recall for fold 1467:  0.3333333333333333\n",
      "precision for fold 1467:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1468:  0.5194174757281553\n",
      "f1  score for fold 1468:  0.38509316770186336\n",
      "recall for fold 1468:  0.3780487804878049\n",
      "precision for fold 1468:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1469:  0.5181347150259067\n",
      "f1  score for fold 1469:  0.422360248447205\n",
      "recall for fold 1469:  0.39080459770114945\n",
      "precision for fold 1469:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1470:  0.5311004784688995\n",
      "f1  score for fold 1470:  0.37974683544303806\n",
      "recall for fold 1470:  0.38461538461538464\n",
      "precision for fold 1470:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1471:  0.5119617224880383\n",
      "f1  score for fold 1471:  0.33766233766233766\n",
      "recall for fold 1471:  0.35135135135135137\n",
      "precision for fold 1471:  0.325\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1472:  0.49047619047619045\n",
      "f1  score for fold 1472:  0.3096774193548387\n",
      "recall for fold 1472:  0.32\n",
      "precision for fold 1472:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1473:  0.5097087378640777\n",
      "f1  score for fold 1473:  0.37267080745341613\n",
      "recall for fold 1473:  0.36585365853658536\n",
      "precision for fold 1473:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1474:  0.5181347150259067\n",
      "f1  score for fold 1474:  0.422360248447205\n",
      "recall for fold 1474:  0.39080459770114945\n",
      "precision for fold 1474:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1475:  0.569377990430622\n",
      "f1  score for fold 1475:  0.43037974683544306\n",
      "recall for fold 1475:  0.4358974358974359\n",
      "precision for fold 1475:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1476:  0.5311004784688995\n",
      "f1  score for fold 1476:  0.36363636363636365\n",
      "recall for fold 1476:  0.3783783783783784\n",
      "precision for fold 1476:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1477:  0.5761904761904761\n",
      "f1  score for fold 1477:  0.4258064516129032\n",
      "recall for fold 1477:  0.44\n",
      "precision for fold 1477:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1478:  0.5194174757281553\n",
      "f1  score for fold 1478:  0.38509316770186336\n",
      "recall for fold 1478:  0.3780487804878049\n",
      "precision for fold 1478:  0.3924050632911392\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 1479:  0.5906735751295337\n",
      "f1  score for fold 1479:  0.5093167701863355\n",
      "recall for fold 1479:  0.47126436781609193\n",
      "precision for fold 1479:  0.5540540540540541\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1480:  0.5119617224880383\n",
      "f1  score for fold 1480:  0.3544303797468355\n",
      "recall for fold 1480:  0.358974358974359\n",
      "precision for fold 1480:  0.35\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1481:  0.5789473684210527\n",
      "f1  score for fold 1481:  0.42857142857142855\n",
      "recall for fold 1481:  0.44594594594594594\n",
      "precision for fold 1481:  0.4125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1482:  0.5\n",
      "f1  score for fold 1482:  0.3225806451612903\n",
      "recall for fold 1482:  0.3333333333333333\n",
      "precision for fold 1482:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1483:  0.529126213592233\n",
      "f1  score for fold 1483:  0.39751552795031053\n",
      "recall for fold 1483:  0.3902439024390244\n",
      "precision for fold 1483:  0.4050632911392405\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 1484:  0.43523316062176165\n",
      "f1  score for fold 1484:  0.3229813664596274\n",
      "recall for fold 1484:  0.2988505747126437\n",
      "precision for fold 1484:  0.35135135135135137\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1485:  0.5598086124401914\n",
      "f1  score for fold 1485:  0.4177215189873418\n",
      "recall for fold 1485:  0.4230769230769231\n",
      "precision for fold 1485:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1486:  0.5311004784688995\n",
      "f1  score for fold 1486:  0.36363636363636365\n",
      "recall for fold 1486:  0.3783783783783784\n",
      "precision for fold 1486:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1487:  0.5761904761904761\n",
      "f1  score for fold 1487:  0.4258064516129032\n",
      "recall for fold 1487:  0.44\n",
      "precision for fold 1487:  0.4125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1488:  0.5\n",
      "f1  score for fold 1488:  0.3602484472049689\n",
      "recall for fold 1488:  0.35365853658536583\n",
      "precision for fold 1488:  0.3670886075949367\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1489:  0.5595854922279793\n",
      "f1  score for fold 1489:  0.4720496894409938\n",
      "recall for fold 1489:  0.4367816091954023\n",
      "precision for fold 1489:  0.5135135135135135\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1490:  0.5311004784688995\n",
      "f1  score for fold 1490:  0.37974683544303806\n",
      "recall for fold 1490:  0.38461538461538464\n",
      "precision for fold 1490:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1491:  0.5119617224880383\n",
      "f1  score for fold 1491:  0.33766233766233766\n",
      "recall for fold 1491:  0.35135135135135137\n",
      "precision for fold 1491:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1492:  0.5476190476190477\n",
      "f1  score for fold 1492:  0.38709677419354843\n",
      "recall for fold 1492:  0.4\n",
      "precision for fold 1492:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1493:  0.529126213592233\n",
      "f1  score for fold 1493:  0.39751552795031053\n",
      "recall for fold 1493:  0.3902439024390244\n",
      "precision for fold 1493:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1494:  0.48704663212435234\n",
      "f1  score for fold 1494:  0.3850931677018633\n",
      "recall for fold 1494:  0.3563218390804598\n",
      "precision for fold 1494:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1495:  0.5406698564593302\n",
      "f1  score for fold 1495:  0.3924050632911393\n",
      "recall for fold 1495:  0.3974358974358974\n",
      "precision for fold 1495:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1496:  0.5119617224880383\n",
      "f1  score for fold 1496:  0.33766233766233766\n",
      "recall for fold 1496:  0.35135135135135137\n",
      "precision for fold 1496:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1497:  0.5190476190476191\n",
      "f1  score for fold 1497:  0.34838709677419355\n",
      "recall for fold 1497:  0.36\n",
      "precision for fold 1497:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1498:  0.5485436893203883\n",
      "f1  score for fold 1498:  0.42236024844720493\n",
      "recall for fold 1498:  0.4146341463414634\n",
      "precision for fold 1498:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1499:  0.5284974093264249\n",
      "f1  score for fold 1499:  0.4347826086956522\n",
      "recall for fold 1499:  0.40229885057471265\n",
      "precision for fold 1499:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1500:  0.5502392344497608\n",
      "f1  score for fold 1500:  0.4050632911392405\n",
      "recall for fold 1500:  0.41025641025641024\n",
      "precision for fold 1500:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1501:  0.5502392344497608\n",
      "f1  score for fold 1501:  0.3896103896103896\n",
      "recall for fold 1501:  0.40540540540540543\n",
      "precision for fold 1501:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1502:  0.5666666666666667\n",
      "f1  score for fold 1502:  0.41290322580645167\n",
      "recall for fold 1502:  0.4266666666666667\n",
      "precision for fold 1502:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1503:  0.5679611650485437\n",
      "f1  score for fold 1503:  0.4472049689440994\n",
      "recall for fold 1503:  0.43902439024390244\n",
      "precision for fold 1503:  0.45569620253164556\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1504:  0.5492227979274611\n",
      "f1  score for fold 1504:  0.45962732919254656\n",
      "recall for fold 1504:  0.42528735632183906\n",
      "precision for fold 1504:  0.5\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1505:  0.5119617224880383\n",
      "f1  score for fold 1505:  0.3544303797468355\n",
      "recall for fold 1505:  0.358974358974359\n",
      "precision for fold 1505:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1506:  0.5406698564593302\n",
      "f1  score for fold 1506:  0.37662337662337664\n",
      "recall for fold 1506:  0.3918918918918919\n",
      "precision for fold 1506:  0.3625\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1507:  0.5952380952380952\n",
      "f1  score for fold 1507:  0.45161290322580644\n",
      "recall for fold 1507:  0.4666666666666667\n",
      "precision for fold 1507:  0.4375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1508:  0.46116504854368934\n",
      "f1  score for fold 1508:  0.31055900621118016\n",
      "recall for fold 1508:  0.3048780487804878\n",
      "precision for fold 1508:  0.31645569620253167\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1509:  0.5077720207253886\n",
      "f1  score for fold 1509:  0.40993788819875776\n",
      "recall for fold 1509:  0.3793103448275862\n",
      "precision for fold 1509:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1510:  0.5119617224880383\n",
      "f1  score for fold 1510:  0.3544303797468355\n",
      "recall for fold 1510:  0.358974358974359\n",
      "precision for fold 1510:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1511:  0.569377990430622\n",
      "f1  score for fold 1511:  0.4155844155844156\n",
      "recall for fold 1511:  0.43243243243243246\n",
      "precision for fold 1511:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1512:  0.5190476190476191\n",
      "f1  score for fold 1512:  0.34838709677419355\n",
      "recall for fold 1512:  0.36\n",
      "precision for fold 1512:  0.3375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1513:  0.470873786407767\n",
      "f1  score for fold 1513:  0.3229813664596273\n",
      "recall for fold 1513:  0.3170731707317073\n",
      "precision for fold 1513:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1514:  0.538860103626943\n",
      "f1  score for fold 1514:  0.4472049689440994\n",
      "recall for fold 1514:  0.41379310344827586\n",
      "precision for fold 1514:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1515:  0.569377990430622\n",
      "f1  score for fold 1515:  0.43037974683544306\n",
      "recall for fold 1515:  0.4358974358974359\n",
      "precision for fold 1515:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1516:  0.5023923444976076\n",
      "f1  score for fold 1516:  0.3246753246753247\n",
      "recall for fold 1516:  0.33783783783783783\n",
      "precision for fold 1516:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1517:  0.5095238095238095\n",
      "f1  score for fold 1517:  0.335483870967742\n",
      "recall for fold 1517:  0.3466666666666667\n",
      "precision for fold 1517:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1518:  0.5097087378640777\n",
      "f1  score for fold 1518:  0.37267080745341613\n",
      "recall for fold 1518:  0.36585365853658536\n",
      "precision for fold 1518:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1519:  0.45595854922279794\n",
      "f1  score for fold 1519:  0.3478260869565218\n",
      "recall for fold 1519:  0.3218390804597701\n",
      "precision for fold 1519:  0.3783783783783784\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 1520:  0.47368421052631576\n",
      "f1  score for fold 1520:  0.3037974683544304\n",
      "recall for fold 1520:  0.3076923076923077\n",
      "precision for fold 1520:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1521:  0.5502392344497608\n",
      "f1  score for fold 1521:  0.3896103896103896\n",
      "recall for fold 1521:  0.40540540540540543\n",
      "precision for fold 1521:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1522:  0.5666666666666667\n",
      "f1  score for fold 1522:  0.41290322580645167\n",
      "recall for fold 1522:  0.4266666666666667\n",
      "precision for fold 1522:  0.4\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1523:  0.5485436893203883\n",
      "f1  score for fold 1523:  0.42236024844720493\n",
      "recall for fold 1523:  0.4146341463414634\n",
      "precision for fold 1523:  0.43037974683544306\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1524:  0.44559585492227977\n",
      "f1  score for fold 1524:  0.33540372670807456\n",
      "recall for fold 1524:  0.3103448275862069\n",
      "precision for fold 1524:  0.36486486486486486\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1525:  0.5598086124401914\n",
      "f1  score for fold 1525:  0.4177215189873418\n",
      "recall for fold 1525:  0.4230769230769231\n",
      "precision for fold 1525:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1526:  0.5311004784688995\n",
      "f1  score for fold 1526:  0.36363636363636365\n",
      "recall for fold 1526:  0.3783783783783784\n",
      "precision for fold 1526:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1527:  0.5285714285714286\n",
      "f1  score for fold 1527:  0.3612903225806451\n",
      "recall for fold 1527:  0.37333333333333335\n",
      "precision for fold 1527:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 1528:  0.5776699029126213\n",
      "f1  score for fold 1528:  0.4596273291925466\n",
      "recall for fold 1528:  0.45121951219512196\n",
      "precision for fold 1528:  0.46835443037974683\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1529:  0.538860103626943\n",
      "f1  score for fold 1529:  0.4472049689440994\n",
      "recall for fold 1529:  0.41379310344827586\n",
      "precision for fold 1529:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1530:  0.5311004784688995\n",
      "f1  score for fold 1530:  0.37974683544303806\n",
      "recall for fold 1530:  0.38461538461538464\n",
      "precision for fold 1530:  0.375\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 1531:  0.6076555023923444\n",
      "f1  score for fold 1531:  0.4675324675324675\n",
      "recall for fold 1531:  0.4864864864864865\n",
      "precision for fold 1531:  0.45\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1532:  0.48095238095238096\n",
      "f1  score for fold 1532:  0.2967741935483871\n",
      "recall for fold 1532:  0.30666666666666664\n",
      "precision for fold 1532:  0.2875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1533:  0.5679611650485437\n",
      "f1  score for fold 1533:  0.4472049689440994\n",
      "recall for fold 1533:  0.43902439024390244\n",
      "precision for fold 1533:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1534:  0.5181347150259067\n",
      "f1  score for fold 1534:  0.422360248447205\n",
      "recall for fold 1534:  0.39080459770114945\n",
      "precision for fold 1534:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1535:  0.5311004784688995\n",
      "f1  score for fold 1535:  0.37974683544303806\n",
      "recall for fold 1535:  0.38461538461538464\n",
      "precision for fold 1535:  0.375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1536:  0.5789473684210527\n",
      "f1  score for fold 1536:  0.42857142857142855\n",
      "recall for fold 1536:  0.44594594594594594\n",
      "precision for fold 1536:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1537:  0.5476190476190477\n",
      "f1  score for fold 1537:  0.38709677419354843\n",
      "recall for fold 1537:  0.4\n",
      "precision for fold 1537:  0.375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1538:  0.48058252427184467\n",
      "f1  score for fold 1538:  0.33540372670807456\n",
      "recall for fold 1538:  0.32926829268292684\n",
      "precision for fold 1538:  0.34177215189873417\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1539:  0.538860103626943\n",
      "f1  score for fold 1539:  0.4472049689440994\n",
      "recall for fold 1539:  0.41379310344827586\n",
      "precision for fold 1539:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1540:  0.5406698564593302\n",
      "f1  score for fold 1540:  0.3924050632911393\n",
      "recall for fold 1540:  0.3974358974358974\n",
      "precision for fold 1540:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1541:  0.5502392344497608\n",
      "f1  score for fold 1541:  0.3896103896103896\n",
      "recall for fold 1541:  0.40540540540540543\n",
      "precision for fold 1541:  0.375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1542:  0.48095238095238096\n",
      "f1  score for fold 1542:  0.2967741935483871\n",
      "recall for fold 1542:  0.30666666666666664\n",
      "precision for fold 1542:  0.2875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1543:  0.49029126213592233\n",
      "f1  score for fold 1543:  0.3478260869565218\n",
      "recall for fold 1543:  0.34146341463414637\n",
      "precision for fold 1543:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1544:  0.48704663212435234\n",
      "f1  score for fold 1544:  0.3850931677018633\n",
      "recall for fold 1544:  0.3563218390804598\n",
      "precision for fold 1544:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1545:  0.569377990430622\n",
      "f1  score for fold 1545:  0.43037974683544306\n",
      "recall for fold 1545:  0.4358974358974359\n",
      "precision for fold 1545:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1546:  0.5311004784688995\n",
      "f1  score for fold 1546:  0.36363636363636365\n",
      "recall for fold 1546:  0.3783783783783784\n",
      "precision for fold 1546:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1547:  0.5095238095238095\n",
      "f1  score for fold 1547:  0.335483870967742\n",
      "recall for fold 1547:  0.3466666666666667\n",
      "precision for fold 1547:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1548:  0.5485436893203883\n",
      "f1  score for fold 1548:  0.42236024844720493\n",
      "recall for fold 1548:  0.4146341463414634\n",
      "precision for fold 1548:  0.43037974683544306\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1549:  0.46632124352331605\n",
      "f1  score for fold 1549:  0.36024844720496896\n",
      "recall for fold 1549:  0.3333333333333333\n",
      "precision for fold 1549:  0.3918918918918919\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1550:  0.5215311004784688\n",
      "f1  score for fold 1550:  0.36708860759493667\n",
      "recall for fold 1550:  0.3717948717948718\n",
      "precision for fold 1550:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1551:  0.5406698564593302\n",
      "f1  score for fold 1551:  0.37662337662337664\n",
      "recall for fold 1551:  0.3918918918918919\n",
      "precision for fold 1551:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1552:  0.5666666666666667\n",
      "f1  score for fold 1552:  0.41290322580645167\n",
      "recall for fold 1552:  0.4266666666666667\n",
      "precision for fold 1552:  0.4\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 1553:  0.5970873786407767\n",
      "f1  score for fold 1553:  0.484472049689441\n",
      "recall for fold 1553:  0.47560975609756095\n",
      "precision for fold 1553:  0.4936708860759494\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 1554:  0.5803108808290155\n",
      "f1  score for fold 1554:  0.49689440993788814\n",
      "recall for fold 1554:  0.45977011494252873\n",
      "precision for fold 1554:  0.5405405405405406\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1555:  0.5502392344497608\n",
      "f1  score for fold 1555:  0.4050632911392405\n",
      "recall for fold 1555:  0.41025641025641024\n",
      "precision for fold 1555:  0.4\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 1556:  0.47368421052631576\n",
      "f1  score for fold 1556:  0.28571428571428575\n",
      "recall for fold 1556:  0.2972972972972973\n",
      "precision for fold 1556:  0.275\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 1557:  0.46190476190476193\n",
      "f1  score for fold 1557:  0.2709677419354839\n",
      "recall for fold 1557:  0.28\n",
      "precision for fold 1557:  0.2625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1558:  0.5\n",
      "f1  score for fold 1558:  0.3602484472049689\n",
      "recall for fold 1558:  0.35365853658536583\n",
      "precision for fold 1558:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1559:  0.48704663212435234\n",
      "f1  score for fold 1559:  0.3850931677018633\n",
      "recall for fold 1559:  0.3563218390804598\n",
      "precision for fold 1559:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1560:  0.5502392344497608\n",
      "f1  score for fold 1560:  0.4050632911392405\n",
      "recall for fold 1560:  0.41025641025641024\n",
      "precision for fold 1560:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1561:  0.5406698564593302\n",
      "f1  score for fold 1561:  0.37662337662337664\n",
      "recall for fold 1561:  0.3918918918918919\n",
      "precision for fold 1561:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1562:  0.5666666666666667\n",
      "f1  score for fold 1562:  0.41290322580645167\n",
      "recall for fold 1562:  0.4266666666666667\n",
      "precision for fold 1562:  0.4\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1563:  0.48058252427184467\n",
      "f1  score for fold 1563:  0.33540372670807456\n",
      "recall for fold 1563:  0.32926829268292684\n",
      "precision for fold 1563:  0.34177215189873417\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1564:  0.45595854922279794\n",
      "f1  score for fold 1564:  0.3478260869565218\n",
      "recall for fold 1564:  0.3218390804597701\n",
      "precision for fold 1564:  0.3783783783783784\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1565:  0.569377990430622\n",
      "f1  score for fold 1565:  0.43037974683544306\n",
      "recall for fold 1565:  0.4358974358974359\n",
      "precision for fold 1565:  0.425\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1566:  0.569377990430622\n",
      "f1  score for fold 1566:  0.4155844155844156\n",
      "recall for fold 1566:  0.43243243243243246\n",
      "precision for fold 1566:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1567:  0.5476190476190477\n",
      "f1  score for fold 1567:  0.38709677419354843\n",
      "recall for fold 1567:  0.4\n",
      "precision for fold 1567:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1568:  0.49029126213592233\n",
      "f1  score for fold 1568:  0.3478260869565218\n",
      "recall for fold 1568:  0.34146341463414637\n",
      "precision for fold 1568:  0.35443037974683544\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1569:  0.5284974093264249\n",
      "f1  score for fold 1569:  0.4347826086956522\n",
      "recall for fold 1569:  0.40229885057471265\n",
      "precision for fold 1569:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1570:  0.5311004784688995\n",
      "f1  score for fold 1570:  0.37974683544303806\n",
      "recall for fold 1570:  0.38461538461538464\n",
      "precision for fold 1570:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1571:  0.569377990430622\n",
      "f1  score for fold 1571:  0.4155844155844156\n",
      "recall for fold 1571:  0.43243243243243246\n",
      "precision for fold 1571:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1572:  0.5285714285714286\n",
      "f1  score for fold 1572:  0.3612903225806451\n",
      "recall for fold 1572:  0.37333333333333335\n",
      "precision for fold 1572:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1573:  0.529126213592233\n",
      "f1  score for fold 1573:  0.39751552795031053\n",
      "recall for fold 1573:  0.3902439024390244\n",
      "precision for fold 1573:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1574:  0.47668393782383417\n",
      "f1  score for fold 1574:  0.3726708074534162\n",
      "recall for fold 1574:  0.3448275862068966\n",
      "precision for fold 1574:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1575:  0.5311004784688995\n",
      "f1  score for fold 1575:  0.37974683544303806\n",
      "recall for fold 1575:  0.38461538461538464\n",
      "precision for fold 1575:  0.375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1576:  0.49282296650717705\n",
      "f1  score for fold 1576:  0.3116883116883117\n",
      "recall for fold 1576:  0.32432432432432434\n",
      "precision for fold 1576:  0.3\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1577:  0.5380952380952381\n",
      "f1  score for fold 1577:  0.3741935483870968\n",
      "recall for fold 1577:  0.38666666666666666\n",
      "precision for fold 1577:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1578:  0.49029126213592233\n",
      "f1  score for fold 1578:  0.3478260869565218\n",
      "recall for fold 1578:  0.34146341463414637\n",
      "precision for fold 1578:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1579:  0.5181347150259067\n",
      "f1  score for fold 1579:  0.422360248447205\n",
      "recall for fold 1579:  0.39080459770114945\n",
      "precision for fold 1579:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1580:  0.569377990430622\n",
      "f1  score for fold 1580:  0.43037974683544306\n",
      "recall for fold 1580:  0.4358974358974359\n",
      "precision for fold 1580:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1581:  0.5502392344497608\n",
      "f1  score for fold 1581:  0.3896103896103896\n",
      "recall for fold 1581:  0.40540540540540543\n",
      "precision for fold 1581:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1582:  0.5380952380952381\n",
      "f1  score for fold 1582:  0.3741935483870968\n",
      "recall for fold 1582:  0.38666666666666666\n",
      "precision for fold 1582:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1583:  0.5097087378640777\n",
      "f1  score for fold 1583:  0.37267080745341613\n",
      "recall for fold 1583:  0.36585365853658536\n",
      "precision for fold 1583:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1584:  0.47668393782383417\n",
      "f1  score for fold 1584:  0.3726708074534162\n",
      "recall for fold 1584:  0.3448275862068966\n",
      "precision for fold 1584:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1585:  0.5311004784688995\n",
      "f1  score for fold 1585:  0.37974683544303806\n",
      "recall for fold 1585:  0.38461538461538464\n",
      "precision for fold 1585:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1586:  0.5502392344497608\n",
      "f1  score for fold 1586:  0.3896103896103896\n",
      "recall for fold 1586:  0.40540540540540543\n",
      "precision for fold 1586:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1587:  0.5476190476190477\n",
      "f1  score for fold 1587:  0.38709677419354843\n",
      "recall for fold 1587:  0.4\n",
      "precision for fold 1587:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1588:  0.5388349514563107\n",
      "f1  score for fold 1588:  0.40993788819875776\n",
      "recall for fold 1588:  0.4024390243902439\n",
      "precision for fold 1588:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1589:  0.48704663212435234\n",
      "f1  score for fold 1589:  0.3850931677018633\n",
      "recall for fold 1589:  0.3563218390804598\n",
      "precision for fold 1589:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1590:  0.5119617224880383\n",
      "f1  score for fold 1590:  0.3544303797468355\n",
      "recall for fold 1590:  0.358974358974359\n",
      "precision for fold 1590:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1591:  0.5311004784688995\n",
      "f1  score for fold 1591:  0.36363636363636365\n",
      "recall for fold 1591:  0.3783783783783784\n",
      "precision for fold 1591:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1592:  0.5857142857142857\n",
      "f1  score for fold 1592:  0.43870967741935485\n",
      "recall for fold 1592:  0.4533333333333333\n",
      "precision for fold 1592:  0.425\n",
      "    0   1\n",
      "0  21  61\n",
      "1  58  66\n",
      "Accuracy for fold 1593:  0.4223300970873786\n",
      "f1  score for fold 1593:  0.2608695652173913\n",
      "recall for fold 1593:  0.25609756097560976\n",
      "precision for fold 1593:  0.26582278481012656\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1594:  0.5284974093264249\n",
      "f1  score for fold 1594:  0.4347826086956522\n",
      "recall for fold 1594:  0.40229885057471265\n",
      "precision for fold 1594:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1595:  0.5119617224880383\n",
      "f1  score for fold 1595:  0.3544303797468355\n",
      "recall for fold 1595:  0.358974358974359\n",
      "precision for fold 1595:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1596:  0.5215311004784688\n",
      "f1  score for fold 1596:  0.3506493506493507\n",
      "recall for fold 1596:  0.36486486486486486\n",
      "precision for fold 1596:  0.3375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1597:  0.48095238095238096\n",
      "f1  score for fold 1597:  0.2967741935483871\n",
      "recall for fold 1597:  0.30666666666666664\n",
      "precision for fold 1597:  0.2875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1598:  0.5097087378640777\n",
      "f1  score for fold 1598:  0.37267080745341613\n",
      "recall for fold 1598:  0.36585365853658536\n",
      "precision for fold 1598:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1599:  0.49740932642487046\n",
      "f1  score for fold 1599:  0.39751552795031053\n",
      "recall for fold 1599:  0.367816091954023\n",
      "precision for fold 1599:  0.43243243243243246\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1600:  0.5789473684210527\n",
      "f1  score for fold 1600:  0.44303797468354433\n",
      "recall for fold 1600:  0.44871794871794873\n",
      "precision for fold 1600:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1601:  0.5311004784688995\n",
      "f1  score for fold 1601:  0.36363636363636365\n",
      "recall for fold 1601:  0.3783783783783784\n",
      "precision for fold 1601:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1602:  0.5\n",
      "f1  score for fold 1602:  0.3225806451612903\n",
      "recall for fold 1602:  0.3333333333333333\n",
      "precision for fold 1602:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1603:  0.558252427184466\n",
      "f1  score for fold 1603:  0.43478260869565216\n",
      "recall for fold 1603:  0.4268292682926829\n",
      "precision for fold 1603:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1604:  0.538860103626943\n",
      "f1  score for fold 1604:  0.4472049689440994\n",
      "recall for fold 1604:  0.41379310344827586\n",
      "precision for fold 1604:  0.4864864864864865\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1605:  0.5789473684210527\n",
      "f1  score for fold 1605:  0.44303797468354433\n",
      "recall for fold 1605:  0.44871794871794873\n",
      "precision for fold 1605:  0.4375\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 1606:  0.47368421052631576\n",
      "f1  score for fold 1606:  0.28571428571428575\n",
      "recall for fold 1606:  0.2972972972972973\n",
      "precision for fold 1606:  0.275\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1607:  0.5571428571428572\n",
      "f1  score for fold 1607:  0.4000000000000001\n",
      "recall for fold 1607:  0.41333333333333333\n",
      "precision for fold 1607:  0.3875\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 1608:  0.587378640776699\n",
      "f1  score for fold 1608:  0.4720496894409938\n",
      "recall for fold 1608:  0.4634146341463415\n",
      "precision for fold 1608:  0.4810126582278481\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1609:  0.5077720207253886\n",
      "f1  score for fold 1609:  0.40993788819875776\n",
      "recall for fold 1609:  0.3793103448275862\n",
      "precision for fold 1609:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1610:  0.5119617224880383\n",
      "f1  score for fold 1610:  0.3544303797468355\n",
      "recall for fold 1610:  0.358974358974359\n",
      "precision for fold 1610:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1611:  0.5502392344497608\n",
      "f1  score for fold 1611:  0.3896103896103896\n",
      "recall for fold 1611:  0.40540540540540543\n",
      "precision for fold 1611:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1612:  0.5\n",
      "f1  score for fold 1612:  0.3225806451612903\n",
      "recall for fold 1612:  0.3333333333333333\n",
      "precision for fold 1612:  0.3125\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1613:  0.46116504854368934\n",
      "f1  score for fold 1613:  0.31055900621118016\n",
      "recall for fold 1613:  0.3048780487804878\n",
      "precision for fold 1613:  0.31645569620253167\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1614:  0.45595854922279794\n",
      "f1  score for fold 1614:  0.3478260869565218\n",
      "recall for fold 1614:  0.3218390804597701\n",
      "precision for fold 1614:  0.3783783783783784\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 1615:  0.6076555023923444\n",
      "f1  score for fold 1615:  0.4810126582278481\n",
      "recall for fold 1615:  0.48717948717948717\n",
      "precision for fold 1615:  0.475\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 1616:  0.47368421052631576\n",
      "f1  score for fold 1616:  0.28571428571428575\n",
      "recall for fold 1616:  0.2972972972972973\n",
      "precision for fold 1616:  0.275\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1617:  0.5761904761904761\n",
      "f1  score for fold 1617:  0.4258064516129032\n",
      "recall for fold 1617:  0.44\n",
      "precision for fold 1617:  0.4125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1618:  0.5388349514563107\n",
      "f1  score for fold 1618:  0.40993788819875776\n",
      "recall for fold 1618:  0.4024390243902439\n",
      "precision for fold 1618:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1619:  0.538860103626943\n",
      "f1  score for fold 1619:  0.4472049689440994\n",
      "recall for fold 1619:  0.41379310344827586\n",
      "precision for fold 1619:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1620:  0.49282296650717705\n",
      "f1  score for fold 1620:  0.32911392405063294\n",
      "recall for fold 1620:  0.3333333333333333\n",
      "precision for fold 1620:  0.325\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1621:  0.5789473684210527\n",
      "f1  score for fold 1621:  0.42857142857142855\n",
      "recall for fold 1621:  0.44594594594594594\n",
      "precision for fold 1621:  0.4125\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 1622:  0.4714285714285714\n",
      "f1  score for fold 1622:  0.2838709677419355\n",
      "recall for fold 1622:  0.29333333333333333\n",
      "precision for fold 1622:  0.275\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1623:  0.49029126213592233\n",
      "f1  score for fold 1623:  0.3478260869565218\n",
      "recall for fold 1623:  0.34146341463414637\n",
      "precision for fold 1623:  0.35443037974683544\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1624:  0.5595854922279793\n",
      "f1  score for fold 1624:  0.4720496894409938\n",
      "recall for fold 1624:  0.4367816091954023\n",
      "precision for fold 1624:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1625:  0.5502392344497608\n",
      "f1  score for fold 1625:  0.4050632911392405\n",
      "recall for fold 1625:  0.41025641025641024\n",
      "precision for fold 1625:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1626:  0.5598086124401914\n",
      "f1  score for fold 1626:  0.40259740259740256\n",
      "recall for fold 1626:  0.4189189189189189\n",
      "precision for fold 1626:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1627:  0.5380952380952381\n",
      "f1  score for fold 1627:  0.3741935483870968\n",
      "recall for fold 1627:  0.38666666666666666\n",
      "precision for fold 1627:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1628:  0.5\n",
      "f1  score for fold 1628:  0.3602484472049689\n",
      "recall for fold 1628:  0.35365853658536583\n",
      "precision for fold 1628:  0.3670886075949367\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 1629:  0.5803108808290155\n",
      "f1  score for fold 1629:  0.49689440993788814\n",
      "recall for fold 1629:  0.45977011494252873\n",
      "precision for fold 1629:  0.5405405405405406\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1630:  0.5311004784688995\n",
      "f1  score for fold 1630:  0.37974683544303806\n",
      "recall for fold 1630:  0.38461538461538464\n",
      "precision for fold 1630:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1631:  0.5215311004784688\n",
      "f1  score for fold 1631:  0.3506493506493507\n",
      "recall for fold 1631:  0.36486486486486486\n",
      "precision for fold 1631:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1632:  0.5476190476190477\n",
      "f1  score for fold 1632:  0.38709677419354843\n",
      "recall for fold 1632:  0.4\n",
      "precision for fold 1632:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1633:  0.5097087378640777\n",
      "f1  score for fold 1633:  0.37267080745341613\n",
      "recall for fold 1633:  0.36585365853658536\n",
      "precision for fold 1633:  0.379746835443038\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1634:  0.5595854922279793\n",
      "f1  score for fold 1634:  0.4720496894409938\n",
      "recall for fold 1634:  0.4367816091954023\n",
      "precision for fold 1634:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1635:  0.5598086124401914\n",
      "f1  score for fold 1635:  0.4177215189873418\n",
      "recall for fold 1635:  0.4230769230769231\n",
      "precision for fold 1635:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1636:  0.5406698564593302\n",
      "f1  score for fold 1636:  0.37662337662337664\n",
      "recall for fold 1636:  0.3918918918918919\n",
      "precision for fold 1636:  0.3625\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 1637:  0.4714285714285714\n",
      "f1  score for fold 1637:  0.2838709677419355\n",
      "recall for fold 1637:  0.29333333333333333\n",
      "precision for fold 1637:  0.275\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1638:  0.48058252427184467\n",
      "f1  score for fold 1638:  0.33540372670807456\n",
      "recall for fold 1638:  0.32926829268292684\n",
      "precision for fold 1638:  0.34177215189873417\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 1639:  0.5906735751295337\n",
      "f1  score for fold 1639:  0.5093167701863355\n",
      "recall for fold 1639:  0.47126436781609193\n",
      "precision for fold 1639:  0.5540540540540541\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1640:  0.5215311004784688\n",
      "f1  score for fold 1640:  0.36708860759493667\n",
      "recall for fold 1640:  0.3717948717948718\n",
      "precision for fold 1640:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1641:  0.5215311004784688\n",
      "f1  score for fold 1641:  0.3506493506493507\n",
      "recall for fold 1641:  0.36486486486486486\n",
      "precision for fold 1641:  0.3375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 1642:  0.48095238095238096\n",
      "f1  score for fold 1642:  0.2967741935483871\n",
      "recall for fold 1642:  0.30666666666666664\n",
      "precision for fold 1642:  0.2875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1643:  0.470873786407767\n",
      "f1  score for fold 1643:  0.3229813664596273\n",
      "recall for fold 1643:  0.3170731707317073\n",
      "precision for fold 1643:  0.3291139240506329\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1644:  0.5181347150259067\n",
      "f1  score for fold 1644:  0.422360248447205\n",
      "recall for fold 1644:  0.39080459770114945\n",
      "precision for fold 1644:  0.4594594594594595\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1645:  0.5789473684210527\n",
      "f1  score for fold 1645:  0.44303797468354433\n",
      "recall for fold 1645:  0.44871794871794873\n",
      "precision for fold 1645:  0.4375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 1646:  0.5885167464114832\n",
      "f1  score for fold 1646:  0.44155844155844154\n",
      "recall for fold 1646:  0.4594594594594595\n",
      "precision for fold 1646:  0.425\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1647:  0.5\n",
      "f1  score for fold 1647:  0.3225806451612903\n",
      "recall for fold 1647:  0.3333333333333333\n",
      "precision for fold 1647:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1648:  0.5194174757281553\n",
      "f1  score for fold 1648:  0.38509316770186336\n",
      "recall for fold 1648:  0.3780487804878049\n",
      "precision for fold 1648:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1649:  0.538860103626943\n",
      "f1  score for fold 1649:  0.4472049689440994\n",
      "recall for fold 1649:  0.41379310344827586\n",
      "precision for fold 1649:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1650:  0.5311004784688995\n",
      "f1  score for fold 1650:  0.37974683544303806\n",
      "recall for fold 1650:  0.38461538461538464\n",
      "precision for fold 1650:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1651:  0.5215311004784688\n",
      "f1  score for fold 1651:  0.3506493506493507\n",
      "recall for fold 1651:  0.36486486486486486\n",
      "precision for fold 1651:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1652:  0.5190476190476191\n",
      "f1  score for fold 1652:  0.34838709677419355\n",
      "recall for fold 1652:  0.36\n",
      "precision for fold 1652:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1653:  0.529126213592233\n",
      "f1  score for fold 1653:  0.39751552795031053\n",
      "recall for fold 1653:  0.3902439024390244\n",
      "precision for fold 1653:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1654:  0.5077720207253886\n",
      "f1  score for fold 1654:  0.40993788819875776\n",
      "recall for fold 1654:  0.3793103448275862\n",
      "precision for fold 1654:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 1655:  0.47368421052631576\n",
      "f1  score for fold 1655:  0.3037974683544304\n",
      "recall for fold 1655:  0.3076923076923077\n",
      "precision for fold 1655:  0.3\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 1656:  0.47368421052631576\n",
      "f1  score for fold 1656:  0.28571428571428575\n",
      "recall for fold 1656:  0.2972972972972973\n",
      "precision for fold 1656:  0.275\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 1657:  0.6142857142857143\n",
      "f1  score for fold 1657:  0.47741935483870973\n",
      "recall for fold 1657:  0.49333333333333335\n",
      "precision for fold 1657:  0.4625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1658:  0.5194174757281553\n",
      "f1  score for fold 1658:  0.38509316770186336\n",
      "recall for fold 1658:  0.3780487804878049\n",
      "precision for fold 1658:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1659:  0.5077720207253886\n",
      "f1  score for fold 1659:  0.40993788819875776\n",
      "recall for fold 1659:  0.3793103448275862\n",
      "precision for fold 1659:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1660:  0.5215311004784688\n",
      "f1  score for fold 1660:  0.36708860759493667\n",
      "recall for fold 1660:  0.3717948717948718\n",
      "precision for fold 1660:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1661:  0.5598086124401914\n",
      "f1  score for fold 1661:  0.40259740259740256\n",
      "recall for fold 1661:  0.4189189189189189\n",
      "precision for fold 1661:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1662:  0.5380952380952381\n",
      "f1  score for fold 1662:  0.3741935483870968\n",
      "recall for fold 1662:  0.38666666666666666\n",
      "precision for fold 1662:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1663:  0.558252427184466\n",
      "f1  score for fold 1663:  0.43478260869565216\n",
      "recall for fold 1663:  0.4268292682926829\n",
      "precision for fold 1663:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1664:  0.46632124352331605\n",
      "f1  score for fold 1664:  0.36024844720496896\n",
      "recall for fold 1664:  0.3333333333333333\n",
      "precision for fold 1664:  0.3918918918918919\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1665:  0.5119617224880383\n",
      "f1  score for fold 1665:  0.3544303797468355\n",
      "recall for fold 1665:  0.358974358974359\n",
      "precision for fold 1665:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1666:  0.5215311004784688\n",
      "f1  score for fold 1666:  0.3506493506493507\n",
      "recall for fold 1666:  0.36486486486486486\n",
      "precision for fold 1666:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1667:  0.49047619047619045\n",
      "f1  score for fold 1667:  0.3096774193548387\n",
      "recall for fold 1667:  0.32\n",
      "precision for fold 1667:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1668:  0.558252427184466\n",
      "f1  score for fold 1668:  0.43478260869565216\n",
      "recall for fold 1668:  0.4268292682926829\n",
      "precision for fold 1668:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1669:  0.5181347150259067\n",
      "f1  score for fold 1669:  0.422360248447205\n",
      "recall for fold 1669:  0.39080459770114945\n",
      "precision for fold 1669:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1670:  0.5311004784688995\n",
      "f1  score for fold 1670:  0.37974683544303806\n",
      "recall for fold 1670:  0.38461538461538464\n",
      "precision for fold 1670:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1671:  0.5023923444976076\n",
      "f1  score for fold 1671:  0.3246753246753247\n",
      "recall for fold 1671:  0.33783783783783783\n",
      "precision for fold 1671:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1672:  0.5571428571428572\n",
      "f1  score for fold 1672:  0.4000000000000001\n",
      "recall for fold 1672:  0.41333333333333333\n",
      "precision for fold 1672:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1673:  0.5194174757281553\n",
      "f1  score for fold 1673:  0.38509316770186336\n",
      "recall for fold 1673:  0.3780487804878049\n",
      "precision for fold 1673:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1674:  0.5181347150259067\n",
      "f1  score for fold 1674:  0.422360248447205\n",
      "recall for fold 1674:  0.39080459770114945\n",
      "precision for fold 1674:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1675:  0.5311004784688995\n",
      "f1  score for fold 1675:  0.37974683544303806\n",
      "recall for fold 1675:  0.38461538461538464\n",
      "precision for fold 1675:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1676:  0.5502392344497608\n",
      "f1  score for fold 1676:  0.3896103896103896\n",
      "recall for fold 1676:  0.40540540540540543\n",
      "precision for fold 1676:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1677:  0.5666666666666667\n",
      "f1  score for fold 1677:  0.41290322580645167\n",
      "recall for fold 1677:  0.4266666666666667\n",
      "precision for fold 1677:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1678:  0.5097087378640777\n",
      "f1  score for fold 1678:  0.37267080745341613\n",
      "recall for fold 1678:  0.36585365853658536\n",
      "precision for fold 1678:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1679:  0.5284974093264249\n",
      "f1  score for fold 1679:  0.4347826086956522\n",
      "recall for fold 1679:  0.40229885057471265\n",
      "precision for fold 1679:  0.47297297297297297\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 1680:  0.5885167464114832\n",
      "f1  score for fold 1680:  0.45569620253164556\n",
      "recall for fold 1680:  0.46153846153846156\n",
      "precision for fold 1680:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1681:  0.5406698564593302\n",
      "f1  score for fold 1681:  0.37662337662337664\n",
      "recall for fold 1681:  0.3918918918918919\n",
      "precision for fold 1681:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1682:  0.5285714285714286\n",
      "f1  score for fold 1682:  0.3612903225806451\n",
      "recall for fold 1682:  0.37333333333333335\n",
      "precision for fold 1682:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1683:  0.49029126213592233\n",
      "f1  score for fold 1683:  0.3478260869565218\n",
      "recall for fold 1683:  0.34146341463414637\n",
      "precision for fold 1683:  0.35443037974683544\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1684:  0.47668393782383417\n",
      "f1  score for fold 1684:  0.3726708074534162\n",
      "recall for fold 1684:  0.3448275862068966\n",
      "precision for fold 1684:  0.40540540540540543\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1685:  0.5406698564593302\n",
      "f1  score for fold 1685:  0.3924050632911393\n",
      "recall for fold 1685:  0.3974358974358974\n",
      "precision for fold 1685:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1686:  0.5215311004784688\n",
      "f1  score for fold 1686:  0.3506493506493507\n",
      "recall for fold 1686:  0.36486486486486486\n",
      "precision for fold 1686:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1687:  0.5190476190476191\n",
      "f1  score for fold 1687:  0.34838709677419355\n",
      "recall for fold 1687:  0.36\n",
      "precision for fold 1687:  0.3375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1688:  0.470873786407767\n",
      "f1  score for fold 1688:  0.3229813664596273\n",
      "recall for fold 1688:  0.3170731707317073\n",
      "precision for fold 1688:  0.3291139240506329\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1689:  0.5492227979274611\n",
      "f1  score for fold 1689:  0.45962732919254656\n",
      "recall for fold 1689:  0.42528735632183906\n",
      "precision for fold 1689:  0.5\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1690:  0.5119617224880383\n",
      "f1  score for fold 1690:  0.3544303797468355\n",
      "recall for fold 1690:  0.358974358974359\n",
      "precision for fold 1690:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1691:  0.5215311004784688\n",
      "f1  score for fold 1691:  0.3506493506493507\n",
      "recall for fold 1691:  0.36486486486486486\n",
      "precision for fold 1691:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1692:  0.49047619047619045\n",
      "f1  score for fold 1692:  0.3096774193548387\n",
      "recall for fold 1692:  0.32\n",
      "precision for fold 1692:  0.3\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1693:  0.529126213592233\n",
      "f1  score for fold 1693:  0.39751552795031053\n",
      "recall for fold 1693:  0.3902439024390244\n",
      "precision for fold 1693:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1694:  0.49740932642487046\n",
      "f1  score for fold 1694:  0.39751552795031053\n",
      "recall for fold 1694:  0.367816091954023\n",
      "precision for fold 1694:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1695:  0.569377990430622\n",
      "f1  score for fold 1695:  0.43037974683544306\n",
      "recall for fold 1695:  0.4358974358974359\n",
      "precision for fold 1695:  0.425\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1696:  0.48325358851674644\n",
      "f1  score for fold 1696:  0.29870129870129863\n",
      "recall for fold 1696:  0.3108108108108108\n",
      "precision for fold 1696:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1697:  0.5476190476190477\n",
      "f1  score for fold 1697:  0.38709677419354843\n",
      "recall for fold 1697:  0.4\n",
      "precision for fold 1697:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1698:  0.5679611650485437\n",
      "f1  score for fold 1698:  0.4472049689440994\n",
      "recall for fold 1698:  0.43902439024390244\n",
      "precision for fold 1698:  0.45569620253164556\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1699:  0.45595854922279794\n",
      "f1  score for fold 1699:  0.3478260869565218\n",
      "recall for fold 1699:  0.3218390804597701\n",
      "precision for fold 1699:  0.3783783783783784\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1700:  0.5598086124401914\n",
      "f1  score for fold 1700:  0.4177215189873418\n",
      "recall for fold 1700:  0.4230769230769231\n",
      "precision for fold 1700:  0.4125\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1701:  0.49282296650717705\n",
      "f1  score for fold 1701:  0.3116883116883117\n",
      "recall for fold 1701:  0.32432432432432434\n",
      "precision for fold 1701:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1702:  0.5476190476190477\n",
      "f1  score for fold 1702:  0.38709677419354843\n",
      "recall for fold 1702:  0.4\n",
      "precision for fold 1702:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1703:  0.5388349514563107\n",
      "f1  score for fold 1703:  0.40993788819875776\n",
      "recall for fold 1703:  0.4024390243902439\n",
      "precision for fold 1703:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1704:  0.47668393782383417\n",
      "f1  score for fold 1704:  0.3726708074534162\n",
      "recall for fold 1704:  0.3448275862068966\n",
      "precision for fold 1704:  0.40540540540540543\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 1705:  0.5885167464114832\n",
      "f1  score for fold 1705:  0.45569620253164556\n",
      "recall for fold 1705:  0.46153846153846156\n",
      "precision for fold 1705:  0.45\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1706:  0.5119617224880383\n",
      "f1  score for fold 1706:  0.33766233766233766\n",
      "recall for fold 1706:  0.35135135135135137\n",
      "precision for fold 1706:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1707:  0.5285714285714286\n",
      "f1  score for fold 1707:  0.3612903225806451\n",
      "recall for fold 1707:  0.37333333333333335\n",
      "precision for fold 1707:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1708:  0.529126213592233\n",
      "f1  score for fold 1708:  0.39751552795031053\n",
      "recall for fold 1708:  0.3902439024390244\n",
      "precision for fold 1708:  0.4050632911392405\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1709:  0.5595854922279793\n",
      "f1  score for fold 1709:  0.4720496894409938\n",
      "recall for fold 1709:  0.4367816091954023\n",
      "precision for fold 1709:  0.5135135135135135\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1710:  0.5023923444976076\n",
      "f1  score for fold 1710:  0.34177215189873417\n",
      "recall for fold 1710:  0.34615384615384615\n",
      "precision for fold 1710:  0.3375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1711:  0.569377990430622\n",
      "f1  score for fold 1711:  0.4155844155844156\n",
      "recall for fold 1711:  0.43243243243243246\n",
      "precision for fold 1711:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1712:  0.5476190476190477\n",
      "f1  score for fold 1712:  0.38709677419354843\n",
      "recall for fold 1712:  0.4\n",
      "precision for fold 1712:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1713:  0.5194174757281553\n",
      "f1  score for fold 1713:  0.38509316770186336\n",
      "recall for fold 1713:  0.3780487804878049\n",
      "precision for fold 1713:  0.3924050632911392\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1714:  0.47668393782383417\n",
      "f1  score for fold 1714:  0.3726708074534162\n",
      "recall for fold 1714:  0.3448275862068966\n",
      "precision for fold 1714:  0.40540540540540543\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1715:  0.5119617224880383\n",
      "f1  score for fold 1715:  0.3544303797468355\n",
      "recall for fold 1715:  0.358974358974359\n",
      "precision for fold 1715:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1716:  0.5502392344497608\n",
      "f1  score for fold 1716:  0.3896103896103896\n",
      "recall for fold 1716:  0.40540540540540543\n",
      "precision for fold 1716:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1717:  0.5380952380952381\n",
      "f1  score for fold 1717:  0.3741935483870968\n",
      "recall for fold 1717:  0.38666666666666666\n",
      "precision for fold 1717:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1718:  0.470873786407767\n",
      "f1  score for fold 1718:  0.3229813664596273\n",
      "recall for fold 1718:  0.3170731707317073\n",
      "precision for fold 1718:  0.3291139240506329\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1719:  0.5284974093264249\n",
      "f1  score for fold 1719:  0.4347826086956522\n",
      "recall for fold 1719:  0.40229885057471265\n",
      "precision for fold 1719:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1720:  0.5119617224880383\n",
      "f1  score for fold 1720:  0.3544303797468355\n",
      "recall for fold 1720:  0.358974358974359\n",
      "precision for fold 1720:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1721:  0.5311004784688995\n",
      "f1  score for fold 1721:  0.36363636363636365\n",
      "recall for fold 1721:  0.3783783783783784\n",
      "precision for fold 1721:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1722:  0.5190476190476191\n",
      "f1  score for fold 1722:  0.34838709677419355\n",
      "recall for fold 1722:  0.36\n",
      "precision for fold 1722:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1723:  0.5097087378640777\n",
      "f1  score for fold 1723:  0.37267080745341613\n",
      "recall for fold 1723:  0.36585365853658536\n",
      "precision for fold 1723:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1724:  0.49740932642487046\n",
      "f1  score for fold 1724:  0.39751552795031053\n",
      "recall for fold 1724:  0.367816091954023\n",
      "precision for fold 1724:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1725:  0.5406698564593302\n",
      "f1  score for fold 1725:  0.3924050632911393\n",
      "recall for fold 1725:  0.3974358974358974\n",
      "precision for fold 1725:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1726:  0.5215311004784688\n",
      "f1  score for fold 1726:  0.3506493506493507\n",
      "recall for fold 1726:  0.36486486486486486\n",
      "precision for fold 1726:  0.3375\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 1727:  0.6047619047619047\n",
      "f1  score for fold 1727:  0.4645161290322581\n",
      "recall for fold 1727:  0.48\n",
      "precision for fold 1727:  0.45\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1728:  0.558252427184466\n",
      "f1  score for fold 1728:  0.43478260869565216\n",
      "recall for fold 1728:  0.4268292682926829\n",
      "precision for fold 1728:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1729:  0.46632124352331605\n",
      "f1  score for fold 1729:  0.36024844720496896\n",
      "recall for fold 1729:  0.3333333333333333\n",
      "precision for fold 1729:  0.3918918918918919\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1730:  0.48325358851674644\n",
      "f1  score for fold 1730:  0.31645569620253167\n",
      "recall for fold 1730:  0.32051282051282054\n",
      "precision for fold 1730:  0.3125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1731:  0.5311004784688995\n",
      "f1  score for fold 1731:  0.36363636363636365\n",
      "recall for fold 1731:  0.3783783783783784\n",
      "precision for fold 1731:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1732:  0.5761904761904761\n",
      "f1  score for fold 1732:  0.4258064516129032\n",
      "recall for fold 1732:  0.44\n",
      "precision for fold 1732:  0.4125\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1733:  0.5679611650485437\n",
      "f1  score for fold 1733:  0.4472049689440994\n",
      "recall for fold 1733:  0.43902439024390244\n",
      "precision for fold 1733:  0.45569620253164556\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1734:  0.5595854922279793\n",
      "f1  score for fold 1734:  0.4720496894409938\n",
      "recall for fold 1734:  0.4367816091954023\n",
      "precision for fold 1734:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1735:  0.5502392344497608\n",
      "f1  score for fold 1735:  0.4050632911392405\n",
      "recall for fold 1735:  0.41025641025641024\n",
      "precision for fold 1735:  0.4\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1736:  0.5980861244019139\n",
      "f1  score for fold 1736:  0.45454545454545453\n",
      "recall for fold 1736:  0.47297297297297297\n",
      "precision for fold 1736:  0.4375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1737:  0.5095238095238095\n",
      "f1  score for fold 1737:  0.335483870967742\n",
      "recall for fold 1737:  0.3466666666666667\n",
      "precision for fold 1737:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1738:  0.558252427184466\n",
      "f1  score for fold 1738:  0.43478260869565216\n",
      "recall for fold 1738:  0.4268292682926829\n",
      "precision for fold 1738:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1739:  0.5077720207253886\n",
      "f1  score for fold 1739:  0.40993788819875776\n",
      "recall for fold 1739:  0.3793103448275862\n",
      "precision for fold 1739:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1740:  0.5215311004784688\n",
      "f1  score for fold 1740:  0.36708860759493667\n",
      "recall for fold 1740:  0.3717948717948718\n",
      "precision for fold 1740:  0.3625\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1741:  0.5980861244019139\n",
      "f1  score for fold 1741:  0.45454545454545453\n",
      "recall for fold 1741:  0.47297297297297297\n",
      "precision for fold 1741:  0.4375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1742:  0.5\n",
      "f1  score for fold 1742:  0.3225806451612903\n",
      "recall for fold 1742:  0.3333333333333333\n",
      "precision for fold 1742:  0.3125\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 1743:  0.5776699029126213\n",
      "f1  score for fold 1743:  0.4596273291925466\n",
      "recall for fold 1743:  0.45121951219512196\n",
      "precision for fold 1743:  0.46835443037974683\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1744:  0.5077720207253886\n",
      "f1  score for fold 1744:  0.40993788819875776\n",
      "recall for fold 1744:  0.3793103448275862\n",
      "precision for fold 1744:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1745:  0.5789473684210527\n",
      "f1  score for fold 1745:  0.44303797468354433\n",
      "recall for fold 1745:  0.44871794871794873\n",
      "precision for fold 1745:  0.4375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 1746:  0.48325358851674644\n",
      "f1  score for fold 1746:  0.29870129870129863\n",
      "recall for fold 1746:  0.3108108108108108\n",
      "precision for fold 1746:  0.2875\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1747:  0.5857142857142857\n",
      "f1  score for fold 1747:  0.43870967741935485\n",
      "recall for fold 1747:  0.4533333333333333\n",
      "precision for fold 1747:  0.425\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1748:  0.5\n",
      "f1  score for fold 1748:  0.3602484472049689\n",
      "recall for fold 1748:  0.35365853658536583\n",
      "precision for fold 1748:  0.3670886075949367\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1749:  0.538860103626943\n",
      "f1  score for fold 1749:  0.4472049689440994\n",
      "recall for fold 1749:  0.41379310344827586\n",
      "precision for fold 1749:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1750:  0.5598086124401914\n",
      "f1  score for fold 1750:  0.4177215189873418\n",
      "recall for fold 1750:  0.4230769230769231\n",
      "precision for fold 1750:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1751:  0.5311004784688995\n",
      "f1  score for fold 1751:  0.36363636363636365\n",
      "recall for fold 1751:  0.3783783783783784\n",
      "precision for fold 1751:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1752:  0.5\n",
      "f1  score for fold 1752:  0.3225806451612903\n",
      "recall for fold 1752:  0.3333333333333333\n",
      "precision for fold 1752:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1753:  0.5097087378640777\n",
      "f1  score for fold 1753:  0.37267080745341613\n",
      "recall for fold 1753:  0.36585365853658536\n",
      "precision for fold 1753:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1754:  0.5181347150259067\n",
      "f1  score for fold 1754:  0.422360248447205\n",
      "recall for fold 1754:  0.39080459770114945\n",
      "precision for fold 1754:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1755:  0.5598086124401914\n",
      "f1  score for fold 1755:  0.4177215189873418\n",
      "recall for fold 1755:  0.4230769230769231\n",
      "precision for fold 1755:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1756:  0.5215311004784688\n",
      "f1  score for fold 1756:  0.3506493506493507\n",
      "recall for fold 1756:  0.36486486486486486\n",
      "precision for fold 1756:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1757:  0.5285714285714286\n",
      "f1  score for fold 1757:  0.3612903225806451\n",
      "recall for fold 1757:  0.37333333333333335\n",
      "precision for fold 1757:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1758:  0.558252427184466\n",
      "f1  score for fold 1758:  0.43478260869565216\n",
      "recall for fold 1758:  0.4268292682926829\n",
      "precision for fold 1758:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1759:  0.5284974093264249\n",
      "f1  score for fold 1759:  0.4347826086956522\n",
      "recall for fold 1759:  0.40229885057471265\n",
      "precision for fold 1759:  0.47297297297297297\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 1760:  0.5885167464114832\n",
      "f1  score for fold 1760:  0.45569620253164556\n",
      "recall for fold 1760:  0.46153846153846156\n",
      "precision for fold 1760:  0.45\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1761:  0.49282296650717705\n",
      "f1  score for fold 1761:  0.3116883116883117\n",
      "recall for fold 1761:  0.32432432432432434\n",
      "precision for fold 1761:  0.3\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1762:  0.5380952380952381\n",
      "f1  score for fold 1762:  0.3741935483870968\n",
      "recall for fold 1762:  0.38666666666666666\n",
      "precision for fold 1762:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1763:  0.5194174757281553\n",
      "f1  score for fold 1763:  0.38509316770186336\n",
      "recall for fold 1763:  0.3780487804878049\n",
      "precision for fold 1763:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1764:  0.5077720207253886\n",
      "f1  score for fold 1764:  0.40993788819875776\n",
      "recall for fold 1764:  0.3793103448275862\n",
      "precision for fold 1764:  0.44594594594594594\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 1765:  0.5980861244019139\n",
      "f1  score for fold 1765:  0.46835443037974683\n",
      "recall for fold 1765:  0.47435897435897434\n",
      "precision for fold 1765:  0.4625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1766:  0.5502392344497608\n",
      "f1  score for fold 1766:  0.3896103896103896\n",
      "recall for fold 1766:  0.40540540540540543\n",
      "precision for fold 1766:  0.375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1767:  0.5857142857142857\n",
      "f1  score for fold 1767:  0.43870967741935485\n",
      "recall for fold 1767:  0.4533333333333333\n",
      "precision for fold 1767:  0.425\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1768:  0.49029126213592233\n",
      "f1  score for fold 1768:  0.3478260869565218\n",
      "recall for fold 1768:  0.34146341463414637\n",
      "precision for fold 1768:  0.35443037974683544\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1769:  0.45595854922279794\n",
      "f1  score for fold 1769:  0.3478260869565218\n",
      "recall for fold 1769:  0.3218390804597701\n",
      "precision for fold 1769:  0.3783783783783784\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1770:  0.5119617224880383\n",
      "f1  score for fold 1770:  0.3544303797468355\n",
      "recall for fold 1770:  0.358974358974359\n",
      "precision for fold 1770:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1771:  0.5406698564593302\n",
      "f1  score for fold 1771:  0.37662337662337664\n",
      "recall for fold 1771:  0.3918918918918919\n",
      "precision for fold 1771:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1772:  0.5190476190476191\n",
      "f1  score for fold 1772:  0.34838709677419355\n",
      "recall for fold 1772:  0.36\n",
      "precision for fold 1772:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1773:  0.5485436893203883\n",
      "f1  score for fold 1773:  0.42236024844720493\n",
      "recall for fold 1773:  0.4146341463414634\n",
      "precision for fold 1773:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1774:  0.49740932642487046\n",
      "f1  score for fold 1774:  0.39751552795031053\n",
      "recall for fold 1774:  0.367816091954023\n",
      "precision for fold 1774:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1775:  0.5311004784688995\n",
      "f1  score for fold 1775:  0.37974683544303806\n",
      "recall for fold 1775:  0.38461538461538464\n",
      "precision for fold 1775:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1776:  0.5406698564593302\n",
      "f1  score for fold 1776:  0.37662337662337664\n",
      "recall for fold 1776:  0.3918918918918919\n",
      "precision for fold 1776:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1777:  0.5285714285714286\n",
      "f1  score for fold 1777:  0.3612903225806451\n",
      "recall for fold 1777:  0.37333333333333335\n",
      "precision for fold 1777:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1778:  0.5\n",
      "f1  score for fold 1778:  0.3602484472049689\n",
      "recall for fold 1778:  0.35365853658536583\n",
      "precision for fold 1778:  0.3670886075949367\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1779:  0.538860103626943\n",
      "f1  score for fold 1779:  0.4472049689440994\n",
      "recall for fold 1779:  0.41379310344827586\n",
      "precision for fold 1779:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1780:  0.5119617224880383\n",
      "f1  score for fold 1780:  0.3544303797468355\n",
      "recall for fold 1780:  0.358974358974359\n",
      "precision for fold 1780:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1781:  0.5311004784688995\n",
      "f1  score for fold 1781:  0.36363636363636365\n",
      "recall for fold 1781:  0.3783783783783784\n",
      "precision for fold 1781:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1782:  0.5571428571428572\n",
      "f1  score for fold 1782:  0.4000000000000001\n",
      "recall for fold 1782:  0.41333333333333333\n",
      "precision for fold 1782:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1783:  0.529126213592233\n",
      "f1  score for fold 1783:  0.39751552795031053\n",
      "recall for fold 1783:  0.3902439024390244\n",
      "precision for fold 1783:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1784:  0.5077720207253886\n",
      "f1  score for fold 1784:  0.40993788819875776\n",
      "recall for fold 1784:  0.3793103448275862\n",
      "precision for fold 1784:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1785:  0.5119617224880383\n",
      "f1  score for fold 1785:  0.3544303797468355\n",
      "recall for fold 1785:  0.358974358974359\n",
      "precision for fold 1785:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1786:  0.5502392344497608\n",
      "f1  score for fold 1786:  0.3896103896103896\n",
      "recall for fold 1786:  0.40540540540540543\n",
      "precision for fold 1786:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1787:  0.5190476190476191\n",
      "f1  score for fold 1787:  0.34838709677419355\n",
      "recall for fold 1787:  0.36\n",
      "precision for fold 1787:  0.3375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1788:  0.46116504854368934\n",
      "f1  score for fold 1788:  0.31055900621118016\n",
      "recall for fold 1788:  0.3048780487804878\n",
      "precision for fold 1788:  0.31645569620253167\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1789:  0.5181347150259067\n",
      "f1  score for fold 1789:  0.422360248447205\n",
      "recall for fold 1789:  0.39080459770114945\n",
      "precision for fold 1789:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1790:  0.5215311004784688\n",
      "f1  score for fold 1790:  0.36708860759493667\n",
      "recall for fold 1790:  0.3717948717948718\n",
      "precision for fold 1790:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 1791:  0.47368421052631576\n",
      "f1  score for fold 1791:  0.28571428571428575\n",
      "recall for fold 1791:  0.2972972972972973\n",
      "precision for fold 1791:  0.275\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1792:  0.5952380952380952\n",
      "f1  score for fold 1792:  0.45161290322580644\n",
      "recall for fold 1792:  0.4666666666666667\n",
      "precision for fold 1792:  0.4375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1793:  0.5097087378640777\n",
      "f1  score for fold 1793:  0.37267080745341613\n",
      "recall for fold 1793:  0.36585365853658536\n",
      "precision for fold 1793:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1794:  0.5181347150259067\n",
      "f1  score for fold 1794:  0.422360248447205\n",
      "recall for fold 1794:  0.39080459770114945\n",
      "precision for fold 1794:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 1795:  0.48325358851674644\n",
      "f1  score for fold 1795:  0.31645569620253167\n",
      "recall for fold 1795:  0.32051282051282054\n",
      "precision for fold 1795:  0.3125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1796:  0.5406698564593302\n",
      "f1  score for fold 1796:  0.37662337662337664\n",
      "recall for fold 1796:  0.3918918918918919\n",
      "precision for fold 1796:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1797:  0.5476190476190477\n",
      "f1  score for fold 1797:  0.38709677419354843\n",
      "recall for fold 1797:  0.4\n",
      "precision for fold 1797:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1798:  0.529126213592233\n",
      "f1  score for fold 1798:  0.39751552795031053\n",
      "recall for fold 1798:  0.3902439024390244\n",
      "precision for fold 1798:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1799:  0.538860103626943\n",
      "f1  score for fold 1799:  0.4472049689440994\n",
      "recall for fold 1799:  0.41379310344827586\n",
      "precision for fold 1799:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1800:  0.5119617224880383\n",
      "f1  score for fold 1800:  0.3544303797468355\n",
      "recall for fold 1800:  0.358974358974359\n",
      "precision for fold 1800:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1801:  0.5502392344497608\n",
      "f1  score for fold 1801:  0.3896103896103896\n",
      "recall for fold 1801:  0.40540540540540543\n",
      "precision for fold 1801:  0.375\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 1802:  0.4714285714285714\n",
      "f1  score for fold 1802:  0.2838709677419355\n",
      "recall for fold 1802:  0.29333333333333333\n",
      "precision for fold 1802:  0.275\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1803:  0.5097087378640777\n",
      "f1  score for fold 1803:  0.37267080745341613\n",
      "recall for fold 1803:  0.36585365853658536\n",
      "precision for fold 1803:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1804:  0.5284974093264249\n",
      "f1  score for fold 1804:  0.4347826086956522\n",
      "recall for fold 1804:  0.40229885057471265\n",
      "precision for fold 1804:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1805:  0.5215311004784688\n",
      "f1  score for fold 1805:  0.36708860759493667\n",
      "recall for fold 1805:  0.3717948717948718\n",
      "precision for fold 1805:  0.3625\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 1806:  0.5885167464114832\n",
      "f1  score for fold 1806:  0.44155844155844154\n",
      "recall for fold 1806:  0.4594594594594595\n",
      "precision for fold 1806:  0.425\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1807:  0.5571428571428572\n",
      "f1  score for fold 1807:  0.4000000000000001\n",
      "recall for fold 1807:  0.41333333333333333\n",
      "precision for fold 1807:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1808:  0.5485436893203883\n",
      "f1  score for fold 1808:  0.42236024844720493\n",
      "recall for fold 1808:  0.4146341463414634\n",
      "precision for fold 1808:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1809:  0.5077720207253886\n",
      "f1  score for fold 1809:  0.40993788819875776\n",
      "recall for fold 1809:  0.3793103448275862\n",
      "precision for fold 1809:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1810:  0.5598086124401914\n",
      "f1  score for fold 1810:  0.4177215189873418\n",
      "recall for fold 1810:  0.4230769230769231\n",
      "precision for fold 1810:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1811:  0.5502392344497608\n",
      "f1  score for fold 1811:  0.3896103896103896\n",
      "recall for fold 1811:  0.40540540540540543\n",
      "precision for fold 1811:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1812:  0.5190476190476191\n",
      "f1  score for fold 1812:  0.34838709677419355\n",
      "recall for fold 1812:  0.36\n",
      "precision for fold 1812:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1813:  0.5097087378640777\n",
      "f1  score for fold 1813:  0.37267080745341613\n",
      "recall for fold 1813:  0.36585365853658536\n",
      "precision for fold 1813:  0.379746835443038\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 1814:  0.6010362694300518\n",
      "f1  score for fold 1814:  0.5217391304347826\n",
      "recall for fold 1814:  0.4827586206896552\n",
      "precision for fold 1814:  0.5675675675675675\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1815:  0.5311004784688995\n",
      "f1  score for fold 1815:  0.37974683544303806\n",
      "recall for fold 1815:  0.38461538461538464\n",
      "precision for fold 1815:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1816:  0.5502392344497608\n",
      "f1  score for fold 1816:  0.3896103896103896\n",
      "recall for fold 1816:  0.40540540540540543\n",
      "precision for fold 1816:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1817:  0.5380952380952381\n",
      "f1  score for fold 1817:  0.3741935483870968\n",
      "recall for fold 1817:  0.38666666666666666\n",
      "precision for fold 1817:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1818:  0.529126213592233\n",
      "f1  score for fold 1818:  0.39751552795031053\n",
      "recall for fold 1818:  0.3902439024390244\n",
      "precision for fold 1818:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1819:  0.47668393782383417\n",
      "f1  score for fold 1819:  0.3726708074534162\n",
      "recall for fold 1819:  0.3448275862068966\n",
      "precision for fold 1819:  0.40540540540540543\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1820:  0.5119617224880383\n",
      "f1  score for fold 1820:  0.3544303797468355\n",
      "recall for fold 1820:  0.358974358974359\n",
      "precision for fold 1820:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1821:  0.5502392344497608\n",
      "f1  score for fold 1821:  0.3896103896103896\n",
      "recall for fold 1821:  0.40540540540540543\n",
      "precision for fold 1821:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1822:  0.5285714285714286\n",
      "f1  score for fold 1822:  0.3612903225806451\n",
      "recall for fold 1822:  0.37333333333333335\n",
      "precision for fold 1822:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1823:  0.48058252427184467\n",
      "f1  score for fold 1823:  0.33540372670807456\n",
      "recall for fold 1823:  0.32926829268292684\n",
      "precision for fold 1823:  0.34177215189873417\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1824:  0.5181347150259067\n",
      "f1  score for fold 1824:  0.422360248447205\n",
      "recall for fold 1824:  0.39080459770114945\n",
      "precision for fold 1824:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1825:  0.5023923444976076\n",
      "f1  score for fold 1825:  0.34177215189873417\n",
      "recall for fold 1825:  0.34615384615384615\n",
      "precision for fold 1825:  0.3375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1826:  0.569377990430622\n",
      "f1  score for fold 1826:  0.4155844155844156\n",
      "recall for fold 1826:  0.43243243243243246\n",
      "precision for fold 1826:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1827:  0.5095238095238095\n",
      "f1  score for fold 1827:  0.335483870967742\n",
      "recall for fold 1827:  0.3466666666666667\n",
      "precision for fold 1827:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1828:  0.5\n",
      "f1  score for fold 1828:  0.3602484472049689\n",
      "recall for fold 1828:  0.35365853658536583\n",
      "precision for fold 1828:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1829:  0.5077720207253886\n",
      "f1  score for fold 1829:  0.40993788819875776\n",
      "recall for fold 1829:  0.3793103448275862\n",
      "precision for fold 1829:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1830:  0.5406698564593302\n",
      "f1  score for fold 1830:  0.3924050632911393\n",
      "recall for fold 1830:  0.3974358974358974\n",
      "precision for fold 1830:  0.3875\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 1831:  0.5885167464114832\n",
      "f1  score for fold 1831:  0.44155844155844154\n",
      "recall for fold 1831:  0.4594594594594595\n",
      "precision for fold 1831:  0.425\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1832:  0.5761904761904761\n",
      "f1  score for fold 1832:  0.4258064516129032\n",
      "recall for fold 1832:  0.44\n",
      "precision for fold 1832:  0.4125\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1833:  0.46116504854368934\n",
      "f1  score for fold 1833:  0.31055900621118016\n",
      "recall for fold 1833:  0.3048780487804878\n",
      "precision for fold 1833:  0.31645569620253167\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1834:  0.5181347150259067\n",
      "f1  score for fold 1834:  0.422360248447205\n",
      "recall for fold 1834:  0.39080459770114945\n",
      "precision for fold 1834:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1835:  0.5119617224880383\n",
      "f1  score for fold 1835:  0.3544303797468355\n",
      "recall for fold 1835:  0.358974358974359\n",
      "precision for fold 1835:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1836:  0.5311004784688995\n",
      "f1  score for fold 1836:  0.36363636363636365\n",
      "recall for fold 1836:  0.3783783783783784\n",
      "precision for fold 1836:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1837:  0.5095238095238095\n",
      "f1  score for fold 1837:  0.335483870967742\n",
      "recall for fold 1837:  0.3466666666666667\n",
      "precision for fold 1837:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1838:  0.5097087378640777\n",
      "f1  score for fold 1838:  0.37267080745341613\n",
      "recall for fold 1838:  0.36585365853658536\n",
      "precision for fold 1838:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1839:  0.49740932642487046\n",
      "f1  score for fold 1839:  0.39751552795031053\n",
      "recall for fold 1839:  0.367816091954023\n",
      "precision for fold 1839:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1840:  0.5119617224880383\n",
      "f1  score for fold 1840:  0.3544303797468355\n",
      "recall for fold 1840:  0.358974358974359\n",
      "precision for fold 1840:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1841:  0.5023923444976076\n",
      "f1  score for fold 1841:  0.3246753246753247\n",
      "recall for fold 1841:  0.33783783783783783\n",
      "precision for fold 1841:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1842:  0.5190476190476191\n",
      "f1  score for fold 1842:  0.34838709677419355\n",
      "recall for fold 1842:  0.36\n",
      "precision for fold 1842:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1843:  0.529126213592233\n",
      "f1  score for fold 1843:  0.39751552795031053\n",
      "recall for fold 1843:  0.3902439024390244\n",
      "precision for fold 1843:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1844:  0.538860103626943\n",
      "f1  score for fold 1844:  0.4472049689440994\n",
      "recall for fold 1844:  0.41379310344827586\n",
      "precision for fold 1844:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1845:  0.5598086124401914\n",
      "f1  score for fold 1845:  0.4177215189873418\n",
      "recall for fold 1845:  0.4230769230769231\n",
      "precision for fold 1845:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1846:  0.5406698564593302\n",
      "f1  score for fold 1846:  0.37662337662337664\n",
      "recall for fold 1846:  0.3918918918918919\n",
      "precision for fold 1846:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1847:  0.5476190476190477\n",
      "f1  score for fold 1847:  0.38709677419354843\n",
      "recall for fold 1847:  0.4\n",
      "precision for fold 1847:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1848:  0.5097087378640777\n",
      "f1  score for fold 1848:  0.37267080745341613\n",
      "recall for fold 1848:  0.36585365853658536\n",
      "precision for fold 1848:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 1849:  0.46632124352331605\n",
      "f1  score for fold 1849:  0.36024844720496896\n",
      "recall for fold 1849:  0.3333333333333333\n",
      "precision for fold 1849:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1850:  0.5023923444976076\n",
      "f1  score for fold 1850:  0.34177215189873417\n",
      "recall for fold 1850:  0.34615384615384615\n",
      "precision for fold 1850:  0.3375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1851:  0.5789473684210527\n",
      "f1  score for fold 1851:  0.42857142857142855\n",
      "recall for fold 1851:  0.44594594594594594\n",
      "precision for fold 1851:  0.4125\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1852:  0.5761904761904761\n",
      "f1  score for fold 1852:  0.4258064516129032\n",
      "recall for fold 1852:  0.44\n",
      "precision for fold 1852:  0.4125\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1853:  0.5679611650485437\n",
      "f1  score for fold 1853:  0.4472049689440994\n",
      "recall for fold 1853:  0.43902439024390244\n",
      "precision for fold 1853:  0.45569620253164556\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1854:  0.538860103626943\n",
      "f1  score for fold 1854:  0.4472049689440994\n",
      "recall for fold 1854:  0.41379310344827586\n",
      "precision for fold 1854:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1855:  0.5215311004784688\n",
      "f1  score for fold 1855:  0.36708860759493667\n",
      "recall for fold 1855:  0.3717948717948718\n",
      "precision for fold 1855:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1856:  0.5502392344497608\n",
      "f1  score for fold 1856:  0.3896103896103896\n",
      "recall for fold 1856:  0.40540540540540543\n",
      "precision for fold 1856:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1857:  0.5190476190476191\n",
      "f1  score for fold 1857:  0.34838709677419355\n",
      "recall for fold 1857:  0.36\n",
      "precision for fold 1857:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1858:  0.529126213592233\n",
      "f1  score for fold 1858:  0.39751552795031053\n",
      "recall for fold 1858:  0.3902439024390244\n",
      "precision for fold 1858:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1859:  0.5181347150259067\n",
      "f1  score for fold 1859:  0.422360248447205\n",
      "recall for fold 1859:  0.39080459770114945\n",
      "precision for fold 1859:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1860:  0.5406698564593302\n",
      "f1  score for fold 1860:  0.3924050632911393\n",
      "recall for fold 1860:  0.3974358974358974\n",
      "precision for fold 1860:  0.3875\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 1861:  0.5789473684210527\n",
      "f1  score for fold 1861:  0.42857142857142855\n",
      "recall for fold 1861:  0.44594594594594594\n",
      "precision for fold 1861:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1862:  0.5380952380952381\n",
      "f1  score for fold 1862:  0.3741935483870968\n",
      "recall for fold 1862:  0.38666666666666666\n",
      "precision for fold 1862:  0.3625\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1863:  0.46116504854368934\n",
      "f1  score for fold 1863:  0.31055900621118016\n",
      "recall for fold 1863:  0.3048780487804878\n",
      "precision for fold 1863:  0.31645569620253167\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1864:  0.5492227979274611\n",
      "f1  score for fold 1864:  0.45962732919254656\n",
      "recall for fold 1864:  0.42528735632183906\n",
      "precision for fold 1864:  0.5\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 1865:  0.46411483253588515\n",
      "f1  score for fold 1865:  0.2911392405063291\n",
      "recall for fold 1865:  0.2948717948717949\n",
      "precision for fold 1865:  0.2875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1866:  0.5311004784688995\n",
      "f1  score for fold 1866:  0.36363636363636365\n",
      "recall for fold 1866:  0.3783783783783784\n",
      "precision for fold 1866:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1867:  0.5190476190476191\n",
      "f1  score for fold 1867:  0.34838709677419355\n",
      "recall for fold 1867:  0.36\n",
      "precision for fold 1867:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1868:  0.5097087378640777\n",
      "f1  score for fold 1868:  0.37267080745341613\n",
      "recall for fold 1868:  0.36585365853658536\n",
      "precision for fold 1868:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1869:  0.5181347150259067\n",
      "f1  score for fold 1869:  0.422360248447205\n",
      "recall for fold 1869:  0.39080459770114945\n",
      "precision for fold 1869:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1870:  0.5311004784688995\n",
      "f1  score for fold 1870:  0.37974683544303806\n",
      "recall for fold 1870:  0.38461538461538464\n",
      "precision for fold 1870:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1871:  0.5502392344497608\n",
      "f1  score for fold 1871:  0.3896103896103896\n",
      "recall for fold 1871:  0.40540540540540543\n",
      "precision for fold 1871:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1872:  0.5095238095238095\n",
      "f1  score for fold 1872:  0.335483870967742\n",
      "recall for fold 1872:  0.3466666666666667\n",
      "precision for fold 1872:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1873:  0.5194174757281553\n",
      "f1  score for fold 1873:  0.38509316770186336\n",
      "recall for fold 1873:  0.3780487804878049\n",
      "precision for fold 1873:  0.3924050632911392\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1874:  0.45595854922279794\n",
      "f1  score for fold 1874:  0.3478260869565218\n",
      "recall for fold 1874:  0.3218390804597701\n",
      "precision for fold 1874:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1875:  0.5215311004784688\n",
      "f1  score for fold 1875:  0.36708860759493667\n",
      "recall for fold 1875:  0.3717948717948718\n",
      "precision for fold 1875:  0.3625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1876:  0.5119617224880383\n",
      "f1  score for fold 1876:  0.33766233766233766\n",
      "recall for fold 1876:  0.35135135135135137\n",
      "precision for fold 1876:  0.325\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1877:  0.5952380952380952\n",
      "f1  score for fold 1877:  0.45161290322580644\n",
      "recall for fold 1877:  0.4666666666666667\n",
      "precision for fold 1877:  0.4375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 1878:  0.470873786407767\n",
      "f1  score for fold 1878:  0.3229813664596273\n",
      "recall for fold 1878:  0.3170731707317073\n",
      "precision for fold 1878:  0.3291139240506329\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1879:  0.5699481865284974\n",
      "f1  score for fold 1879:  0.48447204968944096\n",
      "recall for fold 1879:  0.4482758620689655\n",
      "precision for fold 1879:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1880:  0.5502392344497608\n",
      "f1  score for fold 1880:  0.4050632911392405\n",
      "recall for fold 1880:  0.41025641025641024\n",
      "precision for fold 1880:  0.4\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 1881:  0.6076555023923444\n",
      "f1  score for fold 1881:  0.4675324675324675\n",
      "recall for fold 1881:  0.4864864864864865\n",
      "precision for fold 1881:  0.45\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1882:  0.5571428571428572\n",
      "f1  score for fold 1882:  0.4000000000000001\n",
      "recall for fold 1882:  0.41333333333333333\n",
      "precision for fold 1882:  0.3875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 1883:  0.5679611650485437\n",
      "f1  score for fold 1883:  0.4472049689440994\n",
      "recall for fold 1883:  0.43902439024390244\n",
      "precision for fold 1883:  0.45569620253164556\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1884:  0.47668393782383417\n",
      "f1  score for fold 1884:  0.3726708074534162\n",
      "recall for fold 1884:  0.3448275862068966\n",
      "precision for fold 1884:  0.40540540540540543\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1885:  0.5406698564593302\n",
      "f1  score for fold 1885:  0.3924050632911393\n",
      "recall for fold 1885:  0.3974358974358974\n",
      "precision for fold 1885:  0.3875\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 1886:  0.5885167464114832\n",
      "f1  score for fold 1886:  0.44155844155844154\n",
      "recall for fold 1886:  0.4594594594594595\n",
      "precision for fold 1886:  0.425\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1887:  0.5857142857142857\n",
      "f1  score for fold 1887:  0.43870967741935485\n",
      "recall for fold 1887:  0.4533333333333333\n",
      "precision for fold 1887:  0.425\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1888:  0.5388349514563107\n",
      "f1  score for fold 1888:  0.40993788819875776\n",
      "recall for fold 1888:  0.4024390243902439\n",
      "precision for fold 1888:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1889:  0.5284974093264249\n",
      "f1  score for fold 1889:  0.4347826086956522\n",
      "recall for fold 1889:  0.40229885057471265\n",
      "precision for fold 1889:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1890:  0.5215311004784688\n",
      "f1  score for fold 1890:  0.36708860759493667\n",
      "recall for fold 1890:  0.3717948717948718\n",
      "precision for fold 1890:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 1891:  0.5406698564593302\n",
      "f1  score for fold 1891:  0.37662337662337664\n",
      "recall for fold 1891:  0.3918918918918919\n",
      "precision for fold 1891:  0.3625\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 1892:  0.5857142857142857\n",
      "f1  score for fold 1892:  0.43870967741935485\n",
      "recall for fold 1892:  0.4533333333333333\n",
      "precision for fold 1892:  0.425\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 1893:  0.587378640776699\n",
      "f1  score for fold 1893:  0.4720496894409938\n",
      "recall for fold 1893:  0.4634146341463415\n",
      "precision for fold 1893:  0.4810126582278481\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 1894:  0.5699481865284974\n",
      "f1  score for fold 1894:  0.48447204968944096\n",
      "recall for fold 1894:  0.4482758620689655\n",
      "precision for fold 1894:  0.527027027027027\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 1895:  0.5023923444976076\n",
      "f1  score for fold 1895:  0.34177215189873417\n",
      "recall for fold 1895:  0.34615384615384615\n",
      "precision for fold 1895:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1896:  0.5023923444976076\n",
      "f1  score for fold 1896:  0.3246753246753247\n",
      "recall for fold 1896:  0.33783783783783783\n",
      "precision for fold 1896:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 1897:  0.5190476190476191\n",
      "f1  score for fold 1897:  0.34838709677419355\n",
      "recall for fold 1897:  0.36\n",
      "precision for fold 1897:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1898:  0.5194174757281553\n",
      "f1  score for fold 1898:  0.38509316770186336\n",
      "recall for fold 1898:  0.3780487804878049\n",
      "precision for fold 1898:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1899:  0.5077720207253886\n",
      "f1  score for fold 1899:  0.40993788819875776\n",
      "recall for fold 1899:  0.3793103448275862\n",
      "precision for fold 1899:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1900:  0.5502392344497608\n",
      "f1  score for fold 1900:  0.4050632911392405\n",
      "recall for fold 1900:  0.41025641025641024\n",
      "precision for fold 1900:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1901:  0.5598086124401914\n",
      "f1  score for fold 1901:  0.40259740259740256\n",
      "recall for fold 1901:  0.4189189189189189\n",
      "precision for fold 1901:  0.3875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1902:  0.5761904761904761\n",
      "f1  score for fold 1902:  0.4258064516129032\n",
      "recall for fold 1902:  0.44\n",
      "precision for fold 1902:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1903:  0.5097087378640777\n",
      "f1  score for fold 1903:  0.37267080745341613\n",
      "recall for fold 1903:  0.36585365853658536\n",
      "precision for fold 1903:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1904:  0.44559585492227977\n",
      "f1  score for fold 1904:  0.33540372670807456\n",
      "recall for fold 1904:  0.3103448275862069\n",
      "precision for fold 1904:  0.36486486486486486\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1905:  0.5311004784688995\n",
      "f1  score for fold 1905:  0.37974683544303806\n",
      "recall for fold 1905:  0.38461538461538464\n",
      "precision for fold 1905:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1906:  0.569377990430622\n",
      "f1  score for fold 1906:  0.4155844155844156\n",
      "recall for fold 1906:  0.43243243243243246\n",
      "precision for fold 1906:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1907:  0.5476190476190477\n",
      "f1  score for fold 1907:  0.38709677419354843\n",
      "recall for fold 1907:  0.4\n",
      "precision for fold 1907:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1908:  0.529126213592233\n",
      "f1  score for fold 1908:  0.39751552795031053\n",
      "recall for fold 1908:  0.3902439024390244\n",
      "precision for fold 1908:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1909:  0.5181347150259067\n",
      "f1  score for fold 1909:  0.422360248447205\n",
      "recall for fold 1909:  0.39080459770114945\n",
      "precision for fold 1909:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 1910:  0.5119617224880383\n",
      "f1  score for fold 1910:  0.3544303797468355\n",
      "recall for fold 1910:  0.358974358974359\n",
      "precision for fold 1910:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1911:  0.5598086124401914\n",
      "f1  score for fold 1911:  0.40259740259740256\n",
      "recall for fold 1911:  0.4189189189189189\n",
      "precision for fold 1911:  0.3875\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 1912:  0.5952380952380952\n",
      "f1  score for fold 1912:  0.45161290322580644\n",
      "recall for fold 1912:  0.4666666666666667\n",
      "precision for fold 1912:  0.4375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1913:  0.529126213592233\n",
      "f1  score for fold 1913:  0.39751552795031053\n",
      "recall for fold 1913:  0.3902439024390244\n",
      "precision for fold 1913:  0.4050632911392405\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 1914:  0.44559585492227977\n",
      "f1  score for fold 1914:  0.33540372670807456\n",
      "recall for fold 1914:  0.3103448275862069\n",
      "precision for fold 1914:  0.36486486486486486\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1915:  0.5789473684210527\n",
      "f1  score for fold 1915:  0.44303797468354433\n",
      "recall for fold 1915:  0.44871794871794873\n",
      "precision for fold 1915:  0.4375\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 1916:  0.46411483253588515\n",
      "f1  score for fold 1916:  0.27272727272727276\n",
      "recall for fold 1916:  0.28378378378378377\n",
      "precision for fold 1916:  0.2625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 1917:  0.5761904761904761\n",
      "f1  score for fold 1917:  0.4258064516129032\n",
      "recall for fold 1917:  0.44\n",
      "precision for fold 1917:  0.4125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 1918:  0.49029126213592233\n",
      "f1  score for fold 1918:  0.3478260869565218\n",
      "recall for fold 1918:  0.34146341463414637\n",
      "precision for fold 1918:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1919:  0.48704663212435234\n",
      "f1  score for fold 1919:  0.3850931677018633\n",
      "recall for fold 1919:  0.3563218390804598\n",
      "precision for fold 1919:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1920:  0.5311004784688995\n",
      "f1  score for fold 1920:  0.37974683544303806\n",
      "recall for fold 1920:  0.38461538461538464\n",
      "precision for fold 1920:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 1921:  0.5598086124401914\n",
      "f1  score for fold 1921:  0.40259740259740256\n",
      "recall for fold 1921:  0.4189189189189189\n",
      "precision for fold 1921:  0.3875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1922:  0.5571428571428572\n",
      "f1  score for fold 1922:  0.4000000000000001\n",
      "recall for fold 1922:  0.41333333333333333\n",
      "precision for fold 1922:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1923:  0.5485436893203883\n",
      "f1  score for fold 1923:  0.42236024844720493\n",
      "recall for fold 1923:  0.4146341463414634\n",
      "precision for fold 1923:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1924:  0.5077720207253886\n",
      "f1  score for fold 1924:  0.40993788819875776\n",
      "recall for fold 1924:  0.3793103448275862\n",
      "precision for fold 1924:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 1925:  0.5311004784688995\n",
      "f1  score for fold 1925:  0.37974683544303806\n",
      "recall for fold 1925:  0.38461538461538464\n",
      "precision for fold 1925:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1926:  0.5119617224880383\n",
      "f1  score for fold 1926:  0.33766233766233766\n",
      "recall for fold 1926:  0.35135135135135137\n",
      "precision for fold 1926:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1927:  0.5476190476190477\n",
      "f1  score for fold 1927:  0.38709677419354843\n",
      "recall for fold 1927:  0.4\n",
      "precision for fold 1927:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1928:  0.5194174757281553\n",
      "f1  score for fold 1928:  0.38509316770186336\n",
      "recall for fold 1928:  0.3780487804878049\n",
      "precision for fold 1928:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 1929:  0.5181347150259067\n",
      "f1  score for fold 1929:  0.422360248447205\n",
      "recall for fold 1929:  0.39080459770114945\n",
      "precision for fold 1929:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1930:  0.5502392344497608\n",
      "f1  score for fold 1930:  0.4050632911392405\n",
      "recall for fold 1930:  0.41025641025641024\n",
      "precision for fold 1930:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1931:  0.5119617224880383\n",
      "f1  score for fold 1931:  0.33766233766233766\n",
      "recall for fold 1931:  0.35135135135135137\n",
      "precision for fold 1931:  0.325\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1932:  0.5095238095238095\n",
      "f1  score for fold 1932:  0.335483870967742\n",
      "recall for fold 1932:  0.3466666666666667\n",
      "precision for fold 1932:  0.325\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 1933:  0.5776699029126213\n",
      "f1  score for fold 1933:  0.4596273291925466\n",
      "recall for fold 1933:  0.45121951219512196\n",
      "precision for fold 1933:  0.46835443037974683\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 1934:  0.538860103626943\n",
      "f1  score for fold 1934:  0.4472049689440994\n",
      "recall for fold 1934:  0.41379310344827586\n",
      "precision for fold 1934:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 1935:  0.49282296650717705\n",
      "f1  score for fold 1935:  0.32911392405063294\n",
      "recall for fold 1935:  0.3333333333333333\n",
      "precision for fold 1935:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1936:  0.5215311004784688\n",
      "f1  score for fold 1936:  0.3506493506493507\n",
      "recall for fold 1936:  0.36486486486486486\n",
      "precision for fold 1936:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 1937:  0.5571428571428572\n",
      "f1  score for fold 1937:  0.4000000000000001\n",
      "recall for fold 1937:  0.41333333333333333\n",
      "precision for fold 1937:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1938:  0.5388349514563107\n",
      "f1  score for fold 1938:  0.40993788819875776\n",
      "recall for fold 1938:  0.4024390243902439\n",
      "precision for fold 1938:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 1939:  0.5595854922279793\n",
      "f1  score for fold 1939:  0.4720496894409938\n",
      "recall for fold 1939:  0.4367816091954023\n",
      "precision for fold 1939:  0.5135135135135135\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1940:  0.5789473684210527\n",
      "f1  score for fold 1940:  0.44303797468354433\n",
      "recall for fold 1940:  0.44871794871794873\n",
      "precision for fold 1940:  0.4375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1941:  0.5215311004784688\n",
      "f1  score for fold 1941:  0.3506493506493507\n",
      "recall for fold 1941:  0.36486486486486486\n",
      "precision for fold 1941:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1942:  0.5476190476190477\n",
      "f1  score for fold 1942:  0.38709677419354843\n",
      "recall for fold 1942:  0.4\n",
      "precision for fold 1942:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 1943:  0.558252427184466\n",
      "f1  score for fold 1943:  0.43478260869565216\n",
      "recall for fold 1943:  0.4268292682926829\n",
      "precision for fold 1943:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1944:  0.5284974093264249\n",
      "f1  score for fold 1944:  0.4347826086956522\n",
      "recall for fold 1944:  0.40229885057471265\n",
      "precision for fold 1944:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 1945:  0.5215311004784688\n",
      "f1  score for fold 1945:  0.36708860759493667\n",
      "recall for fold 1945:  0.3717948717948718\n",
      "precision for fold 1945:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1946:  0.49282296650717705\n",
      "f1  score for fold 1946:  0.3116883116883117\n",
      "recall for fold 1946:  0.32432432432432434\n",
      "precision for fold 1946:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1947:  0.5476190476190477\n",
      "f1  score for fold 1947:  0.38709677419354843\n",
      "recall for fold 1947:  0.4\n",
      "precision for fold 1947:  0.375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1948:  0.48058252427184467\n",
      "f1  score for fold 1948:  0.33540372670807456\n",
      "recall for fold 1948:  0.32926829268292684\n",
      "precision for fold 1948:  0.34177215189873417\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1949:  0.5077720207253886\n",
      "f1  score for fold 1949:  0.40993788819875776\n",
      "recall for fold 1949:  0.3793103448275862\n",
      "precision for fold 1949:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1950:  0.569377990430622\n",
      "f1  score for fold 1950:  0.43037974683544306\n",
      "recall for fold 1950:  0.4358974358974359\n",
      "precision for fold 1950:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 1951:  0.5502392344497608\n",
      "f1  score for fold 1951:  0.3896103896103896\n",
      "recall for fold 1951:  0.40540540540540543\n",
      "precision for fold 1951:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1952:  0.5666666666666667\n",
      "f1  score for fold 1952:  0.41290322580645167\n",
      "recall for fold 1952:  0.4266666666666667\n",
      "precision for fold 1952:  0.4\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 1953:  0.48058252427184467\n",
      "f1  score for fold 1953:  0.33540372670807456\n",
      "recall for fold 1953:  0.32926829268292684\n",
      "precision for fold 1953:  0.34177215189873417\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 1954:  0.45595854922279794\n",
      "f1  score for fold 1954:  0.3478260869565218\n",
      "recall for fold 1954:  0.3218390804597701\n",
      "precision for fold 1954:  0.3783783783783784\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 1955:  0.5980861244019139\n",
      "f1  score for fold 1955:  0.46835443037974683\n",
      "recall for fold 1955:  0.47435897435897434\n",
      "precision for fold 1955:  0.4625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 1956:  0.49282296650717705\n",
      "f1  score for fold 1956:  0.3116883116883117\n",
      "recall for fold 1956:  0.32432432432432434\n",
      "precision for fold 1956:  0.3\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 1957:  0.5285714285714286\n",
      "f1  score for fold 1957:  0.3612903225806451\n",
      "recall for fold 1957:  0.37333333333333335\n",
      "precision for fold 1957:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 1958:  0.529126213592233\n",
      "f1  score for fold 1958:  0.39751552795031053\n",
      "recall for fold 1958:  0.3902439024390244\n",
      "precision for fold 1958:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 1959:  0.48704663212435234\n",
      "f1  score for fold 1959:  0.3850931677018633\n",
      "recall for fold 1959:  0.3563218390804598\n",
      "precision for fold 1959:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1960:  0.5598086124401914\n",
      "f1  score for fold 1960:  0.4177215189873418\n",
      "recall for fold 1960:  0.4230769230769231\n",
      "precision for fold 1960:  0.4125\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 1961:  0.569377990430622\n",
      "f1  score for fold 1961:  0.4155844155844156\n",
      "recall for fold 1961:  0.43243243243243246\n",
      "precision for fold 1961:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 1962:  0.5095238095238095\n",
      "f1  score for fold 1962:  0.335483870967742\n",
      "recall for fold 1962:  0.3466666666666667\n",
      "precision for fold 1962:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1963:  0.5097087378640777\n",
      "f1  score for fold 1963:  0.37267080745341613\n",
      "recall for fold 1963:  0.36585365853658536\n",
      "precision for fold 1963:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 1964:  0.47668393782383417\n",
      "f1  score for fold 1964:  0.3726708074534162\n",
      "recall for fold 1964:  0.3448275862068966\n",
      "precision for fold 1964:  0.40540540540540543\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 1965:  0.569377990430622\n",
      "f1  score for fold 1965:  0.43037974683544306\n",
      "recall for fold 1965:  0.4358974358974359\n",
      "precision for fold 1965:  0.425\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 1966:  0.5980861244019139\n",
      "f1  score for fold 1966:  0.45454545454545453\n",
      "recall for fold 1966:  0.47297297297297297\n",
      "precision for fold 1966:  0.4375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1967:  0.5476190476190477\n",
      "f1  score for fold 1967:  0.38709677419354843\n",
      "recall for fold 1967:  0.4\n",
      "precision for fold 1967:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 1968:  0.5485436893203883\n",
      "f1  score for fold 1968:  0.42236024844720493\n",
      "recall for fold 1968:  0.4146341463414634\n",
      "precision for fold 1968:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1969:  0.5284974093264249\n",
      "f1  score for fold 1969:  0.4347826086956522\n",
      "recall for fold 1969:  0.40229885057471265\n",
      "precision for fold 1969:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1970:  0.5406698564593302\n",
      "f1  score for fold 1970:  0.3924050632911393\n",
      "recall for fold 1970:  0.3974358974358974\n",
      "precision for fold 1970:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1971:  0.5215311004784688\n",
      "f1  score for fold 1971:  0.3506493506493507\n",
      "recall for fold 1971:  0.36486486486486486\n",
      "precision for fold 1971:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 1972:  0.5666666666666667\n",
      "f1  score for fold 1972:  0.41290322580645167\n",
      "recall for fold 1972:  0.4266666666666667\n",
      "precision for fold 1972:  0.4\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 1973:  0.46116504854368934\n",
      "f1  score for fold 1973:  0.31055900621118016\n",
      "recall for fold 1973:  0.3048780487804878\n",
      "precision for fold 1973:  0.31645569620253167\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 1974:  0.5284974093264249\n",
      "f1  score for fold 1974:  0.4347826086956522\n",
      "recall for fold 1974:  0.40229885057471265\n",
      "precision for fold 1974:  0.47297297297297297\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 1975:  0.5789473684210527\n",
      "f1  score for fold 1975:  0.44303797468354433\n",
      "recall for fold 1975:  0.44871794871794873\n",
      "precision for fold 1975:  0.4375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 1976:  0.5023923444976076\n",
      "f1  score for fold 1976:  0.3246753246753247\n",
      "recall for fold 1976:  0.33783783783783783\n",
      "precision for fold 1976:  0.3125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 1977:  0.5\n",
      "f1  score for fold 1977:  0.3225806451612903\n",
      "recall for fold 1977:  0.3333333333333333\n",
      "precision for fold 1977:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1978:  0.5388349514563107\n",
      "f1  score for fold 1978:  0.40993788819875776\n",
      "recall for fold 1978:  0.4024390243902439\n",
      "precision for fold 1978:  0.4177215189873418\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1979:  0.5492227979274611\n",
      "f1  score for fold 1979:  0.45962732919254656\n",
      "recall for fold 1979:  0.42528735632183906\n",
      "precision for fold 1979:  0.5\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1980:  0.5502392344497608\n",
      "f1  score for fold 1980:  0.4050632911392405\n",
      "recall for fold 1980:  0.41025641025641024\n",
      "precision for fold 1980:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1981:  0.5119617224880383\n",
      "f1  score for fold 1981:  0.33766233766233766\n",
      "recall for fold 1981:  0.35135135135135137\n",
      "precision for fold 1981:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1982:  0.5380952380952381\n",
      "f1  score for fold 1982:  0.3741935483870968\n",
      "recall for fold 1982:  0.38666666666666666\n",
      "precision for fold 1982:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 1983:  0.5388349514563107\n",
      "f1  score for fold 1983:  0.40993788819875776\n",
      "recall for fold 1983:  0.4024390243902439\n",
      "precision for fold 1983:  0.4177215189873418\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 1984:  0.5492227979274611\n",
      "f1  score for fold 1984:  0.45962732919254656\n",
      "recall for fold 1984:  0.42528735632183906\n",
      "precision for fold 1984:  0.5\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 1985:  0.5598086124401914\n",
      "f1  score for fold 1985:  0.4177215189873418\n",
      "recall for fold 1985:  0.4230769230769231\n",
      "precision for fold 1985:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 1986:  0.5215311004784688\n",
      "f1  score for fold 1986:  0.3506493506493507\n",
      "recall for fold 1986:  0.36486486486486486\n",
      "precision for fold 1986:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 1987:  0.49047619047619045\n",
      "f1  score for fold 1987:  0.3096774193548387\n",
      "recall for fold 1987:  0.32\n",
      "precision for fold 1987:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 1988:  0.5097087378640777\n",
      "f1  score for fold 1988:  0.37267080745341613\n",
      "recall for fold 1988:  0.36585365853658536\n",
      "precision for fold 1988:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1989:  0.49740932642487046\n",
      "f1  score for fold 1989:  0.39751552795031053\n",
      "recall for fold 1989:  0.367816091954023\n",
      "precision for fold 1989:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 1990:  0.5502392344497608\n",
      "f1  score for fold 1990:  0.4050632911392405\n",
      "recall for fold 1990:  0.41025641025641024\n",
      "precision for fold 1990:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 1991:  0.5119617224880383\n",
      "f1  score for fold 1991:  0.33766233766233766\n",
      "recall for fold 1991:  0.35135135135135137\n",
      "precision for fold 1991:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 1992:  0.5476190476190477\n",
      "f1  score for fold 1992:  0.38709677419354843\n",
      "recall for fold 1992:  0.4\n",
      "precision for fold 1992:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 1993:  0.5194174757281553\n",
      "f1  score for fold 1993:  0.38509316770186336\n",
      "recall for fold 1993:  0.3780487804878049\n",
      "precision for fold 1993:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 1994:  0.49740932642487046\n",
      "f1  score for fold 1994:  0.39751552795031053\n",
      "recall for fold 1994:  0.367816091954023\n",
      "precision for fold 1994:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 1995:  0.5406698564593302\n",
      "f1  score for fold 1995:  0.3924050632911393\n",
      "recall for fold 1995:  0.3974358974358974\n",
      "precision for fold 1995:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 1996:  0.5311004784688995\n",
      "f1  score for fold 1996:  0.36363636363636365\n",
      "recall for fold 1996:  0.3783783783783784\n",
      "precision for fold 1996:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 1997:  0.5380952380952381\n",
      "f1  score for fold 1997:  0.3741935483870968\n",
      "recall for fold 1997:  0.38666666666666666\n",
      "precision for fold 1997:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 1998:  0.5\n",
      "f1  score for fold 1998:  0.3602484472049689\n",
      "recall for fold 1998:  0.35365853658536583\n",
      "precision for fold 1998:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 1999:  0.5077720207253886\n",
      "f1  score for fold 1999:  0.40993788819875776\n",
      "recall for fold 1999:  0.3793103448275862\n",
      "precision for fold 1999:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 2000:  0.47368421052631576\n",
      "f1  score for fold 2000:  0.3037974683544304\n",
      "recall for fold 2000:  0.3076923076923077\n",
      "precision for fold 2000:  0.3\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2001:  0.5119617224880383\n",
      "f1  score for fold 2001:  0.33766233766233766\n",
      "recall for fold 2001:  0.35135135135135137\n",
      "precision for fold 2001:  0.325\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2002:  0.5666666666666667\n",
      "f1  score for fold 2002:  0.41290322580645167\n",
      "recall for fold 2002:  0.4266666666666667\n",
      "precision for fold 2002:  0.4\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2003:  0.5194174757281553\n",
      "f1  score for fold 2003:  0.38509316770186336\n",
      "recall for fold 2003:  0.3780487804878049\n",
      "precision for fold 2003:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2004:  0.5284974093264249\n",
      "f1  score for fold 2004:  0.4347826086956522\n",
      "recall for fold 2004:  0.40229885057471265\n",
      "precision for fold 2004:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2005:  0.5023923444976076\n",
      "f1  score for fold 2005:  0.34177215189873417\n",
      "recall for fold 2005:  0.34615384615384615\n",
      "precision for fold 2005:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2006:  0.5406698564593302\n",
      "f1  score for fold 2006:  0.37662337662337664\n",
      "recall for fold 2006:  0.3918918918918919\n",
      "precision for fold 2006:  0.3625\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 2007:  0.6047619047619047\n",
      "f1  score for fold 2007:  0.4645161290322581\n",
      "recall for fold 2007:  0.48\n",
      "precision for fold 2007:  0.45\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2008:  0.529126213592233\n",
      "f1  score for fold 2008:  0.39751552795031053\n",
      "recall for fold 2008:  0.3902439024390244\n",
      "precision for fold 2008:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2009:  0.5181347150259067\n",
      "f1  score for fold 2009:  0.422360248447205\n",
      "recall for fold 2009:  0.39080459770114945\n",
      "precision for fold 2009:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2010:  0.5598086124401914\n",
      "f1  score for fold 2010:  0.4177215189873418\n",
      "recall for fold 2010:  0.4230769230769231\n",
      "precision for fold 2010:  0.4125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2011:  0.5023923444976076\n",
      "f1  score for fold 2011:  0.3246753246753247\n",
      "recall for fold 2011:  0.33783783783783783\n",
      "precision for fold 2011:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2012:  0.5380952380952381\n",
      "f1  score for fold 2012:  0.3741935483870968\n",
      "recall for fold 2012:  0.38666666666666666\n",
      "precision for fold 2012:  0.3625\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 2013:  0.46116504854368934\n",
      "f1  score for fold 2013:  0.31055900621118016\n",
      "recall for fold 2013:  0.3048780487804878\n",
      "precision for fold 2013:  0.31645569620253167\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2014:  0.49740932642487046\n",
      "f1  score for fold 2014:  0.39751552795031053\n",
      "recall for fold 2014:  0.367816091954023\n",
      "precision for fold 2014:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2015:  0.5502392344497608\n",
      "f1  score for fold 2015:  0.4050632911392405\n",
      "recall for fold 2015:  0.41025641025641024\n",
      "precision for fold 2015:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2016:  0.5023923444976076\n",
      "f1  score for fold 2016:  0.3246753246753247\n",
      "recall for fold 2016:  0.33783783783783783\n",
      "precision for fold 2016:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2017:  0.5571428571428572\n",
      "f1  score for fold 2017:  0.4000000000000001\n",
      "recall for fold 2017:  0.41333333333333333\n",
      "precision for fold 2017:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2018:  0.5\n",
      "f1  score for fold 2018:  0.3602484472049689\n",
      "recall for fold 2018:  0.35365853658536583\n",
      "precision for fold 2018:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2019:  0.49740932642487046\n",
      "f1  score for fold 2019:  0.39751552795031053\n",
      "recall for fold 2019:  0.367816091954023\n",
      "precision for fold 2019:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2020:  0.49282296650717705\n",
      "f1  score for fold 2020:  0.32911392405063294\n",
      "recall for fold 2020:  0.3333333333333333\n",
      "precision for fold 2020:  0.325\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2021:  0.569377990430622\n",
      "f1  score for fold 2021:  0.4155844155844156\n",
      "recall for fold 2021:  0.43243243243243246\n",
      "precision for fold 2021:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2022:  0.5190476190476191\n",
      "f1  score for fold 2022:  0.34838709677419355\n",
      "recall for fold 2022:  0.36\n",
      "precision for fold 2022:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2023:  0.558252427184466\n",
      "f1  score for fold 2023:  0.43478260869565216\n",
      "recall for fold 2023:  0.4268292682926829\n",
      "precision for fold 2023:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2024:  0.48704663212435234\n",
      "f1  score for fold 2024:  0.3850931677018633\n",
      "recall for fold 2024:  0.3563218390804598\n",
      "precision for fold 2024:  0.4189189189189189\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2025:  0.5023923444976076\n",
      "f1  score for fold 2025:  0.34177215189873417\n",
      "recall for fold 2025:  0.34615384615384615\n",
      "precision for fold 2025:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2026:  0.5406698564593302\n",
      "f1  score for fold 2026:  0.37662337662337664\n",
      "recall for fold 2026:  0.3918918918918919\n",
      "precision for fold 2026:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2027:  0.5285714285714286\n",
      "f1  score for fold 2027:  0.3612903225806451\n",
      "recall for fold 2027:  0.37333333333333335\n",
      "precision for fold 2027:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2028:  0.5776699029126213\n",
      "f1  score for fold 2028:  0.4596273291925466\n",
      "recall for fold 2028:  0.45121951219512196\n",
      "precision for fold 2028:  0.46835443037974683\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2029:  0.5284974093264249\n",
      "f1  score for fold 2029:  0.4347826086956522\n",
      "recall for fold 2029:  0.40229885057471265\n",
      "precision for fold 2029:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2030:  0.569377990430622\n",
      "f1  score for fold 2030:  0.43037974683544306\n",
      "recall for fold 2030:  0.4358974358974359\n",
      "precision for fold 2030:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2031:  0.5311004784688995\n",
      "f1  score for fold 2031:  0.36363636363636365\n",
      "recall for fold 2031:  0.3783783783783784\n",
      "precision for fold 2031:  0.35\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 2032:  0.46190476190476193\n",
      "f1  score for fold 2032:  0.2709677419354839\n",
      "recall for fold 2032:  0.28\n",
      "precision for fold 2032:  0.2625\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 2033:  0.48058252427184467\n",
      "f1  score for fold 2033:  0.33540372670807456\n",
      "recall for fold 2033:  0.32926829268292684\n",
      "precision for fold 2033:  0.34177215189873417\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2034:  0.49740932642487046\n",
      "f1  score for fold 2034:  0.39751552795031053\n",
      "recall for fold 2034:  0.367816091954023\n",
      "precision for fold 2034:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2035:  0.49282296650717705\n",
      "f1  score for fold 2035:  0.32911392405063294\n",
      "recall for fold 2035:  0.3333333333333333\n",
      "precision for fold 2035:  0.325\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2036:  0.5023923444976076\n",
      "f1  score for fold 2036:  0.3246753246753247\n",
      "recall for fold 2036:  0.33783783783783783\n",
      "precision for fold 2036:  0.3125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2037:  0.49047619047619045\n",
      "f1  score for fold 2037:  0.3096774193548387\n",
      "recall for fold 2037:  0.32\n",
      "precision for fold 2037:  0.3\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2038:  0.5679611650485437\n",
      "f1  score for fold 2038:  0.4472049689440994\n",
      "recall for fold 2038:  0.43902439024390244\n",
      "precision for fold 2038:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2039:  0.5284974093264249\n",
      "f1  score for fold 2039:  0.4347826086956522\n",
      "recall for fold 2039:  0.40229885057471265\n",
      "precision for fold 2039:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2040:  0.5023923444976076\n",
      "f1  score for fold 2040:  0.34177215189873417\n",
      "recall for fold 2040:  0.34615384615384615\n",
      "precision for fold 2040:  0.3375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2041:  0.49282296650717705\n",
      "f1  score for fold 2041:  0.3116883116883117\n",
      "recall for fold 2041:  0.32432432432432434\n",
      "precision for fold 2041:  0.3\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2042:  0.5285714285714286\n",
      "f1  score for fold 2042:  0.3612903225806451\n",
      "recall for fold 2042:  0.37333333333333335\n",
      "precision for fold 2042:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2043:  0.529126213592233\n",
      "f1  score for fold 2043:  0.39751552795031053\n",
      "recall for fold 2043:  0.3902439024390244\n",
      "precision for fold 2043:  0.4050632911392405\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 2044:  0.5906735751295337\n",
      "f1  score for fold 2044:  0.5093167701863355\n",
      "recall for fold 2044:  0.47126436781609193\n",
      "precision for fold 2044:  0.5540540540540541\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 2045:  0.5980861244019139\n",
      "f1  score for fold 2045:  0.46835443037974683\n",
      "recall for fold 2045:  0.47435897435897434\n",
      "precision for fold 2045:  0.4625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2046:  0.5215311004784688\n",
      "f1  score for fold 2046:  0.3506493506493507\n",
      "recall for fold 2046:  0.36486486486486486\n",
      "precision for fold 2046:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2047:  0.5190476190476191\n",
      "f1  score for fold 2047:  0.34838709677419355\n",
      "recall for fold 2047:  0.36\n",
      "precision for fold 2047:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2048:  0.5485436893203883\n",
      "f1  score for fold 2048:  0.42236024844720493\n",
      "recall for fold 2048:  0.4146341463414634\n",
      "precision for fold 2048:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2049:  0.5077720207253886\n",
      "f1  score for fold 2049:  0.40993788819875776\n",
      "recall for fold 2049:  0.3793103448275862\n",
      "precision for fold 2049:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2050:  0.5598086124401914\n",
      "f1  score for fold 2050:  0.4177215189873418\n",
      "recall for fold 2050:  0.4230769230769231\n",
      "precision for fold 2050:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2051:  0.5311004784688995\n",
      "f1  score for fold 2051:  0.36363636363636365\n",
      "recall for fold 2051:  0.3783783783783784\n",
      "precision for fold 2051:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2052:  0.5190476190476191\n",
      "f1  score for fold 2052:  0.34838709677419355\n",
      "recall for fold 2052:  0.36\n",
      "precision for fold 2052:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2053:  0.529126213592233\n",
      "f1  score for fold 2053:  0.39751552795031053\n",
      "recall for fold 2053:  0.3902439024390244\n",
      "precision for fold 2053:  0.4050632911392405\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 2054:  0.44559585492227977\n",
      "f1  score for fold 2054:  0.33540372670807456\n",
      "recall for fold 2054:  0.3103448275862069\n",
      "precision for fold 2054:  0.36486486486486486\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2055:  0.5406698564593302\n",
      "f1  score for fold 2055:  0.3924050632911393\n",
      "recall for fold 2055:  0.3974358974358974\n",
      "precision for fold 2055:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2056:  0.5502392344497608\n",
      "f1  score for fold 2056:  0.3896103896103896\n",
      "recall for fold 2056:  0.40540540540540543\n",
      "precision for fold 2056:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2057:  0.5\n",
      "f1  score for fold 2057:  0.3225806451612903\n",
      "recall for fold 2057:  0.3333333333333333\n",
      "precision for fold 2057:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2058:  0.5388349514563107\n",
      "f1  score for fold 2058:  0.40993788819875776\n",
      "recall for fold 2058:  0.4024390243902439\n",
      "precision for fold 2058:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2059:  0.49740932642487046\n",
      "f1  score for fold 2059:  0.39751552795031053\n",
      "recall for fold 2059:  0.367816091954023\n",
      "precision for fold 2059:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2060:  0.5406698564593302\n",
      "f1  score for fold 2060:  0.3924050632911393\n",
      "recall for fold 2060:  0.3974358974358974\n",
      "precision for fold 2060:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2061:  0.5406698564593302\n",
      "f1  score for fold 2061:  0.37662337662337664\n",
      "recall for fold 2061:  0.3918918918918919\n",
      "precision for fold 2061:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2062:  0.5285714285714286\n",
      "f1  score for fold 2062:  0.3612903225806451\n",
      "recall for fold 2062:  0.37333333333333335\n",
      "precision for fold 2062:  0.35\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2063:  0.470873786407767\n",
      "f1  score for fold 2063:  0.3229813664596273\n",
      "recall for fold 2063:  0.3170731707317073\n",
      "precision for fold 2063:  0.3291139240506329\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2064:  0.5077720207253886\n",
      "f1  score for fold 2064:  0.40993788819875776\n",
      "recall for fold 2064:  0.3793103448275862\n",
      "precision for fold 2064:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2065:  0.5406698564593302\n",
      "f1  score for fold 2065:  0.3924050632911393\n",
      "recall for fold 2065:  0.3974358974358974\n",
      "precision for fold 2065:  0.3875\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 2066:  0.5885167464114832\n",
      "f1  score for fold 2066:  0.44155844155844154\n",
      "recall for fold 2066:  0.4594594594594595\n",
      "precision for fold 2066:  0.425\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2067:  0.49047619047619045\n",
      "f1  score for fold 2067:  0.3096774193548387\n",
      "recall for fold 2067:  0.32\n",
      "precision for fold 2067:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2068:  0.5\n",
      "f1  score for fold 2068:  0.3602484472049689\n",
      "recall for fold 2068:  0.35365853658536583\n",
      "precision for fold 2068:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2069:  0.5284974093264249\n",
      "f1  score for fold 2069:  0.4347826086956522\n",
      "recall for fold 2069:  0.40229885057471265\n",
      "precision for fold 2069:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2070:  0.5502392344497608\n",
      "f1  score for fold 2070:  0.4050632911392405\n",
      "recall for fold 2070:  0.41025641025641024\n",
      "precision for fold 2070:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2071:  0.5502392344497608\n",
      "f1  score for fold 2071:  0.3896103896103896\n",
      "recall for fold 2071:  0.40540540540540543\n",
      "precision for fold 2071:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2072:  0.5095238095238095\n",
      "f1  score for fold 2072:  0.335483870967742\n",
      "recall for fold 2072:  0.3466666666666667\n",
      "precision for fold 2072:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2073:  0.5679611650485437\n",
      "f1  score for fold 2073:  0.4472049689440994\n",
      "recall for fold 2073:  0.43902439024390244\n",
      "precision for fold 2073:  0.45569620253164556\n",
      "    0   1\n",
      "0  43  44\n",
      "1  31  75\n",
      "Accuracy for fold 2074:  0.6113989637305699\n",
      "f1  score for fold 2074:  0.5341614906832297\n",
      "recall for fold 2074:  0.4942528735632184\n",
      "precision for fold 2074:  0.581081081081081\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2075:  0.49282296650717705\n",
      "f1  score for fold 2075:  0.32911392405063294\n",
      "recall for fold 2075:  0.3333333333333333\n",
      "precision for fold 2075:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2076:  0.5215311004784688\n",
      "f1  score for fold 2076:  0.3506493506493507\n",
      "recall for fold 2076:  0.36486486486486486\n",
      "precision for fold 2076:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2077:  0.5380952380952381\n",
      "f1  score for fold 2077:  0.3741935483870968\n",
      "recall for fold 2077:  0.38666666666666666\n",
      "precision for fold 2077:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2078:  0.529126213592233\n",
      "f1  score for fold 2078:  0.39751552795031053\n",
      "recall for fold 2078:  0.3902439024390244\n",
      "precision for fold 2078:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2079:  0.5181347150259067\n",
      "f1  score for fold 2079:  0.422360248447205\n",
      "recall for fold 2079:  0.39080459770114945\n",
      "precision for fold 2079:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2080:  0.49282296650717705\n",
      "f1  score for fold 2080:  0.32911392405063294\n",
      "recall for fold 2080:  0.3333333333333333\n",
      "precision for fold 2080:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2081:  0.5215311004784688\n",
      "f1  score for fold 2081:  0.3506493506493507\n",
      "recall for fold 2081:  0.36486486486486486\n",
      "precision for fold 2081:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2082:  0.5857142857142857\n",
      "f1  score for fold 2082:  0.43870967741935485\n",
      "recall for fold 2082:  0.4533333333333333\n",
      "precision for fold 2082:  0.425\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 2083:  0.587378640776699\n",
      "f1  score for fold 2083:  0.4720496894409938\n",
      "recall for fold 2083:  0.4634146341463415\n",
      "precision for fold 2083:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2084:  0.49740932642487046\n",
      "f1  score for fold 2084:  0.39751552795031053\n",
      "recall for fold 2084:  0.367816091954023\n",
      "precision for fold 2084:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2085:  0.569377990430622\n",
      "f1  score for fold 2085:  0.43037974683544306\n",
      "recall for fold 2085:  0.4358974358974359\n",
      "precision for fold 2085:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2086:  0.5023923444976076\n",
      "f1  score for fold 2086:  0.3246753246753247\n",
      "recall for fold 2086:  0.33783783783783783\n",
      "precision for fold 2086:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2087:  0.5190476190476191\n",
      "f1  score for fold 2087:  0.34838709677419355\n",
      "recall for fold 2087:  0.36\n",
      "precision for fold 2087:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2088:  0.5679611650485437\n",
      "f1  score for fold 2088:  0.4472049689440994\n",
      "recall for fold 2088:  0.43902439024390244\n",
      "precision for fold 2088:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2089:  0.49740932642487046\n",
      "f1  score for fold 2089:  0.39751552795031053\n",
      "recall for fold 2089:  0.367816091954023\n",
      "precision for fold 2089:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2090:  0.5023923444976076\n",
      "f1  score for fold 2090:  0.34177215189873417\n",
      "recall for fold 2090:  0.34615384615384615\n",
      "precision for fold 2090:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2091:  0.5215311004784688\n",
      "f1  score for fold 2091:  0.3506493506493507\n",
      "recall for fold 2091:  0.36486486486486486\n",
      "precision for fold 2091:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2092:  0.5190476190476191\n",
      "f1  score for fold 2092:  0.34838709677419355\n",
      "recall for fold 2092:  0.36\n",
      "precision for fold 2092:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2093:  0.5194174757281553\n",
      "f1  score for fold 2093:  0.38509316770186336\n",
      "recall for fold 2093:  0.3780487804878049\n",
      "precision for fold 2093:  0.3924050632911392\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2094:  0.47668393782383417\n",
      "f1  score for fold 2094:  0.3726708074534162\n",
      "recall for fold 2094:  0.3448275862068966\n",
      "precision for fold 2094:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2095:  0.5215311004784688\n",
      "f1  score for fold 2095:  0.36708860759493667\n",
      "recall for fold 2095:  0.3717948717948718\n",
      "precision for fold 2095:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2096:  0.5215311004784688\n",
      "f1  score for fold 2096:  0.3506493506493507\n",
      "recall for fold 2096:  0.36486486486486486\n",
      "precision for fold 2096:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2097:  0.5380952380952381\n",
      "f1  score for fold 2097:  0.3741935483870968\n",
      "recall for fold 2097:  0.38666666666666666\n",
      "precision for fold 2097:  0.3625\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2098:  0.5776699029126213\n",
      "f1  score for fold 2098:  0.4596273291925466\n",
      "recall for fold 2098:  0.45121951219512196\n",
      "precision for fold 2098:  0.46835443037974683\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2099:  0.5284974093264249\n",
      "f1  score for fold 2099:  0.4347826086956522\n",
      "recall for fold 2099:  0.40229885057471265\n",
      "precision for fold 2099:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2100:  0.5502392344497608\n",
      "f1  score for fold 2100:  0.4050632911392405\n",
      "recall for fold 2100:  0.41025641025641024\n",
      "precision for fold 2100:  0.4\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2101:  0.48325358851674644\n",
      "f1  score for fold 2101:  0.29870129870129863\n",
      "recall for fold 2101:  0.3108108108108108\n",
      "precision for fold 2101:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2102:  0.5571428571428572\n",
      "f1  score for fold 2102:  0.4000000000000001\n",
      "recall for fold 2102:  0.41333333333333333\n",
      "precision for fold 2102:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2103:  0.529126213592233\n",
      "f1  score for fold 2103:  0.39751552795031053\n",
      "recall for fold 2103:  0.3902439024390244\n",
      "precision for fold 2103:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2104:  0.5284974093264249\n",
      "f1  score for fold 2104:  0.4347826086956522\n",
      "recall for fold 2104:  0.40229885057471265\n",
      "precision for fold 2104:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2105:  0.5406698564593302\n",
      "f1  score for fold 2105:  0.3924050632911393\n",
      "recall for fold 2105:  0.3974358974358974\n",
      "precision for fold 2105:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2106:  0.5598086124401914\n",
      "f1  score for fold 2106:  0.40259740259740256\n",
      "recall for fold 2106:  0.4189189189189189\n",
      "precision for fold 2106:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2107:  0.5285714285714286\n",
      "f1  score for fold 2107:  0.3612903225806451\n",
      "recall for fold 2107:  0.37333333333333335\n",
      "precision for fold 2107:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2108:  0.5679611650485437\n",
      "f1  score for fold 2108:  0.4472049689440994\n",
      "recall for fold 2108:  0.43902439024390244\n",
      "precision for fold 2108:  0.45569620253164556\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2109:  0.538860103626943\n",
      "f1  score for fold 2109:  0.4472049689440994\n",
      "recall for fold 2109:  0.41379310344827586\n",
      "precision for fold 2109:  0.4864864864864865\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 2110:  0.47368421052631576\n",
      "f1  score for fold 2110:  0.3037974683544304\n",
      "recall for fold 2110:  0.3076923076923077\n",
      "precision for fold 2110:  0.3\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2111:  0.5119617224880383\n",
      "f1  score for fold 2111:  0.33766233766233766\n",
      "recall for fold 2111:  0.35135135135135137\n",
      "precision for fold 2111:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2112:  0.5285714285714286\n",
      "f1  score for fold 2112:  0.3612903225806451\n",
      "recall for fold 2112:  0.37333333333333335\n",
      "precision for fold 2112:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2113:  0.5485436893203883\n",
      "f1  score for fold 2113:  0.42236024844720493\n",
      "recall for fold 2113:  0.4146341463414634\n",
      "precision for fold 2113:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2114:  0.5284974093264249\n",
      "f1  score for fold 2114:  0.4347826086956522\n",
      "recall for fold 2114:  0.40229885057471265\n",
      "precision for fold 2114:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2115:  0.5119617224880383\n",
      "f1  score for fold 2115:  0.3544303797468355\n",
      "recall for fold 2115:  0.358974358974359\n",
      "precision for fold 2115:  0.35\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 2116:  0.5980861244019139\n",
      "f1  score for fold 2116:  0.45454545454545453\n",
      "recall for fold 2116:  0.47297297297297297\n",
      "precision for fold 2116:  0.4375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2117:  0.5095238095238095\n",
      "f1  score for fold 2117:  0.335483870967742\n",
      "recall for fold 2117:  0.3466666666666667\n",
      "precision for fold 2117:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2118:  0.5097087378640777\n",
      "f1  score for fold 2118:  0.37267080745341613\n",
      "recall for fold 2118:  0.36585365853658536\n",
      "precision for fold 2118:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2119:  0.538860103626943\n",
      "f1  score for fold 2119:  0.4472049689440994\n",
      "recall for fold 2119:  0.41379310344827586\n",
      "precision for fold 2119:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2120:  0.5119617224880383\n",
      "f1  score for fold 2120:  0.3544303797468355\n",
      "recall for fold 2120:  0.358974358974359\n",
      "precision for fold 2120:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2121:  0.5119617224880383\n",
      "f1  score for fold 2121:  0.33766233766233766\n",
      "recall for fold 2121:  0.35135135135135137\n",
      "precision for fold 2121:  0.325\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2122:  0.5095238095238095\n",
      "f1  score for fold 2122:  0.335483870967742\n",
      "recall for fold 2122:  0.3466666666666667\n",
      "precision for fold 2122:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2123:  0.49029126213592233\n",
      "f1  score for fold 2123:  0.3478260869565218\n",
      "recall for fold 2123:  0.34146341463414637\n",
      "precision for fold 2123:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2124:  0.49740932642487046\n",
      "f1  score for fold 2124:  0.39751552795031053\n",
      "recall for fold 2124:  0.367816091954023\n",
      "precision for fold 2124:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2125:  0.5311004784688995\n",
      "f1  score for fold 2125:  0.37974683544303806\n",
      "recall for fold 2125:  0.38461538461538464\n",
      "precision for fold 2125:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2126:  0.5023923444976076\n",
      "f1  score for fold 2126:  0.3246753246753247\n",
      "recall for fold 2126:  0.33783783783783783\n",
      "precision for fold 2126:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2127:  0.5380952380952381\n",
      "f1  score for fold 2127:  0.3741935483870968\n",
      "recall for fold 2127:  0.38666666666666666\n",
      "precision for fold 2127:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2128:  0.529126213592233\n",
      "f1  score for fold 2128:  0.39751552795031053\n",
      "recall for fold 2128:  0.3902439024390244\n",
      "precision for fold 2128:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2129:  0.5284974093264249\n",
      "f1  score for fold 2129:  0.4347826086956522\n",
      "recall for fold 2129:  0.40229885057471265\n",
      "precision for fold 2129:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2130:  0.49282296650717705\n",
      "f1  score for fold 2130:  0.32911392405063294\n",
      "recall for fold 2130:  0.3333333333333333\n",
      "precision for fold 2130:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2131:  0.5502392344497608\n",
      "f1  score for fold 2131:  0.3896103896103896\n",
      "recall for fold 2131:  0.40540540540540543\n",
      "precision for fold 2131:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2132:  0.5380952380952381\n",
      "f1  score for fold 2132:  0.3741935483870968\n",
      "recall for fold 2132:  0.38666666666666666\n",
      "precision for fold 2132:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2133:  0.5\n",
      "f1  score for fold 2133:  0.3602484472049689\n",
      "recall for fold 2133:  0.35365853658536583\n",
      "precision for fold 2133:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2134:  0.49740932642487046\n",
      "f1  score for fold 2134:  0.39751552795031053\n",
      "recall for fold 2134:  0.367816091954023\n",
      "precision for fold 2134:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2135:  0.5311004784688995\n",
      "f1  score for fold 2135:  0.37974683544303806\n",
      "recall for fold 2135:  0.38461538461538464\n",
      "precision for fold 2135:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2136:  0.5406698564593302\n",
      "f1  score for fold 2136:  0.37662337662337664\n",
      "recall for fold 2136:  0.3918918918918919\n",
      "precision for fold 2136:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2137:  0.5380952380952381\n",
      "f1  score for fold 2137:  0.3741935483870968\n",
      "recall for fold 2137:  0.38666666666666666\n",
      "precision for fold 2137:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2138:  0.5\n",
      "f1  score for fold 2138:  0.3602484472049689\n",
      "recall for fold 2138:  0.35365853658536583\n",
      "precision for fold 2138:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2139:  0.48704663212435234\n",
      "f1  score for fold 2139:  0.3850931677018633\n",
      "recall for fold 2139:  0.3563218390804598\n",
      "precision for fold 2139:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2140:  0.48325358851674644\n",
      "f1  score for fold 2140:  0.31645569620253167\n",
      "recall for fold 2140:  0.32051282051282054\n",
      "precision for fold 2140:  0.3125\n",
      "    0   1\n",
      "0  20  54\n",
      "1  60  75\n",
      "Accuracy for fold 2141:  0.45454545454545453\n",
      "f1  score for fold 2141:  0.25974025974025977\n",
      "recall for fold 2141:  0.2702702702702703\n",
      "precision for fold 2141:  0.25\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2142:  0.5666666666666667\n",
      "f1  score for fold 2142:  0.41290322580645167\n",
      "recall for fold 2142:  0.4266666666666667\n",
      "precision for fold 2142:  0.4\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2143:  0.49029126213592233\n",
      "f1  score for fold 2143:  0.3478260869565218\n",
      "recall for fold 2143:  0.34146341463414637\n",
      "precision for fold 2143:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2144:  0.5181347150259067\n",
      "f1  score for fold 2144:  0.422360248447205\n",
      "recall for fold 2144:  0.39080459770114945\n",
      "precision for fold 2144:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2145:  0.569377990430622\n",
      "f1  score for fold 2145:  0.43037974683544306\n",
      "recall for fold 2145:  0.4358974358974359\n",
      "precision for fold 2145:  0.425\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2146:  0.569377990430622\n",
      "f1  score for fold 2146:  0.4155844155844156\n",
      "recall for fold 2146:  0.43243243243243246\n",
      "precision for fold 2146:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2147:  0.5285714285714286\n",
      "f1  score for fold 2147:  0.3612903225806451\n",
      "recall for fold 2147:  0.37333333333333335\n",
      "precision for fold 2147:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2148:  0.5\n",
      "f1  score for fold 2148:  0.3602484472049689\n",
      "recall for fold 2148:  0.35365853658536583\n",
      "precision for fold 2148:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2149:  0.5284974093264249\n",
      "f1  score for fold 2149:  0.4347826086956522\n",
      "recall for fold 2149:  0.40229885057471265\n",
      "precision for fold 2149:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2150:  0.5406698564593302\n",
      "f1  score for fold 2150:  0.3924050632911393\n",
      "recall for fold 2150:  0.3974358974358974\n",
      "precision for fold 2150:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2151:  0.5598086124401914\n",
      "f1  score for fold 2151:  0.40259740259740256\n",
      "recall for fold 2151:  0.4189189189189189\n",
      "precision for fold 2151:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2152:  0.5380952380952381\n",
      "f1  score for fold 2152:  0.3741935483870968\n",
      "recall for fold 2152:  0.38666666666666666\n",
      "precision for fold 2152:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2153:  0.5194174757281553\n",
      "f1  score for fold 2153:  0.38509316770186336\n",
      "recall for fold 2153:  0.3780487804878049\n",
      "precision for fold 2153:  0.3924050632911392\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2154:  0.5699481865284974\n",
      "f1  score for fold 2154:  0.48447204968944096\n",
      "recall for fold 2154:  0.4482758620689655\n",
      "precision for fold 2154:  0.527027027027027\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2155:  0.5023923444976076\n",
      "f1  score for fold 2155:  0.34177215189873417\n",
      "recall for fold 2155:  0.34615384615384615\n",
      "precision for fold 2155:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2156:  0.5406698564593302\n",
      "f1  score for fold 2156:  0.37662337662337664\n",
      "recall for fold 2156:  0.3918918918918919\n",
      "precision for fold 2156:  0.3625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2157:  0.5571428571428572\n",
      "f1  score for fold 2157:  0.4000000000000001\n",
      "recall for fold 2157:  0.41333333333333333\n",
      "precision for fold 2157:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2158:  0.5\n",
      "f1  score for fold 2158:  0.3602484472049689\n",
      "recall for fold 2158:  0.35365853658536583\n",
      "precision for fold 2158:  0.3670886075949367\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2159:  0.5699481865284974\n",
      "f1  score for fold 2159:  0.48447204968944096\n",
      "recall for fold 2159:  0.4482758620689655\n",
      "precision for fold 2159:  0.527027027027027\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2160:  0.5119617224880383\n",
      "f1  score for fold 2160:  0.3544303797468355\n",
      "recall for fold 2160:  0.358974358974359\n",
      "precision for fold 2160:  0.35\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 2161:  0.6172248803827751\n",
      "f1  score for fold 2161:  0.4805194805194805\n",
      "recall for fold 2161:  0.5\n",
      "precision for fold 2161:  0.4625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2162:  0.5095238095238095\n",
      "f1  score for fold 2162:  0.335483870967742\n",
      "recall for fold 2162:  0.3466666666666667\n",
      "precision for fold 2162:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2163:  0.5388349514563107\n",
      "f1  score for fold 2163:  0.40993788819875776\n",
      "recall for fold 2163:  0.4024390243902439\n",
      "precision for fold 2163:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2164:  0.49740932642487046\n",
      "f1  score for fold 2164:  0.39751552795031053\n",
      "recall for fold 2164:  0.367816091954023\n",
      "precision for fold 2164:  0.43243243243243246\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 2165:  0.46411483253588515\n",
      "f1  score for fold 2165:  0.2911392405063291\n",
      "recall for fold 2165:  0.2948717948717949\n",
      "precision for fold 2165:  0.2875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2166:  0.5311004784688995\n",
      "f1  score for fold 2166:  0.36363636363636365\n",
      "recall for fold 2166:  0.3783783783783784\n",
      "precision for fold 2166:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2167:  0.49047619047619045\n",
      "f1  score for fold 2167:  0.3096774193548387\n",
      "recall for fold 2167:  0.32\n",
      "precision for fold 2167:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2168:  0.5097087378640777\n",
      "f1  score for fold 2168:  0.37267080745341613\n",
      "recall for fold 2168:  0.36585365853658536\n",
      "precision for fold 2168:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2169:  0.5077720207253886\n",
      "f1  score for fold 2169:  0.40993788819875776\n",
      "recall for fold 2169:  0.3793103448275862\n",
      "precision for fold 2169:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2170:  0.5789473684210527\n",
      "f1  score for fold 2170:  0.44303797468354433\n",
      "recall for fold 2170:  0.44871794871794873\n",
      "precision for fold 2170:  0.4375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2171:  0.5502392344497608\n",
      "f1  score for fold 2171:  0.3896103896103896\n",
      "recall for fold 2171:  0.40540540540540543\n",
      "precision for fold 2171:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2172:  0.5666666666666667\n",
      "f1  score for fold 2172:  0.41290322580645167\n",
      "recall for fold 2172:  0.4266666666666667\n",
      "precision for fold 2172:  0.4\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2173:  0.5388349514563107\n",
      "f1  score for fold 2173:  0.40993788819875776\n",
      "recall for fold 2173:  0.4024390243902439\n",
      "precision for fold 2173:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2174:  0.5284974093264249\n",
      "f1  score for fold 2174:  0.4347826086956522\n",
      "recall for fold 2174:  0.40229885057471265\n",
      "precision for fold 2174:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2175:  0.5406698564593302\n",
      "f1  score for fold 2175:  0.3924050632911393\n",
      "recall for fold 2175:  0.3974358974358974\n",
      "precision for fold 2175:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2176:  0.5502392344497608\n",
      "f1  score for fold 2176:  0.3896103896103896\n",
      "recall for fold 2176:  0.40540540540540543\n",
      "precision for fold 2176:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2177:  0.5666666666666667\n",
      "f1  score for fold 2177:  0.41290322580645167\n",
      "recall for fold 2177:  0.4266666666666667\n",
      "precision for fold 2177:  0.4\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2178:  0.49029126213592233\n",
      "f1  score for fold 2178:  0.3478260869565218\n",
      "recall for fold 2178:  0.34146341463414637\n",
      "precision for fold 2178:  0.35443037974683544\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2179:  0.47668393782383417\n",
      "f1  score for fold 2179:  0.3726708074534162\n",
      "recall for fold 2179:  0.3448275862068966\n",
      "precision for fold 2179:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2180:  0.5311004784688995\n",
      "f1  score for fold 2180:  0.37974683544303806\n",
      "recall for fold 2180:  0.38461538461538464\n",
      "precision for fold 2180:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2181:  0.5023923444976076\n",
      "f1  score for fold 2181:  0.3246753246753247\n",
      "recall for fold 2181:  0.33783783783783783\n",
      "precision for fold 2181:  0.3125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2182:  0.49047619047619045\n",
      "f1  score for fold 2182:  0.3096774193548387\n",
      "recall for fold 2182:  0.32\n",
      "precision for fold 2182:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2183:  0.558252427184466\n",
      "f1  score for fold 2183:  0.43478260869565216\n",
      "recall for fold 2183:  0.4268292682926829\n",
      "precision for fold 2183:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2184:  0.46632124352331605\n",
      "f1  score for fold 2184:  0.36024844720496896\n",
      "recall for fold 2184:  0.3333333333333333\n",
      "precision for fold 2184:  0.3918918918918919\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2185:  0.5119617224880383\n",
      "f1  score for fold 2185:  0.3544303797468355\n",
      "recall for fold 2185:  0.358974358974359\n",
      "precision for fold 2185:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2186:  0.5023923444976076\n",
      "f1  score for fold 2186:  0.3246753246753247\n",
      "recall for fold 2186:  0.33783783783783783\n",
      "precision for fold 2186:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2187:  0.5190476190476191\n",
      "f1  score for fold 2187:  0.34838709677419355\n",
      "recall for fold 2187:  0.36\n",
      "precision for fold 2187:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2188:  0.5485436893203883\n",
      "f1  score for fold 2188:  0.42236024844720493\n",
      "recall for fold 2188:  0.4146341463414634\n",
      "precision for fold 2188:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2189:  0.538860103626943\n",
      "f1  score for fold 2189:  0.4472049689440994\n",
      "recall for fold 2189:  0.41379310344827586\n",
      "precision for fold 2189:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2190:  0.5215311004784688\n",
      "f1  score for fold 2190:  0.36708860759493667\n",
      "recall for fold 2190:  0.3717948717948718\n",
      "precision for fold 2190:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2191:  0.49282296650717705\n",
      "f1  score for fold 2191:  0.3116883116883117\n",
      "recall for fold 2191:  0.32432432432432434\n",
      "precision for fold 2191:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2192:  0.5\n",
      "f1  score for fold 2192:  0.3225806451612903\n",
      "recall for fold 2192:  0.3333333333333333\n",
      "precision for fold 2192:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2193:  0.5388349514563107\n",
      "f1  score for fold 2193:  0.40993788819875776\n",
      "recall for fold 2193:  0.4024390243902439\n",
      "precision for fold 2193:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2194:  0.538860103626943\n",
      "f1  score for fold 2194:  0.4472049689440994\n",
      "recall for fold 2194:  0.41379310344827586\n",
      "precision for fold 2194:  0.4864864864864865\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 2195:  0.5885167464114832\n",
      "f1  score for fold 2195:  0.45569620253164556\n",
      "recall for fold 2195:  0.46153846153846156\n",
      "precision for fold 2195:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2196:  0.5406698564593302\n",
      "f1  score for fold 2196:  0.37662337662337664\n",
      "recall for fold 2196:  0.3918918918918919\n",
      "precision for fold 2196:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2197:  0.49047619047619045\n",
      "f1  score for fold 2197:  0.3096774193548387\n",
      "recall for fold 2197:  0.32\n",
      "precision for fold 2197:  0.3\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2198:  0.49029126213592233\n",
      "f1  score for fold 2198:  0.3478260869565218\n",
      "recall for fold 2198:  0.34146341463414637\n",
      "precision for fold 2198:  0.35443037974683544\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2199:  0.5284974093264249\n",
      "f1  score for fold 2199:  0.4347826086956522\n",
      "recall for fold 2199:  0.40229885057471265\n",
      "precision for fold 2199:  0.47297297297297297\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 2200:  0.47368421052631576\n",
      "f1  score for fold 2200:  0.3037974683544304\n",
      "recall for fold 2200:  0.3076923076923077\n",
      "precision for fold 2200:  0.3\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2201:  0.5119617224880383\n",
      "f1  score for fold 2201:  0.33766233766233766\n",
      "recall for fold 2201:  0.35135135135135137\n",
      "precision for fold 2201:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2202:  0.5380952380952381\n",
      "f1  score for fold 2202:  0.3741935483870968\n",
      "recall for fold 2202:  0.38666666666666666\n",
      "precision for fold 2202:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2203:  0.5485436893203883\n",
      "f1  score for fold 2203:  0.42236024844720493\n",
      "recall for fold 2203:  0.4146341463414634\n",
      "precision for fold 2203:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2204:  0.538860103626943\n",
      "f1  score for fold 2204:  0.4472049689440994\n",
      "recall for fold 2204:  0.41379310344827586\n",
      "precision for fold 2204:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2205:  0.5406698564593302\n",
      "f1  score for fold 2205:  0.3924050632911393\n",
      "recall for fold 2205:  0.3974358974358974\n",
      "precision for fold 2205:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2206:  0.5119617224880383\n",
      "f1  score for fold 2206:  0.33766233766233766\n",
      "recall for fold 2206:  0.35135135135135137\n",
      "precision for fold 2206:  0.325\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2207:  0.5761904761904761\n",
      "f1  score for fold 2207:  0.4258064516129032\n",
      "recall for fold 2207:  0.44\n",
      "precision for fold 2207:  0.4125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2208:  0.5\n",
      "f1  score for fold 2208:  0.3602484472049689\n",
      "recall for fold 2208:  0.35365853658536583\n",
      "precision for fold 2208:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2209:  0.5181347150259067\n",
      "f1  score for fold 2209:  0.422360248447205\n",
      "recall for fold 2209:  0.39080459770114945\n",
      "precision for fold 2209:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2210:  0.5023923444976076\n",
      "f1  score for fold 2210:  0.34177215189873417\n",
      "recall for fold 2210:  0.34615384615384615\n",
      "precision for fold 2210:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2211:  0.5215311004784688\n",
      "f1  score for fold 2211:  0.3506493506493507\n",
      "recall for fold 2211:  0.36486486486486486\n",
      "precision for fold 2211:  0.3375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2212:  0.5761904761904761\n",
      "f1  score for fold 2212:  0.4258064516129032\n",
      "recall for fold 2212:  0.44\n",
      "precision for fold 2212:  0.4125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 2213:  0.48058252427184467\n",
      "f1  score for fold 2213:  0.33540372670807456\n",
      "recall for fold 2213:  0.32926829268292684\n",
      "precision for fold 2213:  0.34177215189873417\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2214:  0.5077720207253886\n",
      "f1  score for fold 2214:  0.40993788819875776\n",
      "recall for fold 2214:  0.3793103448275862\n",
      "precision for fold 2214:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2215:  0.5789473684210527\n",
      "f1  score for fold 2215:  0.44303797468354433\n",
      "recall for fold 2215:  0.44871794871794873\n",
      "precision for fold 2215:  0.4375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 2216:  0.5885167464114832\n",
      "f1  score for fold 2216:  0.44155844155844154\n",
      "recall for fold 2216:  0.4594594594594595\n",
      "precision for fold 2216:  0.425\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2217:  0.5571428571428572\n",
      "f1  score for fold 2217:  0.4000000000000001\n",
      "recall for fold 2217:  0.41333333333333333\n",
      "precision for fold 2217:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2218:  0.529126213592233\n",
      "f1  score for fold 2218:  0.39751552795031053\n",
      "recall for fold 2218:  0.3902439024390244\n",
      "precision for fold 2218:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2219:  0.48704663212435234\n",
      "f1  score for fold 2219:  0.3850931677018633\n",
      "recall for fold 2219:  0.3563218390804598\n",
      "precision for fold 2219:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2220:  0.5598086124401914\n",
      "f1  score for fold 2220:  0.4177215189873418\n",
      "recall for fold 2220:  0.4230769230769231\n",
      "precision for fold 2220:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2221:  0.5406698564593302\n",
      "f1  score for fold 2221:  0.37662337662337664\n",
      "recall for fold 2221:  0.3918918918918919\n",
      "precision for fold 2221:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2222:  0.5190476190476191\n",
      "f1  score for fold 2222:  0.34838709677419355\n",
      "recall for fold 2222:  0.36\n",
      "precision for fold 2222:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2223:  0.49029126213592233\n",
      "f1  score for fold 2223:  0.3478260869565218\n",
      "recall for fold 2223:  0.34146341463414637\n",
      "precision for fold 2223:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2224:  0.48704663212435234\n",
      "f1  score for fold 2224:  0.3850931677018633\n",
      "recall for fold 2224:  0.3563218390804598\n",
      "precision for fold 2224:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2225:  0.48325358851674644\n",
      "f1  score for fold 2225:  0.31645569620253167\n",
      "recall for fold 2225:  0.32051282051282054\n",
      "precision for fold 2225:  0.3125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2226:  0.5119617224880383\n",
      "f1  score for fold 2226:  0.33766233766233766\n",
      "recall for fold 2226:  0.35135135135135137\n",
      "precision for fold 2226:  0.325\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 2227:  0.5952380952380952\n",
      "f1  score for fold 2227:  0.45161290322580644\n",
      "recall for fold 2227:  0.4666666666666667\n",
      "precision for fold 2227:  0.4375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2228:  0.5097087378640777\n",
      "f1  score for fold 2228:  0.37267080745341613\n",
      "recall for fold 2228:  0.36585365853658536\n",
      "precision for fold 2228:  0.379746835443038\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 2229:  0.43523316062176165\n",
      "f1  score for fold 2229:  0.3229813664596274\n",
      "recall for fold 2229:  0.2988505747126437\n",
      "precision for fold 2229:  0.35135135135135137\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2230:  0.569377990430622\n",
      "f1  score for fold 2230:  0.43037974683544306\n",
      "recall for fold 2230:  0.4358974358974359\n",
      "precision for fold 2230:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2231:  0.5502392344497608\n",
      "f1  score for fold 2231:  0.3896103896103896\n",
      "recall for fold 2231:  0.40540540540540543\n",
      "precision for fold 2231:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2232:  0.5761904761904761\n",
      "f1  score for fold 2232:  0.4258064516129032\n",
      "recall for fold 2232:  0.44\n",
      "precision for fold 2232:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2233:  0.5097087378640777\n",
      "f1  score for fold 2233:  0.37267080745341613\n",
      "recall for fold 2233:  0.36585365853658536\n",
      "precision for fold 2233:  0.379746835443038\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2234:  0.5699481865284974\n",
      "f1  score for fold 2234:  0.48447204968944096\n",
      "recall for fold 2234:  0.4482758620689655\n",
      "precision for fold 2234:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2235:  0.5502392344497608\n",
      "f1  score for fold 2235:  0.4050632911392405\n",
      "recall for fold 2235:  0.41025641025641024\n",
      "precision for fold 2235:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2236:  0.569377990430622\n",
      "f1  score for fold 2236:  0.4155844155844156\n",
      "recall for fold 2236:  0.43243243243243246\n",
      "precision for fold 2236:  0.4\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 2237:  0.5952380952380952\n",
      "f1  score for fold 2237:  0.45161290322580644\n",
      "recall for fold 2237:  0.4666666666666667\n",
      "precision for fold 2237:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2238:  0.5485436893203883\n",
      "f1  score for fold 2238:  0.42236024844720493\n",
      "recall for fold 2238:  0.4146341463414634\n",
      "precision for fold 2238:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2239:  0.5492227979274611\n",
      "f1  score for fold 2239:  0.45962732919254656\n",
      "recall for fold 2239:  0.42528735632183906\n",
      "precision for fold 2239:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2240:  0.5215311004784688\n",
      "f1  score for fold 2240:  0.36708860759493667\n",
      "recall for fold 2240:  0.3717948717948718\n",
      "precision for fold 2240:  0.3625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2241:  0.5119617224880383\n",
      "f1  score for fold 2241:  0.33766233766233766\n",
      "recall for fold 2241:  0.35135135135135137\n",
      "precision for fold 2241:  0.325\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2242:  0.5\n",
      "f1  score for fold 2242:  0.3225806451612903\n",
      "recall for fold 2242:  0.3333333333333333\n",
      "precision for fold 2242:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2243:  0.5485436893203883\n",
      "f1  score for fold 2243:  0.42236024844720493\n",
      "recall for fold 2243:  0.4146341463414634\n",
      "precision for fold 2243:  0.43037974683544306\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2244:  0.5699481865284974\n",
      "f1  score for fold 2244:  0.48447204968944096\n",
      "recall for fold 2244:  0.4482758620689655\n",
      "precision for fold 2244:  0.527027027027027\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2245:  0.5215311004784688\n",
      "f1  score for fold 2245:  0.36708860759493667\n",
      "recall for fold 2245:  0.3717948717948718\n",
      "precision for fold 2245:  0.3625\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2246:  0.48325358851674644\n",
      "f1  score for fold 2246:  0.29870129870129863\n",
      "recall for fold 2246:  0.3108108108108108\n",
      "precision for fold 2246:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2247:  0.5285714285714286\n",
      "f1  score for fold 2247:  0.3612903225806451\n",
      "recall for fold 2247:  0.37333333333333335\n",
      "precision for fold 2247:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2248:  0.5097087378640777\n",
      "f1  score for fold 2248:  0.37267080745341613\n",
      "recall for fold 2248:  0.36585365853658536\n",
      "precision for fold 2248:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2249:  0.5181347150259067\n",
      "f1  score for fold 2249:  0.422360248447205\n",
      "recall for fold 2249:  0.39080459770114945\n",
      "precision for fold 2249:  0.4594594594594595\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2250:  0.5789473684210527\n",
      "f1  score for fold 2250:  0.44303797468354433\n",
      "recall for fold 2250:  0.44871794871794873\n",
      "precision for fold 2250:  0.4375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2251:  0.5598086124401914\n",
      "f1  score for fold 2251:  0.40259740259740256\n",
      "recall for fold 2251:  0.4189189189189189\n",
      "precision for fold 2251:  0.3875\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2252:  0.48095238095238096\n",
      "f1  score for fold 2252:  0.2967741935483871\n",
      "recall for fold 2252:  0.30666666666666664\n",
      "precision for fold 2252:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2253:  0.5388349514563107\n",
      "f1  score for fold 2253:  0.40993788819875776\n",
      "recall for fold 2253:  0.4024390243902439\n",
      "precision for fold 2253:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2254:  0.5595854922279793\n",
      "f1  score for fold 2254:  0.4720496894409938\n",
      "recall for fold 2254:  0.4367816091954023\n",
      "precision for fold 2254:  0.5135135135135135\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2255:  0.5215311004784688\n",
      "f1  score for fold 2255:  0.36708860759493667\n",
      "recall for fold 2255:  0.3717948717948718\n",
      "precision for fold 2255:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 2256:  0.47368421052631576\n",
      "f1  score for fold 2256:  0.28571428571428575\n",
      "recall for fold 2256:  0.2972972972972973\n",
      "precision for fold 2256:  0.275\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2257:  0.5285714285714286\n",
      "f1  score for fold 2257:  0.3612903225806451\n",
      "recall for fold 2257:  0.37333333333333335\n",
      "precision for fold 2257:  0.35\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 2258:  0.441747572815534\n",
      "f1  score for fold 2258:  0.28571428571428575\n",
      "recall for fold 2258:  0.2804878048780488\n",
      "precision for fold 2258:  0.2911392405063291\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 2259:  0.44559585492227977\n",
      "f1  score for fold 2259:  0.33540372670807456\n",
      "recall for fold 2259:  0.3103448275862069\n",
      "precision for fold 2259:  0.36486486486486486\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2260:  0.5311004784688995\n",
      "f1  score for fold 2260:  0.37974683544303806\n",
      "recall for fold 2260:  0.38461538461538464\n",
      "precision for fold 2260:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2261:  0.5215311004784688\n",
      "f1  score for fold 2261:  0.3506493506493507\n",
      "recall for fold 2261:  0.36486486486486486\n",
      "precision for fold 2261:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2262:  0.5095238095238095\n",
      "f1  score for fold 2262:  0.335483870967742\n",
      "recall for fold 2262:  0.3466666666666667\n",
      "precision for fold 2262:  0.325\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2263:  0.5776699029126213\n",
      "f1  score for fold 2263:  0.4596273291925466\n",
      "recall for fold 2263:  0.45121951219512196\n",
      "precision for fold 2263:  0.46835443037974683\n",
      "    0   1\n",
      "0  44  43\n",
      "1  30  76\n",
      "Accuracy for fold 2264:  0.6217616580310881\n",
      "f1  score for fold 2264:  0.5465838509316772\n",
      "recall for fold 2264:  0.5057471264367817\n",
      "precision for fold 2264:  0.5945945945945946\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2265:  0.5311004784688995\n",
      "f1  score for fold 2265:  0.37974683544303806\n",
      "recall for fold 2265:  0.38461538461538464\n",
      "precision for fold 2265:  0.375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2266:  0.5789473684210527\n",
      "f1  score for fold 2266:  0.42857142857142855\n",
      "recall for fold 2266:  0.44594594594594594\n",
      "precision for fold 2266:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2267:  0.5285714285714286\n",
      "f1  score for fold 2267:  0.3612903225806451\n",
      "recall for fold 2267:  0.37333333333333335\n",
      "precision for fold 2267:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2268:  0.5679611650485437\n",
      "f1  score for fold 2268:  0.4472049689440994\n",
      "recall for fold 2268:  0.43902439024390244\n",
      "precision for fold 2268:  0.45569620253164556\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2269:  0.47668393782383417\n",
      "f1  score for fold 2269:  0.3726708074534162\n",
      "recall for fold 2269:  0.3448275862068966\n",
      "precision for fold 2269:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2270:  0.5215311004784688\n",
      "f1  score for fold 2270:  0.36708860759493667\n",
      "recall for fold 2270:  0.3717948717948718\n",
      "precision for fold 2270:  0.3625\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 2271:  0.6076555023923444\n",
      "f1  score for fold 2271:  0.4675324675324675\n",
      "recall for fold 2271:  0.4864864864864865\n",
      "precision for fold 2271:  0.45\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2272:  0.48095238095238096\n",
      "f1  score for fold 2272:  0.2967741935483871\n",
      "recall for fold 2272:  0.30666666666666664\n",
      "precision for fold 2272:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2273:  0.5388349514563107\n",
      "f1  score for fold 2273:  0.40993788819875776\n",
      "recall for fold 2273:  0.4024390243902439\n",
      "precision for fold 2273:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2274:  0.5595854922279793\n",
      "f1  score for fold 2274:  0.4720496894409938\n",
      "recall for fold 2274:  0.4367816091954023\n",
      "precision for fold 2274:  0.5135135135135135\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2275:  0.569377990430622\n",
      "f1  score for fold 2275:  0.43037974683544306\n",
      "recall for fold 2275:  0.4358974358974359\n",
      "precision for fold 2275:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2276:  0.5215311004784688\n",
      "f1  score for fold 2276:  0.3506493506493507\n",
      "recall for fold 2276:  0.36486486486486486\n",
      "precision for fold 2276:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2277:  0.5380952380952381\n",
      "f1  score for fold 2277:  0.3741935483870968\n",
      "recall for fold 2277:  0.38666666666666666\n",
      "precision for fold 2277:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2278:  0.558252427184466\n",
      "f1  score for fold 2278:  0.43478260869565216\n",
      "recall for fold 2278:  0.4268292682926829\n",
      "precision for fold 2278:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2279:  0.5077720207253886\n",
      "f1  score for fold 2279:  0.40993788819875776\n",
      "recall for fold 2279:  0.3793103448275862\n",
      "precision for fold 2279:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2280:  0.5502392344497608\n",
      "f1  score for fold 2280:  0.4050632911392405\n",
      "recall for fold 2280:  0.41025641025641024\n",
      "precision for fold 2280:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2281:  0.5598086124401914\n",
      "f1  score for fold 2281:  0.40259740259740256\n",
      "recall for fold 2281:  0.4189189189189189\n",
      "precision for fold 2281:  0.3875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2282:  0.5095238095238095\n",
      "f1  score for fold 2282:  0.335483870967742\n",
      "recall for fold 2282:  0.3466666666666667\n",
      "precision for fold 2282:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2283:  0.5097087378640777\n",
      "f1  score for fold 2283:  0.37267080745341613\n",
      "recall for fold 2283:  0.36585365853658536\n",
      "precision for fold 2283:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2284:  0.538860103626943\n",
      "f1  score for fold 2284:  0.4472049689440994\n",
      "recall for fold 2284:  0.41379310344827586\n",
      "precision for fold 2284:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2285:  0.5215311004784688\n",
      "f1  score for fold 2285:  0.36708860759493667\n",
      "recall for fold 2285:  0.3717948717948718\n",
      "precision for fold 2285:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2286:  0.5598086124401914\n",
      "f1  score for fold 2286:  0.40259740259740256\n",
      "recall for fold 2286:  0.4189189189189189\n",
      "precision for fold 2286:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2287:  0.5285714285714286\n",
      "f1  score for fold 2287:  0.3612903225806451\n",
      "recall for fold 2287:  0.37333333333333335\n",
      "precision for fold 2287:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2288:  0.5194174757281553\n",
      "f1  score for fold 2288:  0.38509316770186336\n",
      "recall for fold 2288:  0.3780487804878049\n",
      "precision for fold 2288:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2289:  0.5595854922279793\n",
      "f1  score for fold 2289:  0.4720496894409938\n",
      "recall for fold 2289:  0.4367816091954023\n",
      "precision for fold 2289:  0.5135135135135135\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2290:  0.48325358851674644\n",
      "f1  score for fold 2290:  0.31645569620253167\n",
      "recall for fold 2290:  0.32051282051282054\n",
      "precision for fold 2290:  0.3125\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2291:  0.49282296650717705\n",
      "f1  score for fold 2291:  0.3116883116883117\n",
      "recall for fold 2291:  0.32432432432432434\n",
      "precision for fold 2291:  0.3\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2292:  0.5571428571428572\n",
      "f1  score for fold 2292:  0.4000000000000001\n",
      "recall for fold 2292:  0.41333333333333333\n",
      "precision for fold 2292:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2293:  0.5388349514563107\n",
      "f1  score for fold 2293:  0.40993788819875776\n",
      "recall for fold 2293:  0.4024390243902439\n",
      "precision for fold 2293:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2294:  0.49740932642487046\n",
      "f1  score for fold 2294:  0.39751552795031053\n",
      "recall for fold 2294:  0.367816091954023\n",
      "precision for fold 2294:  0.43243243243243246\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2295:  0.48325358851674644\n",
      "f1  score for fold 2295:  0.31645569620253167\n",
      "recall for fold 2295:  0.32051282051282054\n",
      "precision for fold 2295:  0.3125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2296:  0.5406698564593302\n",
      "f1  score for fold 2296:  0.37662337662337664\n",
      "recall for fold 2296:  0.3918918918918919\n",
      "precision for fold 2296:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2297:  0.5095238095238095\n",
      "f1  score for fold 2297:  0.335483870967742\n",
      "recall for fold 2297:  0.3466666666666667\n",
      "precision for fold 2297:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2298:  0.5097087378640777\n",
      "f1  score for fold 2298:  0.37267080745341613\n",
      "recall for fold 2298:  0.36585365853658536\n",
      "precision for fold 2298:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2299:  0.48704663212435234\n",
      "f1  score for fold 2299:  0.3850931677018633\n",
      "recall for fold 2299:  0.3563218390804598\n",
      "precision for fold 2299:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2300:  0.48325358851674644\n",
      "f1  score for fold 2300:  0.31645569620253167\n",
      "recall for fold 2300:  0.32051282051282054\n",
      "precision for fold 2300:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2301:  0.5598086124401914\n",
      "f1  score for fold 2301:  0.40259740259740256\n",
      "recall for fold 2301:  0.4189189189189189\n",
      "precision for fold 2301:  0.3875\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 2302:  0.5952380952380952\n",
      "f1  score for fold 2302:  0.45161290322580644\n",
      "recall for fold 2302:  0.4666666666666667\n",
      "precision for fold 2302:  0.4375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2303:  0.5\n",
      "f1  score for fold 2303:  0.3602484472049689\n",
      "recall for fold 2303:  0.35365853658536583\n",
      "precision for fold 2303:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2304:  0.49740932642487046\n",
      "f1  score for fold 2304:  0.39751552795031053\n",
      "recall for fold 2304:  0.367816091954023\n",
      "precision for fold 2304:  0.43243243243243246\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2305:  0.5789473684210527\n",
      "f1  score for fold 2305:  0.44303797468354433\n",
      "recall for fold 2305:  0.44871794871794873\n",
      "precision for fold 2305:  0.4375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2306:  0.48325358851674644\n",
      "f1  score for fold 2306:  0.29870129870129863\n",
      "recall for fold 2306:  0.3108108108108108\n",
      "precision for fold 2306:  0.2875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2307:  0.5190476190476191\n",
      "f1  score for fold 2307:  0.34838709677419355\n",
      "recall for fold 2307:  0.36\n",
      "precision for fold 2307:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2308:  0.5485436893203883\n",
      "f1  score for fold 2308:  0.42236024844720493\n",
      "recall for fold 2308:  0.4146341463414634\n",
      "precision for fold 2308:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2309:  0.47668393782383417\n",
      "f1  score for fold 2309:  0.3726708074534162\n",
      "recall for fold 2309:  0.3448275862068966\n",
      "precision for fold 2309:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2310:  0.5023923444976076\n",
      "f1  score for fold 2310:  0.34177215189873417\n",
      "recall for fold 2310:  0.34615384615384615\n",
      "precision for fold 2310:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2311:  0.5598086124401914\n",
      "f1  score for fold 2311:  0.40259740259740256\n",
      "recall for fold 2311:  0.4189189189189189\n",
      "precision for fold 2311:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2312:  0.5380952380952381\n",
      "f1  score for fold 2312:  0.3741935483870968\n",
      "recall for fold 2312:  0.38666666666666666\n",
      "precision for fold 2312:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2313:  0.470873786407767\n",
      "f1  score for fold 2313:  0.3229813664596273\n",
      "recall for fold 2313:  0.3170731707317073\n",
      "precision for fold 2313:  0.3291139240506329\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2314:  0.49740932642487046\n",
      "f1  score for fold 2314:  0.39751552795031053\n",
      "recall for fold 2314:  0.367816091954023\n",
      "precision for fold 2314:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2315:  0.5502392344497608\n",
      "f1  score for fold 2315:  0.4050632911392405\n",
      "recall for fold 2315:  0.41025641025641024\n",
      "precision for fold 2315:  0.4\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 2316:  0.46411483253588515\n",
      "f1  score for fold 2316:  0.27272727272727276\n",
      "recall for fold 2316:  0.28378378378378377\n",
      "precision for fold 2316:  0.2625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2317:  0.5571428571428572\n",
      "f1  score for fold 2317:  0.4000000000000001\n",
      "recall for fold 2317:  0.41333333333333333\n",
      "precision for fold 2317:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2318:  0.5097087378640777\n",
      "f1  score for fold 2318:  0.37267080745341613\n",
      "recall for fold 2318:  0.36585365853658536\n",
      "precision for fold 2318:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2319:  0.5077720207253886\n",
      "f1  score for fold 2319:  0.40993788819875776\n",
      "recall for fold 2319:  0.3793103448275862\n",
      "precision for fold 2319:  0.44594594594594594\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 2320:  0.5885167464114832\n",
      "f1  score for fold 2320:  0.45569620253164556\n",
      "recall for fold 2320:  0.46153846153846156\n",
      "precision for fold 2320:  0.45\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2321:  0.5502392344497608\n",
      "f1  score for fold 2321:  0.3896103896103896\n",
      "recall for fold 2321:  0.40540540540540543\n",
      "precision for fold 2321:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2322:  0.5190476190476191\n",
      "f1  score for fold 2322:  0.34838709677419355\n",
      "recall for fold 2322:  0.36\n",
      "precision for fold 2322:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2323:  0.5\n",
      "f1  score for fold 2323:  0.3602484472049689\n",
      "recall for fold 2323:  0.35365853658536583\n",
      "precision for fold 2323:  0.3670886075949367\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2324:  0.46632124352331605\n",
      "f1  score for fold 2324:  0.36024844720496896\n",
      "recall for fold 2324:  0.3333333333333333\n",
      "precision for fold 2324:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2325:  0.5023923444976076\n",
      "f1  score for fold 2325:  0.34177215189873417\n",
      "recall for fold 2325:  0.34615384615384615\n",
      "precision for fold 2325:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2326:  0.5023923444976076\n",
      "f1  score for fold 2326:  0.3246753246753247\n",
      "recall for fold 2326:  0.33783783783783783\n",
      "precision for fold 2326:  0.3125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2327:  0.5285714285714286\n",
      "f1  score for fold 2327:  0.3612903225806451\n",
      "recall for fold 2327:  0.37333333333333335\n",
      "precision for fold 2327:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2328:  0.5194174757281553\n",
      "f1  score for fold 2328:  0.38509316770186336\n",
      "recall for fold 2328:  0.3780487804878049\n",
      "precision for fold 2328:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2329:  0.48704663212435234\n",
      "f1  score for fold 2329:  0.3850931677018633\n",
      "recall for fold 2329:  0.3563218390804598\n",
      "precision for fold 2329:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2330:  0.5406698564593302\n",
      "f1  score for fold 2330:  0.3924050632911393\n",
      "recall for fold 2330:  0.3974358974358974\n",
      "precision for fold 2330:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2331:  0.5406698564593302\n",
      "f1  score for fold 2331:  0.37662337662337664\n",
      "recall for fold 2331:  0.3918918918918919\n",
      "precision for fold 2331:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2332:  0.5476190476190477\n",
      "f1  score for fold 2332:  0.38709677419354843\n",
      "recall for fold 2332:  0.4\n",
      "precision for fold 2332:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2333:  0.5097087378640777\n",
      "f1  score for fold 2333:  0.37267080745341613\n",
      "recall for fold 2333:  0.36585365853658536\n",
      "precision for fold 2333:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2334:  0.5077720207253886\n",
      "f1  score for fold 2334:  0.40993788819875776\n",
      "recall for fold 2334:  0.3793103448275862\n",
      "precision for fold 2334:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2335:  0.5023923444976076\n",
      "f1  score for fold 2335:  0.34177215189873417\n",
      "recall for fold 2335:  0.34615384615384615\n",
      "precision for fold 2335:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2336:  0.5215311004784688\n",
      "f1  score for fold 2336:  0.3506493506493507\n",
      "recall for fold 2336:  0.36486486486486486\n",
      "precision for fold 2336:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2337:  0.5380952380952381\n",
      "f1  score for fold 2337:  0.3741935483870968\n",
      "recall for fold 2337:  0.38666666666666666\n",
      "precision for fold 2337:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2338:  0.5\n",
      "f1  score for fold 2338:  0.3602484472049689\n",
      "recall for fold 2338:  0.35365853658536583\n",
      "precision for fold 2338:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2339:  0.49740932642487046\n",
      "f1  score for fold 2339:  0.39751552795031053\n",
      "recall for fold 2339:  0.367816091954023\n",
      "precision for fold 2339:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2340:  0.5598086124401914\n",
      "f1  score for fold 2340:  0.4177215189873418\n",
      "recall for fold 2340:  0.4230769230769231\n",
      "precision for fold 2340:  0.4125\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 2341:  0.5885167464114832\n",
      "f1  score for fold 2341:  0.44155844155844154\n",
      "recall for fold 2341:  0.4594594594594595\n",
      "precision for fold 2341:  0.425\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2342:  0.5476190476190477\n",
      "f1  score for fold 2342:  0.38709677419354843\n",
      "recall for fold 2342:  0.4\n",
      "precision for fold 2342:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2343:  0.470873786407767\n",
      "f1  score for fold 2343:  0.3229813664596273\n",
      "recall for fold 2343:  0.3170731707317073\n",
      "precision for fold 2343:  0.3291139240506329\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2344:  0.5284974093264249\n",
      "f1  score for fold 2344:  0.4347826086956522\n",
      "recall for fold 2344:  0.40229885057471265\n",
      "precision for fold 2344:  0.47297297297297297\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2345:  0.48325358851674644\n",
      "f1  score for fold 2345:  0.31645569620253167\n",
      "recall for fold 2345:  0.32051282051282054\n",
      "precision for fold 2345:  0.3125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2346:  0.5023923444976076\n",
      "f1  score for fold 2346:  0.3246753246753247\n",
      "recall for fold 2346:  0.33783783783783783\n",
      "precision for fold 2346:  0.3125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2347:  0.5\n",
      "f1  score for fold 2347:  0.3225806451612903\n",
      "recall for fold 2347:  0.3333333333333333\n",
      "precision for fold 2347:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2348:  0.5388349514563107\n",
      "f1  score for fold 2348:  0.40993788819875776\n",
      "recall for fold 2348:  0.4024390243902439\n",
      "precision for fold 2348:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2349:  0.5595854922279793\n",
      "f1  score for fold 2349:  0.4720496894409938\n",
      "recall for fold 2349:  0.4367816091954023\n",
      "precision for fold 2349:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2350:  0.5502392344497608\n",
      "f1  score for fold 2350:  0.4050632911392405\n",
      "recall for fold 2350:  0.41025641025641024\n",
      "precision for fold 2350:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2351:  0.5598086124401914\n",
      "f1  score for fold 2351:  0.40259740259740256\n",
      "recall for fold 2351:  0.4189189189189189\n",
      "precision for fold 2351:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2352:  0.5285714285714286\n",
      "f1  score for fold 2352:  0.3612903225806451\n",
      "recall for fold 2352:  0.37333333333333335\n",
      "precision for fold 2352:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2353:  0.529126213592233\n",
      "f1  score for fold 2353:  0.39751552795031053\n",
      "recall for fold 2353:  0.3902439024390244\n",
      "precision for fold 2353:  0.4050632911392405\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2354:  0.5699481865284974\n",
      "f1  score for fold 2354:  0.48447204968944096\n",
      "recall for fold 2354:  0.4482758620689655\n",
      "precision for fold 2354:  0.527027027027027\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2355:  0.5023923444976076\n",
      "f1  score for fold 2355:  0.34177215189873417\n",
      "recall for fold 2355:  0.34615384615384615\n",
      "precision for fold 2355:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2356:  0.5598086124401914\n",
      "f1  score for fold 2356:  0.40259740259740256\n",
      "recall for fold 2356:  0.4189189189189189\n",
      "precision for fold 2356:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2357:  0.5380952380952381\n",
      "f1  score for fold 2357:  0.3741935483870968\n",
      "recall for fold 2357:  0.38666666666666666\n",
      "precision for fold 2357:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2358:  0.5485436893203883\n",
      "f1  score for fold 2358:  0.42236024844720493\n",
      "recall for fold 2358:  0.4146341463414634\n",
      "precision for fold 2358:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2359:  0.48704663212435234\n",
      "f1  score for fold 2359:  0.3850931677018633\n",
      "recall for fold 2359:  0.3563218390804598\n",
      "precision for fold 2359:  0.4189189189189189\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 2360:  0.46411483253588515\n",
      "f1  score for fold 2360:  0.2911392405063291\n",
      "recall for fold 2360:  0.2948717948717949\n",
      "precision for fold 2360:  0.2875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2361:  0.5406698564593302\n",
      "f1  score for fold 2361:  0.37662337662337664\n",
      "recall for fold 2361:  0.3918918918918919\n",
      "precision for fold 2361:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2362:  0.5666666666666667\n",
      "f1  score for fold 2362:  0.41290322580645167\n",
      "recall for fold 2362:  0.4266666666666667\n",
      "precision for fold 2362:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2363:  0.5097087378640777\n",
      "f1  score for fold 2363:  0.37267080745341613\n",
      "recall for fold 2363:  0.36585365853658536\n",
      "precision for fold 2363:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2364:  0.5181347150259067\n",
      "f1  score for fold 2364:  0.422360248447205\n",
      "recall for fold 2364:  0.39080459770114945\n",
      "precision for fold 2364:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2365:  0.5119617224880383\n",
      "f1  score for fold 2365:  0.3544303797468355\n",
      "recall for fold 2365:  0.358974358974359\n",
      "precision for fold 2365:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2366:  0.5215311004784688\n",
      "f1  score for fold 2366:  0.3506493506493507\n",
      "recall for fold 2366:  0.36486486486486486\n",
      "precision for fold 2366:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2367:  0.5095238095238095\n",
      "f1  score for fold 2367:  0.335483870967742\n",
      "recall for fold 2367:  0.3466666666666667\n",
      "precision for fold 2367:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2368:  0.5194174757281553\n",
      "f1  score for fold 2368:  0.38509316770186336\n",
      "recall for fold 2368:  0.3780487804878049\n",
      "precision for fold 2368:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2369:  0.5595854922279793\n",
      "f1  score for fold 2369:  0.4720496894409938\n",
      "recall for fold 2369:  0.4367816091954023\n",
      "precision for fold 2369:  0.5135135135135135\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2370:  0.48325358851674644\n",
      "f1  score for fold 2370:  0.31645569620253167\n",
      "recall for fold 2370:  0.32051282051282054\n",
      "precision for fold 2370:  0.3125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2371:  0.5406698564593302\n",
      "f1  score for fold 2371:  0.37662337662337664\n",
      "recall for fold 2371:  0.3918918918918919\n",
      "precision for fold 2371:  0.3625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2372:  0.5571428571428572\n",
      "f1  score for fold 2372:  0.4000000000000001\n",
      "recall for fold 2372:  0.41333333333333333\n",
      "precision for fold 2372:  0.3875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2373:  0.470873786407767\n",
      "f1  score for fold 2373:  0.3229813664596273\n",
      "recall for fold 2373:  0.3170731707317073\n",
      "precision for fold 2373:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2374:  0.538860103626943\n",
      "f1  score for fold 2374:  0.4472049689440994\n",
      "recall for fold 2374:  0.41379310344827586\n",
      "precision for fold 2374:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2375:  0.5598086124401914\n",
      "f1  score for fold 2375:  0.4177215189873418\n",
      "recall for fold 2375:  0.4230769230769231\n",
      "precision for fold 2375:  0.4125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2376:  0.5119617224880383\n",
      "f1  score for fold 2376:  0.33766233766233766\n",
      "recall for fold 2376:  0.35135135135135137\n",
      "precision for fold 2376:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2377:  0.5380952380952381\n",
      "f1  score for fold 2377:  0.3741935483870968\n",
      "recall for fold 2377:  0.38666666666666666\n",
      "precision for fold 2377:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2378:  0.470873786407767\n",
      "f1  score for fold 2378:  0.3229813664596273\n",
      "recall for fold 2378:  0.3170731707317073\n",
      "precision for fold 2378:  0.3291139240506329\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2379:  0.5077720207253886\n",
      "f1  score for fold 2379:  0.40993788819875776\n",
      "recall for fold 2379:  0.3793103448275862\n",
      "precision for fold 2379:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2380:  0.5119617224880383\n",
      "f1  score for fold 2380:  0.3544303797468355\n",
      "recall for fold 2380:  0.358974358974359\n",
      "precision for fold 2380:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2381:  0.5406698564593302\n",
      "f1  score for fold 2381:  0.37662337662337664\n",
      "recall for fold 2381:  0.3918918918918919\n",
      "precision for fold 2381:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2382:  0.5190476190476191\n",
      "f1  score for fold 2382:  0.34838709677419355\n",
      "recall for fold 2382:  0.36\n",
      "precision for fold 2382:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2383:  0.5\n",
      "f1  score for fold 2383:  0.3602484472049689\n",
      "recall for fold 2383:  0.35365853658536583\n",
      "precision for fold 2383:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2384:  0.48704663212435234\n",
      "f1  score for fold 2384:  0.3850931677018633\n",
      "recall for fold 2384:  0.3563218390804598\n",
      "precision for fold 2384:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2385:  0.569377990430622\n",
      "f1  score for fold 2385:  0.43037974683544306\n",
      "recall for fold 2385:  0.4358974358974359\n",
      "precision for fold 2385:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2386:  0.5215311004784688\n",
      "f1  score for fold 2386:  0.3506493506493507\n",
      "recall for fold 2386:  0.36486486486486486\n",
      "precision for fold 2386:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2387:  0.5380952380952381\n",
      "f1  score for fold 2387:  0.3741935483870968\n",
      "recall for fold 2387:  0.38666666666666666\n",
      "precision for fold 2387:  0.3625\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 2388:  0.48058252427184467\n",
      "f1  score for fold 2388:  0.33540372670807456\n",
      "recall for fold 2388:  0.32926829268292684\n",
      "precision for fold 2388:  0.34177215189873417\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2389:  0.538860103626943\n",
      "f1  score for fold 2389:  0.4472049689440994\n",
      "recall for fold 2389:  0.41379310344827586\n",
      "precision for fold 2389:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2390:  0.5311004784688995\n",
      "f1  score for fold 2390:  0.37974683544303806\n",
      "recall for fold 2390:  0.38461538461538464\n",
      "precision for fold 2390:  0.375\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 2391:  0.46411483253588515\n",
      "f1  score for fold 2391:  0.27272727272727276\n",
      "recall for fold 2391:  0.28378378378378377\n",
      "precision for fold 2391:  0.2625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2392:  0.5095238095238095\n",
      "f1  score for fold 2392:  0.335483870967742\n",
      "recall for fold 2392:  0.3466666666666667\n",
      "precision for fold 2392:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2393:  0.5485436893203883\n",
      "f1  score for fold 2393:  0.42236024844720493\n",
      "recall for fold 2393:  0.4146341463414634\n",
      "precision for fold 2393:  0.43037974683544306\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 2394:  0.45595854922279794\n",
      "f1  score for fold 2394:  0.3478260869565218\n",
      "recall for fold 2394:  0.3218390804597701\n",
      "precision for fold 2394:  0.3783783783783784\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2395:  0.5023923444976076\n",
      "f1  score for fold 2395:  0.34177215189873417\n",
      "recall for fold 2395:  0.34615384615384615\n",
      "precision for fold 2395:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2396:  0.5406698564593302\n",
      "f1  score for fold 2396:  0.37662337662337664\n",
      "recall for fold 2396:  0.3918918918918919\n",
      "precision for fold 2396:  0.3625\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2397:  0.5\n",
      "f1  score for fold 2397:  0.3225806451612903\n",
      "recall for fold 2397:  0.3333333333333333\n",
      "precision for fold 2397:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2398:  0.5097087378640777\n",
      "f1  score for fold 2398:  0.37267080745341613\n",
      "recall for fold 2398:  0.36585365853658536\n",
      "precision for fold 2398:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2399:  0.5181347150259067\n",
      "f1  score for fold 2399:  0.422360248447205\n",
      "recall for fold 2399:  0.39080459770114945\n",
      "precision for fold 2399:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2400:  0.5598086124401914\n",
      "f1  score for fold 2400:  0.4177215189873418\n",
      "recall for fold 2400:  0.4230769230769231\n",
      "precision for fold 2400:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2401:  0.5598086124401914\n",
      "f1  score for fold 2401:  0.40259740259740256\n",
      "recall for fold 2401:  0.4189189189189189\n",
      "precision for fold 2401:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2402:  0.5\n",
      "f1  score for fold 2402:  0.3225806451612903\n",
      "recall for fold 2402:  0.3333333333333333\n",
      "precision for fold 2402:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2403:  0.5194174757281553\n",
      "f1  score for fold 2403:  0.38509316770186336\n",
      "recall for fold 2403:  0.3780487804878049\n",
      "precision for fold 2403:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2404:  0.49740932642487046\n",
      "f1  score for fold 2404:  0.39751552795031053\n",
      "recall for fold 2404:  0.367816091954023\n",
      "precision for fold 2404:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2405:  0.5215311004784688\n",
      "f1  score for fold 2405:  0.36708860759493667\n",
      "recall for fold 2405:  0.3717948717948718\n",
      "precision for fold 2405:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2406:  0.5023923444976076\n",
      "f1  score for fold 2406:  0.3246753246753247\n",
      "recall for fold 2406:  0.33783783783783783\n",
      "precision for fold 2406:  0.3125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2407:  0.5285714285714286\n",
      "f1  score for fold 2407:  0.3612903225806451\n",
      "recall for fold 2407:  0.37333333333333335\n",
      "precision for fold 2407:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2408:  0.5194174757281553\n",
      "f1  score for fold 2408:  0.38509316770186336\n",
      "recall for fold 2408:  0.3780487804878049\n",
      "precision for fold 2408:  0.3924050632911392\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2409:  0.46632124352331605\n",
      "f1  score for fold 2409:  0.36024844720496896\n",
      "recall for fold 2409:  0.3333333333333333\n",
      "precision for fold 2409:  0.3918918918918919\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2410:  0.5311004784688995\n",
      "f1  score for fold 2410:  0.37974683544303806\n",
      "recall for fold 2410:  0.38461538461538464\n",
      "precision for fold 2410:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2411:  0.5598086124401914\n",
      "f1  score for fold 2411:  0.40259740259740256\n",
      "recall for fold 2411:  0.4189189189189189\n",
      "precision for fold 2411:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2412:  0.49047619047619045\n",
      "f1  score for fold 2412:  0.3096774193548387\n",
      "recall for fold 2412:  0.32\n",
      "precision for fold 2412:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2413:  0.5097087378640777\n",
      "f1  score for fold 2413:  0.37267080745341613\n",
      "recall for fold 2413:  0.36585365853658536\n",
      "precision for fold 2413:  0.379746835443038\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 2414:  0.42487046632124353\n",
      "f1  score for fold 2414:  0.3105590062111801\n",
      "recall for fold 2414:  0.28735632183908044\n",
      "precision for fold 2414:  0.33783783783783783\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2415:  0.5215311004784688\n",
      "f1  score for fold 2415:  0.36708860759493667\n",
      "recall for fold 2415:  0.3717948717948718\n",
      "precision for fold 2415:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2416:  0.5215311004784688\n",
      "f1  score for fold 2416:  0.3506493506493507\n",
      "recall for fold 2416:  0.36486486486486486\n",
      "precision for fold 2416:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2417:  0.5476190476190477\n",
      "f1  score for fold 2417:  0.38709677419354843\n",
      "recall for fold 2417:  0.4\n",
      "precision for fold 2417:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2418:  0.49029126213592233\n",
      "f1  score for fold 2418:  0.3478260869565218\n",
      "recall for fold 2418:  0.34146341463414637\n",
      "precision for fold 2418:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2419:  0.5077720207253886\n",
      "f1  score for fold 2419:  0.40993788819875776\n",
      "recall for fold 2419:  0.3793103448275862\n",
      "precision for fold 2419:  0.44594594594594594\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2420:  0.49282296650717705\n",
      "f1  score for fold 2420:  0.32911392405063294\n",
      "recall for fold 2420:  0.3333333333333333\n",
      "precision for fold 2420:  0.325\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2421:  0.5119617224880383\n",
      "f1  score for fold 2421:  0.33766233766233766\n",
      "recall for fold 2421:  0.35135135135135137\n",
      "precision for fold 2421:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2422:  0.5285714285714286\n",
      "f1  score for fold 2422:  0.3612903225806451\n",
      "recall for fold 2422:  0.37333333333333335\n",
      "precision for fold 2422:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2423:  0.5\n",
      "f1  score for fold 2423:  0.3602484472049689\n",
      "recall for fold 2423:  0.35365853658536583\n",
      "precision for fold 2423:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2424:  0.5284974093264249\n",
      "f1  score for fold 2424:  0.4347826086956522\n",
      "recall for fold 2424:  0.40229885057471265\n",
      "precision for fold 2424:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2425:  0.5598086124401914\n",
      "f1  score for fold 2425:  0.4177215189873418\n",
      "recall for fold 2425:  0.4230769230769231\n",
      "precision for fold 2425:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2426:  0.5502392344497608\n",
      "f1  score for fold 2426:  0.3896103896103896\n",
      "recall for fold 2426:  0.40540540540540543\n",
      "precision for fold 2426:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2427:  0.5666666666666667\n",
      "f1  score for fold 2427:  0.41290322580645167\n",
      "recall for fold 2427:  0.4266666666666667\n",
      "precision for fold 2427:  0.4\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2428:  0.5\n",
      "f1  score for fold 2428:  0.3602484472049689\n",
      "recall for fold 2428:  0.35365853658536583\n",
      "precision for fold 2428:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2429:  0.5284974093264249\n",
      "f1  score for fold 2429:  0.4347826086956522\n",
      "recall for fold 2429:  0.40229885057471265\n",
      "precision for fold 2429:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2430:  0.49282296650717705\n",
      "f1  score for fold 2430:  0.32911392405063294\n",
      "recall for fold 2430:  0.3333333333333333\n",
      "precision for fold 2430:  0.325\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2431:  0.5598086124401914\n",
      "f1  score for fold 2431:  0.40259740259740256\n",
      "recall for fold 2431:  0.4189189189189189\n",
      "precision for fold 2431:  0.3875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2432:  0.5571428571428572\n",
      "f1  score for fold 2432:  0.4000000000000001\n",
      "recall for fold 2432:  0.41333333333333333\n",
      "precision for fold 2432:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2433:  0.5194174757281553\n",
      "f1  score for fold 2433:  0.38509316770186336\n",
      "recall for fold 2433:  0.3780487804878049\n",
      "precision for fold 2433:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2434:  0.48704663212435234\n",
      "f1  score for fold 2434:  0.3850931677018633\n",
      "recall for fold 2434:  0.3563218390804598\n",
      "precision for fold 2434:  0.4189189189189189\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2435:  0.5789473684210527\n",
      "f1  score for fold 2435:  0.44303797468354433\n",
      "recall for fold 2435:  0.44871794871794873\n",
      "precision for fold 2435:  0.4375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2436:  0.49282296650717705\n",
      "f1  score for fold 2436:  0.3116883116883117\n",
      "recall for fold 2436:  0.32432432432432434\n",
      "precision for fold 2436:  0.3\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2437:  0.5190476190476191\n",
      "f1  score for fold 2437:  0.34838709677419355\n",
      "recall for fold 2437:  0.36\n",
      "precision for fold 2437:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2438:  0.5097087378640777\n",
      "f1  score for fold 2438:  0.37267080745341613\n",
      "recall for fold 2438:  0.36585365853658536\n",
      "precision for fold 2438:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2439:  0.48704663212435234\n",
      "f1  score for fold 2439:  0.3850931677018633\n",
      "recall for fold 2439:  0.3563218390804598\n",
      "precision for fold 2439:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2440:  0.5119617224880383\n",
      "f1  score for fold 2440:  0.3544303797468355\n",
      "recall for fold 2440:  0.358974358974359\n",
      "precision for fold 2440:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2441:  0.5502392344497608\n",
      "f1  score for fold 2441:  0.3896103896103896\n",
      "recall for fold 2441:  0.40540540540540543\n",
      "precision for fold 2441:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2442:  0.5476190476190477\n",
      "f1  score for fold 2442:  0.38709677419354843\n",
      "recall for fold 2442:  0.4\n",
      "precision for fold 2442:  0.375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2443:  0.5\n",
      "f1  score for fold 2443:  0.3602484472049689\n",
      "recall for fold 2443:  0.35365853658536583\n",
      "precision for fold 2443:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2444:  0.5077720207253886\n",
      "f1  score for fold 2444:  0.40993788819875776\n",
      "recall for fold 2444:  0.3793103448275862\n",
      "precision for fold 2444:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2445:  0.5502392344497608\n",
      "f1  score for fold 2445:  0.4050632911392405\n",
      "recall for fold 2445:  0.41025641025641024\n",
      "precision for fold 2445:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2446:  0.5406698564593302\n",
      "f1  score for fold 2446:  0.37662337662337664\n",
      "recall for fold 2446:  0.3918918918918919\n",
      "precision for fold 2446:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2447:  0.5095238095238095\n",
      "f1  score for fold 2447:  0.335483870967742\n",
      "recall for fold 2447:  0.3466666666666667\n",
      "precision for fold 2447:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2448:  0.5388349514563107\n",
      "f1  score for fold 2448:  0.40993788819875776\n",
      "recall for fold 2448:  0.4024390243902439\n",
      "precision for fold 2448:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2449:  0.5181347150259067\n",
      "f1  score for fold 2449:  0.422360248447205\n",
      "recall for fold 2449:  0.39080459770114945\n",
      "precision for fold 2449:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2450:  0.5119617224880383\n",
      "f1  score for fold 2450:  0.3544303797468355\n",
      "recall for fold 2450:  0.358974358974359\n",
      "precision for fold 2450:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2451:  0.5598086124401914\n",
      "f1  score for fold 2451:  0.40259740259740256\n",
      "recall for fold 2451:  0.4189189189189189\n",
      "precision for fold 2451:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2452:  0.5285714285714286\n",
      "f1  score for fold 2452:  0.3612903225806451\n",
      "recall for fold 2452:  0.37333333333333335\n",
      "precision for fold 2452:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2453:  0.529126213592233\n",
      "f1  score for fold 2453:  0.39751552795031053\n",
      "recall for fold 2453:  0.3902439024390244\n",
      "precision for fold 2453:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2454:  0.5077720207253886\n",
      "f1  score for fold 2454:  0.40993788819875776\n",
      "recall for fold 2454:  0.3793103448275862\n",
      "precision for fold 2454:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2455:  0.5789473684210527\n",
      "f1  score for fold 2455:  0.44303797468354433\n",
      "recall for fold 2455:  0.44871794871794873\n",
      "precision for fold 2455:  0.4375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2456:  0.569377990430622\n",
      "f1  score for fold 2456:  0.4155844155844156\n",
      "recall for fold 2456:  0.43243243243243246\n",
      "precision for fold 2456:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2457:  0.5285714285714286\n",
      "f1  score for fold 2457:  0.3612903225806451\n",
      "recall for fold 2457:  0.37333333333333335\n",
      "precision for fold 2457:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2458:  0.5\n",
      "f1  score for fold 2458:  0.3602484472049689\n",
      "recall for fold 2458:  0.35365853658536583\n",
      "precision for fold 2458:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2459:  0.5181347150259067\n",
      "f1  score for fold 2459:  0.422360248447205\n",
      "recall for fold 2459:  0.39080459770114945\n",
      "precision for fold 2459:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2460:  0.569377990430622\n",
      "f1  score for fold 2460:  0.43037974683544306\n",
      "recall for fold 2460:  0.4358974358974359\n",
      "precision for fold 2460:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2461:  0.5215311004784688\n",
      "f1  score for fold 2461:  0.3506493506493507\n",
      "recall for fold 2461:  0.36486486486486486\n",
      "precision for fold 2461:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2462:  0.5190476190476191\n",
      "f1  score for fold 2462:  0.34838709677419355\n",
      "recall for fold 2462:  0.36\n",
      "precision for fold 2462:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2463:  0.5097087378640777\n",
      "f1  score for fold 2463:  0.37267080745341613\n",
      "recall for fold 2463:  0.36585365853658536\n",
      "precision for fold 2463:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2464:  0.46632124352331605\n",
      "f1  score for fold 2464:  0.36024844720496896\n",
      "recall for fold 2464:  0.3333333333333333\n",
      "precision for fold 2464:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2465:  0.49282296650717705\n",
      "f1  score for fold 2465:  0.32911392405063294\n",
      "recall for fold 2465:  0.3333333333333333\n",
      "precision for fold 2465:  0.325\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2466:  0.5119617224880383\n",
      "f1  score for fold 2466:  0.33766233766233766\n",
      "recall for fold 2466:  0.35135135135135137\n",
      "precision for fold 2466:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2467:  0.5476190476190477\n",
      "f1  score for fold 2467:  0.38709677419354843\n",
      "recall for fold 2467:  0.4\n",
      "precision for fold 2467:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2468:  0.5194174757281553\n",
      "f1  score for fold 2468:  0.38509316770186336\n",
      "recall for fold 2468:  0.3780487804878049\n",
      "precision for fold 2468:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2469:  0.5492227979274611\n",
      "f1  score for fold 2469:  0.45962732919254656\n",
      "recall for fold 2469:  0.42528735632183906\n",
      "precision for fold 2469:  0.5\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2470:  0.5598086124401914\n",
      "f1  score for fold 2470:  0.4177215189873418\n",
      "recall for fold 2470:  0.4230769230769231\n",
      "precision for fold 2470:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2471:  0.5215311004784688\n",
      "f1  score for fold 2471:  0.3506493506493507\n",
      "recall for fold 2471:  0.36486486486486486\n",
      "precision for fold 2471:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2472:  0.5666666666666667\n",
      "f1  score for fold 2472:  0.41290322580645167\n",
      "recall for fold 2472:  0.4266666666666667\n",
      "precision for fold 2472:  0.4\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2473:  0.5776699029126213\n",
      "f1  score for fold 2473:  0.4596273291925466\n",
      "recall for fold 2473:  0.45121951219512196\n",
      "precision for fold 2473:  0.46835443037974683\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2474:  0.5181347150259067\n",
      "f1  score for fold 2474:  0.422360248447205\n",
      "recall for fold 2474:  0.39080459770114945\n",
      "precision for fold 2474:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2475:  0.5215311004784688\n",
      "f1  score for fold 2475:  0.36708860759493667\n",
      "recall for fold 2475:  0.3717948717948718\n",
      "precision for fold 2475:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2476:  0.5023923444976076\n",
      "f1  score for fold 2476:  0.3246753246753247\n",
      "recall for fold 2476:  0.33783783783783783\n",
      "precision for fold 2476:  0.3125\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 2477:  0.5952380952380952\n",
      "f1  score for fold 2477:  0.45161290322580644\n",
      "recall for fold 2477:  0.4666666666666667\n",
      "precision for fold 2477:  0.4375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2478:  0.49029126213592233\n",
      "f1  score for fold 2478:  0.3478260869565218\n",
      "recall for fold 2478:  0.34146341463414637\n",
      "precision for fold 2478:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2479:  0.538860103626943\n",
      "f1  score for fold 2479:  0.4472049689440994\n",
      "recall for fold 2479:  0.41379310344827586\n",
      "precision for fold 2479:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2480:  0.5598086124401914\n",
      "f1  score for fold 2480:  0.4177215189873418\n",
      "recall for fold 2480:  0.4230769230769231\n",
      "precision for fold 2480:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2481:  0.5406698564593302\n",
      "f1  score for fold 2481:  0.37662337662337664\n",
      "recall for fold 2481:  0.3918918918918919\n",
      "precision for fold 2481:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2482:  0.5285714285714286\n",
      "f1  score for fold 2482:  0.3612903225806451\n",
      "recall for fold 2482:  0.37333333333333335\n",
      "precision for fold 2482:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2483:  0.49029126213592233\n",
      "f1  score for fold 2483:  0.3478260869565218\n",
      "recall for fold 2483:  0.34146341463414637\n",
      "precision for fold 2483:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2484:  0.5077720207253886\n",
      "f1  score for fold 2484:  0.40993788819875776\n",
      "recall for fold 2484:  0.3793103448275862\n",
      "precision for fold 2484:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2485:  0.5023923444976076\n",
      "f1  score for fold 2485:  0.34177215189873417\n",
      "recall for fold 2485:  0.34615384615384615\n",
      "precision for fold 2485:  0.3375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2486:  0.49282296650717705\n",
      "f1  score for fold 2486:  0.3116883116883117\n",
      "recall for fold 2486:  0.32432432432432434\n",
      "precision for fold 2486:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2487:  0.5\n",
      "f1  score for fold 2487:  0.3225806451612903\n",
      "recall for fold 2487:  0.3333333333333333\n",
      "precision for fold 2487:  0.3125\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2488:  0.5679611650485437\n",
      "f1  score for fold 2488:  0.4472049689440994\n",
      "recall for fold 2488:  0.43902439024390244\n",
      "precision for fold 2488:  0.45569620253164556\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2489:  0.5699481865284974\n",
      "f1  score for fold 2489:  0.48447204968944096\n",
      "recall for fold 2489:  0.4482758620689655\n",
      "precision for fold 2489:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2490:  0.5502392344497608\n",
      "f1  score for fold 2490:  0.4050632911392405\n",
      "recall for fold 2490:  0.41025641025641024\n",
      "precision for fold 2490:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2491:  0.5023923444976076\n",
      "f1  score for fold 2491:  0.3246753246753247\n",
      "recall for fold 2491:  0.33783783783783783\n",
      "precision for fold 2491:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2492:  0.5190476190476191\n",
      "f1  score for fold 2492:  0.34838709677419355\n",
      "recall for fold 2492:  0.36\n",
      "precision for fold 2492:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2493:  0.49029126213592233\n",
      "f1  score for fold 2493:  0.3478260869565218\n",
      "recall for fold 2493:  0.34146341463414637\n",
      "precision for fold 2493:  0.35443037974683544\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2494:  0.48704663212435234\n",
      "f1  score for fold 2494:  0.3850931677018633\n",
      "recall for fold 2494:  0.3563218390804598\n",
      "precision for fold 2494:  0.4189189189189189\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2495:  0.5789473684210527\n",
      "f1  score for fold 2495:  0.44303797468354433\n",
      "recall for fold 2495:  0.44871794871794873\n",
      "precision for fold 2495:  0.4375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2496:  0.5406698564593302\n",
      "f1  score for fold 2496:  0.37662337662337664\n",
      "recall for fold 2496:  0.3918918918918919\n",
      "precision for fold 2496:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2497:  0.49047619047619045\n",
      "f1  score for fold 2497:  0.3096774193548387\n",
      "recall for fold 2497:  0.32\n",
      "precision for fold 2497:  0.3\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2498:  0.5485436893203883\n",
      "f1  score for fold 2498:  0.42236024844720493\n",
      "recall for fold 2498:  0.4146341463414634\n",
      "precision for fold 2498:  0.43037974683544306\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2499:  0.5595854922279793\n",
      "f1  score for fold 2499:  0.4720496894409938\n",
      "recall for fold 2499:  0.4367816091954023\n",
      "precision for fold 2499:  0.5135135135135135\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 2500:  0.5885167464114832\n",
      "f1  score for fold 2500:  0.45569620253164556\n",
      "recall for fold 2500:  0.46153846153846156\n",
      "precision for fold 2500:  0.45\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2501:  0.5215311004784688\n",
      "f1  score for fold 2501:  0.3506493506493507\n",
      "recall for fold 2501:  0.36486486486486486\n",
      "precision for fold 2501:  0.3375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2502:  0.5761904761904761\n",
      "f1  score for fold 2502:  0.4258064516129032\n",
      "recall for fold 2502:  0.44\n",
      "precision for fold 2502:  0.4125\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 2503:  0.5970873786407767\n",
      "f1  score for fold 2503:  0.484472049689441\n",
      "recall for fold 2503:  0.47560975609756095\n",
      "precision for fold 2503:  0.4936708860759494\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2504:  0.5181347150259067\n",
      "f1  score for fold 2504:  0.422360248447205\n",
      "recall for fold 2504:  0.39080459770114945\n",
      "precision for fold 2504:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2505:  0.569377990430622\n",
      "f1  score for fold 2505:  0.43037974683544306\n",
      "recall for fold 2505:  0.4358974358974359\n",
      "precision for fold 2505:  0.425\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 2506:  0.5980861244019139\n",
      "f1  score for fold 2506:  0.45454545454545453\n",
      "recall for fold 2506:  0.47297297297297297\n",
      "precision for fold 2506:  0.4375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2507:  0.5190476190476191\n",
      "f1  score for fold 2507:  0.34838709677419355\n",
      "recall for fold 2507:  0.36\n",
      "precision for fold 2507:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2508:  0.5388349514563107\n",
      "f1  score for fold 2508:  0.40993788819875776\n",
      "recall for fold 2508:  0.4024390243902439\n",
      "precision for fold 2508:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2509:  0.5077720207253886\n",
      "f1  score for fold 2509:  0.40993788819875776\n",
      "recall for fold 2509:  0.3793103448275862\n",
      "precision for fold 2509:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2510:  0.5119617224880383\n",
      "f1  score for fold 2510:  0.3544303797468355\n",
      "recall for fold 2510:  0.358974358974359\n",
      "precision for fold 2510:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2511:  0.5311004784688995\n",
      "f1  score for fold 2511:  0.36363636363636365\n",
      "recall for fold 2511:  0.3783783783783784\n",
      "precision for fold 2511:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2512:  0.5285714285714286\n",
      "f1  score for fold 2512:  0.3612903225806451\n",
      "recall for fold 2512:  0.37333333333333335\n",
      "precision for fold 2512:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2513:  0.5679611650485437\n",
      "f1  score for fold 2513:  0.4472049689440994\n",
      "recall for fold 2513:  0.43902439024390244\n",
      "precision for fold 2513:  0.45569620253164556\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2514:  0.538860103626943\n",
      "f1  score for fold 2514:  0.4472049689440994\n",
      "recall for fold 2514:  0.41379310344827586\n",
      "precision for fold 2514:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2515:  0.5598086124401914\n",
      "f1  score for fold 2515:  0.4177215189873418\n",
      "recall for fold 2515:  0.4230769230769231\n",
      "precision for fold 2515:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2516:  0.5406698564593302\n",
      "f1  score for fold 2516:  0.37662337662337664\n",
      "recall for fold 2516:  0.3918918918918919\n",
      "precision for fold 2516:  0.3625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2517:  0.5571428571428572\n",
      "f1  score for fold 2517:  0.4000000000000001\n",
      "recall for fold 2517:  0.41333333333333333\n",
      "precision for fold 2517:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2518:  0.5388349514563107\n",
      "f1  score for fold 2518:  0.40993788819875776\n",
      "recall for fold 2518:  0.4024390243902439\n",
      "precision for fold 2518:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2519:  0.5077720207253886\n",
      "f1  score for fold 2519:  0.40993788819875776\n",
      "recall for fold 2519:  0.3793103448275862\n",
      "precision for fold 2519:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2520:  0.5215311004784688\n",
      "f1  score for fold 2520:  0.36708860759493667\n",
      "recall for fold 2520:  0.3717948717948718\n",
      "precision for fold 2520:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2521:  0.5215311004784688\n",
      "f1  score for fold 2521:  0.3506493506493507\n",
      "recall for fold 2521:  0.36486486486486486\n",
      "precision for fold 2521:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2522:  0.5190476190476191\n",
      "f1  score for fold 2522:  0.34838709677419355\n",
      "recall for fold 2522:  0.36\n",
      "precision for fold 2522:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2523:  0.5\n",
      "f1  score for fold 2523:  0.3602484472049689\n",
      "recall for fold 2523:  0.35365853658536583\n",
      "precision for fold 2523:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2524:  0.5492227979274611\n",
      "f1  score for fold 2524:  0.45962732919254656\n",
      "recall for fold 2524:  0.42528735632183906\n",
      "precision for fold 2524:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2525:  0.5215311004784688\n",
      "f1  score for fold 2525:  0.36708860759493667\n",
      "recall for fold 2525:  0.3717948717948718\n",
      "precision for fold 2525:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2526:  0.5502392344497608\n",
      "f1  score for fold 2526:  0.3896103896103896\n",
      "recall for fold 2526:  0.40540540540540543\n",
      "precision for fold 2526:  0.375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2527:  0.5857142857142857\n",
      "f1  score for fold 2527:  0.43870967741935485\n",
      "recall for fold 2527:  0.4533333333333333\n",
      "precision for fold 2527:  0.425\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2528:  0.529126213592233\n",
      "f1  score for fold 2528:  0.39751552795031053\n",
      "recall for fold 2528:  0.3902439024390244\n",
      "precision for fold 2528:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2529:  0.49740932642487046\n",
      "f1  score for fold 2529:  0.39751552795031053\n",
      "recall for fold 2529:  0.367816091954023\n",
      "precision for fold 2529:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2530:  0.5502392344497608\n",
      "f1  score for fold 2530:  0.4050632911392405\n",
      "recall for fold 2530:  0.41025641025641024\n",
      "precision for fold 2530:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2531:  0.569377990430622\n",
      "f1  score for fold 2531:  0.4155844155844156\n",
      "recall for fold 2531:  0.43243243243243246\n",
      "precision for fold 2531:  0.4\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2532:  0.5571428571428572\n",
      "f1  score for fold 2532:  0.4000000000000001\n",
      "recall for fold 2532:  0.41333333333333333\n",
      "precision for fold 2532:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2533:  0.5485436893203883\n",
      "f1  score for fold 2533:  0.42236024844720493\n",
      "recall for fold 2533:  0.4146341463414634\n",
      "precision for fold 2533:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2534:  0.5181347150259067\n",
      "f1  score for fold 2534:  0.422360248447205\n",
      "recall for fold 2534:  0.39080459770114945\n",
      "precision for fold 2534:  0.4594594594594595\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 2535:  0.45454545454545453\n",
      "f1  score for fold 2535:  0.27848101265822783\n",
      "recall for fold 2535:  0.28205128205128205\n",
      "precision for fold 2535:  0.275\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2536:  0.5406698564593302\n",
      "f1  score for fold 2536:  0.37662337662337664\n",
      "recall for fold 2536:  0.3918918918918919\n",
      "precision for fold 2536:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2537:  0.5190476190476191\n",
      "f1  score for fold 2537:  0.34838709677419355\n",
      "recall for fold 2537:  0.36\n",
      "precision for fold 2537:  0.3375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 2538:  0.46116504854368934\n",
      "f1  score for fold 2538:  0.31055900621118016\n",
      "recall for fold 2538:  0.3048780487804878\n",
      "precision for fold 2538:  0.31645569620253167\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2539:  0.47668393782383417\n",
      "f1  score for fold 2539:  0.3726708074534162\n",
      "recall for fold 2539:  0.3448275862068966\n",
      "precision for fold 2539:  0.40540540540540543\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2540:  0.49282296650717705\n",
      "f1  score for fold 2540:  0.32911392405063294\n",
      "recall for fold 2540:  0.3333333333333333\n",
      "precision for fold 2540:  0.325\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2541:  0.5119617224880383\n",
      "f1  score for fold 2541:  0.33766233766233766\n",
      "recall for fold 2541:  0.35135135135135137\n",
      "precision for fold 2541:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2542:  0.5380952380952381\n",
      "f1  score for fold 2542:  0.3741935483870968\n",
      "recall for fold 2542:  0.38666666666666666\n",
      "precision for fold 2542:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2543:  0.5485436893203883\n",
      "f1  score for fold 2543:  0.42236024844720493\n",
      "recall for fold 2543:  0.4146341463414634\n",
      "precision for fold 2543:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2544:  0.538860103626943\n",
      "f1  score for fold 2544:  0.4472049689440994\n",
      "recall for fold 2544:  0.41379310344827586\n",
      "precision for fold 2544:  0.4864864864864865\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2545:  0.48325358851674644\n",
      "f1  score for fold 2545:  0.31645569620253167\n",
      "recall for fold 2545:  0.32051282051282054\n",
      "precision for fold 2545:  0.3125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2546:  0.5789473684210527\n",
      "f1  score for fold 2546:  0.42857142857142855\n",
      "recall for fold 2546:  0.44594594594594594\n",
      "precision for fold 2546:  0.4125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2547:  0.5190476190476191\n",
      "f1  score for fold 2547:  0.34838709677419355\n",
      "recall for fold 2547:  0.36\n",
      "precision for fold 2547:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2548:  0.5097087378640777\n",
      "f1  score for fold 2548:  0.37267080745341613\n",
      "recall for fold 2548:  0.36585365853658536\n",
      "precision for fold 2548:  0.379746835443038\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2549:  0.5492227979274611\n",
      "f1  score for fold 2549:  0.45962732919254656\n",
      "recall for fold 2549:  0.42528735632183906\n",
      "precision for fold 2549:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2550:  0.5215311004784688\n",
      "f1  score for fold 2550:  0.36708860759493667\n",
      "recall for fold 2550:  0.3717948717948718\n",
      "precision for fold 2550:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2551:  0.5215311004784688\n",
      "f1  score for fold 2551:  0.3506493506493507\n",
      "recall for fold 2551:  0.36486486486486486\n",
      "precision for fold 2551:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2552:  0.5476190476190477\n",
      "f1  score for fold 2552:  0.38709677419354843\n",
      "recall for fold 2552:  0.4\n",
      "precision for fold 2552:  0.375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2553:  0.5\n",
      "f1  score for fold 2553:  0.3602484472049689\n",
      "recall for fold 2553:  0.35365853658536583\n",
      "precision for fold 2553:  0.3670886075949367\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2554:  0.47668393782383417\n",
      "f1  score for fold 2554:  0.3726708074534162\n",
      "recall for fold 2554:  0.3448275862068966\n",
      "precision for fold 2554:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2555:  0.5598086124401914\n",
      "f1  score for fold 2555:  0.4177215189873418\n",
      "recall for fold 2555:  0.4230769230769231\n",
      "precision for fold 2555:  0.4125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2556:  0.5119617224880383\n",
      "f1  score for fold 2556:  0.33766233766233766\n",
      "recall for fold 2556:  0.35135135135135137\n",
      "precision for fold 2556:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2557:  0.5571428571428572\n",
      "f1  score for fold 2557:  0.4000000000000001\n",
      "recall for fold 2557:  0.41333333333333333\n",
      "precision for fold 2557:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2558:  0.529126213592233\n",
      "f1  score for fold 2558:  0.39751552795031053\n",
      "recall for fold 2558:  0.3902439024390244\n",
      "precision for fold 2558:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2559:  0.5284974093264249\n",
      "f1  score for fold 2559:  0.4347826086956522\n",
      "recall for fold 2559:  0.40229885057471265\n",
      "precision for fold 2559:  0.47297297297297297\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2560:  0.48325358851674644\n",
      "f1  score for fold 2560:  0.31645569620253167\n",
      "recall for fold 2560:  0.32051282051282054\n",
      "precision for fold 2560:  0.3125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2561:  0.5406698564593302\n",
      "f1  score for fold 2561:  0.37662337662337664\n",
      "recall for fold 2561:  0.3918918918918919\n",
      "precision for fold 2561:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2562:  0.5380952380952381\n",
      "f1  score for fold 2562:  0.3741935483870968\n",
      "recall for fold 2562:  0.38666666666666666\n",
      "precision for fold 2562:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2563:  0.558252427184466\n",
      "f1  score for fold 2563:  0.43478260869565216\n",
      "recall for fold 2563:  0.4268292682926829\n",
      "precision for fold 2563:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2564:  0.5077720207253886\n",
      "f1  score for fold 2564:  0.40993788819875776\n",
      "recall for fold 2564:  0.3793103448275862\n",
      "precision for fold 2564:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2565:  0.5023923444976076\n",
      "f1  score for fold 2565:  0.34177215189873417\n",
      "recall for fold 2565:  0.34615384615384615\n",
      "precision for fold 2565:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2566:  0.5119617224880383\n",
      "f1  score for fold 2566:  0.33766233766233766\n",
      "recall for fold 2566:  0.35135135135135137\n",
      "precision for fold 2566:  0.325\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2567:  0.49047619047619045\n",
      "f1  score for fold 2567:  0.3096774193548387\n",
      "recall for fold 2567:  0.32\n",
      "precision for fold 2567:  0.3\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2568:  0.5194174757281553\n",
      "f1  score for fold 2568:  0.38509316770186336\n",
      "recall for fold 2568:  0.3780487804878049\n",
      "precision for fold 2568:  0.3924050632911392\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 2569:  0.5803108808290155\n",
      "f1  score for fold 2569:  0.49689440993788814\n",
      "recall for fold 2569:  0.45977011494252873\n",
      "precision for fold 2569:  0.5405405405405406\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2570:  0.5502392344497608\n",
      "f1  score for fold 2570:  0.4050632911392405\n",
      "recall for fold 2570:  0.41025641025641024\n",
      "precision for fold 2570:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2571:  0.5311004784688995\n",
      "f1  score for fold 2571:  0.36363636363636365\n",
      "recall for fold 2571:  0.3783783783783784\n",
      "precision for fold 2571:  0.35\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2572:  0.5380952380952381\n",
      "f1  score for fold 2572:  0.3741935483870968\n",
      "recall for fold 2572:  0.38666666666666666\n",
      "precision for fold 2572:  0.3625\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 2573:  0.587378640776699\n",
      "f1  score for fold 2573:  0.4720496894409938\n",
      "recall for fold 2573:  0.4634146341463415\n",
      "precision for fold 2573:  0.4810126582278481\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2574:  0.46632124352331605\n",
      "f1  score for fold 2574:  0.36024844720496896\n",
      "recall for fold 2574:  0.3333333333333333\n",
      "precision for fold 2574:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2575:  0.5023923444976076\n",
      "f1  score for fold 2575:  0.34177215189873417\n",
      "recall for fold 2575:  0.34615384615384615\n",
      "precision for fold 2575:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2576:  0.5502392344497608\n",
      "f1  score for fold 2576:  0.3896103896103896\n",
      "recall for fold 2576:  0.40540540540540543\n",
      "precision for fold 2576:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2577:  0.5761904761904761\n",
      "f1  score for fold 2577:  0.4258064516129032\n",
      "recall for fold 2577:  0.44\n",
      "precision for fold 2577:  0.4125\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2578:  0.470873786407767\n",
      "f1  score for fold 2578:  0.3229813664596273\n",
      "recall for fold 2578:  0.3170731707317073\n",
      "precision for fold 2578:  0.3291139240506329\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2579:  0.5077720207253886\n",
      "f1  score for fold 2579:  0.40993788819875776\n",
      "recall for fold 2579:  0.3793103448275862\n",
      "precision for fold 2579:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2580:  0.5406698564593302\n",
      "f1  score for fold 2580:  0.3924050632911393\n",
      "recall for fold 2580:  0.3974358974358974\n",
      "precision for fold 2580:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2581:  0.5311004784688995\n",
      "f1  score for fold 2581:  0.36363636363636365\n",
      "recall for fold 2581:  0.3783783783783784\n",
      "precision for fold 2581:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2582:  0.5190476190476191\n",
      "f1  score for fold 2582:  0.34838709677419355\n",
      "recall for fold 2582:  0.36\n",
      "precision for fold 2582:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2583:  0.5194174757281553\n",
      "f1  score for fold 2583:  0.38509316770186336\n",
      "recall for fold 2583:  0.3780487804878049\n",
      "precision for fold 2583:  0.3924050632911392\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2584:  0.46632124352331605\n",
      "f1  score for fold 2584:  0.36024844720496896\n",
      "recall for fold 2584:  0.3333333333333333\n",
      "precision for fold 2584:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2585:  0.49282296650717705\n",
      "f1  score for fold 2585:  0.32911392405063294\n",
      "recall for fold 2585:  0.3333333333333333\n",
      "precision for fold 2585:  0.325\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2586:  0.569377990430622\n",
      "f1  score for fold 2586:  0.4155844155844156\n",
      "recall for fold 2586:  0.43243243243243246\n",
      "precision for fold 2586:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2587:  0.5380952380952381\n",
      "f1  score for fold 2587:  0.3741935483870968\n",
      "recall for fold 2587:  0.38666666666666666\n",
      "precision for fold 2587:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2588:  0.558252427184466\n",
      "f1  score for fold 2588:  0.43478260869565216\n",
      "recall for fold 2588:  0.4268292682926829\n",
      "precision for fold 2588:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2589:  0.5077720207253886\n",
      "f1  score for fold 2589:  0.40993788819875776\n",
      "recall for fold 2589:  0.3793103448275862\n",
      "precision for fold 2589:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2590:  0.5119617224880383\n",
      "f1  score for fold 2590:  0.3544303797468355\n",
      "recall for fold 2590:  0.358974358974359\n",
      "precision for fold 2590:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2591:  0.5119617224880383\n",
      "f1  score for fold 2591:  0.33766233766233766\n",
      "recall for fold 2591:  0.35135135135135137\n",
      "precision for fold 2591:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2592:  0.5380952380952381\n",
      "f1  score for fold 2592:  0.3741935483870968\n",
      "recall for fold 2592:  0.38666666666666666\n",
      "precision for fold 2592:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2593:  0.558252427184466\n",
      "f1  score for fold 2593:  0.43478260869565216\n",
      "recall for fold 2593:  0.4268292682926829\n",
      "precision for fold 2593:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2594:  0.5284974093264249\n",
      "f1  score for fold 2594:  0.4347826086956522\n",
      "recall for fold 2594:  0.40229885057471265\n",
      "precision for fold 2594:  0.47297297297297297\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2595:  0.5789473684210527\n",
      "f1  score for fold 2595:  0.44303797468354433\n",
      "recall for fold 2595:  0.44871794871794873\n",
      "precision for fold 2595:  0.4375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2596:  0.5789473684210527\n",
      "f1  score for fold 2596:  0.42857142857142855\n",
      "recall for fold 2596:  0.44594594594594594\n",
      "precision for fold 2596:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2597:  0.5285714285714286\n",
      "f1  score for fold 2597:  0.3612903225806451\n",
      "recall for fold 2597:  0.37333333333333335\n",
      "precision for fold 2597:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2598:  0.5485436893203883\n",
      "f1  score for fold 2598:  0.42236024844720493\n",
      "recall for fold 2598:  0.4146341463414634\n",
      "precision for fold 2598:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2599:  0.49740932642487046\n",
      "f1  score for fold 2599:  0.39751552795031053\n",
      "recall for fold 2599:  0.367816091954023\n",
      "precision for fold 2599:  0.43243243243243246\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2600:  0.48325358851674644\n",
      "f1  score for fold 2600:  0.31645569620253167\n",
      "recall for fold 2600:  0.32051282051282054\n",
      "precision for fold 2600:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2601:  0.5215311004784688\n",
      "f1  score for fold 2601:  0.3506493506493507\n",
      "recall for fold 2601:  0.36486486486486486\n",
      "precision for fold 2601:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2602:  0.5666666666666667\n",
      "f1  score for fold 2602:  0.41290322580645167\n",
      "recall for fold 2602:  0.4266666666666667\n",
      "precision for fold 2602:  0.4\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2603:  0.5388349514563107\n",
      "f1  score for fold 2603:  0.40993788819875776\n",
      "recall for fold 2603:  0.4024390243902439\n",
      "precision for fold 2603:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2604:  0.48704663212435234\n",
      "f1  score for fold 2604:  0.3850931677018633\n",
      "recall for fold 2604:  0.3563218390804598\n",
      "precision for fold 2604:  0.4189189189189189\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 2605:  0.45454545454545453\n",
      "f1  score for fold 2605:  0.27848101265822783\n",
      "recall for fold 2605:  0.28205128205128205\n",
      "precision for fold 2605:  0.275\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2606:  0.5023923444976076\n",
      "f1  score for fold 2606:  0.3246753246753247\n",
      "recall for fold 2606:  0.33783783783783783\n",
      "precision for fold 2606:  0.3125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2607:  0.5285714285714286\n",
      "f1  score for fold 2607:  0.3612903225806451\n",
      "recall for fold 2607:  0.37333333333333335\n",
      "precision for fold 2607:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2608:  0.5388349514563107\n",
      "f1  score for fold 2608:  0.40993788819875776\n",
      "recall for fold 2608:  0.4024390243902439\n",
      "precision for fold 2608:  0.4177215189873418\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 2609:  0.43523316062176165\n",
      "f1  score for fold 2609:  0.3229813664596274\n",
      "recall for fold 2609:  0.2988505747126437\n",
      "precision for fold 2609:  0.35135135135135137\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2610:  0.5598086124401914\n",
      "f1  score for fold 2610:  0.4177215189873418\n",
      "recall for fold 2610:  0.4230769230769231\n",
      "precision for fold 2610:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2611:  0.5311004784688995\n",
      "f1  score for fold 2611:  0.36363636363636365\n",
      "recall for fold 2611:  0.3783783783783784\n",
      "precision for fold 2611:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2612:  0.5190476190476191\n",
      "f1  score for fold 2612:  0.34838709677419355\n",
      "recall for fold 2612:  0.36\n",
      "precision for fold 2612:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2613:  0.5388349514563107\n",
      "f1  score for fold 2613:  0.40993788819875776\n",
      "recall for fold 2613:  0.4024390243902439\n",
      "precision for fold 2613:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2614:  0.48704663212435234\n",
      "f1  score for fold 2614:  0.3850931677018633\n",
      "recall for fold 2614:  0.3563218390804598\n",
      "precision for fold 2614:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2615:  0.5598086124401914\n",
      "f1  score for fold 2615:  0.4177215189873418\n",
      "recall for fold 2615:  0.4230769230769231\n",
      "precision for fold 2615:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2616:  0.5406698564593302\n",
      "f1  score for fold 2616:  0.37662337662337664\n",
      "recall for fold 2616:  0.3918918918918919\n",
      "precision for fold 2616:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2617:  0.5285714285714286\n",
      "f1  score for fold 2617:  0.3612903225806451\n",
      "recall for fold 2617:  0.37333333333333335\n",
      "precision for fold 2617:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 2618:  0.48058252427184467\n",
      "f1  score for fold 2618:  0.33540372670807456\n",
      "recall for fold 2618:  0.32926829268292684\n",
      "precision for fold 2618:  0.34177215189873417\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2619:  0.5595854922279793\n",
      "f1  score for fold 2619:  0.4720496894409938\n",
      "recall for fold 2619:  0.4367816091954023\n",
      "precision for fold 2619:  0.5135135135135135\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 2620:  0.6076555023923444\n",
      "f1  score for fold 2620:  0.4810126582278481\n",
      "recall for fold 2620:  0.48717948717948717\n",
      "precision for fold 2620:  0.475\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2621:  0.5406698564593302\n",
      "f1  score for fold 2621:  0.37662337662337664\n",
      "recall for fold 2621:  0.3918918918918919\n",
      "precision for fold 2621:  0.3625\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2622:  0.5857142857142857\n",
      "f1  score for fold 2622:  0.43870967741935485\n",
      "recall for fold 2622:  0.4533333333333333\n",
      "precision for fold 2622:  0.425\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2623:  0.5194174757281553\n",
      "f1  score for fold 2623:  0.38509316770186336\n",
      "recall for fold 2623:  0.3780487804878049\n",
      "precision for fold 2623:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2624:  0.5181347150259067\n",
      "f1  score for fold 2624:  0.422360248447205\n",
      "recall for fold 2624:  0.39080459770114945\n",
      "precision for fold 2624:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2625:  0.5406698564593302\n",
      "f1  score for fold 2625:  0.3924050632911393\n",
      "recall for fold 2625:  0.3974358974358974\n",
      "precision for fold 2625:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2626:  0.5215311004784688\n",
      "f1  score for fold 2626:  0.3506493506493507\n",
      "recall for fold 2626:  0.36486486486486486\n",
      "precision for fold 2626:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2627:  0.5476190476190477\n",
      "f1  score for fold 2627:  0.38709677419354843\n",
      "recall for fold 2627:  0.4\n",
      "precision for fold 2627:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2628:  0.5194174757281553\n",
      "f1  score for fold 2628:  0.38509316770186336\n",
      "recall for fold 2628:  0.3780487804878049\n",
      "precision for fold 2628:  0.3924050632911392\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 2629:  0.5803108808290155\n",
      "f1  score for fold 2629:  0.49689440993788814\n",
      "recall for fold 2629:  0.45977011494252873\n",
      "precision for fold 2629:  0.5405405405405406\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2630:  0.5598086124401914\n",
      "f1  score for fold 2630:  0.4177215189873418\n",
      "recall for fold 2630:  0.4230769230769231\n",
      "precision for fold 2630:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2631:  0.5311004784688995\n",
      "f1  score for fold 2631:  0.36363636363636365\n",
      "recall for fold 2631:  0.3783783783783784\n",
      "precision for fold 2631:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2632:  0.5476190476190477\n",
      "f1  score for fold 2632:  0.38709677419354843\n",
      "recall for fold 2632:  0.4\n",
      "precision for fold 2632:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2633:  0.470873786407767\n",
      "f1  score for fold 2633:  0.3229813664596273\n",
      "recall for fold 2633:  0.3170731707317073\n",
      "precision for fold 2633:  0.3291139240506329\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2634:  0.46632124352331605\n",
      "f1  score for fold 2634:  0.36024844720496896\n",
      "recall for fold 2634:  0.3333333333333333\n",
      "precision for fold 2634:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2635:  0.49282296650717705\n",
      "f1  score for fold 2635:  0.32911392405063294\n",
      "recall for fold 2635:  0.3333333333333333\n",
      "precision for fold 2635:  0.325\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2636:  0.49282296650717705\n",
      "f1  score for fold 2636:  0.3116883116883117\n",
      "recall for fold 2636:  0.32432432432432434\n",
      "precision for fold 2636:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2637:  0.5095238095238095\n",
      "f1  score for fold 2637:  0.335483870967742\n",
      "recall for fold 2637:  0.3466666666666667\n",
      "precision for fold 2637:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2638:  0.5679611650485437\n",
      "f1  score for fold 2638:  0.4472049689440994\n",
      "recall for fold 2638:  0.43902439024390244\n",
      "precision for fold 2638:  0.45569620253164556\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2639:  0.46632124352331605\n",
      "f1  score for fold 2639:  0.36024844720496896\n",
      "recall for fold 2639:  0.3333333333333333\n",
      "precision for fold 2639:  0.3918918918918919\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2640:  0.5215311004784688\n",
      "f1  score for fold 2640:  0.36708860759493667\n",
      "recall for fold 2640:  0.3717948717948718\n",
      "precision for fold 2640:  0.3625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2641:  0.569377990430622\n",
      "f1  score for fold 2641:  0.4155844155844156\n",
      "recall for fold 2641:  0.43243243243243246\n",
      "precision for fold 2641:  0.4\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2642:  0.5857142857142857\n",
      "f1  score for fold 2642:  0.43870967741935485\n",
      "recall for fold 2642:  0.4533333333333333\n",
      "precision for fold 2642:  0.425\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2643:  0.5679611650485437\n",
      "f1  score for fold 2643:  0.4472049689440994\n",
      "recall for fold 2643:  0.43902439024390244\n",
      "precision for fold 2643:  0.45569620253164556\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2644:  0.5699481865284974\n",
      "f1  score for fold 2644:  0.48447204968944096\n",
      "recall for fold 2644:  0.4482758620689655\n",
      "precision for fold 2644:  0.527027027027027\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2645:  0.5215311004784688\n",
      "f1  score for fold 2645:  0.36708860759493667\n",
      "recall for fold 2645:  0.3717948717948718\n",
      "precision for fold 2645:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2646:  0.5215311004784688\n",
      "f1  score for fold 2646:  0.3506493506493507\n",
      "recall for fold 2646:  0.36486486486486486\n",
      "precision for fold 2646:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2647:  0.5\n",
      "f1  score for fold 2647:  0.3225806451612903\n",
      "recall for fold 2647:  0.3333333333333333\n",
      "precision for fold 2647:  0.3125\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2648:  0.5679611650485437\n",
      "f1  score for fold 2648:  0.4472049689440994\n",
      "recall for fold 2648:  0.43902439024390244\n",
      "precision for fold 2648:  0.45569620253164556\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 2649:  0.5699481865284974\n",
      "f1  score for fold 2649:  0.48447204968944096\n",
      "recall for fold 2649:  0.4482758620689655\n",
      "precision for fold 2649:  0.527027027027027\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2650:  0.49282296650717705\n",
      "f1  score for fold 2650:  0.32911392405063294\n",
      "recall for fold 2650:  0.3333333333333333\n",
      "precision for fold 2650:  0.325\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 2651:  0.6076555023923444\n",
      "f1  score for fold 2651:  0.4675324675324675\n",
      "recall for fold 2651:  0.4864864864864865\n",
      "precision for fold 2651:  0.45\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2652:  0.5285714285714286\n",
      "f1  score for fold 2652:  0.3612903225806451\n",
      "recall for fold 2652:  0.37333333333333335\n",
      "precision for fold 2652:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2653:  0.49029126213592233\n",
      "f1  score for fold 2653:  0.3478260869565218\n",
      "recall for fold 2653:  0.34146341463414637\n",
      "precision for fold 2653:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2654:  0.49740932642487046\n",
      "f1  score for fold 2654:  0.39751552795031053\n",
      "recall for fold 2654:  0.367816091954023\n",
      "precision for fold 2654:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2655:  0.5311004784688995\n",
      "f1  score for fold 2655:  0.37974683544303806\n",
      "recall for fold 2655:  0.38461538461538464\n",
      "precision for fold 2655:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2656:  0.5406698564593302\n",
      "f1  score for fold 2656:  0.37662337662337664\n",
      "recall for fold 2656:  0.3918918918918919\n",
      "precision for fold 2656:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2657:  0.5666666666666667\n",
      "f1  score for fold 2657:  0.41290322580645167\n",
      "recall for fold 2657:  0.4266666666666667\n",
      "precision for fold 2657:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2658:  0.529126213592233\n",
      "f1  score for fold 2658:  0.39751552795031053\n",
      "recall for fold 2658:  0.3902439024390244\n",
      "precision for fold 2658:  0.4050632911392405\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 2659:  0.44559585492227977\n",
      "f1  score for fold 2659:  0.33540372670807456\n",
      "recall for fold 2659:  0.3103448275862069\n",
      "precision for fold 2659:  0.36486486486486486\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2660:  0.5023923444976076\n",
      "f1  score for fold 2660:  0.34177215189873417\n",
      "recall for fold 2660:  0.34615384615384615\n",
      "precision for fold 2660:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2661:  0.5311004784688995\n",
      "f1  score for fold 2661:  0.36363636363636365\n",
      "recall for fold 2661:  0.3783783783783784\n",
      "precision for fold 2661:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2662:  0.5\n",
      "f1  score for fold 2662:  0.3225806451612903\n",
      "recall for fold 2662:  0.3333333333333333\n",
      "precision for fold 2662:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2663:  0.529126213592233\n",
      "f1  score for fold 2663:  0.39751552795031053\n",
      "recall for fold 2663:  0.3902439024390244\n",
      "precision for fold 2663:  0.4050632911392405\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 2664:  0.44559585492227977\n",
      "f1  score for fold 2664:  0.33540372670807456\n",
      "recall for fold 2664:  0.3103448275862069\n",
      "precision for fold 2664:  0.36486486486486486\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2665:  0.5406698564593302\n",
      "f1  score for fold 2665:  0.3924050632911393\n",
      "recall for fold 2665:  0.3974358974358974\n",
      "precision for fold 2665:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2666:  0.5215311004784688\n",
      "f1  score for fold 2666:  0.3506493506493507\n",
      "recall for fold 2666:  0.36486486486486486\n",
      "precision for fold 2666:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2667:  0.5285714285714286\n",
      "f1  score for fold 2667:  0.3612903225806451\n",
      "recall for fold 2667:  0.37333333333333335\n",
      "precision for fold 2667:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2668:  0.5388349514563107\n",
      "f1  score for fold 2668:  0.40993788819875776\n",
      "recall for fold 2668:  0.4024390243902439\n",
      "precision for fold 2668:  0.4177215189873418\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 2669:  0.43523316062176165\n",
      "f1  score for fold 2669:  0.3229813664596274\n",
      "recall for fold 2669:  0.2988505747126437\n",
      "precision for fold 2669:  0.35135135135135137\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2670:  0.5215311004784688\n",
      "f1  score for fold 2670:  0.36708860759493667\n",
      "recall for fold 2670:  0.3717948717948718\n",
      "precision for fold 2670:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2671:  0.5502392344497608\n",
      "f1  score for fold 2671:  0.3896103896103896\n",
      "recall for fold 2671:  0.40540540540540543\n",
      "precision for fold 2671:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2672:  0.5476190476190477\n",
      "f1  score for fold 2672:  0.38709677419354843\n",
      "recall for fold 2672:  0.4\n",
      "precision for fold 2672:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2673:  0.5388349514563107\n",
      "f1  score for fold 2673:  0.40993788819875776\n",
      "recall for fold 2673:  0.4024390243902439\n",
      "precision for fold 2673:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2674:  0.538860103626943\n",
      "f1  score for fold 2674:  0.4472049689440994\n",
      "recall for fold 2674:  0.41379310344827586\n",
      "precision for fold 2674:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2675:  0.5215311004784688\n",
      "f1  score for fold 2675:  0.36708860759493667\n",
      "recall for fold 2675:  0.3717948717948718\n",
      "precision for fold 2675:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2676:  0.5598086124401914\n",
      "f1  score for fold 2676:  0.40259740259740256\n",
      "recall for fold 2676:  0.4189189189189189\n",
      "precision for fold 2676:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2677:  0.5190476190476191\n",
      "f1  score for fold 2677:  0.34838709677419355\n",
      "recall for fold 2677:  0.36\n",
      "precision for fold 2677:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2678:  0.5388349514563107\n",
      "f1  score for fold 2678:  0.40993788819875776\n",
      "recall for fold 2678:  0.4024390243902439\n",
      "precision for fold 2678:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2679:  0.5181347150259067\n",
      "f1  score for fold 2679:  0.422360248447205\n",
      "recall for fold 2679:  0.39080459770114945\n",
      "precision for fold 2679:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2680:  0.5406698564593302\n",
      "f1  score for fold 2680:  0.3924050632911393\n",
      "recall for fold 2680:  0.3974358974358974\n",
      "precision for fold 2680:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2681:  0.5215311004784688\n",
      "f1  score for fold 2681:  0.3506493506493507\n",
      "recall for fold 2681:  0.36486486486486486\n",
      "precision for fold 2681:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2682:  0.5857142857142857\n",
      "f1  score for fold 2682:  0.43870967741935485\n",
      "recall for fold 2682:  0.4533333333333333\n",
      "precision for fold 2682:  0.425\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2683:  0.529126213592233\n",
      "f1  score for fold 2683:  0.39751552795031053\n",
      "recall for fold 2683:  0.3902439024390244\n",
      "precision for fold 2683:  0.4050632911392405\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2684:  0.5492227979274611\n",
      "f1  score for fold 2684:  0.45962732919254656\n",
      "recall for fold 2684:  0.42528735632183906\n",
      "precision for fold 2684:  0.5\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2685:  0.48325358851674644\n",
      "f1  score for fold 2685:  0.31645569620253167\n",
      "recall for fold 2685:  0.32051282051282054\n",
      "precision for fold 2685:  0.3125\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2686:  0.48325358851674644\n",
      "f1  score for fold 2686:  0.29870129870129863\n",
      "recall for fold 2686:  0.3108108108108108\n",
      "precision for fold 2686:  0.2875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2687:  0.5095238095238095\n",
      "f1  score for fold 2687:  0.335483870967742\n",
      "recall for fold 2687:  0.3466666666666667\n",
      "precision for fold 2687:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2688:  0.5194174757281553\n",
      "f1  score for fold 2688:  0.38509316770186336\n",
      "recall for fold 2688:  0.3780487804878049\n",
      "precision for fold 2688:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2689:  0.49740932642487046\n",
      "f1  score for fold 2689:  0.39751552795031053\n",
      "recall for fold 2689:  0.367816091954023\n",
      "precision for fold 2689:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2690:  0.5406698564593302\n",
      "f1  score for fold 2690:  0.3924050632911393\n",
      "recall for fold 2690:  0.3974358974358974\n",
      "precision for fold 2690:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2691:  0.5215311004784688\n",
      "f1  score for fold 2691:  0.3506493506493507\n",
      "recall for fold 2691:  0.36486486486486486\n",
      "precision for fold 2691:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2692:  0.5285714285714286\n",
      "f1  score for fold 2692:  0.3612903225806451\n",
      "recall for fold 2692:  0.37333333333333335\n",
      "precision for fold 2692:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2693:  0.5679611650485437\n",
      "f1  score for fold 2693:  0.4472049689440994\n",
      "recall for fold 2693:  0.43902439024390244\n",
      "precision for fold 2693:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2694:  0.5284974093264249\n",
      "f1  score for fold 2694:  0.4347826086956522\n",
      "recall for fold 2694:  0.40229885057471265\n",
      "precision for fold 2694:  0.47297297297297297\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 2695:  0.45454545454545453\n",
      "f1  score for fold 2695:  0.27848101265822783\n",
      "recall for fold 2695:  0.28205128205128205\n",
      "precision for fold 2695:  0.275\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2696:  0.5023923444976076\n",
      "f1  score for fold 2696:  0.3246753246753247\n",
      "recall for fold 2696:  0.33783783783783783\n",
      "precision for fold 2696:  0.3125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2697:  0.5476190476190477\n",
      "f1  score for fold 2697:  0.38709677419354843\n",
      "recall for fold 2697:  0.4\n",
      "precision for fold 2697:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2698:  0.558252427184466\n",
      "f1  score for fold 2698:  0.43478260869565216\n",
      "recall for fold 2698:  0.4268292682926829\n",
      "precision for fold 2698:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2699:  0.5077720207253886\n",
      "f1  score for fold 2699:  0.40993788819875776\n",
      "recall for fold 2699:  0.3793103448275862\n",
      "precision for fold 2699:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2700:  0.5215311004784688\n",
      "f1  score for fold 2700:  0.36708860759493667\n",
      "recall for fold 2700:  0.3717948717948718\n",
      "precision for fold 2700:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2701:  0.5215311004784688\n",
      "f1  score for fold 2701:  0.3506493506493507\n",
      "recall for fold 2701:  0.36486486486486486\n",
      "precision for fold 2701:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2702:  0.5190476190476191\n",
      "f1  score for fold 2702:  0.34838709677419355\n",
      "recall for fold 2702:  0.36\n",
      "precision for fold 2702:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2703:  0.5388349514563107\n",
      "f1  score for fold 2703:  0.40993788819875776\n",
      "recall for fold 2703:  0.4024390243902439\n",
      "precision for fold 2703:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2704:  0.5284974093264249\n",
      "f1  score for fold 2704:  0.4347826086956522\n",
      "recall for fold 2704:  0.40229885057471265\n",
      "precision for fold 2704:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2705:  0.5598086124401914\n",
      "f1  score for fold 2705:  0.4177215189873418\n",
      "recall for fold 2705:  0.4230769230769231\n",
      "precision for fold 2705:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2706:  0.5311004784688995\n",
      "f1  score for fold 2706:  0.36363636363636365\n",
      "recall for fold 2706:  0.3783783783783784\n",
      "precision for fold 2706:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2707:  0.5476190476190477\n",
      "f1  score for fold 2707:  0.38709677419354843\n",
      "recall for fold 2707:  0.4\n",
      "precision for fold 2707:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2708:  0.529126213592233\n",
      "f1  score for fold 2708:  0.39751552795031053\n",
      "recall for fold 2708:  0.3902439024390244\n",
      "precision for fold 2708:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2709:  0.47668393782383417\n",
      "f1  score for fold 2709:  0.3726708074534162\n",
      "recall for fold 2709:  0.3448275862068966\n",
      "precision for fold 2709:  0.40540540540540543\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2710:  0.49282296650717705\n",
      "f1  score for fold 2710:  0.32911392405063294\n",
      "recall for fold 2710:  0.3333333333333333\n",
      "precision for fold 2710:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2711:  0.5406698564593302\n",
      "f1  score for fold 2711:  0.37662337662337664\n",
      "recall for fold 2711:  0.3918918918918919\n",
      "precision for fold 2711:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2712:  0.5190476190476191\n",
      "f1  score for fold 2712:  0.34838709677419355\n",
      "recall for fold 2712:  0.36\n",
      "precision for fold 2712:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2713:  0.5\n",
      "f1  score for fold 2713:  0.3602484472049689\n",
      "recall for fold 2713:  0.35365853658536583\n",
      "precision for fold 2713:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2714:  0.5181347150259067\n",
      "f1  score for fold 2714:  0.422360248447205\n",
      "recall for fold 2714:  0.39080459770114945\n",
      "precision for fold 2714:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2715:  0.5023923444976076\n",
      "f1  score for fold 2715:  0.34177215189873417\n",
      "recall for fold 2715:  0.34615384615384615\n",
      "precision for fold 2715:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2716:  0.5311004784688995\n",
      "f1  score for fold 2716:  0.36363636363636365\n",
      "recall for fold 2716:  0.3783783783783784\n",
      "precision for fold 2716:  0.35\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2717:  0.48095238095238096\n",
      "f1  score for fold 2717:  0.2967741935483871\n",
      "recall for fold 2717:  0.30666666666666664\n",
      "precision for fold 2717:  0.2875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2718:  0.5679611650485437\n",
      "f1  score for fold 2718:  0.4472049689440994\n",
      "recall for fold 2718:  0.43902439024390244\n",
      "precision for fold 2718:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2719:  0.49740932642487046\n",
      "f1  score for fold 2719:  0.39751552795031053\n",
      "recall for fold 2719:  0.367816091954023\n",
      "precision for fold 2719:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2720:  0.5502392344497608\n",
      "f1  score for fold 2720:  0.4050632911392405\n",
      "recall for fold 2720:  0.41025641025641024\n",
      "precision for fold 2720:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2721:  0.5023923444976076\n",
      "f1  score for fold 2721:  0.3246753246753247\n",
      "recall for fold 2721:  0.33783783783783783\n",
      "precision for fold 2721:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2722:  0.5571428571428572\n",
      "f1  score for fold 2722:  0.4000000000000001\n",
      "recall for fold 2722:  0.41333333333333333\n",
      "precision for fold 2722:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2723:  0.5097087378640777\n",
      "f1  score for fold 2723:  0.37267080745341613\n",
      "recall for fold 2723:  0.36585365853658536\n",
      "precision for fold 2723:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2724:  0.5284974093264249\n",
      "f1  score for fold 2724:  0.4347826086956522\n",
      "recall for fold 2724:  0.40229885057471265\n",
      "precision for fold 2724:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2725:  0.5119617224880383\n",
      "f1  score for fold 2725:  0.3544303797468355\n",
      "recall for fold 2725:  0.358974358974359\n",
      "precision for fold 2725:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 2726:  0.569377990430622\n",
      "f1  score for fold 2726:  0.4155844155844156\n",
      "recall for fold 2726:  0.43243243243243246\n",
      "precision for fold 2726:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2727:  0.5476190476190477\n",
      "f1  score for fold 2727:  0.38709677419354843\n",
      "recall for fold 2727:  0.4\n",
      "precision for fold 2727:  0.375\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 2728:  0.587378640776699\n",
      "f1  score for fold 2728:  0.4720496894409938\n",
      "recall for fold 2728:  0.4634146341463415\n",
      "precision for fold 2728:  0.4810126582278481\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2729:  0.5181347150259067\n",
      "f1  score for fold 2729:  0.422360248447205\n",
      "recall for fold 2729:  0.39080459770114945\n",
      "precision for fold 2729:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2730:  0.5406698564593302\n",
      "f1  score for fold 2730:  0.3924050632911393\n",
      "recall for fold 2730:  0.3974358974358974\n",
      "precision for fold 2730:  0.3875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2731:  0.5023923444976076\n",
      "f1  score for fold 2731:  0.3246753246753247\n",
      "recall for fold 2731:  0.33783783783783783\n",
      "precision for fold 2731:  0.3125\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2732:  0.5857142857142857\n",
      "f1  score for fold 2732:  0.43870967741935485\n",
      "recall for fold 2732:  0.4533333333333333\n",
      "precision for fold 2732:  0.425\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2733:  0.5194174757281553\n",
      "f1  score for fold 2733:  0.38509316770186336\n",
      "recall for fold 2733:  0.3780487804878049\n",
      "precision for fold 2733:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2734:  0.5492227979274611\n",
      "f1  score for fold 2734:  0.45962732919254656\n",
      "recall for fold 2734:  0.42528735632183906\n",
      "precision for fold 2734:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2735:  0.5311004784688995\n",
      "f1  score for fold 2735:  0.37974683544303806\n",
      "recall for fold 2735:  0.38461538461538464\n",
      "precision for fold 2735:  0.375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2736:  0.48325358851674644\n",
      "f1  score for fold 2736:  0.29870129870129863\n",
      "recall for fold 2736:  0.3108108108108108\n",
      "precision for fold 2736:  0.2875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2737:  0.49047619047619045\n",
      "f1  score for fold 2737:  0.3096774193548387\n",
      "recall for fold 2737:  0.32\n",
      "precision for fold 2737:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2738:  0.5\n",
      "f1  score for fold 2738:  0.3602484472049689\n",
      "recall for fold 2738:  0.35365853658536583\n",
      "precision for fold 2738:  0.3670886075949367\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 2739:  0.45595854922279794\n",
      "f1  score for fold 2739:  0.3478260869565218\n",
      "recall for fold 2739:  0.3218390804597701\n",
      "precision for fold 2739:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2740:  0.5406698564593302\n",
      "f1  score for fold 2740:  0.3924050632911393\n",
      "recall for fold 2740:  0.3974358974358974\n",
      "precision for fold 2740:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2741:  0.5215311004784688\n",
      "f1  score for fold 2741:  0.3506493506493507\n",
      "recall for fold 2741:  0.36486486486486486\n",
      "precision for fold 2741:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2742:  0.5380952380952381\n",
      "f1  score for fold 2742:  0.3741935483870968\n",
      "recall for fold 2742:  0.38666666666666666\n",
      "precision for fold 2742:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2743:  0.529126213592233\n",
      "f1  score for fold 2743:  0.39751552795031053\n",
      "recall for fold 2743:  0.3902439024390244\n",
      "precision for fold 2743:  0.4050632911392405\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 2744:  0.45595854922279794\n",
      "f1  score for fold 2744:  0.3478260869565218\n",
      "recall for fold 2744:  0.3218390804597701\n",
      "precision for fold 2744:  0.3783783783783784\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2745:  0.5023923444976076\n",
      "f1  score for fold 2745:  0.34177215189873417\n",
      "recall for fold 2745:  0.34615384615384615\n",
      "precision for fold 2745:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2746:  0.5023923444976076\n",
      "f1  score for fold 2746:  0.3246753246753247\n",
      "recall for fold 2746:  0.33783783783783783\n",
      "precision for fold 2746:  0.3125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2747:  0.5666666666666667\n",
      "f1  score for fold 2747:  0.41290322580645167\n",
      "recall for fold 2747:  0.4266666666666667\n",
      "precision for fold 2747:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2748:  0.529126213592233\n",
      "f1  score for fold 2748:  0.39751552795031053\n",
      "recall for fold 2748:  0.3902439024390244\n",
      "precision for fold 2748:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2749:  0.48704663212435234\n",
      "f1  score for fold 2749:  0.3850931677018633\n",
      "recall for fold 2749:  0.3563218390804598\n",
      "precision for fold 2749:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2750:  0.5598086124401914\n",
      "f1  score for fold 2750:  0.4177215189873418\n",
      "recall for fold 2750:  0.4230769230769231\n",
      "precision for fold 2750:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2751:  0.5215311004784688\n",
      "f1  score for fold 2751:  0.3506493506493507\n",
      "recall for fold 2751:  0.36486486486486486\n",
      "precision for fold 2751:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2752:  0.5571428571428572\n",
      "f1  score for fold 2752:  0.4000000000000001\n",
      "recall for fold 2752:  0.41333333333333333\n",
      "precision for fold 2752:  0.3875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2753:  0.470873786407767\n",
      "f1  score for fold 2753:  0.3229813664596273\n",
      "recall for fold 2753:  0.3170731707317073\n",
      "precision for fold 2753:  0.3291139240506329\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 2754:  0.5595854922279793\n",
      "f1  score for fold 2754:  0.4720496894409938\n",
      "recall for fold 2754:  0.4367816091954023\n",
      "precision for fold 2754:  0.5135135135135135\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2755:  0.5119617224880383\n",
      "f1  score for fold 2755:  0.3544303797468355\n",
      "recall for fold 2755:  0.358974358974359\n",
      "precision for fold 2755:  0.35\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 2756:  0.5980861244019139\n",
      "f1  score for fold 2756:  0.45454545454545453\n",
      "recall for fold 2756:  0.47297297297297297\n",
      "precision for fold 2756:  0.4375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2757:  0.5\n",
      "f1  score for fold 2757:  0.3225806451612903\n",
      "recall for fold 2757:  0.3333333333333333\n",
      "precision for fold 2757:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2758:  0.5388349514563107\n",
      "f1  score for fold 2758:  0.40993788819875776\n",
      "recall for fold 2758:  0.4024390243902439\n",
      "precision for fold 2758:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2759:  0.5181347150259067\n",
      "f1  score for fold 2759:  0.422360248447205\n",
      "recall for fold 2759:  0.39080459770114945\n",
      "precision for fold 2759:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2760:  0.5023923444976076\n",
      "f1  score for fold 2760:  0.34177215189873417\n",
      "recall for fold 2760:  0.34615384615384615\n",
      "precision for fold 2760:  0.3375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2761:  0.49282296650717705\n",
      "f1  score for fold 2761:  0.3116883116883117\n",
      "recall for fold 2761:  0.32432432432432434\n",
      "precision for fold 2761:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2762:  0.5476190476190477\n",
      "f1  score for fold 2762:  0.38709677419354843\n",
      "recall for fold 2762:  0.4\n",
      "precision for fold 2762:  0.375\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2763:  0.5776699029126213\n",
      "f1  score for fold 2763:  0.4596273291925466\n",
      "recall for fold 2763:  0.45121951219512196\n",
      "precision for fold 2763:  0.46835443037974683\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2764:  0.5181347150259067\n",
      "f1  score for fold 2764:  0.422360248447205\n",
      "recall for fold 2764:  0.39080459770114945\n",
      "precision for fold 2764:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2765:  0.49282296650717705\n",
      "f1  score for fold 2765:  0.32911392405063294\n",
      "recall for fold 2765:  0.3333333333333333\n",
      "precision for fold 2765:  0.325\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2766:  0.5789473684210527\n",
      "f1  score for fold 2766:  0.42857142857142855\n",
      "recall for fold 2766:  0.44594594594594594\n",
      "precision for fold 2766:  0.4125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2767:  0.5190476190476191\n",
      "f1  score for fold 2767:  0.34838709677419355\n",
      "recall for fold 2767:  0.36\n",
      "precision for fold 2767:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2768:  0.5194174757281553\n",
      "f1  score for fold 2768:  0.38509316770186336\n",
      "recall for fold 2768:  0.3780487804878049\n",
      "precision for fold 2768:  0.3924050632911392\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 2769:  0.6010362694300518\n",
      "f1  score for fold 2769:  0.5217391304347826\n",
      "recall for fold 2769:  0.4827586206896552\n",
      "precision for fold 2769:  0.5675675675675675\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2770:  0.5311004784688995\n",
      "f1  score for fold 2770:  0.37974683544303806\n",
      "recall for fold 2770:  0.38461538461538464\n",
      "precision for fold 2770:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2771:  0.5023923444976076\n",
      "f1  score for fold 2771:  0.3246753246753247\n",
      "recall for fold 2771:  0.33783783783783783\n",
      "precision for fold 2771:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2772:  0.5095238095238095\n",
      "f1  score for fold 2772:  0.335483870967742\n",
      "recall for fold 2772:  0.3466666666666667\n",
      "precision for fold 2772:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2773:  0.5\n",
      "f1  score for fold 2773:  0.3602484472049689\n",
      "recall for fold 2773:  0.35365853658536583\n",
      "precision for fold 2773:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2774:  0.5284974093264249\n",
      "f1  score for fold 2774:  0.4347826086956522\n",
      "recall for fold 2774:  0.40229885057471265\n",
      "precision for fold 2774:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2775:  0.5023923444976076\n",
      "f1  score for fold 2775:  0.34177215189873417\n",
      "recall for fold 2775:  0.34615384615384615\n",
      "precision for fold 2775:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2776:  0.5502392344497608\n",
      "f1  score for fold 2776:  0.3896103896103896\n",
      "recall for fold 2776:  0.40540540540540543\n",
      "precision for fold 2776:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2777:  0.5095238095238095\n",
      "f1  score for fold 2777:  0.335483870967742\n",
      "recall for fold 2777:  0.3466666666666667\n",
      "precision for fold 2777:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2778:  0.5194174757281553\n",
      "f1  score for fold 2778:  0.38509316770186336\n",
      "recall for fold 2778:  0.3780487804878049\n",
      "precision for fold 2778:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2779:  0.49740932642487046\n",
      "f1  score for fold 2779:  0.39751552795031053\n",
      "recall for fold 2779:  0.367816091954023\n",
      "precision for fold 2779:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2780:  0.5119617224880383\n",
      "f1  score for fold 2780:  0.3544303797468355\n",
      "recall for fold 2780:  0.358974358974359\n",
      "precision for fold 2780:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2781:  0.5598086124401914\n",
      "f1  score for fold 2781:  0.40259740259740256\n",
      "recall for fold 2781:  0.4189189189189189\n",
      "precision for fold 2781:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2782:  0.5476190476190477\n",
      "f1  score for fold 2782:  0.38709677419354843\n",
      "recall for fold 2782:  0.4\n",
      "precision for fold 2782:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2783:  0.5679611650485437\n",
      "f1  score for fold 2783:  0.4472049689440994\n",
      "recall for fold 2783:  0.43902439024390244\n",
      "precision for fold 2783:  0.45569620253164556\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2784:  0.538860103626943\n",
      "f1  score for fold 2784:  0.4472049689440994\n",
      "recall for fold 2784:  0.41379310344827586\n",
      "precision for fold 2784:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2785:  0.5215311004784688\n",
      "f1  score for fold 2785:  0.36708860759493667\n",
      "recall for fold 2785:  0.3717948717948718\n",
      "precision for fold 2785:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2786:  0.5215311004784688\n",
      "f1  score for fold 2786:  0.3506493506493507\n",
      "recall for fold 2786:  0.36486486486486486\n",
      "precision for fold 2786:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2787:  0.5095238095238095\n",
      "f1  score for fold 2787:  0.335483870967742\n",
      "recall for fold 2787:  0.3466666666666667\n",
      "precision for fold 2787:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2788:  0.5097087378640777\n",
      "f1  score for fold 2788:  0.37267080745341613\n",
      "recall for fold 2788:  0.36585365853658536\n",
      "precision for fold 2788:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2789:  0.48704663212435234\n",
      "f1  score for fold 2789:  0.3850931677018633\n",
      "recall for fold 2789:  0.3563218390804598\n",
      "precision for fold 2789:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2790:  0.5311004784688995\n",
      "f1  score for fold 2790:  0.37974683544303806\n",
      "recall for fold 2790:  0.38461538461538464\n",
      "precision for fold 2790:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2791:  0.5215311004784688\n",
      "f1  score for fold 2791:  0.3506493506493507\n",
      "recall for fold 2791:  0.36486486486486486\n",
      "precision for fold 2791:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2792:  0.5571428571428572\n",
      "f1  score for fold 2792:  0.4000000000000001\n",
      "recall for fold 2792:  0.41333333333333333\n",
      "precision for fold 2792:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2793:  0.5388349514563107\n",
      "f1  score for fold 2793:  0.40993788819875776\n",
      "recall for fold 2793:  0.4024390243902439\n",
      "precision for fold 2793:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2794:  0.5284974093264249\n",
      "f1  score for fold 2794:  0.4347826086956522\n",
      "recall for fold 2794:  0.40229885057471265\n",
      "precision for fold 2794:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2795:  0.49282296650717705\n",
      "f1  score for fold 2795:  0.32911392405063294\n",
      "recall for fold 2795:  0.3333333333333333\n",
      "precision for fold 2795:  0.325\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2796:  0.5789473684210527\n",
      "f1  score for fold 2796:  0.42857142857142855\n",
      "recall for fold 2796:  0.44594594594594594\n",
      "precision for fold 2796:  0.4125\n",
      "    0   1\n",
      "0  40  35\n",
      "1  40  95\n",
      "Accuracy for fold 2797:  0.6428571428571429\n",
      "f1  score for fold 2797:  0.5161290322580646\n",
      "recall for fold 2797:  0.5333333333333333\n",
      "precision for fold 2797:  0.5\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2798:  0.5\n",
      "f1  score for fold 2798:  0.3602484472049689\n",
      "recall for fold 2798:  0.35365853658536583\n",
      "precision for fold 2798:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2799:  0.5077720207253886\n",
      "f1  score for fold 2799:  0.40993788819875776\n",
      "recall for fold 2799:  0.3793103448275862\n",
      "precision for fold 2799:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2800:  0.5311004784688995\n",
      "f1  score for fold 2800:  0.37974683544303806\n",
      "recall for fold 2800:  0.38461538461538464\n",
      "precision for fold 2800:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2801:  0.5598086124401914\n",
      "f1  score for fold 2801:  0.40259740259740256\n",
      "recall for fold 2801:  0.4189189189189189\n",
      "precision for fold 2801:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2802:  0.5476190476190477\n",
      "f1  score for fold 2802:  0.38709677419354843\n",
      "recall for fold 2802:  0.4\n",
      "precision for fold 2802:  0.375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 2803:  0.46116504854368934\n",
      "f1  score for fold 2803:  0.31055900621118016\n",
      "recall for fold 2803:  0.3048780487804878\n",
      "precision for fold 2803:  0.31645569620253167\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2804:  0.49740932642487046\n",
      "f1  score for fold 2804:  0.39751552795031053\n",
      "recall for fold 2804:  0.367816091954023\n",
      "precision for fold 2804:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2805:  0.5598086124401914\n",
      "f1  score for fold 2805:  0.4177215189873418\n",
      "recall for fold 2805:  0.4230769230769231\n",
      "precision for fold 2805:  0.4125\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 2806:  0.5980861244019139\n",
      "f1  score for fold 2806:  0.45454545454545453\n",
      "recall for fold 2806:  0.47297297297297297\n",
      "precision for fold 2806:  0.4375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2807:  0.48095238095238096\n",
      "f1  score for fold 2807:  0.2967741935483871\n",
      "recall for fold 2807:  0.30666666666666664\n",
      "precision for fold 2807:  0.2875\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 2808:  0.48058252427184467\n",
      "f1  score for fold 2808:  0.33540372670807456\n",
      "recall for fold 2808:  0.32926829268292684\n",
      "precision for fold 2808:  0.34177215189873417\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 2809:  0.45595854922279794\n",
      "f1  score for fold 2809:  0.3478260869565218\n",
      "recall for fold 2809:  0.3218390804597701\n",
      "precision for fold 2809:  0.3783783783783784\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2810:  0.5598086124401914\n",
      "f1  score for fold 2810:  0.4177215189873418\n",
      "recall for fold 2810:  0.4230769230769231\n",
      "precision for fold 2810:  0.4125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2811:  0.5023923444976076\n",
      "f1  score for fold 2811:  0.3246753246753247\n",
      "recall for fold 2811:  0.33783783783783783\n",
      "precision for fold 2811:  0.3125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2812:  0.5666666666666667\n",
      "f1  score for fold 2812:  0.41290322580645167\n",
      "recall for fold 2812:  0.4266666666666667\n",
      "precision for fold 2812:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2813:  0.5097087378640777\n",
      "f1  score for fold 2813:  0.37267080745341613\n",
      "recall for fold 2813:  0.36585365853658536\n",
      "precision for fold 2813:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 2814:  0.45595854922279794\n",
      "f1  score for fold 2814:  0.3478260869565218\n",
      "recall for fold 2814:  0.3218390804597701\n",
      "precision for fold 2814:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2815:  0.5215311004784688\n",
      "f1  score for fold 2815:  0.36708860759493667\n",
      "recall for fold 2815:  0.3717948717948718\n",
      "precision for fold 2815:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2816:  0.5311004784688995\n",
      "f1  score for fold 2816:  0.36363636363636365\n",
      "recall for fold 2816:  0.3783783783783784\n",
      "precision for fold 2816:  0.35\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 2817:  0.5666666666666667\n",
      "f1  score for fold 2817:  0.41290322580645167\n",
      "recall for fold 2817:  0.4266666666666667\n",
      "precision for fold 2817:  0.4\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2818:  0.5194174757281553\n",
      "f1  score for fold 2818:  0.38509316770186336\n",
      "recall for fold 2818:  0.3780487804878049\n",
      "precision for fold 2818:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2819:  0.5181347150259067\n",
      "f1  score for fold 2819:  0.422360248447205\n",
      "recall for fold 2819:  0.39080459770114945\n",
      "precision for fold 2819:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2820:  0.5406698564593302\n",
      "f1  score for fold 2820:  0.3924050632911393\n",
      "recall for fold 2820:  0.3974358974358974\n",
      "precision for fold 2820:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2821:  0.48325358851674644\n",
      "f1  score for fold 2821:  0.29870129870129863\n",
      "recall for fold 2821:  0.3108108108108108\n",
      "precision for fold 2821:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2822:  0.5571428571428572\n",
      "f1  score for fold 2822:  0.4000000000000001\n",
      "recall for fold 2822:  0.41333333333333333\n",
      "precision for fold 2822:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2823:  0.5\n",
      "f1  score for fold 2823:  0.3602484472049689\n",
      "recall for fold 2823:  0.35365853658536583\n",
      "precision for fold 2823:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2824:  0.5181347150259067\n",
      "f1  score for fold 2824:  0.422360248447205\n",
      "recall for fold 2824:  0.39080459770114945\n",
      "precision for fold 2824:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2825:  0.49282296650717705\n",
      "f1  score for fold 2825:  0.32911392405063294\n",
      "recall for fold 2825:  0.3333333333333333\n",
      "precision for fold 2825:  0.325\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 2826:  0.5885167464114832\n",
      "f1  score for fold 2826:  0.44155844155844154\n",
      "recall for fold 2826:  0.4594594594594595\n",
      "precision for fold 2826:  0.425\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2827:  0.49047619047619045\n",
      "f1  score for fold 2827:  0.3096774193548387\n",
      "recall for fold 2827:  0.32\n",
      "precision for fold 2827:  0.3\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2828:  0.49029126213592233\n",
      "f1  score for fold 2828:  0.3478260869565218\n",
      "recall for fold 2828:  0.34146341463414637\n",
      "precision for fold 2828:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2829:  0.49740932642487046\n",
      "f1  score for fold 2829:  0.39751552795031053\n",
      "recall for fold 2829:  0.367816091954023\n",
      "precision for fold 2829:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2830:  0.5502392344497608\n",
      "f1  score for fold 2830:  0.4050632911392405\n",
      "recall for fold 2830:  0.41025641025641024\n",
      "precision for fold 2830:  0.4\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 2831:  0.49282296650717705\n",
      "f1  score for fold 2831:  0.3116883116883117\n",
      "recall for fold 2831:  0.32432432432432434\n",
      "precision for fold 2831:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2832:  0.5\n",
      "f1  score for fold 2832:  0.3225806451612903\n",
      "recall for fold 2832:  0.3333333333333333\n",
      "precision for fold 2832:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2833:  0.558252427184466\n",
      "f1  score for fold 2833:  0.43478260869565216\n",
      "recall for fold 2833:  0.4268292682926829\n",
      "precision for fold 2833:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 2834:  0.46632124352331605\n",
      "f1  score for fold 2834:  0.36024844720496896\n",
      "recall for fold 2834:  0.3333333333333333\n",
      "precision for fold 2834:  0.3918918918918919\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2835:  0.5406698564593302\n",
      "f1  score for fold 2835:  0.3924050632911393\n",
      "recall for fold 2835:  0.3974358974358974\n",
      "precision for fold 2835:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2836:  0.5598086124401914\n",
      "f1  score for fold 2836:  0.40259740259740256\n",
      "recall for fold 2836:  0.4189189189189189\n",
      "precision for fold 2836:  0.3875\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2837:  0.48095238095238096\n",
      "f1  score for fold 2837:  0.2967741935483871\n",
      "recall for fold 2837:  0.30666666666666664\n",
      "precision for fold 2837:  0.2875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2838:  0.5194174757281553\n",
      "f1  score for fold 2838:  0.38509316770186336\n",
      "recall for fold 2838:  0.3780487804878049\n",
      "precision for fold 2838:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2839:  0.49740932642487046\n",
      "f1  score for fold 2839:  0.39751552795031053\n",
      "recall for fold 2839:  0.367816091954023\n",
      "precision for fold 2839:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2840:  0.5311004784688995\n",
      "f1  score for fold 2840:  0.37974683544303806\n",
      "recall for fold 2840:  0.38461538461538464\n",
      "precision for fold 2840:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2841:  0.5311004784688995\n",
      "f1  score for fold 2841:  0.36363636363636365\n",
      "recall for fold 2841:  0.3783783783783784\n",
      "precision for fold 2841:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2842:  0.5095238095238095\n",
      "f1  score for fold 2842:  0.335483870967742\n",
      "recall for fold 2842:  0.3466666666666667\n",
      "precision for fold 2842:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2843:  0.49029126213592233\n",
      "f1  score for fold 2843:  0.3478260869565218\n",
      "recall for fold 2843:  0.34146341463414637\n",
      "precision for fold 2843:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2844:  0.5077720207253886\n",
      "f1  score for fold 2844:  0.40993788819875776\n",
      "recall for fold 2844:  0.3793103448275862\n",
      "precision for fold 2844:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2845:  0.5215311004784688\n",
      "f1  score for fold 2845:  0.36708860759493667\n",
      "recall for fold 2845:  0.3717948717948718\n",
      "precision for fold 2845:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2846:  0.5789473684210527\n",
      "f1  score for fold 2846:  0.42857142857142855\n",
      "recall for fold 2846:  0.44594594594594594\n",
      "precision for fold 2846:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2847:  0.5285714285714286\n",
      "f1  score for fold 2847:  0.3612903225806451\n",
      "recall for fold 2847:  0.37333333333333335\n",
      "precision for fold 2847:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2848:  0.5\n",
      "f1  score for fold 2848:  0.3602484472049689\n",
      "recall for fold 2848:  0.35365853658536583\n",
      "precision for fold 2848:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2849:  0.5077720207253886\n",
      "f1  score for fold 2849:  0.40993788819875776\n",
      "recall for fold 2849:  0.3793103448275862\n",
      "precision for fold 2849:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2850:  0.5598086124401914\n",
      "f1  score for fold 2850:  0.4177215189873418\n",
      "recall for fold 2850:  0.4230769230769231\n",
      "precision for fold 2850:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2851:  0.5311004784688995\n",
      "f1  score for fold 2851:  0.36363636363636365\n",
      "recall for fold 2851:  0.3783783783783784\n",
      "precision for fold 2851:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2852:  0.5095238095238095\n",
      "f1  score for fold 2852:  0.335483870967742\n",
      "recall for fold 2852:  0.3466666666666667\n",
      "precision for fold 2852:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2853:  0.5194174757281553\n",
      "f1  score for fold 2853:  0.38509316770186336\n",
      "recall for fold 2853:  0.3780487804878049\n",
      "precision for fold 2853:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2854:  0.5181347150259067\n",
      "f1  score for fold 2854:  0.422360248447205\n",
      "recall for fold 2854:  0.39080459770114945\n",
      "precision for fold 2854:  0.4594594594594595\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 2855:  0.6076555023923444\n",
      "f1  score for fold 2855:  0.4810126582278481\n",
      "recall for fold 2855:  0.48717948717948717\n",
      "precision for fold 2855:  0.475\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 2856:  0.5789473684210527\n",
      "f1  score for fold 2856:  0.42857142857142855\n",
      "recall for fold 2856:  0.44594594594594594\n",
      "precision for fold 2856:  0.4125\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2857:  0.5857142857142857\n",
      "f1  score for fold 2857:  0.43870967741935485\n",
      "recall for fold 2857:  0.4533333333333333\n",
      "precision for fold 2857:  0.425\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2858:  0.5776699029126213\n",
      "f1  score for fold 2858:  0.4596273291925466\n",
      "recall for fold 2858:  0.45121951219512196\n",
      "precision for fold 2858:  0.46835443037974683\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2859:  0.5077720207253886\n",
      "f1  score for fold 2859:  0.40993788819875776\n",
      "recall for fold 2859:  0.3793103448275862\n",
      "precision for fold 2859:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2860:  0.5502392344497608\n",
      "f1  score for fold 2860:  0.4050632911392405\n",
      "recall for fold 2860:  0.41025641025641024\n",
      "precision for fold 2860:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2861:  0.5311004784688995\n",
      "f1  score for fold 2861:  0.36363636363636365\n",
      "recall for fold 2861:  0.3783783783783784\n",
      "precision for fold 2861:  0.35\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 2862:  0.4523809523809524\n",
      "f1  score for fold 2862:  0.2580645161290323\n",
      "recall for fold 2862:  0.26666666666666666\n",
      "precision for fold 2862:  0.25\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2863:  0.5\n",
      "f1  score for fold 2863:  0.3602484472049689\n",
      "recall for fold 2863:  0.35365853658536583\n",
      "precision for fold 2863:  0.3670886075949367\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2864:  0.538860103626943\n",
      "f1  score for fold 2864:  0.4472049689440994\n",
      "recall for fold 2864:  0.41379310344827586\n",
      "precision for fold 2864:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2865:  0.5215311004784688\n",
      "f1  score for fold 2865:  0.36708860759493667\n",
      "recall for fold 2865:  0.3717948717948718\n",
      "precision for fold 2865:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2866:  0.5311004784688995\n",
      "f1  score for fold 2866:  0.36363636363636365\n",
      "recall for fold 2866:  0.3783783783783784\n",
      "precision for fold 2866:  0.35\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 2867:  0.4714285714285714\n",
      "f1  score for fold 2867:  0.2838709677419355\n",
      "recall for fold 2867:  0.29333333333333333\n",
      "precision for fold 2867:  0.275\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2868:  0.5194174757281553\n",
      "f1  score for fold 2868:  0.38509316770186336\n",
      "recall for fold 2868:  0.3780487804878049\n",
      "precision for fold 2868:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2869:  0.5284974093264249\n",
      "f1  score for fold 2869:  0.4347826086956522\n",
      "recall for fold 2869:  0.40229885057471265\n",
      "precision for fold 2869:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 2870:  0.569377990430622\n",
      "f1  score for fold 2870:  0.43037974683544306\n",
      "recall for fold 2870:  0.4358974358974359\n",
      "precision for fold 2870:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2871:  0.5023923444976076\n",
      "f1  score for fold 2871:  0.3246753246753247\n",
      "recall for fold 2871:  0.33783783783783783\n",
      "precision for fold 2871:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 2872:  0.5380952380952381\n",
      "f1  score for fold 2872:  0.3741935483870968\n",
      "recall for fold 2872:  0.38666666666666666\n",
      "precision for fold 2872:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2873:  0.5485436893203883\n",
      "f1  score for fold 2873:  0.42236024844720493\n",
      "recall for fold 2873:  0.4146341463414634\n",
      "precision for fold 2873:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2874:  0.538860103626943\n",
      "f1  score for fold 2874:  0.4472049689440994\n",
      "recall for fold 2874:  0.41379310344827586\n",
      "precision for fold 2874:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 2875:  0.49282296650717705\n",
      "f1  score for fold 2875:  0.32911392405063294\n",
      "recall for fold 2875:  0.3333333333333333\n",
      "precision for fold 2875:  0.325\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2876:  0.5311004784688995\n",
      "f1  score for fold 2876:  0.36363636363636365\n",
      "recall for fold 2876:  0.3783783783783784\n",
      "precision for fold 2876:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2877:  0.5761904761904761\n",
      "f1  score for fold 2877:  0.4258064516129032\n",
      "recall for fold 2877:  0.44\n",
      "precision for fold 2877:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2878:  0.5097087378640777\n",
      "f1  score for fold 2878:  0.37267080745341613\n",
      "recall for fold 2878:  0.36585365853658536\n",
      "precision for fold 2878:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2879:  0.48704663212435234\n",
      "f1  score for fold 2879:  0.3850931677018633\n",
      "recall for fold 2879:  0.3563218390804598\n",
      "precision for fold 2879:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2880:  0.5311004784688995\n",
      "f1  score for fold 2880:  0.37974683544303806\n",
      "recall for fold 2880:  0.38461538461538464\n",
      "precision for fold 2880:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2881:  0.5502392344497608\n",
      "f1  score for fold 2881:  0.3896103896103896\n",
      "recall for fold 2881:  0.40540540540540543\n",
      "precision for fold 2881:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2882:  0.5571428571428572\n",
      "f1  score for fold 2882:  0.4000000000000001\n",
      "recall for fold 2882:  0.41333333333333333\n",
      "precision for fold 2882:  0.3875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2883:  0.558252427184466\n",
      "f1  score for fold 2883:  0.43478260869565216\n",
      "recall for fold 2883:  0.4268292682926829\n",
      "precision for fold 2883:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2884:  0.5284974093264249\n",
      "f1  score for fold 2884:  0.4347826086956522\n",
      "recall for fold 2884:  0.40229885057471265\n",
      "precision for fold 2884:  0.47297297297297297\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 2885:  0.46411483253588515\n",
      "f1  score for fold 2885:  0.2911392405063291\n",
      "recall for fold 2885:  0.2948717948717949\n",
      "precision for fold 2885:  0.2875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2886:  0.5598086124401914\n",
      "f1  score for fold 2886:  0.40259740259740256\n",
      "recall for fold 2886:  0.4189189189189189\n",
      "precision for fold 2886:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2887:  0.49047619047619045\n",
      "f1  score for fold 2887:  0.3096774193548387\n",
      "recall for fold 2887:  0.32\n",
      "precision for fold 2887:  0.3\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 2888:  0.5970873786407767\n",
      "f1  score for fold 2888:  0.484472049689441\n",
      "recall for fold 2888:  0.47560975609756095\n",
      "precision for fold 2888:  0.4936708860759494\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 2889:  0.5906735751295337\n",
      "f1  score for fold 2889:  0.5093167701863355\n",
      "recall for fold 2889:  0.47126436781609193\n",
      "precision for fold 2889:  0.5540540540540541\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2890:  0.5215311004784688\n",
      "f1  score for fold 2890:  0.36708860759493667\n",
      "recall for fold 2890:  0.3717948717948718\n",
      "precision for fold 2890:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2891:  0.5598086124401914\n",
      "f1  score for fold 2891:  0.40259740259740256\n",
      "recall for fold 2891:  0.4189189189189189\n",
      "precision for fold 2891:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 2892:  0.49047619047619045\n",
      "f1  score for fold 2892:  0.3096774193548387\n",
      "recall for fold 2892:  0.32\n",
      "precision for fold 2892:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2893:  0.5\n",
      "f1  score for fold 2893:  0.3602484472049689\n",
      "recall for fold 2893:  0.35365853658536583\n",
      "precision for fold 2893:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2894:  0.49740932642487046\n",
      "f1  score for fold 2894:  0.39751552795031053\n",
      "recall for fold 2894:  0.367816091954023\n",
      "precision for fold 2894:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2895:  0.5598086124401914\n",
      "f1  score for fold 2895:  0.4177215189873418\n",
      "recall for fold 2895:  0.4230769230769231\n",
      "precision for fold 2895:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2896:  0.5502392344497608\n",
      "f1  score for fold 2896:  0.3896103896103896\n",
      "recall for fold 2896:  0.40540540540540543\n",
      "precision for fold 2896:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2897:  0.5095238095238095\n",
      "f1  score for fold 2897:  0.335483870967742\n",
      "recall for fold 2897:  0.3466666666666667\n",
      "precision for fold 2897:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2898:  0.5485436893203883\n",
      "f1  score for fold 2898:  0.42236024844720493\n",
      "recall for fold 2898:  0.4146341463414634\n",
      "precision for fold 2898:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2899:  0.538860103626943\n",
      "f1  score for fold 2899:  0.4472049689440994\n",
      "recall for fold 2899:  0.41379310344827586\n",
      "precision for fold 2899:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2900:  0.5119617224880383\n",
      "f1  score for fold 2900:  0.3544303797468355\n",
      "recall for fold 2900:  0.358974358974359\n",
      "precision for fold 2900:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2901:  0.5023923444976076\n",
      "f1  score for fold 2901:  0.3246753246753247\n",
      "recall for fold 2901:  0.33783783783783783\n",
      "precision for fold 2901:  0.3125\n",
      "    0   1\n",
      "0  40  35\n",
      "1  40  95\n",
      "Accuracy for fold 2902:  0.6428571428571429\n",
      "f1  score for fold 2902:  0.5161290322580646\n",
      "recall for fold 2902:  0.5333333333333333\n",
      "precision for fold 2902:  0.5\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 2903:  0.5\n",
      "f1  score for fold 2903:  0.3602484472049689\n",
      "recall for fold 2903:  0.35365853658536583\n",
      "precision for fold 2903:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2904:  0.5492227979274611\n",
      "f1  score for fold 2904:  0.45962732919254656\n",
      "recall for fold 2904:  0.42528735632183906\n",
      "precision for fold 2904:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2905:  0.5023923444976076\n",
      "f1  score for fold 2905:  0.34177215189873417\n",
      "recall for fold 2905:  0.34615384615384615\n",
      "precision for fold 2905:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2906:  0.5023923444976076\n",
      "f1  score for fold 2906:  0.3246753246753247\n",
      "recall for fold 2906:  0.33783783783783783\n",
      "precision for fold 2906:  0.3125\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2907:  0.5095238095238095\n",
      "f1  score for fold 2907:  0.335483870967742\n",
      "recall for fold 2907:  0.3466666666666667\n",
      "precision for fold 2907:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2908:  0.5485436893203883\n",
      "f1  score for fold 2908:  0.42236024844720493\n",
      "recall for fold 2908:  0.4146341463414634\n",
      "precision for fold 2908:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2909:  0.48704663212435234\n",
      "f1  score for fold 2909:  0.3850931677018633\n",
      "recall for fold 2909:  0.3563218390804598\n",
      "precision for fold 2909:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2910:  0.5119617224880383\n",
      "f1  score for fold 2910:  0.3544303797468355\n",
      "recall for fold 2910:  0.358974358974359\n",
      "precision for fold 2910:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2911:  0.5311004784688995\n",
      "f1  score for fold 2911:  0.36363636363636365\n",
      "recall for fold 2911:  0.3783783783783784\n",
      "precision for fold 2911:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 2912:  0.5285714285714286\n",
      "f1  score for fold 2912:  0.3612903225806451\n",
      "recall for fold 2912:  0.37333333333333335\n",
      "precision for fold 2912:  0.35\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2913:  0.558252427184466\n",
      "f1  score for fold 2913:  0.43478260869565216\n",
      "recall for fold 2913:  0.4268292682926829\n",
      "precision for fold 2913:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2914:  0.48704663212435234\n",
      "f1  score for fold 2914:  0.3850931677018633\n",
      "recall for fold 2914:  0.3563218390804598\n",
      "precision for fold 2914:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2915:  0.5406698564593302\n",
      "f1  score for fold 2915:  0.3924050632911393\n",
      "recall for fold 2915:  0.3974358974358974\n",
      "precision for fold 2915:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2916:  0.5406698564593302\n",
      "f1  score for fold 2916:  0.37662337662337664\n",
      "recall for fold 2916:  0.3918918918918919\n",
      "precision for fold 2916:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2917:  0.5476190476190477\n",
      "f1  score for fold 2917:  0.38709677419354843\n",
      "recall for fold 2917:  0.4\n",
      "precision for fold 2917:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2918:  0.5679611650485437\n",
      "f1  score for fold 2918:  0.4472049689440994\n",
      "recall for fold 2918:  0.43902439024390244\n",
      "precision for fold 2918:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2919:  0.49740932642487046\n",
      "f1  score for fold 2919:  0.39751552795031053\n",
      "recall for fold 2919:  0.367816091954023\n",
      "precision for fold 2919:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2920:  0.5502392344497608\n",
      "f1  score for fold 2920:  0.4050632911392405\n",
      "recall for fold 2920:  0.41025641025641024\n",
      "precision for fold 2920:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2921:  0.5502392344497608\n",
      "f1  score for fold 2921:  0.3896103896103896\n",
      "recall for fold 2921:  0.40540540540540543\n",
      "precision for fold 2921:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2922:  0.5476190476190477\n",
      "f1  score for fold 2922:  0.38709677419354843\n",
      "recall for fold 2922:  0.4\n",
      "precision for fold 2922:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2923:  0.529126213592233\n",
      "f1  score for fold 2923:  0.39751552795031053\n",
      "recall for fold 2923:  0.3902439024390244\n",
      "precision for fold 2923:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2924:  0.5077720207253886\n",
      "f1  score for fold 2924:  0.40993788819875776\n",
      "recall for fold 2924:  0.3793103448275862\n",
      "precision for fold 2924:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2925:  0.5502392344497608\n",
      "f1  score for fold 2925:  0.4050632911392405\n",
      "recall for fold 2925:  0.41025641025641024\n",
      "precision for fold 2925:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2926:  0.5119617224880383\n",
      "f1  score for fold 2926:  0.33766233766233766\n",
      "recall for fold 2926:  0.35135135135135137\n",
      "precision for fold 2926:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2927:  0.5476190476190477\n",
      "f1  score for fold 2927:  0.38709677419354843\n",
      "recall for fold 2927:  0.4\n",
      "precision for fold 2927:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2928:  0.5485436893203883\n",
      "f1  score for fold 2928:  0.42236024844720493\n",
      "recall for fold 2928:  0.4146341463414634\n",
      "precision for fold 2928:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2929:  0.5077720207253886\n",
      "f1  score for fold 2929:  0.40993788819875776\n",
      "recall for fold 2929:  0.3793103448275862\n",
      "precision for fold 2929:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 2930:  0.5119617224880383\n",
      "f1  score for fold 2930:  0.3544303797468355\n",
      "recall for fold 2930:  0.358974358974359\n",
      "precision for fold 2930:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2931:  0.5119617224880383\n",
      "f1  score for fold 2931:  0.33766233766233766\n",
      "recall for fold 2931:  0.35135135135135137\n",
      "precision for fold 2931:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2932:  0.5190476190476191\n",
      "f1  score for fold 2932:  0.34838709677419355\n",
      "recall for fold 2932:  0.36\n",
      "precision for fold 2932:  0.3375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 2933:  0.470873786407767\n",
      "f1  score for fold 2933:  0.3229813664596273\n",
      "recall for fold 2933:  0.3170731707317073\n",
      "precision for fold 2933:  0.3291139240506329\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2934:  0.48704663212435234\n",
      "f1  score for fold 2934:  0.3850931677018633\n",
      "recall for fold 2934:  0.3563218390804598\n",
      "precision for fold 2934:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 2935:  0.5406698564593302\n",
      "f1  score for fold 2935:  0.3924050632911393\n",
      "recall for fold 2935:  0.3974358974358974\n",
      "precision for fold 2935:  0.3875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 2936:  0.5023923444976076\n",
      "f1  score for fold 2936:  0.3246753246753247\n",
      "recall for fold 2936:  0.33783783783783783\n",
      "precision for fold 2936:  0.3125\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 2937:  0.5857142857142857\n",
      "f1  score for fold 2937:  0.43870967741935485\n",
      "recall for fold 2937:  0.4533333333333333\n",
      "precision for fold 2937:  0.425\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2938:  0.529126213592233\n",
      "f1  score for fold 2938:  0.39751552795031053\n",
      "recall for fold 2938:  0.3902439024390244\n",
      "precision for fold 2938:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2939:  0.48704663212435234\n",
      "f1  score for fold 2939:  0.3850931677018633\n",
      "recall for fold 2939:  0.3563218390804598\n",
      "precision for fold 2939:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2940:  0.5502392344497608\n",
      "f1  score for fold 2940:  0.4050632911392405\n",
      "recall for fold 2940:  0.41025641025641024\n",
      "precision for fold 2940:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 2941:  0.5311004784688995\n",
      "f1  score for fold 2941:  0.36363636363636365\n",
      "recall for fold 2941:  0.3783783783783784\n",
      "precision for fold 2941:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2942:  0.5095238095238095\n",
      "f1  score for fold 2942:  0.335483870967742\n",
      "recall for fold 2942:  0.3466666666666667\n",
      "precision for fold 2942:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 2943:  0.5679611650485437\n",
      "f1  score for fold 2943:  0.4472049689440994\n",
      "recall for fold 2943:  0.43902439024390244\n",
      "precision for fold 2943:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2944:  0.5181347150259067\n",
      "f1  score for fold 2944:  0.422360248447205\n",
      "recall for fold 2944:  0.39080459770114945\n",
      "precision for fold 2944:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2945:  0.5215311004784688\n",
      "f1  score for fold 2945:  0.36708860759493667\n",
      "recall for fold 2945:  0.3717948717948718\n",
      "precision for fold 2945:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 2946:  0.47368421052631576\n",
      "f1  score for fold 2946:  0.28571428571428575\n",
      "recall for fold 2946:  0.2972972972972973\n",
      "precision for fold 2946:  0.275\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2947:  0.5571428571428572\n",
      "f1  score for fold 2947:  0.4000000000000001\n",
      "recall for fold 2947:  0.41333333333333333\n",
      "precision for fold 2947:  0.3875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2948:  0.49029126213592233\n",
      "f1  score for fold 2948:  0.3478260869565218\n",
      "recall for fold 2948:  0.34146341463414637\n",
      "precision for fold 2948:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2949:  0.5181347150259067\n",
      "f1  score for fold 2949:  0.422360248447205\n",
      "recall for fold 2949:  0.39080459770114945\n",
      "precision for fold 2949:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 2950:  0.48325358851674644\n",
      "f1  score for fold 2950:  0.31645569620253167\n",
      "recall for fold 2950:  0.32051282051282054\n",
      "precision for fold 2950:  0.3125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 2951:  0.5502392344497608\n",
      "f1  score for fold 2951:  0.3896103896103896\n",
      "recall for fold 2951:  0.40540540540540543\n",
      "precision for fold 2951:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 2952:  0.5\n",
      "f1  score for fold 2952:  0.3225806451612903\n",
      "recall for fold 2952:  0.3333333333333333\n",
      "precision for fold 2952:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 2953:  0.529126213592233\n",
      "f1  score for fold 2953:  0.39751552795031053\n",
      "recall for fold 2953:  0.3902439024390244\n",
      "precision for fold 2953:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2954:  0.5077720207253886\n",
      "f1  score for fold 2954:  0.40993788819875776\n",
      "recall for fold 2954:  0.3793103448275862\n",
      "precision for fold 2954:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2955:  0.5502392344497608\n",
      "f1  score for fold 2955:  0.4050632911392405\n",
      "recall for fold 2955:  0.41025641025641024\n",
      "precision for fold 2955:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2956:  0.5406698564593302\n",
      "f1  score for fold 2956:  0.37662337662337664\n",
      "recall for fold 2956:  0.3918918918918919\n",
      "precision for fold 2956:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2957:  0.5476190476190477\n",
      "f1  score for fold 2957:  0.38709677419354843\n",
      "recall for fold 2957:  0.4\n",
      "precision for fold 2957:  0.375\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 2958:  0.45145631067961167\n",
      "f1  score for fold 2958:  0.29813664596273287\n",
      "recall for fold 2958:  0.2926829268292683\n",
      "precision for fold 2958:  0.3037974683544304\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 2959:  0.48704663212435234\n",
      "f1  score for fold 2959:  0.3850931677018633\n",
      "recall for fold 2959:  0.3563218390804598\n",
      "precision for fold 2959:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2960:  0.5215311004784688\n",
      "f1  score for fold 2960:  0.36708860759493667\n",
      "recall for fold 2960:  0.3717948717948718\n",
      "precision for fold 2960:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 2961:  0.5406698564593302\n",
      "f1  score for fold 2961:  0.37662337662337664\n",
      "recall for fold 2961:  0.3918918918918919\n",
      "precision for fold 2961:  0.3625\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 2962:  0.48095238095238096\n",
      "f1  score for fold 2962:  0.2967741935483871\n",
      "recall for fold 2962:  0.30666666666666664\n",
      "precision for fold 2962:  0.2875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 2963:  0.5097087378640777\n",
      "f1  score for fold 2963:  0.37267080745341613\n",
      "recall for fold 2963:  0.36585365853658536\n",
      "precision for fold 2963:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 2964:  0.5284974093264249\n",
      "f1  score for fold 2964:  0.4347826086956522\n",
      "recall for fold 2964:  0.40229885057471265\n",
      "precision for fold 2964:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 2965:  0.5215311004784688\n",
      "f1  score for fold 2965:  0.36708860759493667\n",
      "recall for fold 2965:  0.3717948717948718\n",
      "precision for fold 2965:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 2966:  0.47368421052631576\n",
      "f1  score for fold 2966:  0.28571428571428575\n",
      "recall for fold 2966:  0.2972972972972973\n",
      "precision for fold 2966:  0.275\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2967:  0.5571428571428572\n",
      "f1  score for fold 2967:  0.4000000000000001\n",
      "recall for fold 2967:  0.41333333333333333\n",
      "precision for fold 2967:  0.3875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 2968:  0.558252427184466\n",
      "f1  score for fold 2968:  0.43478260869565216\n",
      "recall for fold 2968:  0.4268292682926829\n",
      "precision for fold 2968:  0.4430379746835443\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2969:  0.49740932642487046\n",
      "f1  score for fold 2969:  0.39751552795031053\n",
      "recall for fold 2969:  0.367816091954023\n",
      "precision for fold 2969:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 2970:  0.5598086124401914\n",
      "f1  score for fold 2970:  0.4177215189873418\n",
      "recall for fold 2970:  0.4230769230769231\n",
      "precision for fold 2970:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 2971:  0.5598086124401914\n",
      "f1  score for fold 2971:  0.40259740259740256\n",
      "recall for fold 2971:  0.4189189189189189\n",
      "precision for fold 2971:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 2972:  0.5476190476190477\n",
      "f1  score for fold 2972:  0.38709677419354843\n",
      "recall for fold 2972:  0.4\n",
      "precision for fold 2972:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 2973:  0.5194174757281553\n",
      "f1  score for fold 2973:  0.38509316770186336\n",
      "recall for fold 2973:  0.3780487804878049\n",
      "precision for fold 2973:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 2974:  0.5492227979274611\n",
      "f1  score for fold 2974:  0.45962732919254656\n",
      "recall for fold 2974:  0.42528735632183906\n",
      "precision for fold 2974:  0.5\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 2975:  0.5789473684210527\n",
      "f1  score for fold 2975:  0.44303797468354433\n",
      "recall for fold 2975:  0.44871794871794873\n",
      "precision for fold 2975:  0.4375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2976:  0.48325358851674644\n",
      "f1  score for fold 2976:  0.29870129870129863\n",
      "recall for fold 2976:  0.3108108108108108\n",
      "precision for fold 2976:  0.2875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 2977:  0.5190476190476191\n",
      "f1  score for fold 2977:  0.34838709677419355\n",
      "recall for fold 2977:  0.36\n",
      "precision for fold 2977:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 2978:  0.5485436893203883\n",
      "f1  score for fold 2978:  0.42236024844720493\n",
      "recall for fold 2978:  0.4146341463414634\n",
      "precision for fold 2978:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 2979:  0.5181347150259067\n",
      "f1  score for fold 2979:  0.422360248447205\n",
      "recall for fold 2979:  0.39080459770114945\n",
      "precision for fold 2979:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2980:  0.5502392344497608\n",
      "f1  score for fold 2980:  0.4050632911392405\n",
      "recall for fold 2980:  0.41025641025641024\n",
      "precision for fold 2980:  0.4\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2981:  0.5215311004784688\n",
      "f1  score for fold 2981:  0.3506493506493507\n",
      "recall for fold 2981:  0.36486486486486486\n",
      "precision for fold 2981:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2982:  0.5571428571428572\n",
      "f1  score for fold 2982:  0.4000000000000001\n",
      "recall for fold 2982:  0.41333333333333333\n",
      "precision for fold 2982:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 2983:  0.5388349514563107\n",
      "f1  score for fold 2983:  0.40993788819875776\n",
      "recall for fold 2983:  0.4024390243902439\n",
      "precision for fold 2983:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 2984:  0.47668393782383417\n",
      "f1  score for fold 2984:  0.3726708074534162\n",
      "recall for fold 2984:  0.3448275862068966\n",
      "precision for fold 2984:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 2985:  0.5023923444976076\n",
      "f1  score for fold 2985:  0.34177215189873417\n",
      "recall for fold 2985:  0.34615384615384615\n",
      "precision for fold 2985:  0.3375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 2986:  0.48325358851674644\n",
      "f1  score for fold 2986:  0.29870129870129863\n",
      "recall for fold 2986:  0.3108108108108108\n",
      "precision for fold 2986:  0.2875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 2987:  0.5761904761904761\n",
      "f1  score for fold 2987:  0.4258064516129032\n",
      "recall for fold 2987:  0.44\n",
      "precision for fold 2987:  0.4125\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 2988:  0.587378640776699\n",
      "f1  score for fold 2988:  0.4720496894409938\n",
      "recall for fold 2988:  0.4634146341463415\n",
      "precision for fold 2988:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 2989:  0.49740932642487046\n",
      "f1  score for fold 2989:  0.39751552795031053\n",
      "recall for fold 2989:  0.367816091954023\n",
      "precision for fold 2989:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 2990:  0.5502392344497608\n",
      "f1  score for fold 2990:  0.4050632911392405\n",
      "recall for fold 2990:  0.41025641025641024\n",
      "precision for fold 2990:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 2991:  0.5119617224880383\n",
      "f1  score for fold 2991:  0.33766233766233766\n",
      "recall for fold 2991:  0.35135135135135137\n",
      "precision for fold 2991:  0.325\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 2992:  0.5095238095238095\n",
      "f1  score for fold 2992:  0.335483870967742\n",
      "recall for fold 2992:  0.3466666666666667\n",
      "precision for fold 2992:  0.325\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 2993:  0.5776699029126213\n",
      "f1  score for fold 2993:  0.4596273291925466\n",
      "recall for fold 2993:  0.45121951219512196\n",
      "precision for fold 2993:  0.46835443037974683\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 2994:  0.538860103626943\n",
      "f1  score for fold 2994:  0.4472049689440994\n",
      "recall for fold 2994:  0.41379310344827586\n",
      "precision for fold 2994:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 2995:  0.5311004784688995\n",
      "f1  score for fold 2995:  0.37974683544303806\n",
      "recall for fold 2995:  0.38461538461538464\n",
      "precision for fold 2995:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 2996:  0.5215311004784688\n",
      "f1  score for fold 2996:  0.3506493506493507\n",
      "recall for fold 2996:  0.36486486486486486\n",
      "precision for fold 2996:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 2997:  0.5571428571428572\n",
      "f1  score for fold 2997:  0.4000000000000001\n",
      "recall for fold 2997:  0.41333333333333333\n",
      "precision for fold 2997:  0.3875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 2998:  0.49029126213592233\n",
      "f1  score for fold 2998:  0.3478260869565218\n",
      "recall for fold 2998:  0.34146341463414637\n",
      "precision for fold 2998:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 2999:  0.5077720207253886\n",
      "f1  score for fold 2999:  0.40993788819875776\n",
      "recall for fold 2999:  0.3793103448275862\n",
      "precision for fold 2999:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3000:  0.5598086124401914\n",
      "f1  score for fold 3000:  0.4177215189873418\n",
      "recall for fold 3000:  0.4230769230769231\n",
      "precision for fold 3000:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3001:  0.5598086124401914\n",
      "f1  score for fold 3001:  0.40259740259740256\n",
      "recall for fold 3001:  0.4189189189189189\n",
      "precision for fold 3001:  0.3875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3002:  0.5571428571428572\n",
      "f1  score for fold 3002:  0.4000000000000001\n",
      "recall for fold 3002:  0.41333333333333333\n",
      "precision for fold 3002:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3003:  0.529126213592233\n",
      "f1  score for fold 3003:  0.39751552795031053\n",
      "recall for fold 3003:  0.3902439024390244\n",
      "precision for fold 3003:  0.4050632911392405\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 3004:  0.5906735751295337\n",
      "f1  score for fold 3004:  0.5093167701863355\n",
      "recall for fold 3004:  0.47126436781609193\n",
      "precision for fold 3004:  0.5540540540540541\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3005:  0.5311004784688995\n",
      "f1  score for fold 3005:  0.37974683544303806\n",
      "recall for fold 3005:  0.38461538461538464\n",
      "precision for fold 3005:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3006:  0.569377990430622\n",
      "f1  score for fold 3006:  0.4155844155844156\n",
      "recall for fold 3006:  0.43243243243243246\n",
      "precision for fold 3006:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3007:  0.5285714285714286\n",
      "f1  score for fold 3007:  0.3612903225806451\n",
      "recall for fold 3007:  0.37333333333333335\n",
      "precision for fold 3007:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3008:  0.5194174757281553\n",
      "f1  score for fold 3008:  0.38509316770186336\n",
      "recall for fold 3008:  0.3780487804878049\n",
      "precision for fold 3008:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3009:  0.49740932642487046\n",
      "f1  score for fold 3009:  0.39751552795031053\n",
      "recall for fold 3009:  0.367816091954023\n",
      "precision for fold 3009:  0.43243243243243246\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3010:  0.5789473684210527\n",
      "f1  score for fold 3010:  0.44303797468354433\n",
      "recall for fold 3010:  0.44871794871794873\n",
      "precision for fold 3010:  0.4375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3011:  0.5023923444976076\n",
      "f1  score for fold 3011:  0.3246753246753247\n",
      "recall for fold 3011:  0.33783783783783783\n",
      "precision for fold 3011:  0.3125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3012:  0.5476190476190477\n",
      "f1  score for fold 3012:  0.38709677419354843\n",
      "recall for fold 3012:  0.4\n",
      "precision for fold 3012:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3013:  0.5194174757281553\n",
      "f1  score for fold 3013:  0.38509316770186336\n",
      "recall for fold 3013:  0.3780487804878049\n",
      "precision for fold 3013:  0.3924050632911392\n",
      "    0   1\n",
      "0  41  46\n",
      "1  33  73\n",
      "Accuracy for fold 3014:  0.5906735751295337\n",
      "f1  score for fold 3014:  0.5093167701863355\n",
      "recall for fold 3014:  0.47126436781609193\n",
      "precision for fold 3014:  0.5540540540540541\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3015:  0.5023923444976076\n",
      "f1  score for fold 3015:  0.34177215189873417\n",
      "recall for fold 3015:  0.34615384615384615\n",
      "precision for fold 3015:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3016:  0.5502392344497608\n",
      "f1  score for fold 3016:  0.3896103896103896\n",
      "recall for fold 3016:  0.40540540540540543\n",
      "precision for fold 3016:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3017:  0.5761904761904761\n",
      "f1  score for fold 3017:  0.4258064516129032\n",
      "recall for fold 3017:  0.44\n",
      "precision for fold 3017:  0.4125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3018:  0.49029126213592233\n",
      "f1  score for fold 3018:  0.3478260869565218\n",
      "recall for fold 3018:  0.34146341463414637\n",
      "precision for fold 3018:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3019:  0.5077720207253886\n",
      "f1  score for fold 3019:  0.40993788819875776\n",
      "recall for fold 3019:  0.3793103448275862\n",
      "precision for fold 3019:  0.44594594594594594\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 3020:  0.45454545454545453\n",
      "f1  score for fold 3020:  0.27848101265822783\n",
      "recall for fold 3020:  0.28205128205128205\n",
      "precision for fold 3020:  0.275\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3021:  0.5311004784688995\n",
      "f1  score for fold 3021:  0.36363636363636365\n",
      "recall for fold 3021:  0.3783783783783784\n",
      "precision for fold 3021:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3022:  0.5\n",
      "f1  score for fold 3022:  0.3225806451612903\n",
      "recall for fold 3022:  0.3333333333333333\n",
      "precision for fold 3022:  0.3125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3023:  0.48058252427184467\n",
      "f1  score for fold 3023:  0.33540372670807456\n",
      "recall for fold 3023:  0.32926829268292684\n",
      "precision for fold 3023:  0.34177215189873417\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3024:  0.5181347150259067\n",
      "f1  score for fold 3024:  0.422360248447205\n",
      "recall for fold 3024:  0.39080459770114945\n",
      "precision for fold 3024:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3025:  0.569377990430622\n",
      "f1  score for fold 3025:  0.43037974683544306\n",
      "recall for fold 3025:  0.4358974358974359\n",
      "precision for fold 3025:  0.425\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3026:  0.5119617224880383\n",
      "f1  score for fold 3026:  0.33766233766233766\n",
      "recall for fold 3026:  0.35135135135135137\n",
      "precision for fold 3026:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3027:  0.5571428571428572\n",
      "f1  score for fold 3027:  0.4000000000000001\n",
      "recall for fold 3027:  0.41333333333333333\n",
      "precision for fold 3027:  0.3875\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3028:  0.46116504854368934\n",
      "f1  score for fold 3028:  0.31055900621118016\n",
      "recall for fold 3028:  0.3048780487804878\n",
      "precision for fold 3028:  0.31645569620253167\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 3029:  0.5699481865284974\n",
      "f1  score for fold 3029:  0.48447204968944096\n",
      "recall for fold 3029:  0.4482758620689655\n",
      "precision for fold 3029:  0.527027027027027\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3030:  0.5311004784688995\n",
      "f1  score for fold 3030:  0.37974683544303806\n",
      "recall for fold 3030:  0.38461538461538464\n",
      "precision for fold 3030:  0.375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3031:  0.5885167464114832\n",
      "f1  score for fold 3031:  0.44155844155844154\n",
      "recall for fold 3031:  0.4594594594594595\n",
      "precision for fold 3031:  0.425\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3032:  0.5190476190476191\n",
      "f1  score for fold 3032:  0.34838709677419355\n",
      "recall for fold 3032:  0.36\n",
      "precision for fold 3032:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3033:  0.48058252427184467\n",
      "f1  score for fold 3033:  0.33540372670807456\n",
      "recall for fold 3033:  0.32926829268292684\n",
      "precision for fold 3033:  0.34177215189873417\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3034:  0.538860103626943\n",
      "f1  score for fold 3034:  0.4472049689440994\n",
      "recall for fold 3034:  0.41379310344827586\n",
      "precision for fold 3034:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3035:  0.5406698564593302\n",
      "f1  score for fold 3035:  0.3924050632911393\n",
      "recall for fold 3035:  0.3974358974358974\n",
      "precision for fold 3035:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3036:  0.5311004784688995\n",
      "f1  score for fold 3036:  0.36363636363636365\n",
      "recall for fold 3036:  0.3783783783783784\n",
      "precision for fold 3036:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3037:  0.5285714285714286\n",
      "f1  score for fold 3037:  0.3612903225806451\n",
      "recall for fold 3037:  0.37333333333333335\n",
      "precision for fold 3037:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3038:  0.5776699029126213\n",
      "f1  score for fold 3038:  0.4596273291925466\n",
      "recall for fold 3038:  0.45121951219512196\n",
      "precision for fold 3038:  0.46835443037974683\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3039:  0.49740932642487046\n",
      "f1  score for fold 3039:  0.39751552795031053\n",
      "recall for fold 3039:  0.367816091954023\n",
      "precision for fold 3039:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3040:  0.5023923444976076\n",
      "f1  score for fold 3040:  0.34177215189873417\n",
      "recall for fold 3040:  0.34615384615384615\n",
      "precision for fold 3040:  0.3375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3041:  0.569377990430622\n",
      "f1  score for fold 3041:  0.4155844155844156\n",
      "recall for fold 3041:  0.43243243243243246\n",
      "precision for fold 3041:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3042:  0.5285714285714286\n",
      "f1  score for fold 3042:  0.3612903225806451\n",
      "recall for fold 3042:  0.37333333333333335\n",
      "precision for fold 3042:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3043:  0.5097087378640777\n",
      "f1  score for fold 3043:  0.37267080745341613\n",
      "recall for fold 3043:  0.36585365853658536\n",
      "precision for fold 3043:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3044:  0.5284974093264249\n",
      "f1  score for fold 3044:  0.4347826086956522\n",
      "recall for fold 3044:  0.40229885057471265\n",
      "precision for fold 3044:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3045:  0.5023923444976076\n",
      "f1  score for fold 3045:  0.34177215189873417\n",
      "recall for fold 3045:  0.34615384615384615\n",
      "precision for fold 3045:  0.3375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3046:  0.5789473684210527\n",
      "f1  score for fold 3046:  0.42857142857142855\n",
      "recall for fold 3046:  0.44594594594594594\n",
      "precision for fold 3046:  0.4125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3047:  0.49047619047619045\n",
      "f1  score for fold 3047:  0.3096774193548387\n",
      "recall for fold 3047:  0.32\n",
      "precision for fold 3047:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3048:  0.5097087378640777\n",
      "f1  score for fold 3048:  0.37267080745341613\n",
      "recall for fold 3048:  0.36585365853658536\n",
      "precision for fold 3048:  0.379746835443038\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 3049:  0.42487046632124353\n",
      "f1  score for fold 3049:  0.3105590062111801\n",
      "recall for fold 3049:  0.28735632183908044\n",
      "precision for fold 3049:  0.33783783783783783\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3050:  0.5406698564593302\n",
      "f1  score for fold 3050:  0.3924050632911393\n",
      "recall for fold 3050:  0.3974358974358974\n",
      "precision for fold 3050:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3051:  0.5311004784688995\n",
      "f1  score for fold 3051:  0.36363636363636365\n",
      "recall for fold 3051:  0.3783783783783784\n",
      "precision for fold 3051:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3052:  0.5095238095238095\n",
      "f1  score for fold 3052:  0.335483870967742\n",
      "recall for fold 3052:  0.3466666666666667\n",
      "precision for fold 3052:  0.325\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 3053:  0.587378640776699\n",
      "f1  score for fold 3053:  0.4720496894409938\n",
      "recall for fold 3053:  0.4634146341463415\n",
      "precision for fold 3053:  0.4810126582278481\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3054:  0.45595854922279794\n",
      "f1  score for fold 3054:  0.3478260869565218\n",
      "recall for fold 3054:  0.3218390804597701\n",
      "precision for fold 3054:  0.3783783783783784\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3055:  0.5502392344497608\n",
      "f1  score for fold 3055:  0.4050632911392405\n",
      "recall for fold 3055:  0.41025641025641024\n",
      "precision for fold 3055:  0.4\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3056:  0.47368421052631576\n",
      "f1  score for fold 3056:  0.28571428571428575\n",
      "recall for fold 3056:  0.2972972972972973\n",
      "precision for fold 3056:  0.275\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3057:  0.5571428571428572\n",
      "f1  score for fold 3057:  0.4000000000000001\n",
      "recall for fold 3057:  0.41333333333333333\n",
      "precision for fold 3057:  0.3875\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3058:  0.48058252427184467\n",
      "f1  score for fold 3058:  0.33540372670807456\n",
      "recall for fold 3058:  0.32926829268292684\n",
      "precision for fold 3058:  0.34177215189873417\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3059:  0.5077720207253886\n",
      "f1  score for fold 3059:  0.40993788819875776\n",
      "recall for fold 3059:  0.3793103448275862\n",
      "precision for fold 3059:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3060:  0.5598086124401914\n",
      "f1  score for fold 3060:  0.4177215189873418\n",
      "recall for fold 3060:  0.4230769230769231\n",
      "precision for fold 3060:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3061:  0.5215311004784688\n",
      "f1  score for fold 3061:  0.3506493506493507\n",
      "recall for fold 3061:  0.36486486486486486\n",
      "precision for fold 3061:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3062:  0.5380952380952381\n",
      "f1  score for fold 3062:  0.3741935483870968\n",
      "recall for fold 3062:  0.38666666666666666\n",
      "precision for fold 3062:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3063:  0.5388349514563107\n",
      "f1  score for fold 3063:  0.40993788819875776\n",
      "recall for fold 3063:  0.4024390243902439\n",
      "precision for fold 3063:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 3064:  0.5595854922279793\n",
      "f1  score for fold 3064:  0.4720496894409938\n",
      "recall for fold 3064:  0.4367816091954023\n",
      "precision for fold 3064:  0.5135135135135135\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3065:  0.5598086124401914\n",
      "f1  score for fold 3065:  0.4177215189873418\n",
      "recall for fold 3065:  0.4230769230769231\n",
      "precision for fold 3065:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3066:  0.5311004784688995\n",
      "f1  score for fold 3066:  0.36363636363636365\n",
      "recall for fold 3066:  0.3783783783783784\n",
      "precision for fold 3066:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3067:  0.5571428571428572\n",
      "f1  score for fold 3067:  0.4000000000000001\n",
      "recall for fold 3067:  0.41333333333333333\n",
      "precision for fold 3067:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3068:  0.5485436893203883\n",
      "f1  score for fold 3068:  0.42236024844720493\n",
      "recall for fold 3068:  0.4146341463414634\n",
      "precision for fold 3068:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3069:  0.5492227979274611\n",
      "f1  score for fold 3069:  0.45962732919254656\n",
      "recall for fold 3069:  0.42528735632183906\n",
      "precision for fold 3069:  0.5\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3070:  0.5502392344497608\n",
      "f1  score for fold 3070:  0.4050632911392405\n",
      "recall for fold 3070:  0.41025641025641024\n",
      "precision for fold 3070:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3071:  0.5502392344497608\n",
      "f1  score for fold 3071:  0.3896103896103896\n",
      "recall for fold 3071:  0.40540540540540543\n",
      "precision for fold 3071:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3072:  0.5476190476190477\n",
      "f1  score for fold 3072:  0.38709677419354843\n",
      "recall for fold 3072:  0.4\n",
      "precision for fold 3072:  0.375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3073:  0.46116504854368934\n",
      "f1  score for fold 3073:  0.31055900621118016\n",
      "recall for fold 3073:  0.3048780487804878\n",
      "precision for fold 3073:  0.31645569620253167\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 3074:  0.43523316062176165\n",
      "f1  score for fold 3074:  0.3229813664596274\n",
      "recall for fold 3074:  0.2988505747126437\n",
      "precision for fold 3074:  0.35135135135135137\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3075:  0.5119617224880383\n",
      "f1  score for fold 3075:  0.3544303797468355\n",
      "recall for fold 3075:  0.358974358974359\n",
      "precision for fold 3075:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3076:  0.5119617224880383\n",
      "f1  score for fold 3076:  0.33766233766233766\n",
      "recall for fold 3076:  0.35135135135135137\n",
      "precision for fold 3076:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3077:  0.5380952380952381\n",
      "f1  score for fold 3077:  0.3741935483870968\n",
      "recall for fold 3077:  0.38666666666666666\n",
      "precision for fold 3077:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3078:  0.5\n",
      "f1  score for fold 3078:  0.3602484472049689\n",
      "recall for fold 3078:  0.35365853658536583\n",
      "precision for fold 3078:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3079:  0.48704663212435234\n",
      "f1  score for fold 3079:  0.3850931677018633\n",
      "recall for fold 3079:  0.3563218390804598\n",
      "precision for fold 3079:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3080:  0.5311004784688995\n",
      "f1  score for fold 3080:  0.37974683544303806\n",
      "recall for fold 3080:  0.38461538461538464\n",
      "precision for fold 3080:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3081:  0.5406698564593302\n",
      "f1  score for fold 3081:  0.37662337662337664\n",
      "recall for fold 3081:  0.3918918918918919\n",
      "precision for fold 3081:  0.3625\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3082:  0.5\n",
      "f1  score for fold 3082:  0.3225806451612903\n",
      "recall for fold 3082:  0.3333333333333333\n",
      "precision for fold 3082:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3083:  0.529126213592233\n",
      "f1  score for fold 3083:  0.39751552795031053\n",
      "recall for fold 3083:  0.3902439024390244\n",
      "precision for fold 3083:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3084:  0.5181347150259067\n",
      "f1  score for fold 3084:  0.422360248447205\n",
      "recall for fold 3084:  0.39080459770114945\n",
      "precision for fold 3084:  0.4594594594594595\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 3085:  0.5980861244019139\n",
      "f1  score for fold 3085:  0.46835443037974683\n",
      "recall for fold 3085:  0.47435897435897434\n",
      "precision for fold 3085:  0.4625\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3086:  0.5885167464114832\n",
      "f1  score for fold 3086:  0.44155844155844154\n",
      "recall for fold 3086:  0.4594594594594595\n",
      "precision for fold 3086:  0.425\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3087:  0.5285714285714286\n",
      "f1  score for fold 3087:  0.3612903225806451\n",
      "recall for fold 3087:  0.37333333333333335\n",
      "precision for fold 3087:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3088:  0.5388349514563107\n",
      "f1  score for fold 3088:  0.40993788819875776\n",
      "recall for fold 3088:  0.4024390243902439\n",
      "precision for fold 3088:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3089:  0.47668393782383417\n",
      "f1  score for fold 3089:  0.3726708074534162\n",
      "recall for fold 3089:  0.3448275862068966\n",
      "precision for fold 3089:  0.40540540540540543\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3090:  0.48325358851674644\n",
      "f1  score for fold 3090:  0.31645569620253167\n",
      "recall for fold 3090:  0.32051282051282054\n",
      "precision for fold 3090:  0.3125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3091:  0.5598086124401914\n",
      "f1  score for fold 3091:  0.40259740259740256\n",
      "recall for fold 3091:  0.4189189189189189\n",
      "precision for fold 3091:  0.3875\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 3092:  0.4523809523809524\n",
      "f1  score for fold 3092:  0.2580645161290323\n",
      "recall for fold 3092:  0.26666666666666666\n",
      "precision for fold 3092:  0.25\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3093:  0.5679611650485437\n",
      "f1  score for fold 3093:  0.4472049689440994\n",
      "recall for fold 3093:  0.43902439024390244\n",
      "precision for fold 3093:  0.45569620253164556\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3094:  0.46632124352331605\n",
      "f1  score for fold 3094:  0.36024844720496896\n",
      "recall for fold 3094:  0.3333333333333333\n",
      "precision for fold 3094:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3095:  0.5023923444976076\n",
      "f1  score for fold 3095:  0.34177215189873417\n",
      "recall for fold 3095:  0.34615384615384615\n",
      "precision for fold 3095:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3096:  0.5406698564593302\n",
      "f1  score for fold 3096:  0.37662337662337664\n",
      "recall for fold 3096:  0.3918918918918919\n",
      "precision for fold 3096:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3097:  0.5476190476190477\n",
      "f1  score for fold 3097:  0.38709677419354843\n",
      "recall for fold 3097:  0.4\n",
      "precision for fold 3097:  0.375\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3098:  0.5776699029126213\n",
      "f1  score for fold 3098:  0.4596273291925466\n",
      "recall for fold 3098:  0.45121951219512196\n",
      "precision for fold 3098:  0.46835443037974683\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3099:  0.5284974093264249\n",
      "f1  score for fold 3099:  0.4347826086956522\n",
      "recall for fold 3099:  0.40229885057471265\n",
      "precision for fold 3099:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3100:  0.5215311004784688\n",
      "f1  score for fold 3100:  0.36708860759493667\n",
      "recall for fold 3100:  0.3717948717948718\n",
      "precision for fold 3100:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3101:  0.5598086124401914\n",
      "f1  score for fold 3101:  0.40259740259740256\n",
      "recall for fold 3101:  0.4189189189189189\n",
      "precision for fold 3101:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3102:  0.5380952380952381\n",
      "f1  score for fold 3102:  0.3741935483870968\n",
      "recall for fold 3102:  0.38666666666666666\n",
      "precision for fold 3102:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3103:  0.5194174757281553\n",
      "f1  score for fold 3103:  0.38509316770186336\n",
      "recall for fold 3103:  0.3780487804878049\n",
      "precision for fold 3103:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3104:  0.5181347150259067\n",
      "f1  score for fold 3104:  0.422360248447205\n",
      "recall for fold 3104:  0.39080459770114945\n",
      "precision for fold 3104:  0.4594594594594595\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 3105:  0.5980861244019139\n",
      "f1  score for fold 3105:  0.46835443037974683\n",
      "recall for fold 3105:  0.47435897435897434\n",
      "precision for fold 3105:  0.4625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3106:  0.5406698564593302\n",
      "f1  score for fold 3106:  0.37662337662337664\n",
      "recall for fold 3106:  0.3918918918918919\n",
      "precision for fold 3106:  0.3625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3107:  0.5761904761904761\n",
      "f1  score for fold 3107:  0.4258064516129032\n",
      "recall for fold 3107:  0.44\n",
      "precision for fold 3107:  0.4125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3108:  0.529126213592233\n",
      "f1  score for fold 3108:  0.39751552795031053\n",
      "recall for fold 3108:  0.3902439024390244\n",
      "precision for fold 3108:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3109:  0.5284974093264249\n",
      "f1  score for fold 3109:  0.4347826086956522\n",
      "recall for fold 3109:  0.40229885057471265\n",
      "precision for fold 3109:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3110:  0.5311004784688995\n",
      "f1  score for fold 3110:  0.37974683544303806\n",
      "recall for fold 3110:  0.38461538461538464\n",
      "precision for fold 3110:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3111:  0.5502392344497608\n",
      "f1  score for fold 3111:  0.3896103896103896\n",
      "recall for fold 3111:  0.40540540540540543\n",
      "precision for fold 3111:  0.375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3112:  0.49047619047619045\n",
      "f1  score for fold 3112:  0.3096774193548387\n",
      "recall for fold 3112:  0.32\n",
      "precision for fold 3112:  0.3\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3113:  0.529126213592233\n",
      "f1  score for fold 3113:  0.39751552795031053\n",
      "recall for fold 3113:  0.3902439024390244\n",
      "precision for fold 3113:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3114:  0.47668393782383417\n",
      "f1  score for fold 3114:  0.3726708074534162\n",
      "recall for fold 3114:  0.3448275862068966\n",
      "precision for fold 3114:  0.40540540540540543\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3115:  0.5119617224880383\n",
      "f1  score for fold 3115:  0.3544303797468355\n",
      "recall for fold 3115:  0.358974358974359\n",
      "precision for fold 3115:  0.35\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3116:  0.5215311004784688\n",
      "f1  score for fold 3116:  0.3506493506493507\n",
      "recall for fold 3116:  0.36486486486486486\n",
      "precision for fold 3116:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3117:  0.5285714285714286\n",
      "f1  score for fold 3117:  0.3612903225806451\n",
      "recall for fold 3117:  0.37333333333333335\n",
      "precision for fold 3117:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3118:  0.529126213592233\n",
      "f1  score for fold 3118:  0.39751552795031053\n",
      "recall for fold 3118:  0.3902439024390244\n",
      "precision for fold 3118:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3119:  0.49740932642487046\n",
      "f1  score for fold 3119:  0.39751552795031053\n",
      "recall for fold 3119:  0.367816091954023\n",
      "precision for fold 3119:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3120:  0.5023923444976076\n",
      "f1  score for fold 3120:  0.34177215189873417\n",
      "recall for fold 3120:  0.34615384615384615\n",
      "precision for fold 3120:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3121:  0.5502392344497608\n",
      "f1  score for fold 3121:  0.3896103896103896\n",
      "recall for fold 3121:  0.40540540540540543\n",
      "precision for fold 3121:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3122:  0.5476190476190477\n",
      "f1  score for fold 3122:  0.38709677419354843\n",
      "recall for fold 3122:  0.4\n",
      "precision for fold 3122:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3123:  0.470873786407767\n",
      "f1  score for fold 3123:  0.3229813664596273\n",
      "recall for fold 3123:  0.3170731707317073\n",
      "precision for fold 3123:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3124:  0.538860103626943\n",
      "f1  score for fold 3124:  0.4472049689440994\n",
      "recall for fold 3124:  0.41379310344827586\n",
      "precision for fold 3124:  0.4864864864864865\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3125:  0.5406698564593302\n",
      "f1  score for fold 3125:  0.3924050632911393\n",
      "recall for fold 3125:  0.3974358974358974\n",
      "precision for fold 3125:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 3126:  0.48325358851674644\n",
      "f1  score for fold 3126:  0.29870129870129863\n",
      "recall for fold 3126:  0.3108108108108108\n",
      "precision for fold 3126:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3127:  0.5476190476190477\n",
      "f1  score for fold 3127:  0.38709677419354843\n",
      "recall for fold 3127:  0.4\n",
      "precision for fold 3127:  0.375\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3128:  0.5776699029126213\n",
      "f1  score for fold 3128:  0.4596273291925466\n",
      "recall for fold 3128:  0.45121951219512196\n",
      "precision for fold 3128:  0.46835443037974683\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3129:  0.538860103626943\n",
      "f1  score for fold 3129:  0.4472049689440994\n",
      "recall for fold 3129:  0.41379310344827586\n",
      "precision for fold 3129:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3130:  0.5119617224880383\n",
      "f1  score for fold 3130:  0.3544303797468355\n",
      "recall for fold 3130:  0.358974358974359\n",
      "precision for fold 3130:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3131:  0.5406698564593302\n",
      "f1  score for fold 3131:  0.37662337662337664\n",
      "recall for fold 3131:  0.3918918918918919\n",
      "precision for fold 3131:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3132:  0.5380952380952381\n",
      "f1  score for fold 3132:  0.3741935483870968\n",
      "recall for fold 3132:  0.38666666666666666\n",
      "precision for fold 3132:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3133:  0.5\n",
      "f1  score for fold 3133:  0.3602484472049689\n",
      "recall for fold 3133:  0.35365853658536583\n",
      "precision for fold 3133:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3134:  0.5284974093264249\n",
      "f1  score for fold 3134:  0.4347826086956522\n",
      "recall for fold 3134:  0.40229885057471265\n",
      "precision for fold 3134:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3135:  0.5311004784688995\n",
      "f1  score for fold 3135:  0.37974683544303806\n",
      "recall for fold 3135:  0.38461538461538464\n",
      "precision for fold 3135:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3136:  0.5502392344497608\n",
      "f1  score for fold 3136:  0.3896103896103896\n",
      "recall for fold 3136:  0.40540540540540543\n",
      "precision for fold 3136:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3137:  0.5571428571428572\n",
      "f1  score for fold 3137:  0.4000000000000001\n",
      "recall for fold 3137:  0.41333333333333333\n",
      "precision for fold 3137:  0.3875\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3138:  0.5776699029126213\n",
      "f1  score for fold 3138:  0.4596273291925466\n",
      "recall for fold 3138:  0.45121951219512196\n",
      "precision for fold 3138:  0.46835443037974683\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3139:  0.45595854922279794\n",
      "f1  score for fold 3139:  0.3478260869565218\n",
      "recall for fold 3139:  0.3218390804597701\n",
      "precision for fold 3139:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3140:  0.5215311004784688\n",
      "f1  score for fold 3140:  0.36708860759493667\n",
      "recall for fold 3140:  0.3717948717948718\n",
      "precision for fold 3140:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3141:  0.5215311004784688\n",
      "f1  score for fold 3141:  0.3506493506493507\n",
      "recall for fold 3141:  0.36486486486486486\n",
      "precision for fold 3141:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3142:  0.5285714285714286\n",
      "f1  score for fold 3142:  0.3612903225806451\n",
      "recall for fold 3142:  0.37333333333333335\n",
      "precision for fold 3142:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3143:  0.5485436893203883\n",
      "f1  score for fold 3143:  0.42236024844720493\n",
      "recall for fold 3143:  0.4146341463414634\n",
      "precision for fold 3143:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3144:  0.538860103626943\n",
      "f1  score for fold 3144:  0.4472049689440994\n",
      "recall for fold 3144:  0.41379310344827586\n",
      "precision for fold 3144:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3145:  0.5119617224880383\n",
      "f1  score for fold 3145:  0.3544303797468355\n",
      "recall for fold 3145:  0.358974358974359\n",
      "precision for fold 3145:  0.35\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 3146:  0.46411483253588515\n",
      "f1  score for fold 3146:  0.27272727272727276\n",
      "recall for fold 3146:  0.28378378378378377\n",
      "precision for fold 3146:  0.2625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3147:  0.5285714285714286\n",
      "f1  score for fold 3147:  0.3612903225806451\n",
      "recall for fold 3147:  0.37333333333333335\n",
      "precision for fold 3147:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3148:  0.529126213592233\n",
      "f1  score for fold 3148:  0.39751552795031053\n",
      "recall for fold 3148:  0.3902439024390244\n",
      "precision for fold 3148:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3149:  0.49740932642487046\n",
      "f1  score for fold 3149:  0.39751552795031053\n",
      "recall for fold 3149:  0.367816091954023\n",
      "precision for fold 3149:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3150:  0.5502392344497608\n",
      "f1  score for fold 3150:  0.4050632911392405\n",
      "recall for fold 3150:  0.41025641025641024\n",
      "precision for fold 3150:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3151:  0.5119617224880383\n",
      "f1  score for fold 3151:  0.33766233766233766\n",
      "recall for fold 3151:  0.35135135135135137\n",
      "precision for fold 3151:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3152:  0.5476190476190477\n",
      "f1  score for fold 3152:  0.38709677419354843\n",
      "recall for fold 3152:  0.4\n",
      "precision for fold 3152:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3153:  0.5388349514563107\n",
      "f1  score for fold 3153:  0.40993788819875776\n",
      "recall for fold 3153:  0.4024390243902439\n",
      "precision for fold 3153:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3154:  0.5077720207253886\n",
      "f1  score for fold 3154:  0.40993788819875776\n",
      "recall for fold 3154:  0.3793103448275862\n",
      "precision for fold 3154:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3155:  0.5215311004784688\n",
      "f1  score for fold 3155:  0.36708860759493667\n",
      "recall for fold 3155:  0.3717948717948718\n",
      "precision for fold 3155:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3156:  0.5311004784688995\n",
      "f1  score for fold 3156:  0.36363636363636365\n",
      "recall for fold 3156:  0.3783783783783784\n",
      "precision for fold 3156:  0.35\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3157:  0.5666666666666667\n",
      "f1  score for fold 3157:  0.41290322580645167\n",
      "recall for fold 3157:  0.4266666666666667\n",
      "precision for fold 3157:  0.4\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3158:  0.558252427184466\n",
      "f1  score for fold 3158:  0.43478260869565216\n",
      "recall for fold 3158:  0.4268292682926829\n",
      "precision for fold 3158:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3159:  0.538860103626943\n",
      "f1  score for fold 3159:  0.4472049689440994\n",
      "recall for fold 3159:  0.41379310344827586\n",
      "precision for fold 3159:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3160:  0.49282296650717705\n",
      "f1  score for fold 3160:  0.32911392405063294\n",
      "recall for fold 3160:  0.3333333333333333\n",
      "precision for fold 3160:  0.325\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3161:  0.49282296650717705\n",
      "f1  score for fold 3161:  0.3116883116883117\n",
      "recall for fold 3161:  0.32432432432432434\n",
      "precision for fold 3161:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3162:  0.5\n",
      "f1  score for fold 3162:  0.3225806451612903\n",
      "recall for fold 3162:  0.3333333333333333\n",
      "precision for fold 3162:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3163:  0.5\n",
      "f1  score for fold 3163:  0.3602484472049689\n",
      "recall for fold 3163:  0.35365853658536583\n",
      "precision for fold 3163:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3164:  0.49740932642487046\n",
      "f1  score for fold 3164:  0.39751552795031053\n",
      "recall for fold 3164:  0.367816091954023\n",
      "precision for fold 3164:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3165:  0.49282296650717705\n",
      "f1  score for fold 3165:  0.32911392405063294\n",
      "recall for fold 3165:  0.3333333333333333\n",
      "precision for fold 3165:  0.325\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 3166:  0.5980861244019139\n",
      "f1  score for fold 3166:  0.45454545454545453\n",
      "recall for fold 3166:  0.47297297297297297\n",
      "precision for fold 3166:  0.4375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3167:  0.5571428571428572\n",
      "f1  score for fold 3167:  0.4000000000000001\n",
      "recall for fold 3167:  0.41333333333333333\n",
      "precision for fold 3167:  0.3875\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 3168:  0.441747572815534\n",
      "f1  score for fold 3168:  0.28571428571428575\n",
      "recall for fold 3168:  0.2804878048780488\n",
      "precision for fold 3168:  0.2911392405063291\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3169:  0.5284974093264249\n",
      "f1  score for fold 3169:  0.4347826086956522\n",
      "recall for fold 3169:  0.40229885057471265\n",
      "precision for fold 3169:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3170:  0.5502392344497608\n",
      "f1  score for fold 3170:  0.4050632911392405\n",
      "recall for fold 3170:  0.41025641025641024\n",
      "precision for fold 3170:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3171:  0.5311004784688995\n",
      "f1  score for fold 3171:  0.36363636363636365\n",
      "recall for fold 3171:  0.3783783783783784\n",
      "precision for fold 3171:  0.35\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 3172:  0.4714285714285714\n",
      "f1  score for fold 3172:  0.2838709677419355\n",
      "recall for fold 3172:  0.29333333333333333\n",
      "precision for fold 3172:  0.275\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 3173:  0.587378640776699\n",
      "f1  score for fold 3173:  0.4720496894409938\n",
      "recall for fold 3173:  0.4634146341463415\n",
      "precision for fold 3173:  0.4810126582278481\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3174:  0.5284974093264249\n",
      "f1  score for fold 3174:  0.4347826086956522\n",
      "recall for fold 3174:  0.40229885057471265\n",
      "precision for fold 3174:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3175:  0.49282296650717705\n",
      "f1  score for fold 3175:  0.32911392405063294\n",
      "recall for fold 3175:  0.3333333333333333\n",
      "precision for fold 3175:  0.325\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3176:  0.5023923444976076\n",
      "f1  score for fold 3176:  0.3246753246753247\n",
      "recall for fold 3176:  0.33783783783783783\n",
      "precision for fold 3176:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3177:  0.5380952380952381\n",
      "f1  score for fold 3177:  0.3741935483870968\n",
      "recall for fold 3177:  0.38666666666666666\n",
      "precision for fold 3177:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3178:  0.558252427184466\n",
      "f1  score for fold 3178:  0.43478260869565216\n",
      "recall for fold 3178:  0.4268292682926829\n",
      "precision for fold 3178:  0.4430379746835443\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3179:  0.47668393782383417\n",
      "f1  score for fold 3179:  0.3726708074534162\n",
      "recall for fold 3179:  0.3448275862068966\n",
      "precision for fold 3179:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3180:  0.5311004784688995\n",
      "f1  score for fold 3180:  0.37974683544303806\n",
      "recall for fold 3180:  0.38461538461538464\n",
      "precision for fold 3180:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3181:  0.5215311004784688\n",
      "f1  score for fold 3181:  0.3506493506493507\n",
      "recall for fold 3181:  0.36486486486486486\n",
      "precision for fold 3181:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3182:  0.5285714285714286\n",
      "f1  score for fold 3182:  0.3612903225806451\n",
      "recall for fold 3182:  0.37333333333333335\n",
      "precision for fold 3182:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3183:  0.529126213592233\n",
      "f1  score for fold 3183:  0.39751552795031053\n",
      "recall for fold 3183:  0.3902439024390244\n",
      "precision for fold 3183:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3184:  0.49740932642487046\n",
      "f1  score for fold 3184:  0.39751552795031053\n",
      "recall for fold 3184:  0.367816091954023\n",
      "precision for fold 3184:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3185:  0.5215311004784688\n",
      "f1  score for fold 3185:  0.36708860759493667\n",
      "recall for fold 3185:  0.3717948717948718\n",
      "precision for fold 3185:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3186:  0.5311004784688995\n",
      "f1  score for fold 3186:  0.36363636363636365\n",
      "recall for fold 3186:  0.3783783783783784\n",
      "precision for fold 3186:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 3187:  0.5857142857142857\n",
      "f1  score for fold 3187:  0.43870967741935485\n",
      "recall for fold 3187:  0.4533333333333333\n",
      "precision for fold 3187:  0.425\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3188:  0.558252427184466\n",
      "f1  score for fold 3188:  0.43478260869565216\n",
      "recall for fold 3188:  0.4268292682926829\n",
      "precision for fold 3188:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3189:  0.48704663212435234\n",
      "f1  score for fold 3189:  0.3850931677018633\n",
      "recall for fold 3189:  0.3563218390804598\n",
      "precision for fold 3189:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3190:  0.5502392344497608\n",
      "f1  score for fold 3190:  0.4050632911392405\n",
      "recall for fold 3190:  0.41025641025641024\n",
      "precision for fold 3190:  0.4\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3191:  0.5789473684210527\n",
      "f1  score for fold 3191:  0.42857142857142855\n",
      "recall for fold 3191:  0.44594594594594594\n",
      "precision for fold 3191:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3192:  0.5476190476190477\n",
      "f1  score for fold 3192:  0.38709677419354843\n",
      "recall for fold 3192:  0.4\n",
      "precision for fold 3192:  0.375\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 3193:  0.441747572815534\n",
      "f1  score for fold 3193:  0.28571428571428575\n",
      "recall for fold 3193:  0.2804878048780488\n",
      "precision for fold 3193:  0.2911392405063291\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 3194:  0.44559585492227977\n",
      "f1  score for fold 3194:  0.33540372670807456\n",
      "recall for fold 3194:  0.3103448275862069\n",
      "precision for fold 3194:  0.36486486486486486\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3195:  0.5502392344497608\n",
      "f1  score for fold 3195:  0.4050632911392405\n",
      "recall for fold 3195:  0.41025641025641024\n",
      "precision for fold 3195:  0.4\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3196:  0.5215311004784688\n",
      "f1  score for fold 3196:  0.3506493506493507\n",
      "recall for fold 3196:  0.36486486486486486\n",
      "precision for fold 3196:  0.3375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3197:  0.5761904761904761\n",
      "f1  score for fold 3197:  0.4258064516129032\n",
      "recall for fold 3197:  0.44\n",
      "precision for fold 3197:  0.4125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3198:  0.5388349514563107\n",
      "f1  score for fold 3198:  0.40993788819875776\n",
      "recall for fold 3198:  0.4024390243902439\n",
      "precision for fold 3198:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3199:  0.47668393782383417\n",
      "f1  score for fold 3199:  0.3726708074534162\n",
      "recall for fold 3199:  0.3448275862068966\n",
      "precision for fold 3199:  0.40540540540540543\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 3200:  0.6076555023923444\n",
      "f1  score for fold 3200:  0.4810126582278481\n",
      "recall for fold 3200:  0.48717948717948717\n",
      "precision for fold 3200:  0.475\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3201:  0.5119617224880383\n",
      "f1  score for fold 3201:  0.33766233766233766\n",
      "recall for fold 3201:  0.35135135135135137\n",
      "precision for fold 3201:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3202:  0.5285714285714286\n",
      "f1  score for fold 3202:  0.3612903225806451\n",
      "recall for fold 3202:  0.37333333333333335\n",
      "precision for fold 3202:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3203:  0.5485436893203883\n",
      "f1  score for fold 3203:  0.42236024844720493\n",
      "recall for fold 3203:  0.4146341463414634\n",
      "precision for fold 3203:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3204:  0.538860103626943\n",
      "f1  score for fold 3204:  0.4472049689440994\n",
      "recall for fold 3204:  0.41379310344827586\n",
      "precision for fold 3204:  0.4864864864864865\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3205:  0.5023923444976076\n",
      "f1  score for fold 3205:  0.34177215189873417\n",
      "recall for fold 3205:  0.34615384615384615\n",
      "precision for fold 3205:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3206:  0.5406698564593302\n",
      "f1  score for fold 3206:  0.37662337662337664\n",
      "recall for fold 3206:  0.3918918918918919\n",
      "precision for fold 3206:  0.3625\n",
      "    0   1\n",
      "0  19  56\n",
      "1  61  74\n",
      "Accuracy for fold 3207:  0.44285714285714284\n",
      "f1  score for fold 3207:  0.24516129032258063\n",
      "recall for fold 3207:  0.25333333333333335\n",
      "precision for fold 3207:  0.2375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3208:  0.5679611650485437\n",
      "f1  score for fold 3208:  0.4472049689440994\n",
      "recall for fold 3208:  0.43902439024390244\n",
      "precision for fold 3208:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3209:  0.5284974093264249\n",
      "f1  score for fold 3209:  0.4347826086956522\n",
      "recall for fold 3209:  0.40229885057471265\n",
      "precision for fold 3209:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3210:  0.5215311004784688\n",
      "f1  score for fold 3210:  0.36708860759493667\n",
      "recall for fold 3210:  0.3717948717948718\n",
      "precision for fold 3210:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3211:  0.5598086124401914\n",
      "f1  score for fold 3211:  0.40259740259740256\n",
      "recall for fold 3211:  0.4189189189189189\n",
      "precision for fold 3211:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3212:  0.5476190476190477\n",
      "f1  score for fold 3212:  0.38709677419354843\n",
      "recall for fold 3212:  0.4\n",
      "precision for fold 3212:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3213:  0.5485436893203883\n",
      "f1  score for fold 3213:  0.42236024844720493\n",
      "recall for fold 3213:  0.4146341463414634\n",
      "precision for fold 3213:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3214:  0.5077720207253886\n",
      "f1  score for fold 3214:  0.40993788819875776\n",
      "recall for fold 3214:  0.3793103448275862\n",
      "precision for fold 3214:  0.44594594594594594\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3215:  0.49282296650717705\n",
      "f1  score for fold 3215:  0.32911392405063294\n",
      "recall for fold 3215:  0.3333333333333333\n",
      "precision for fold 3215:  0.325\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3216:  0.47368421052631576\n",
      "f1  score for fold 3216:  0.28571428571428575\n",
      "recall for fold 3216:  0.2972972972972973\n",
      "precision for fold 3216:  0.275\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3217:  0.5571428571428572\n",
      "f1  score for fold 3217:  0.4000000000000001\n",
      "recall for fold 3217:  0.41333333333333333\n",
      "precision for fold 3217:  0.3875\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3218:  0.46116504854368934\n",
      "f1  score for fold 3218:  0.31055900621118016\n",
      "recall for fold 3218:  0.3048780487804878\n",
      "precision for fold 3218:  0.31645569620253167\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3219:  0.48704663212435234\n",
      "f1  score for fold 3219:  0.3850931677018633\n",
      "recall for fold 3219:  0.3563218390804598\n",
      "precision for fold 3219:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3220:  0.5311004784688995\n",
      "f1  score for fold 3220:  0.37974683544303806\n",
      "recall for fold 3220:  0.38461538461538464\n",
      "precision for fold 3220:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3221:  0.5119617224880383\n",
      "f1  score for fold 3221:  0.33766233766233766\n",
      "recall for fold 3221:  0.35135135135135137\n",
      "precision for fold 3221:  0.325\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3222:  0.5\n",
      "f1  score for fold 3222:  0.3225806451612903\n",
      "recall for fold 3222:  0.3333333333333333\n",
      "precision for fold 3222:  0.3125\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3223:  0.470873786407767\n",
      "f1  score for fold 3223:  0.3229813664596273\n",
      "recall for fold 3223:  0.3170731707317073\n",
      "precision for fold 3223:  0.3291139240506329\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 3224:  0.5595854922279793\n",
      "f1  score for fold 3224:  0.4720496894409938\n",
      "recall for fold 3224:  0.4367816091954023\n",
      "precision for fold 3224:  0.5135135135135135\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3225:  0.5119617224880383\n",
      "f1  score for fold 3225:  0.3544303797468355\n",
      "recall for fold 3225:  0.358974358974359\n",
      "precision for fold 3225:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3226:  0.5406698564593302\n",
      "f1  score for fold 3226:  0.37662337662337664\n",
      "recall for fold 3226:  0.3918918918918919\n",
      "precision for fold 3226:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3227:  0.5476190476190477\n",
      "f1  score for fold 3227:  0.38709677419354843\n",
      "recall for fold 3227:  0.4\n",
      "precision for fold 3227:  0.375\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3228:  0.470873786407767\n",
      "f1  score for fold 3228:  0.3229813664596273\n",
      "recall for fold 3228:  0.3170731707317073\n",
      "precision for fold 3228:  0.3291139240506329\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3229:  0.5284974093264249\n",
      "f1  score for fold 3229:  0.4347826086956522\n",
      "recall for fold 3229:  0.40229885057471265\n",
      "precision for fold 3229:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3230:  0.5406698564593302\n",
      "f1  score for fold 3230:  0.3924050632911393\n",
      "recall for fold 3230:  0.3974358974358974\n",
      "precision for fold 3230:  0.3875\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3231:  0.5789473684210527\n",
      "f1  score for fold 3231:  0.42857142857142855\n",
      "recall for fold 3231:  0.44594594594594594\n",
      "precision for fold 3231:  0.4125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3232:  0.5190476190476191\n",
      "f1  score for fold 3232:  0.34838709677419355\n",
      "recall for fold 3232:  0.36\n",
      "precision for fold 3232:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3233:  0.5194174757281553\n",
      "f1  score for fold 3233:  0.38509316770186336\n",
      "recall for fold 3233:  0.3780487804878049\n",
      "precision for fold 3233:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3234:  0.49740932642487046\n",
      "f1  score for fold 3234:  0.39751552795031053\n",
      "recall for fold 3234:  0.367816091954023\n",
      "precision for fold 3234:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3235:  0.5215311004784688\n",
      "f1  score for fold 3235:  0.36708860759493667\n",
      "recall for fold 3235:  0.3717948717948718\n",
      "precision for fold 3235:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3236:  0.5789473684210527\n",
      "f1  score for fold 3236:  0.42857142857142855\n",
      "recall for fold 3236:  0.44594594594594594\n",
      "precision for fold 3236:  0.4125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3237:  0.49047619047619045\n",
      "f1  score for fold 3237:  0.3096774193548387\n",
      "recall for fold 3237:  0.32\n",
      "precision for fold 3237:  0.3\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3238:  0.5388349514563107\n",
      "f1  score for fold 3238:  0.40993788819875776\n",
      "recall for fold 3238:  0.4024390243902439\n",
      "precision for fold 3238:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3239:  0.5284974093264249\n",
      "f1  score for fold 3239:  0.4347826086956522\n",
      "recall for fold 3239:  0.40229885057471265\n",
      "precision for fold 3239:  0.47297297297297297\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3240:  0.48325358851674644\n",
      "f1  score for fold 3240:  0.31645569620253167\n",
      "recall for fold 3240:  0.32051282051282054\n",
      "precision for fold 3240:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3241:  0.5215311004784688\n",
      "f1  score for fold 3241:  0.3506493506493507\n",
      "recall for fold 3241:  0.36486486486486486\n",
      "precision for fold 3241:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 3242:  0.5857142857142857\n",
      "f1  score for fold 3242:  0.43870967741935485\n",
      "recall for fold 3242:  0.4533333333333333\n",
      "precision for fold 3242:  0.425\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3243:  0.529126213592233\n",
      "f1  score for fold 3243:  0.39751552795031053\n",
      "recall for fold 3243:  0.3902439024390244\n",
      "precision for fold 3243:  0.4050632911392405\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3244:  0.45595854922279794\n",
      "f1  score for fold 3244:  0.3478260869565218\n",
      "recall for fold 3244:  0.3218390804597701\n",
      "precision for fold 3244:  0.3783783783783784\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3245:  0.5023923444976076\n",
      "f1  score for fold 3245:  0.34177215189873417\n",
      "recall for fold 3245:  0.34615384615384615\n",
      "precision for fold 3245:  0.3375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3246:  0.5885167464114832\n",
      "f1  score for fold 3246:  0.44155844155844154\n",
      "recall for fold 3246:  0.4594594594594595\n",
      "precision for fold 3246:  0.425\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3247:  0.5285714285714286\n",
      "f1  score for fold 3247:  0.3612903225806451\n",
      "recall for fold 3247:  0.37333333333333335\n",
      "precision for fold 3247:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3248:  0.5485436893203883\n",
      "f1  score for fold 3248:  0.42236024844720493\n",
      "recall for fold 3248:  0.4146341463414634\n",
      "precision for fold 3248:  0.43037974683544306\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 3249:  0.5699481865284974\n",
      "f1  score for fold 3249:  0.48447204968944096\n",
      "recall for fold 3249:  0.4482758620689655\n",
      "precision for fold 3249:  0.527027027027027\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3250:  0.46411483253588515\n",
      "f1  score for fold 3250:  0.2911392405063291\n",
      "recall for fold 3250:  0.2948717948717949\n",
      "precision for fold 3250:  0.2875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3251:  0.5406698564593302\n",
      "f1  score for fold 3251:  0.37662337662337664\n",
      "recall for fold 3251:  0.3918918918918919\n",
      "precision for fold 3251:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3252:  0.49047619047619045\n",
      "f1  score for fold 3252:  0.3096774193548387\n",
      "recall for fold 3252:  0.32\n",
      "precision for fold 3252:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3253:  0.5097087378640777\n",
      "f1  score for fold 3253:  0.37267080745341613\n",
      "recall for fold 3253:  0.36585365853658536\n",
      "precision for fold 3253:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3254:  0.5284974093264249\n",
      "f1  score for fold 3254:  0.4347826086956522\n",
      "recall for fold 3254:  0.40229885057471265\n",
      "precision for fold 3254:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3255:  0.5311004784688995\n",
      "f1  score for fold 3255:  0.37974683544303806\n",
      "recall for fold 3255:  0.38461538461538464\n",
      "precision for fold 3255:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3256:  0.5119617224880383\n",
      "f1  score for fold 3256:  0.33766233766233766\n",
      "recall for fold 3256:  0.35135135135135137\n",
      "precision for fold 3256:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3257:  0.5190476190476191\n",
      "f1  score for fold 3257:  0.34838709677419355\n",
      "recall for fold 3257:  0.36\n",
      "precision for fold 3257:  0.3375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3258:  0.49029126213592233\n",
      "f1  score for fold 3258:  0.3478260869565218\n",
      "recall for fold 3258:  0.34146341463414637\n",
      "precision for fold 3258:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3259:  0.49740932642487046\n",
      "f1  score for fold 3259:  0.39751552795031053\n",
      "recall for fold 3259:  0.367816091954023\n",
      "precision for fold 3259:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3260:  0.569377990430622\n",
      "f1  score for fold 3260:  0.43037974683544306\n",
      "recall for fold 3260:  0.4358974358974359\n",
      "precision for fold 3260:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3261:  0.5311004784688995\n",
      "f1  score for fold 3261:  0.36363636363636365\n",
      "recall for fold 3261:  0.3783783783783784\n",
      "precision for fold 3261:  0.35\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3262:  0.5666666666666667\n",
      "f1  score for fold 3262:  0.41290322580645167\n",
      "recall for fold 3262:  0.4266666666666667\n",
      "precision for fold 3262:  0.4\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3263:  0.558252427184466\n",
      "f1  score for fold 3263:  0.43478260869565216\n",
      "recall for fold 3263:  0.4268292682926829\n",
      "precision for fold 3263:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3264:  0.5181347150259067\n",
      "f1  score for fold 3264:  0.422360248447205\n",
      "recall for fold 3264:  0.39080459770114945\n",
      "precision for fold 3264:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3265:  0.5502392344497608\n",
      "f1  score for fold 3265:  0.4050632911392405\n",
      "recall for fold 3265:  0.41025641025641024\n",
      "precision for fold 3265:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3266:  0.5311004784688995\n",
      "f1  score for fold 3266:  0.36363636363636365\n",
      "recall for fold 3266:  0.3783783783783784\n",
      "precision for fold 3266:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3267:  0.5761904761904761\n",
      "f1  score for fold 3267:  0.4258064516129032\n",
      "recall for fold 3267:  0.44\n",
      "precision for fold 3267:  0.4125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3268:  0.48058252427184467\n",
      "f1  score for fold 3268:  0.33540372670807456\n",
      "recall for fold 3268:  0.32926829268292684\n",
      "precision for fold 3268:  0.34177215189873417\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3269:  0.5181347150259067\n",
      "f1  score for fold 3269:  0.422360248447205\n",
      "recall for fold 3269:  0.39080459770114945\n",
      "precision for fold 3269:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3270:  0.5502392344497608\n",
      "f1  score for fold 3270:  0.4050632911392405\n",
      "recall for fold 3270:  0.41025641025641024\n",
      "precision for fold 3270:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3271:  0.5311004784688995\n",
      "f1  score for fold 3271:  0.36363636363636365\n",
      "recall for fold 3271:  0.3783783783783784\n",
      "precision for fold 3271:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3272:  0.5285714285714286\n",
      "f1  score for fold 3272:  0.3612903225806451\n",
      "recall for fold 3272:  0.37333333333333335\n",
      "precision for fold 3272:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3273:  0.5097087378640777\n",
      "f1  score for fold 3273:  0.37267080745341613\n",
      "recall for fold 3273:  0.36585365853658536\n",
      "precision for fold 3273:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3274:  0.46632124352331605\n",
      "f1  score for fold 3274:  0.36024844720496896\n",
      "recall for fold 3274:  0.3333333333333333\n",
      "precision for fold 3274:  0.3918918918918919\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3275:  0.569377990430622\n",
      "f1  score for fold 3275:  0.43037974683544306\n",
      "recall for fold 3275:  0.4358974358974359\n",
      "precision for fold 3275:  0.425\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3276:  0.5406698564593302\n",
      "f1  score for fold 3276:  0.37662337662337664\n",
      "recall for fold 3276:  0.3918918918918919\n",
      "precision for fold 3276:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3277:  0.5095238095238095\n",
      "f1  score for fold 3277:  0.335483870967742\n",
      "recall for fold 3277:  0.3466666666666667\n",
      "precision for fold 3277:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3278:  0.5097087378640777\n",
      "f1  score for fold 3278:  0.37267080745341613\n",
      "recall for fold 3278:  0.36585365853658536\n",
      "precision for fold 3278:  0.379746835443038\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 3279:  0.5699481865284974\n",
      "f1  score for fold 3279:  0.48447204968944096\n",
      "recall for fold 3279:  0.4482758620689655\n",
      "precision for fold 3279:  0.527027027027027\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3280:  0.5311004784688995\n",
      "f1  score for fold 3280:  0.37974683544303806\n",
      "recall for fold 3280:  0.38461538461538464\n",
      "precision for fold 3280:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3281:  0.569377990430622\n",
      "f1  score for fold 3281:  0.4155844155844156\n",
      "recall for fold 3281:  0.43243243243243246\n",
      "precision for fold 3281:  0.4\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3282:  0.5666666666666667\n",
      "f1  score for fold 3282:  0.41290322580645167\n",
      "recall for fold 3282:  0.4266666666666667\n",
      "precision for fold 3282:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3283:  0.5679611650485437\n",
      "f1  score for fold 3283:  0.4472049689440994\n",
      "recall for fold 3283:  0.43902439024390244\n",
      "precision for fold 3283:  0.45569620253164556\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3284:  0.5492227979274611\n",
      "f1  score for fold 3284:  0.45962732919254656\n",
      "recall for fold 3284:  0.42528735632183906\n",
      "precision for fold 3284:  0.5\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3285:  0.46411483253588515\n",
      "f1  score for fold 3285:  0.2911392405063291\n",
      "recall for fold 3285:  0.2948717948717949\n",
      "precision for fold 3285:  0.2875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3286:  0.5311004784688995\n",
      "f1  score for fold 3286:  0.36363636363636365\n",
      "recall for fold 3286:  0.3783783783783784\n",
      "precision for fold 3286:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3287:  0.5476190476190477\n",
      "f1  score for fold 3287:  0.38709677419354843\n",
      "recall for fold 3287:  0.4\n",
      "precision for fold 3287:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3288:  0.5194174757281553\n",
      "f1  score for fold 3288:  0.38509316770186336\n",
      "recall for fold 3288:  0.3780487804878049\n",
      "precision for fold 3288:  0.3924050632911392\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 3289:  0.6010362694300518\n",
      "f1  score for fold 3289:  0.5217391304347826\n",
      "recall for fold 3289:  0.4827586206896552\n",
      "precision for fold 3289:  0.5675675675675675\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3290:  0.5311004784688995\n",
      "f1  score for fold 3290:  0.37974683544303806\n",
      "recall for fold 3290:  0.38461538461538464\n",
      "precision for fold 3290:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3291:  0.5311004784688995\n",
      "f1  score for fold 3291:  0.36363636363636365\n",
      "recall for fold 3291:  0.3783783783783784\n",
      "precision for fold 3291:  0.35\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 3292:  0.48095238095238096\n",
      "f1  score for fold 3292:  0.2967741935483871\n",
      "recall for fold 3292:  0.30666666666666664\n",
      "precision for fold 3292:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3293:  0.5388349514563107\n",
      "f1  score for fold 3293:  0.40993788819875776\n",
      "recall for fold 3293:  0.4024390243902439\n",
      "precision for fold 3293:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3294:  0.5077720207253886\n",
      "f1  score for fold 3294:  0.40993788819875776\n",
      "recall for fold 3294:  0.3793103448275862\n",
      "precision for fold 3294:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3295:  0.5023923444976076\n",
      "f1  score for fold 3295:  0.34177215189873417\n",
      "recall for fold 3295:  0.34615384615384615\n",
      "precision for fold 3295:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3296:  0.5502392344497608\n",
      "f1  score for fold 3296:  0.3896103896103896\n",
      "recall for fold 3296:  0.40540540540540543\n",
      "precision for fold 3296:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3297:  0.5380952380952381\n",
      "f1  score for fold 3297:  0.3741935483870968\n",
      "recall for fold 3297:  0.38666666666666666\n",
      "precision for fold 3297:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3298:  0.5485436893203883\n",
      "f1  score for fold 3298:  0.42236024844720493\n",
      "recall for fold 3298:  0.4146341463414634\n",
      "precision for fold 3298:  0.43037974683544306\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 3299:  0.5803108808290155\n",
      "f1  score for fold 3299:  0.49689440993788814\n",
      "recall for fold 3299:  0.45977011494252873\n",
      "precision for fold 3299:  0.5405405405405406\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 3300:  0.47368421052631576\n",
      "f1  score for fold 3300:  0.3037974683544304\n",
      "recall for fold 3300:  0.3076923076923077\n",
      "precision for fold 3300:  0.3\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3301:  0.5598086124401914\n",
      "f1  score for fold 3301:  0.40259740259740256\n",
      "recall for fold 3301:  0.4189189189189189\n",
      "precision for fold 3301:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3302:  0.5190476190476191\n",
      "f1  score for fold 3302:  0.34838709677419355\n",
      "recall for fold 3302:  0.36\n",
      "precision for fold 3302:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3303:  0.5388349514563107\n",
      "f1  score for fold 3303:  0.40993788819875776\n",
      "recall for fold 3303:  0.4024390243902439\n",
      "precision for fold 3303:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3304:  0.49740932642487046\n",
      "f1  score for fold 3304:  0.39751552795031053\n",
      "recall for fold 3304:  0.367816091954023\n",
      "precision for fold 3304:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3305:  0.5598086124401914\n",
      "f1  score for fold 3305:  0.4177215189873418\n",
      "recall for fold 3305:  0.4230769230769231\n",
      "precision for fold 3305:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3306:  0.5598086124401914\n",
      "f1  score for fold 3306:  0.40259740259740256\n",
      "recall for fold 3306:  0.4189189189189189\n",
      "precision for fold 3306:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3307:  0.49047619047619045\n",
      "f1  score for fold 3307:  0.3096774193548387\n",
      "recall for fold 3307:  0.32\n",
      "precision for fold 3307:  0.3\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3308:  0.5194174757281553\n",
      "f1  score for fold 3308:  0.38509316770186336\n",
      "recall for fold 3308:  0.3780487804878049\n",
      "precision for fold 3308:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3309:  0.5284974093264249\n",
      "f1  score for fold 3309:  0.4347826086956522\n",
      "recall for fold 3309:  0.40229885057471265\n",
      "precision for fold 3309:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3310:  0.5023923444976076\n",
      "f1  score for fold 3310:  0.34177215189873417\n",
      "recall for fold 3310:  0.34615384615384615\n",
      "precision for fold 3310:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3311:  0.5406698564593302\n",
      "f1  score for fold 3311:  0.37662337662337664\n",
      "recall for fold 3311:  0.3918918918918919\n",
      "precision for fold 3311:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3312:  0.5380952380952381\n",
      "f1  score for fold 3312:  0.3741935483870968\n",
      "recall for fold 3312:  0.38666666666666666\n",
      "precision for fold 3312:  0.3625\n",
      "    0   1\n",
      "0  40  42\n",
      "1  39  85\n",
      "Accuracy for fold 3313:  0.6067961165048543\n",
      "f1  score for fold 3313:  0.49689440993788825\n",
      "recall for fold 3313:  0.4878048780487805\n",
      "precision for fold 3313:  0.5063291139240507\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3314:  0.49740932642487046\n",
      "f1  score for fold 3314:  0.39751552795031053\n",
      "recall for fold 3314:  0.367816091954023\n",
      "precision for fold 3314:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3315:  0.5406698564593302\n",
      "f1  score for fold 3315:  0.3924050632911393\n",
      "recall for fold 3315:  0.3974358974358974\n",
      "precision for fold 3315:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3316:  0.5215311004784688\n",
      "f1  score for fold 3316:  0.3506493506493507\n",
      "recall for fold 3316:  0.36486486486486486\n",
      "precision for fold 3316:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3317:  0.5571428571428572\n",
      "f1  score for fold 3317:  0.4000000000000001\n",
      "recall for fold 3317:  0.41333333333333333\n",
      "precision for fold 3317:  0.3875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3318:  0.49029126213592233\n",
      "f1  score for fold 3318:  0.3478260869565218\n",
      "recall for fold 3318:  0.34146341463414637\n",
      "precision for fold 3318:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3319:  0.5181347150259067\n",
      "f1  score for fold 3319:  0.422360248447205\n",
      "recall for fold 3319:  0.39080459770114945\n",
      "precision for fold 3319:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3320:  0.5023923444976076\n",
      "f1  score for fold 3320:  0.34177215189873417\n",
      "recall for fold 3320:  0.34615384615384615\n",
      "precision for fold 3320:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3321:  0.5406698564593302\n",
      "f1  score for fold 3321:  0.37662337662337664\n",
      "recall for fold 3321:  0.3918918918918919\n",
      "precision for fold 3321:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3322:  0.5095238095238095\n",
      "f1  score for fold 3322:  0.335483870967742\n",
      "recall for fold 3322:  0.3466666666666667\n",
      "precision for fold 3322:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3323:  0.5097087378640777\n",
      "f1  score for fold 3323:  0.37267080745341613\n",
      "recall for fold 3323:  0.36585365853658536\n",
      "precision for fold 3323:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3324:  0.46632124352331605\n",
      "f1  score for fold 3324:  0.36024844720496896\n",
      "recall for fold 3324:  0.3333333333333333\n",
      "precision for fold 3324:  0.3918918918918919\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3325:  0.5789473684210527\n",
      "f1  score for fold 3325:  0.44303797468354433\n",
      "recall for fold 3325:  0.44871794871794873\n",
      "precision for fold 3325:  0.4375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3326:  0.5502392344497608\n",
      "f1  score for fold 3326:  0.3896103896103896\n",
      "recall for fold 3326:  0.40540540540540543\n",
      "precision for fold 3326:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3327:  0.5571428571428572\n",
      "f1  score for fold 3327:  0.4000000000000001\n",
      "recall for fold 3327:  0.41333333333333333\n",
      "precision for fold 3327:  0.3875\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3328:  0.558252427184466\n",
      "f1  score for fold 3328:  0.43478260869565216\n",
      "recall for fold 3328:  0.4268292682926829\n",
      "precision for fold 3328:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3329:  0.5077720207253886\n",
      "f1  score for fold 3329:  0.40993788819875776\n",
      "recall for fold 3329:  0.3793103448275862\n",
      "precision for fold 3329:  0.44594594594594594\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3330:  0.49282296650717705\n",
      "f1  score for fold 3330:  0.32911392405063294\n",
      "recall for fold 3330:  0.3333333333333333\n",
      "precision for fold 3330:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3331:  0.5502392344497608\n",
      "f1  score for fold 3331:  0.3896103896103896\n",
      "recall for fold 3331:  0.40540540540540543\n",
      "precision for fold 3331:  0.375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3332:  0.5666666666666667\n",
      "f1  score for fold 3332:  0.41290322580645167\n",
      "recall for fold 3332:  0.4266666666666667\n",
      "precision for fold 3332:  0.4\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3333:  0.46116504854368934\n",
      "f1  score for fold 3333:  0.31055900621118016\n",
      "recall for fold 3333:  0.3048780487804878\n",
      "precision for fold 3333:  0.31645569620253167\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3334:  0.538860103626943\n",
      "f1  score for fold 3334:  0.4472049689440994\n",
      "recall for fold 3334:  0.41379310344827586\n",
      "precision for fold 3334:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3335:  0.5598086124401914\n",
      "f1  score for fold 3335:  0.4177215189873418\n",
      "recall for fold 3335:  0.4230769230769231\n",
      "precision for fold 3335:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3336:  0.5502392344497608\n",
      "f1  score for fold 3336:  0.3896103896103896\n",
      "recall for fold 3336:  0.40540540540540543\n",
      "precision for fold 3336:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3337:  0.5190476190476191\n",
      "f1  score for fold 3337:  0.34838709677419355\n",
      "recall for fold 3337:  0.36\n",
      "precision for fold 3337:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3338:  0.5388349514563107\n",
      "f1  score for fold 3338:  0.40993788819875776\n",
      "recall for fold 3338:  0.4024390243902439\n",
      "precision for fold 3338:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3339:  0.49740932642487046\n",
      "f1  score for fold 3339:  0.39751552795031053\n",
      "recall for fold 3339:  0.367816091954023\n",
      "precision for fold 3339:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3340:  0.5119617224880383\n",
      "f1  score for fold 3340:  0.3544303797468355\n",
      "recall for fold 3340:  0.358974358974359\n",
      "precision for fold 3340:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3341:  0.5023923444976076\n",
      "f1  score for fold 3341:  0.3246753246753247\n",
      "recall for fold 3341:  0.33783783783783783\n",
      "precision for fold 3341:  0.3125\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3342:  0.5761904761904761\n",
      "f1  score for fold 3342:  0.4258064516129032\n",
      "recall for fold 3342:  0.44\n",
      "precision for fold 3342:  0.4125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3343:  0.529126213592233\n",
      "f1  score for fold 3343:  0.39751552795031053\n",
      "recall for fold 3343:  0.3902439024390244\n",
      "precision for fold 3343:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3344:  0.538860103626943\n",
      "f1  score for fold 3344:  0.4472049689440994\n",
      "recall for fold 3344:  0.41379310344827586\n",
      "precision for fold 3344:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3345:  0.5119617224880383\n",
      "f1  score for fold 3345:  0.3544303797468355\n",
      "recall for fold 3345:  0.358974358974359\n",
      "precision for fold 3345:  0.35\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3346:  0.5789473684210527\n",
      "f1  score for fold 3346:  0.42857142857142855\n",
      "recall for fold 3346:  0.44594594594594594\n",
      "precision for fold 3346:  0.4125\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 3347:  0.6047619047619047\n",
      "f1  score for fold 3347:  0.4645161290322581\n",
      "recall for fold 3347:  0.48\n",
      "precision for fold 3347:  0.45\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 3348:  0.45145631067961167\n",
      "f1  score for fold 3348:  0.29813664596273287\n",
      "recall for fold 3348:  0.2926829268292683\n",
      "precision for fold 3348:  0.3037974683544304\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3349:  0.49740932642487046\n",
      "f1  score for fold 3349:  0.39751552795031053\n",
      "recall for fold 3349:  0.367816091954023\n",
      "precision for fold 3349:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3350:  0.5215311004784688\n",
      "f1  score for fold 3350:  0.36708860759493667\n",
      "recall for fold 3350:  0.3717948717948718\n",
      "precision for fold 3350:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3351:  0.5023923444976076\n",
      "f1  score for fold 3351:  0.3246753246753247\n",
      "recall for fold 3351:  0.33783783783783783\n",
      "precision for fold 3351:  0.3125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3352:  0.49047619047619045\n",
      "f1  score for fold 3352:  0.3096774193548387\n",
      "recall for fold 3352:  0.32\n",
      "precision for fold 3352:  0.3\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3353:  0.48058252427184467\n",
      "f1  score for fold 3353:  0.33540372670807456\n",
      "recall for fold 3353:  0.32926829268292684\n",
      "precision for fold 3353:  0.34177215189873417\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3354:  0.5284974093264249\n",
      "f1  score for fold 3354:  0.4347826086956522\n",
      "recall for fold 3354:  0.40229885057471265\n",
      "precision for fold 3354:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3355:  0.5406698564593302\n",
      "f1  score for fold 3355:  0.3924050632911393\n",
      "recall for fold 3355:  0.3974358974358974\n",
      "precision for fold 3355:  0.3875\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 3356:  0.5980861244019139\n",
      "f1  score for fold 3356:  0.45454545454545453\n",
      "recall for fold 3356:  0.47297297297297297\n",
      "precision for fold 3356:  0.4375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3357:  0.5571428571428572\n",
      "f1  score for fold 3357:  0.4000000000000001\n",
      "recall for fold 3357:  0.41333333333333333\n",
      "precision for fold 3357:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3358:  0.5388349514563107\n",
      "f1  score for fold 3358:  0.40993788819875776\n",
      "recall for fold 3358:  0.4024390243902439\n",
      "precision for fold 3358:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3359:  0.5077720207253886\n",
      "f1  score for fold 3359:  0.40993788819875776\n",
      "recall for fold 3359:  0.3793103448275862\n",
      "precision for fold 3359:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3360:  0.5598086124401914\n",
      "f1  score for fold 3360:  0.4177215189873418\n",
      "recall for fold 3360:  0.4230769230769231\n",
      "precision for fold 3360:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3361:  0.5406698564593302\n",
      "f1  score for fold 3361:  0.37662337662337664\n",
      "recall for fold 3361:  0.3918918918918919\n",
      "precision for fold 3361:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3362:  0.5666666666666667\n",
      "f1  score for fold 3362:  0.41290322580645167\n",
      "recall for fold 3362:  0.4266666666666667\n",
      "precision for fold 3362:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3363:  0.5097087378640777\n",
      "f1  score for fold 3363:  0.37267080745341613\n",
      "recall for fold 3363:  0.36585365853658536\n",
      "precision for fold 3363:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3364:  0.5284974093264249\n",
      "f1  score for fold 3364:  0.4347826086956522\n",
      "recall for fold 3364:  0.40229885057471265\n",
      "precision for fold 3364:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3365:  0.5406698564593302\n",
      "f1  score for fold 3365:  0.3924050632911393\n",
      "recall for fold 3365:  0.3974358974358974\n",
      "precision for fold 3365:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3366:  0.5311004784688995\n",
      "f1  score for fold 3366:  0.36363636363636365\n",
      "recall for fold 3366:  0.3783783783783784\n",
      "precision for fold 3366:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3367:  0.5571428571428572\n",
      "f1  score for fold 3367:  0.4000000000000001\n",
      "recall for fold 3367:  0.41333333333333333\n",
      "precision for fold 3367:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3368:  0.529126213592233\n",
      "f1  score for fold 3368:  0.39751552795031053\n",
      "recall for fold 3368:  0.3902439024390244\n",
      "precision for fold 3368:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3369:  0.5284974093264249\n",
      "f1  score for fold 3369:  0.4347826086956522\n",
      "recall for fold 3369:  0.40229885057471265\n",
      "precision for fold 3369:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3370:  0.5023923444976076\n",
      "f1  score for fold 3370:  0.34177215189873417\n",
      "recall for fold 3370:  0.34615384615384615\n",
      "precision for fold 3370:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3371:  0.5119617224880383\n",
      "f1  score for fold 3371:  0.33766233766233766\n",
      "recall for fold 3371:  0.35135135135135137\n",
      "precision for fold 3371:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3372:  0.5190476190476191\n",
      "f1  score for fold 3372:  0.34838709677419355\n",
      "recall for fold 3372:  0.36\n",
      "precision for fold 3372:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3373:  0.529126213592233\n",
      "f1  score for fold 3373:  0.39751552795031053\n",
      "recall for fold 3373:  0.3902439024390244\n",
      "precision for fold 3373:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3374:  0.5181347150259067\n",
      "f1  score for fold 3374:  0.422360248447205\n",
      "recall for fold 3374:  0.39080459770114945\n",
      "precision for fold 3374:  0.4594594594594595\n",
      "    0   1\n",
      "0  38  40\n",
      "1  42  89\n",
      "Accuracy for fold 3375:  0.6076555023923444\n",
      "f1  score for fold 3375:  0.4810126582278481\n",
      "recall for fold 3375:  0.48717948717948717\n",
      "precision for fold 3375:  0.475\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3376:  0.5311004784688995\n",
      "f1  score for fold 3376:  0.36363636363636365\n",
      "recall for fold 3376:  0.3783783783783784\n",
      "precision for fold 3376:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3377:  0.5095238095238095\n",
      "f1  score for fold 3377:  0.335483870967742\n",
      "recall for fold 3377:  0.3466666666666667\n",
      "precision for fold 3377:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3378:  0.5485436893203883\n",
      "f1  score for fold 3378:  0.42236024844720493\n",
      "recall for fold 3378:  0.4146341463414634\n",
      "precision for fold 3378:  0.43037974683544306\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 3379:  0.43523316062176165\n",
      "f1  score for fold 3379:  0.3229813664596274\n",
      "recall for fold 3379:  0.2988505747126437\n",
      "precision for fold 3379:  0.35135135135135137\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3380:  0.49282296650717705\n",
      "f1  score for fold 3380:  0.32911392405063294\n",
      "recall for fold 3380:  0.3333333333333333\n",
      "precision for fold 3380:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3381:  0.5502392344497608\n",
      "f1  score for fold 3381:  0.3896103896103896\n",
      "recall for fold 3381:  0.40540540540540543\n",
      "precision for fold 3381:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3382:  0.5380952380952381\n",
      "f1  score for fold 3382:  0.3741935483870968\n",
      "recall for fold 3382:  0.38666666666666666\n",
      "precision for fold 3382:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3383:  0.5194174757281553\n",
      "f1  score for fold 3383:  0.38509316770186336\n",
      "recall for fold 3383:  0.3780487804878049\n",
      "precision for fold 3383:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3384:  0.5077720207253886\n",
      "f1  score for fold 3384:  0.40993788819875776\n",
      "recall for fold 3384:  0.3793103448275862\n",
      "precision for fold 3384:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3385:  0.5119617224880383\n",
      "f1  score for fold 3385:  0.3544303797468355\n",
      "recall for fold 3385:  0.358974358974359\n",
      "precision for fold 3385:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3386:  0.5502392344497608\n",
      "f1  score for fold 3386:  0.3896103896103896\n",
      "recall for fold 3386:  0.40540540540540543\n",
      "precision for fold 3386:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3387:  0.5095238095238095\n",
      "f1  score for fold 3387:  0.335483870967742\n",
      "recall for fold 3387:  0.3466666666666667\n",
      "precision for fold 3387:  0.325\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 3388:  0.587378640776699\n",
      "f1  score for fold 3388:  0.4720496894409938\n",
      "recall for fold 3388:  0.4634146341463415\n",
      "precision for fold 3388:  0.4810126582278481\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3389:  0.5077720207253886\n",
      "f1  score for fold 3389:  0.40993788819875776\n",
      "recall for fold 3389:  0.3793103448275862\n",
      "precision for fold 3389:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3390:  0.5311004784688995\n",
      "f1  score for fold 3390:  0.37974683544303806\n",
      "recall for fold 3390:  0.38461538461538464\n",
      "precision for fold 3390:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3391:  0.5406698564593302\n",
      "f1  score for fold 3391:  0.37662337662337664\n",
      "recall for fold 3391:  0.3918918918918919\n",
      "precision for fold 3391:  0.3625\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 3392:  0.5952380952380952\n",
      "f1  score for fold 3392:  0.45161290322580644\n",
      "recall for fold 3392:  0.4666666666666667\n",
      "precision for fold 3392:  0.4375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3393:  0.5388349514563107\n",
      "f1  score for fold 3393:  0.40993788819875776\n",
      "recall for fold 3393:  0.4024390243902439\n",
      "precision for fold 3393:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3394:  0.538860103626943\n",
      "f1  score for fold 3394:  0.4472049689440994\n",
      "recall for fold 3394:  0.41379310344827586\n",
      "precision for fold 3394:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3395:  0.5311004784688995\n",
      "f1  score for fold 3395:  0.37974683544303806\n",
      "recall for fold 3395:  0.38461538461538464\n",
      "precision for fold 3395:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3396:  0.5119617224880383\n",
      "f1  score for fold 3396:  0.33766233766233766\n",
      "recall for fold 3396:  0.35135135135135137\n",
      "precision for fold 3396:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3397:  0.5380952380952381\n",
      "f1  score for fold 3397:  0.3741935483870968\n",
      "recall for fold 3397:  0.38666666666666666\n",
      "precision for fold 3397:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3398:  0.529126213592233\n",
      "f1  score for fold 3398:  0.39751552795031053\n",
      "recall for fold 3398:  0.3902439024390244\n",
      "precision for fold 3398:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3399:  0.48704663212435234\n",
      "f1  score for fold 3399:  0.3850931677018633\n",
      "recall for fold 3399:  0.3563218390804598\n",
      "precision for fold 3399:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3400:  0.48325358851674644\n",
      "f1  score for fold 3400:  0.31645569620253167\n",
      "recall for fold 3400:  0.32051282051282054\n",
      "precision for fold 3400:  0.3125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3401:  0.5502392344497608\n",
      "f1  score for fold 3401:  0.3896103896103896\n",
      "recall for fold 3401:  0.40540540540540543\n",
      "precision for fold 3401:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3402:  0.5761904761904761\n",
      "f1  score for fold 3402:  0.4258064516129032\n",
      "recall for fold 3402:  0.44\n",
      "precision for fold 3402:  0.4125\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 3403:  0.45145631067961167\n",
      "f1  score for fold 3403:  0.29813664596273287\n",
      "recall for fold 3403:  0.2926829268292683\n",
      "precision for fold 3403:  0.3037974683544304\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3404:  0.49740932642487046\n",
      "f1  score for fold 3404:  0.39751552795031053\n",
      "recall for fold 3404:  0.367816091954023\n",
      "precision for fold 3404:  0.43243243243243246\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3405:  0.46411483253588515\n",
      "f1  score for fold 3405:  0.2911392405063291\n",
      "recall for fold 3405:  0.2948717948717949\n",
      "precision for fold 3405:  0.2875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3406:  0.5215311004784688\n",
      "f1  score for fold 3406:  0.3506493506493507\n",
      "recall for fold 3406:  0.36486486486486486\n",
      "precision for fold 3406:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3407:  0.5666666666666667\n",
      "f1  score for fold 3407:  0.41290322580645167\n",
      "recall for fold 3407:  0.4266666666666667\n",
      "precision for fold 3407:  0.4\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3408:  0.48058252427184467\n",
      "f1  score for fold 3408:  0.33540372670807456\n",
      "recall for fold 3408:  0.32926829268292684\n",
      "precision for fold 3408:  0.34177215189873417\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3409:  0.48704663212435234\n",
      "f1  score for fold 3409:  0.3850931677018633\n",
      "recall for fold 3409:  0.3563218390804598\n",
      "precision for fold 3409:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3410:  0.5311004784688995\n",
      "f1  score for fold 3410:  0.37974683544303806\n",
      "recall for fold 3410:  0.38461538461538464\n",
      "precision for fold 3410:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3411:  0.5406698564593302\n",
      "f1  score for fold 3411:  0.37662337662337664\n",
      "recall for fold 3411:  0.3918918918918919\n",
      "precision for fold 3411:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3412:  0.5380952380952381\n",
      "f1  score for fold 3412:  0.3741935483870968\n",
      "recall for fold 3412:  0.38666666666666666\n",
      "precision for fold 3412:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3413:  0.49029126213592233\n",
      "f1  score for fold 3413:  0.3478260869565218\n",
      "recall for fold 3413:  0.34146341463414637\n",
      "precision for fold 3413:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3414:  0.538860103626943\n",
      "f1  score for fold 3414:  0.4472049689440994\n",
      "recall for fold 3414:  0.41379310344827586\n",
      "precision for fold 3414:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3415:  0.49282296650717705\n",
      "f1  score for fold 3415:  0.32911392405063294\n",
      "recall for fold 3415:  0.3333333333333333\n",
      "precision for fold 3415:  0.325\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 3416:  0.5980861244019139\n",
      "f1  score for fold 3416:  0.45454545454545453\n",
      "recall for fold 3416:  0.47297297297297297\n",
      "precision for fold 3416:  0.4375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3417:  0.5571428571428572\n",
      "f1  score for fold 3417:  0.4000000000000001\n",
      "recall for fold 3417:  0.41333333333333333\n",
      "precision for fold 3417:  0.3875\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3418:  0.5776699029126213\n",
      "f1  score for fold 3418:  0.4596273291925466\n",
      "recall for fold 3418:  0.45121951219512196\n",
      "precision for fold 3418:  0.46835443037974683\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3419:  0.5181347150259067\n",
      "f1  score for fold 3419:  0.422360248447205\n",
      "recall for fold 3419:  0.39080459770114945\n",
      "precision for fold 3419:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3420:  0.5023923444976076\n",
      "f1  score for fold 3420:  0.34177215189873417\n",
      "recall for fold 3420:  0.34615384615384615\n",
      "precision for fold 3420:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3421:  0.5598086124401914\n",
      "f1  score for fold 3421:  0.40259740259740256\n",
      "recall for fold 3421:  0.4189189189189189\n",
      "precision for fold 3421:  0.3875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3422:  0.5571428571428572\n",
      "f1  score for fold 3422:  0.4000000000000001\n",
      "recall for fold 3422:  0.41333333333333333\n",
      "precision for fold 3422:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3423:  0.5194174757281553\n",
      "f1  score for fold 3423:  0.38509316770186336\n",
      "recall for fold 3423:  0.3780487804878049\n",
      "precision for fold 3423:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3424:  0.48704663212435234\n",
      "f1  score for fold 3424:  0.3850931677018633\n",
      "recall for fold 3424:  0.3563218390804598\n",
      "precision for fold 3424:  0.4189189189189189\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3425:  0.5311004784688995\n",
      "f1  score for fold 3425:  0.37974683544303806\n",
      "recall for fold 3425:  0.38461538461538464\n",
      "precision for fold 3425:  0.375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3426:  0.5023923444976076\n",
      "f1  score for fold 3426:  0.3246753246753247\n",
      "recall for fold 3426:  0.33783783783783783\n",
      "precision for fold 3426:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3427:  0.5380952380952381\n",
      "f1  score for fold 3427:  0.3741935483870968\n",
      "recall for fold 3427:  0.38666666666666666\n",
      "precision for fold 3427:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3428:  0.5388349514563107\n",
      "f1  score for fold 3428:  0.40993788819875776\n",
      "recall for fold 3428:  0.4024390243902439\n",
      "precision for fold 3428:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3429:  0.5284974093264249\n",
      "f1  score for fold 3429:  0.4347826086956522\n",
      "recall for fold 3429:  0.40229885057471265\n",
      "precision for fold 3429:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3430:  0.5119617224880383\n",
      "f1  score for fold 3430:  0.3544303797468355\n",
      "recall for fold 3430:  0.358974358974359\n",
      "precision for fold 3430:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3431:  0.5023923444976076\n",
      "f1  score for fold 3431:  0.3246753246753247\n",
      "recall for fold 3431:  0.33783783783783783\n",
      "precision for fold 3431:  0.3125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3432:  0.5666666666666667\n",
      "f1  score for fold 3432:  0.41290322580645167\n",
      "recall for fold 3432:  0.4266666666666667\n",
      "precision for fold 3432:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3433:  0.5679611650485437\n",
      "f1  score for fold 3433:  0.4472049689440994\n",
      "recall for fold 3433:  0.43902439024390244\n",
      "precision for fold 3433:  0.45569620253164556\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3434:  0.48704663212435234\n",
      "f1  score for fold 3434:  0.3850931677018633\n",
      "recall for fold 3434:  0.3563218390804598\n",
      "precision for fold 3434:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3435:  0.5598086124401914\n",
      "f1  score for fold 3435:  0.4177215189873418\n",
      "recall for fold 3435:  0.4230769230769231\n",
      "precision for fold 3435:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3436:  0.5502392344497608\n",
      "f1  score for fold 3436:  0.3896103896103896\n",
      "recall for fold 3436:  0.40540540540540543\n",
      "precision for fold 3436:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3437:  0.5\n",
      "f1  score for fold 3437:  0.3225806451612903\n",
      "recall for fold 3437:  0.3333333333333333\n",
      "precision for fold 3437:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3438:  0.5\n",
      "f1  score for fold 3438:  0.3602484472049689\n",
      "recall for fold 3438:  0.35365853658536583\n",
      "precision for fold 3438:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3439:  0.5181347150259067\n",
      "f1  score for fold 3439:  0.422360248447205\n",
      "recall for fold 3439:  0.39080459770114945\n",
      "precision for fold 3439:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3440:  0.5502392344497608\n",
      "f1  score for fold 3440:  0.4050632911392405\n",
      "recall for fold 3440:  0.41025641025641024\n",
      "precision for fold 3440:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3441:  0.5119617224880383\n",
      "f1  score for fold 3441:  0.33766233766233766\n",
      "recall for fold 3441:  0.35135135135135137\n",
      "precision for fold 3441:  0.325\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3442:  0.5666666666666667\n",
      "f1  score for fold 3442:  0.41290322580645167\n",
      "recall for fold 3442:  0.4266666666666667\n",
      "precision for fold 3442:  0.4\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3443:  0.46116504854368934\n",
      "f1  score for fold 3443:  0.31055900621118016\n",
      "recall for fold 3443:  0.3048780487804878\n",
      "precision for fold 3443:  0.31645569620253167\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 3444:  0.43523316062176165\n",
      "f1  score for fold 3444:  0.3229813664596274\n",
      "recall for fold 3444:  0.2988505747126437\n",
      "precision for fold 3444:  0.35135135135135137\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 3445:  0.5885167464114832\n",
      "f1  score for fold 3445:  0.45569620253164556\n",
      "recall for fold 3445:  0.46153846153846156\n",
      "precision for fold 3445:  0.45\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3446:  0.5119617224880383\n",
      "f1  score for fold 3446:  0.33766233766233766\n",
      "recall for fold 3446:  0.35135135135135137\n",
      "precision for fold 3446:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3447:  0.5476190476190477\n",
      "f1  score for fold 3447:  0.38709677419354843\n",
      "recall for fold 3447:  0.4\n",
      "precision for fold 3447:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3448:  0.5194174757281553\n",
      "f1  score for fold 3448:  0.38509316770186336\n",
      "recall for fold 3448:  0.3780487804878049\n",
      "precision for fold 3448:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3449:  0.538860103626943\n",
      "f1  score for fold 3449:  0.4472049689440994\n",
      "recall for fold 3449:  0.41379310344827586\n",
      "precision for fold 3449:  0.4864864864864865\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3450:  0.5215311004784688\n",
      "f1  score for fold 3450:  0.36708860759493667\n",
      "recall for fold 3450:  0.3717948717948718\n",
      "precision for fold 3450:  0.3625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3451:  0.5789473684210527\n",
      "f1  score for fold 3451:  0.42857142857142855\n",
      "recall for fold 3451:  0.44594594594594594\n",
      "precision for fold 3451:  0.4125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3452:  0.5190476190476191\n",
      "f1  score for fold 3452:  0.34838709677419355\n",
      "recall for fold 3452:  0.36\n",
      "precision for fold 3452:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3453:  0.5\n",
      "f1  score for fold 3453:  0.3602484472049689\n",
      "recall for fold 3453:  0.35365853658536583\n",
      "precision for fold 3453:  0.3670886075949367\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3454:  0.46632124352331605\n",
      "f1  score for fold 3454:  0.36024844720496896\n",
      "recall for fold 3454:  0.3333333333333333\n",
      "precision for fold 3454:  0.3918918918918919\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3455:  0.48325358851674644\n",
      "f1  score for fold 3455:  0.31645569620253167\n",
      "recall for fold 3455:  0.32051282051282054\n",
      "precision for fold 3455:  0.3125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3456:  0.5023923444976076\n",
      "f1  score for fold 3456:  0.3246753246753247\n",
      "recall for fold 3456:  0.33783783783783783\n",
      "precision for fold 3456:  0.3125\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3457:  0.5761904761904761\n",
      "f1  score for fold 3457:  0.4258064516129032\n",
      "recall for fold 3457:  0.44\n",
      "precision for fold 3457:  0.4125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3458:  0.5485436893203883\n",
      "f1  score for fold 3458:  0.42236024844720493\n",
      "recall for fold 3458:  0.4146341463414634\n",
      "precision for fold 3458:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3459:  0.47668393782383417\n",
      "f1  score for fold 3459:  0.3726708074534162\n",
      "recall for fold 3459:  0.3448275862068966\n",
      "precision for fold 3459:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3460:  0.5311004784688995\n",
      "f1  score for fold 3460:  0.37974683544303806\n",
      "recall for fold 3460:  0.38461538461538464\n",
      "precision for fold 3460:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3461:  0.5215311004784688\n",
      "f1  score for fold 3461:  0.3506493506493507\n",
      "recall for fold 3461:  0.36486486486486486\n",
      "precision for fold 3461:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3462:  0.49047619047619045\n",
      "f1  score for fold 3462:  0.3096774193548387\n",
      "recall for fold 3462:  0.32\n",
      "precision for fold 3462:  0.3\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3463:  0.5679611650485437\n",
      "f1  score for fold 3463:  0.4472049689440994\n",
      "recall for fold 3463:  0.43902439024390244\n",
      "precision for fold 3463:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3464:  0.5181347150259067\n",
      "f1  score for fold 3464:  0.422360248447205\n",
      "recall for fold 3464:  0.39080459770114945\n",
      "precision for fold 3464:  0.4594594594594595\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3465:  0.46411483253588515\n",
      "f1  score for fold 3465:  0.2911392405063291\n",
      "recall for fold 3465:  0.2948717948717949\n",
      "precision for fold 3465:  0.2875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3466:  0.49282296650717705\n",
      "f1  score for fold 3466:  0.3116883116883117\n",
      "recall for fold 3466:  0.32432432432432434\n",
      "precision for fold 3466:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3467:  0.5\n",
      "f1  score for fold 3467:  0.3225806451612903\n",
      "recall for fold 3467:  0.3333333333333333\n",
      "precision for fold 3467:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3468:  0.5097087378640777\n",
      "f1  score for fold 3468:  0.37267080745341613\n",
      "recall for fold 3468:  0.36585365853658536\n",
      "precision for fold 3468:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3469:  0.47668393782383417\n",
      "f1  score for fold 3469:  0.3726708074534162\n",
      "recall for fold 3469:  0.3448275862068966\n",
      "precision for fold 3469:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3470:  0.5215311004784688\n",
      "f1  score for fold 3470:  0.36708860759493667\n",
      "recall for fold 3470:  0.3717948717948718\n",
      "precision for fold 3470:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3471:  0.5023923444976076\n",
      "f1  score for fold 3471:  0.3246753246753247\n",
      "recall for fold 3471:  0.33783783783783783\n",
      "precision for fold 3471:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3472:  0.5380952380952381\n",
      "f1  score for fold 3472:  0.3741935483870968\n",
      "recall for fold 3472:  0.38666666666666666\n",
      "precision for fold 3472:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3473:  0.5485436893203883\n",
      "f1  score for fold 3473:  0.42236024844720493\n",
      "recall for fold 3473:  0.4146341463414634\n",
      "precision for fold 3473:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3474:  0.48704663212435234\n",
      "f1  score for fold 3474:  0.3850931677018633\n",
      "recall for fold 3474:  0.3563218390804598\n",
      "precision for fold 3474:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3475:  0.5215311004784688\n",
      "f1  score for fold 3475:  0.36708860759493667\n",
      "recall for fold 3475:  0.3717948717948718\n",
      "precision for fold 3475:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3476:  0.5023923444976076\n",
      "f1  score for fold 3476:  0.3246753246753247\n",
      "recall for fold 3476:  0.33783783783783783\n",
      "precision for fold 3476:  0.3125\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3477:  0.5761904761904761\n",
      "f1  score for fold 3477:  0.4258064516129032\n",
      "recall for fold 3477:  0.44\n",
      "precision for fold 3477:  0.4125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3478:  0.5485436893203883\n",
      "f1  score for fold 3478:  0.42236024844720493\n",
      "recall for fold 3478:  0.4146341463414634\n",
      "precision for fold 3478:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3479:  0.48704663212435234\n",
      "f1  score for fold 3479:  0.3850931677018633\n",
      "recall for fold 3479:  0.3563218390804598\n",
      "precision for fold 3479:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3480:  0.5119617224880383\n",
      "f1  score for fold 3480:  0.3544303797468355\n",
      "recall for fold 3480:  0.358974358974359\n",
      "precision for fold 3480:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3481:  0.569377990430622\n",
      "f1  score for fold 3481:  0.4155844155844156\n",
      "recall for fold 3481:  0.43243243243243246\n",
      "precision for fold 3481:  0.4\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3482:  0.5571428571428572\n",
      "f1  score for fold 3482:  0.4000000000000001\n",
      "recall for fold 3482:  0.41333333333333333\n",
      "precision for fold 3482:  0.3875\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3483:  0.5776699029126213\n",
      "f1  score for fold 3483:  0.4596273291925466\n",
      "recall for fold 3483:  0.45121951219512196\n",
      "precision for fold 3483:  0.46835443037974683\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3484:  0.538860103626943\n",
      "f1  score for fold 3484:  0.4472049689440994\n",
      "recall for fold 3484:  0.41379310344827586\n",
      "precision for fold 3484:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3485:  0.5119617224880383\n",
      "f1  score for fold 3485:  0.3544303797468355\n",
      "recall for fold 3485:  0.358974358974359\n",
      "precision for fold 3485:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3486:  0.5502392344497608\n",
      "f1  score for fold 3486:  0.3896103896103896\n",
      "recall for fold 3486:  0.40540540540540543\n",
      "precision for fold 3486:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3487:  0.5\n",
      "f1  score for fold 3487:  0.3225806451612903\n",
      "recall for fold 3487:  0.3333333333333333\n",
      "precision for fold 3487:  0.3125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3488:  0.49029126213592233\n",
      "f1  score for fold 3488:  0.3478260869565218\n",
      "recall for fold 3488:  0.34146341463414637\n",
      "precision for fold 3488:  0.35443037974683544\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3489:  0.5492227979274611\n",
      "f1  score for fold 3489:  0.45962732919254656\n",
      "recall for fold 3489:  0.42528735632183906\n",
      "precision for fold 3489:  0.5\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3490:  0.5598086124401914\n",
      "f1  score for fold 3490:  0.4177215189873418\n",
      "recall for fold 3490:  0.4230769230769231\n",
      "precision for fold 3490:  0.4125\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3491:  0.569377990430622\n",
      "f1  score for fold 3491:  0.4155844155844156\n",
      "recall for fold 3491:  0.43243243243243246\n",
      "precision for fold 3491:  0.4\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3492:  0.5285714285714286\n",
      "f1  score for fold 3492:  0.3612903225806451\n",
      "recall for fold 3492:  0.37333333333333335\n",
      "precision for fold 3492:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3493:  0.5097087378640777\n",
      "f1  score for fold 3493:  0.37267080745341613\n",
      "recall for fold 3493:  0.36585365853658536\n",
      "precision for fold 3493:  0.379746835443038\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3494:  0.5492227979274611\n",
      "f1  score for fold 3494:  0.45962732919254656\n",
      "recall for fold 3494:  0.42528735632183906\n",
      "precision for fold 3494:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3495:  0.5215311004784688\n",
      "f1  score for fold 3495:  0.36708860759493667\n",
      "recall for fold 3495:  0.3717948717948718\n",
      "precision for fold 3495:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3496:  0.5502392344497608\n",
      "f1  score for fold 3496:  0.3896103896103896\n",
      "recall for fold 3496:  0.40540540540540543\n",
      "precision for fold 3496:  0.375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3497:  0.49047619047619045\n",
      "f1  score for fold 3497:  0.3096774193548387\n",
      "recall for fold 3497:  0.32\n",
      "precision for fold 3497:  0.3\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3498:  0.5194174757281553\n",
      "f1  score for fold 3498:  0.38509316770186336\n",
      "recall for fold 3498:  0.3780487804878049\n",
      "precision for fold 3498:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3499:  0.5181347150259067\n",
      "f1  score for fold 3499:  0.422360248447205\n",
      "recall for fold 3499:  0.39080459770114945\n",
      "precision for fold 3499:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3500:  0.5119617224880383\n",
      "f1  score for fold 3500:  0.3544303797468355\n",
      "recall for fold 3500:  0.358974358974359\n",
      "precision for fold 3500:  0.35\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 3501:  0.48325358851674644\n",
      "f1  score for fold 3501:  0.29870129870129863\n",
      "recall for fold 3501:  0.3108108108108108\n",
      "precision for fold 3501:  0.2875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3502:  0.5095238095238095\n",
      "f1  score for fold 3502:  0.335483870967742\n",
      "recall for fold 3502:  0.3466666666666667\n",
      "precision for fold 3502:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3503:  0.5485436893203883\n",
      "f1  score for fold 3503:  0.42236024844720493\n",
      "recall for fold 3503:  0.4146341463414634\n",
      "precision for fold 3503:  0.43037974683544306\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3504:  0.45595854922279794\n",
      "f1  score for fold 3504:  0.3478260869565218\n",
      "recall for fold 3504:  0.3218390804597701\n",
      "precision for fold 3504:  0.3783783783783784\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3505:  0.48325358851674644\n",
      "f1  score for fold 3505:  0.31645569620253167\n",
      "recall for fold 3505:  0.32051282051282054\n",
      "precision for fold 3505:  0.3125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3506:  0.5119617224880383\n",
      "f1  score for fold 3506:  0.33766233766233766\n",
      "recall for fold 3506:  0.35135135135135137\n",
      "precision for fold 3506:  0.325\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 3507:  0.5952380952380952\n",
      "f1  score for fold 3507:  0.45161290322580644\n",
      "recall for fold 3507:  0.4666666666666667\n",
      "precision for fold 3507:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3508:  0.5485436893203883\n",
      "f1  score for fold 3508:  0.42236024844720493\n",
      "recall for fold 3508:  0.4146341463414634\n",
      "precision for fold 3508:  0.43037974683544306\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3509:  0.45595854922279794\n",
      "f1  score for fold 3509:  0.3478260869565218\n",
      "recall for fold 3509:  0.3218390804597701\n",
      "precision for fold 3509:  0.3783783783783784\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3510:  0.5215311004784688\n",
      "f1  score for fold 3510:  0.36708860759493667\n",
      "recall for fold 3510:  0.3717948717948718\n",
      "precision for fold 3510:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3511:  0.5311004784688995\n",
      "f1  score for fold 3511:  0.36363636363636365\n",
      "recall for fold 3511:  0.3783783783783784\n",
      "precision for fold 3511:  0.35\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 3512:  0.4714285714285714\n",
      "f1  score for fold 3512:  0.2838709677419355\n",
      "recall for fold 3512:  0.29333333333333333\n",
      "precision for fold 3512:  0.275\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 3513:  0.587378640776699\n",
      "f1  score for fold 3513:  0.4720496894409938\n",
      "recall for fold 3513:  0.4634146341463415\n",
      "precision for fold 3513:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3514:  0.49740932642487046\n",
      "f1  score for fold 3514:  0.39751552795031053\n",
      "recall for fold 3514:  0.367816091954023\n",
      "precision for fold 3514:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3515:  0.5215311004784688\n",
      "f1  score for fold 3515:  0.36708860759493667\n",
      "recall for fold 3515:  0.3717948717948718\n",
      "precision for fold 3515:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3516:  0.49282296650717705\n",
      "f1  score for fold 3516:  0.3116883116883117\n",
      "recall for fold 3516:  0.32432432432432434\n",
      "precision for fold 3516:  0.3\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3517:  0.5190476190476191\n",
      "f1  score for fold 3517:  0.34838709677419355\n",
      "recall for fold 3517:  0.36\n",
      "precision for fold 3517:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3518:  0.529126213592233\n",
      "f1  score for fold 3518:  0.39751552795031053\n",
      "recall for fold 3518:  0.3902439024390244\n",
      "precision for fold 3518:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3519:  0.49740932642487046\n",
      "f1  score for fold 3519:  0.39751552795031053\n",
      "recall for fold 3519:  0.367816091954023\n",
      "precision for fold 3519:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3520:  0.5502392344497608\n",
      "f1  score for fold 3520:  0.4050632911392405\n",
      "recall for fold 3520:  0.41025641025641024\n",
      "precision for fold 3520:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3521:  0.5406698564593302\n",
      "f1  score for fold 3521:  0.37662337662337664\n",
      "recall for fold 3521:  0.3918918918918919\n",
      "precision for fold 3521:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3522:  0.49047619047619045\n",
      "f1  score for fold 3522:  0.3096774193548387\n",
      "recall for fold 3522:  0.32\n",
      "precision for fold 3522:  0.3\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3523:  0.5194174757281553\n",
      "f1  score for fold 3523:  0.38509316770186336\n",
      "recall for fold 3523:  0.3780487804878049\n",
      "precision for fold 3523:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3524:  0.5077720207253886\n",
      "f1  score for fold 3524:  0.40993788819875776\n",
      "recall for fold 3524:  0.3793103448275862\n",
      "precision for fold 3524:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3525:  0.5598086124401914\n",
      "f1  score for fold 3525:  0.4177215189873418\n",
      "recall for fold 3525:  0.4230769230769231\n",
      "precision for fold 3525:  0.4125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3526:  0.5789473684210527\n",
      "f1  score for fold 3526:  0.42857142857142855\n",
      "recall for fold 3526:  0.44594594594594594\n",
      "precision for fold 3526:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3527:  0.5285714285714286\n",
      "f1  score for fold 3527:  0.3612903225806451\n",
      "recall for fold 3527:  0.37333333333333335\n",
      "precision for fold 3527:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3528:  0.5485436893203883\n",
      "f1  score for fold 3528:  0.42236024844720493\n",
      "recall for fold 3528:  0.4146341463414634\n",
      "precision for fold 3528:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3529:  0.49740932642487046\n",
      "f1  score for fold 3529:  0.39751552795031053\n",
      "recall for fold 3529:  0.367816091954023\n",
      "precision for fold 3529:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3530:  0.5406698564593302\n",
      "f1  score for fold 3530:  0.3924050632911393\n",
      "recall for fold 3530:  0.3974358974358974\n",
      "precision for fold 3530:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3531:  0.5215311004784688\n",
      "f1  score for fold 3531:  0.3506493506493507\n",
      "recall for fold 3531:  0.36486486486486486\n",
      "precision for fold 3531:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3532:  0.5571428571428572\n",
      "f1  score for fold 3532:  0.4000000000000001\n",
      "recall for fold 3532:  0.41333333333333333\n",
      "precision for fold 3532:  0.3875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3533:  0.5388349514563107\n",
      "f1  score for fold 3533:  0.40993788819875776\n",
      "recall for fold 3533:  0.4024390243902439\n",
      "precision for fold 3533:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3534:  0.5077720207253886\n",
      "f1  score for fold 3534:  0.40993788819875776\n",
      "recall for fold 3534:  0.3793103448275862\n",
      "precision for fold 3534:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3535:  0.5311004784688995\n",
      "f1  score for fold 3535:  0.37974683544303806\n",
      "recall for fold 3535:  0.38461538461538464\n",
      "precision for fold 3535:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3536:  0.5215311004784688\n",
      "f1  score for fold 3536:  0.3506493506493507\n",
      "recall for fold 3536:  0.36486486486486486\n",
      "precision for fold 3536:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3537:  0.5571428571428572\n",
      "f1  score for fold 3537:  0.4000000000000001\n",
      "recall for fold 3537:  0.41333333333333333\n",
      "precision for fold 3537:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3538:  0.5194174757281553\n",
      "f1  score for fold 3538:  0.38509316770186336\n",
      "recall for fold 3538:  0.3780487804878049\n",
      "precision for fold 3538:  0.3924050632911392\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 3539:  0.5699481865284974\n",
      "f1  score for fold 3539:  0.48447204968944096\n",
      "recall for fold 3539:  0.4482758620689655\n",
      "precision for fold 3539:  0.527027027027027\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3540:  0.5502392344497608\n",
      "f1  score for fold 3540:  0.4050632911392405\n",
      "recall for fold 3540:  0.41025641025641024\n",
      "precision for fold 3540:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3541:  0.5502392344497608\n",
      "f1  score for fold 3541:  0.3896103896103896\n",
      "recall for fold 3541:  0.40540540540540543\n",
      "precision for fold 3541:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3542:  0.5\n",
      "f1  score for fold 3542:  0.3225806451612903\n",
      "recall for fold 3542:  0.3333333333333333\n",
      "precision for fold 3542:  0.3125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3543:  0.5194174757281553\n",
      "f1  score for fold 3543:  0.38509316770186336\n",
      "recall for fold 3543:  0.3780487804878049\n",
      "precision for fold 3543:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3544:  0.49740932642487046\n",
      "f1  score for fold 3544:  0.39751552795031053\n",
      "recall for fold 3544:  0.367816091954023\n",
      "precision for fold 3544:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3545:  0.5502392344497608\n",
      "f1  score for fold 3545:  0.4050632911392405\n",
      "recall for fold 3545:  0.41025641025641024\n",
      "precision for fold 3545:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3546:  0.5023923444976076\n",
      "f1  score for fold 3546:  0.3246753246753247\n",
      "recall for fold 3546:  0.33783783783783783\n",
      "precision for fold 3546:  0.3125\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 3547:  0.46190476190476193\n",
      "f1  score for fold 3547:  0.2709677419354839\n",
      "recall for fold 3547:  0.28\n",
      "precision for fold 3547:  0.2625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3548:  0.5388349514563107\n",
      "f1  score for fold 3548:  0.40993788819875776\n",
      "recall for fold 3548:  0.4024390243902439\n",
      "precision for fold 3548:  0.4177215189873418\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3549:  0.46632124352331605\n",
      "f1  score for fold 3549:  0.36024844720496896\n",
      "recall for fold 3549:  0.3333333333333333\n",
      "precision for fold 3549:  0.3918918918918919\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3550:  0.5598086124401914\n",
      "f1  score for fold 3550:  0.4177215189873418\n",
      "recall for fold 3550:  0.4230769230769231\n",
      "precision for fold 3550:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3551:  0.5502392344497608\n",
      "f1  score for fold 3551:  0.3896103896103896\n",
      "recall for fold 3551:  0.40540540540540543\n",
      "precision for fold 3551:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3552:  0.5761904761904761\n",
      "f1  score for fold 3552:  0.4258064516129032\n",
      "recall for fold 3552:  0.44\n",
      "precision for fold 3552:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3553:  0.5194174757281553\n",
      "f1  score for fold 3553:  0.38509316770186336\n",
      "recall for fold 3553:  0.3780487804878049\n",
      "precision for fold 3553:  0.3924050632911392\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3554:  0.45595854922279794\n",
      "f1  score for fold 3554:  0.3478260869565218\n",
      "recall for fold 3554:  0.3218390804597701\n",
      "precision for fold 3554:  0.3783783783783784\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3555:  0.5598086124401914\n",
      "f1  score for fold 3555:  0.4177215189873418\n",
      "recall for fold 3555:  0.4230769230769231\n",
      "precision for fold 3555:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3556:  0.5406698564593302\n",
      "f1  score for fold 3556:  0.37662337662337664\n",
      "recall for fold 3556:  0.3918918918918919\n",
      "precision for fold 3556:  0.3625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3557:  0.5761904761904761\n",
      "f1  score for fold 3557:  0.4258064516129032\n",
      "recall for fold 3557:  0.44\n",
      "precision for fold 3557:  0.4125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3558:  0.558252427184466\n",
      "f1  score for fold 3558:  0.43478260869565216\n",
      "recall for fold 3558:  0.4268292682926829\n",
      "precision for fold 3558:  0.4430379746835443\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 3559:  0.44559585492227977\n",
      "f1  score for fold 3559:  0.33540372670807456\n",
      "recall for fold 3559:  0.3103448275862069\n",
      "precision for fold 3559:  0.36486486486486486\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3560:  0.5119617224880383\n",
      "f1  score for fold 3560:  0.3544303797468355\n",
      "recall for fold 3560:  0.358974358974359\n",
      "precision for fold 3560:  0.35\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3561:  0.5311004784688995\n",
      "f1  score for fold 3561:  0.36363636363636365\n",
      "recall for fold 3561:  0.3783783783783784\n",
      "precision for fold 3561:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3562:  0.5476190476190477\n",
      "f1  score for fold 3562:  0.38709677419354843\n",
      "recall for fold 3562:  0.4\n",
      "precision for fold 3562:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3563:  0.49029126213592233\n",
      "f1  score for fold 3563:  0.3478260869565218\n",
      "recall for fold 3563:  0.34146341463414637\n",
      "precision for fold 3563:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3564:  0.5181347150259067\n",
      "f1  score for fold 3564:  0.422360248447205\n",
      "recall for fold 3564:  0.39080459770114945\n",
      "precision for fold 3564:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3565:  0.5215311004784688\n",
      "f1  score for fold 3565:  0.36708860759493667\n",
      "recall for fold 3565:  0.3717948717948718\n",
      "precision for fold 3565:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3566:  0.5215311004784688\n",
      "f1  score for fold 3566:  0.3506493506493507\n",
      "recall for fold 3566:  0.36486486486486486\n",
      "precision for fold 3566:  0.3375\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 3567:  0.4714285714285714\n",
      "f1  score for fold 3567:  0.2838709677419355\n",
      "recall for fold 3567:  0.29333333333333333\n",
      "precision for fold 3567:  0.275\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3568:  0.49029126213592233\n",
      "f1  score for fold 3568:  0.3478260869565218\n",
      "recall for fold 3568:  0.34146341463414637\n",
      "precision for fold 3568:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3569:  0.538860103626943\n",
      "f1  score for fold 3569:  0.4472049689440994\n",
      "recall for fold 3569:  0.41379310344827586\n",
      "precision for fold 3569:  0.4864864864864865\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3570:  0.46411483253588515\n",
      "f1  score for fold 3570:  0.2911392405063291\n",
      "recall for fold 3570:  0.2948717948717949\n",
      "precision for fold 3570:  0.2875\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3571:  0.5789473684210527\n",
      "f1  score for fold 3571:  0.42857142857142855\n",
      "recall for fold 3571:  0.44594594594594594\n",
      "precision for fold 3571:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3572:  0.5476190476190477\n",
      "f1  score for fold 3572:  0.38709677419354843\n",
      "recall for fold 3572:  0.4\n",
      "precision for fold 3572:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3573:  0.49029126213592233\n",
      "f1  score for fold 3573:  0.3478260869565218\n",
      "recall for fold 3573:  0.34146341463414637\n",
      "precision for fold 3573:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3574:  0.538860103626943\n",
      "f1  score for fold 3574:  0.4472049689440994\n",
      "recall for fold 3574:  0.41379310344827586\n",
      "precision for fold 3574:  0.4864864864864865\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3575:  0.48325358851674644\n",
      "f1  score for fold 3575:  0.31645569620253167\n",
      "recall for fold 3575:  0.32051282051282054\n",
      "precision for fold 3575:  0.3125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3576:  0.5119617224880383\n",
      "f1  score for fold 3576:  0.33766233766233766\n",
      "recall for fold 3576:  0.35135135135135137\n",
      "precision for fold 3576:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3577:  0.5380952380952381\n",
      "f1  score for fold 3577:  0.3741935483870968\n",
      "recall for fold 3577:  0.38666666666666666\n",
      "precision for fold 3577:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3578:  0.49029126213592233\n",
      "f1  score for fold 3578:  0.3478260869565218\n",
      "recall for fold 3578:  0.34146341463414637\n",
      "precision for fold 3578:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3579:  0.49740932642487046\n",
      "f1  score for fold 3579:  0.39751552795031053\n",
      "recall for fold 3579:  0.367816091954023\n",
      "precision for fold 3579:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3580:  0.5023923444976076\n",
      "f1  score for fold 3580:  0.34177215189873417\n",
      "recall for fold 3580:  0.34615384615384615\n",
      "precision for fold 3580:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3581:  0.5502392344497608\n",
      "f1  score for fold 3581:  0.3896103896103896\n",
      "recall for fold 3581:  0.40540540540540543\n",
      "precision for fold 3581:  0.375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 3582:  0.48095238095238096\n",
      "f1  score for fold 3582:  0.2967741935483871\n",
      "recall for fold 3582:  0.30666666666666664\n",
      "precision for fold 3582:  0.2875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3583:  0.5485436893203883\n",
      "f1  score for fold 3583:  0.42236024844720493\n",
      "recall for fold 3583:  0.4146341463414634\n",
      "precision for fold 3583:  0.43037974683544306\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3584:  0.46632124352331605\n",
      "f1  score for fold 3584:  0.36024844720496896\n",
      "recall for fold 3584:  0.3333333333333333\n",
      "precision for fold 3584:  0.3918918918918919\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3585:  0.5406698564593302\n",
      "f1  score for fold 3585:  0.3924050632911393\n",
      "recall for fold 3585:  0.3974358974358974\n",
      "precision for fold 3585:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3586:  0.5119617224880383\n",
      "f1  score for fold 3586:  0.33766233766233766\n",
      "recall for fold 3586:  0.35135135135135137\n",
      "precision for fold 3586:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3587:  0.5571428571428572\n",
      "f1  score for fold 3587:  0.4000000000000001\n",
      "recall for fold 3587:  0.41333333333333333\n",
      "precision for fold 3587:  0.3875\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3588:  0.5776699029126213\n",
      "f1  score for fold 3588:  0.4596273291925466\n",
      "recall for fold 3588:  0.45121951219512196\n",
      "precision for fold 3588:  0.46835443037974683\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3589:  0.46632124352331605\n",
      "f1  score for fold 3589:  0.36024844720496896\n",
      "recall for fold 3589:  0.3333333333333333\n",
      "precision for fold 3589:  0.3918918918918919\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3590:  0.5119617224880383\n",
      "f1  score for fold 3590:  0.3544303797468355\n",
      "recall for fold 3590:  0.358974358974359\n",
      "precision for fold 3590:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3591:  0.569377990430622\n",
      "f1  score for fold 3591:  0.4155844155844156\n",
      "recall for fold 3591:  0.43243243243243246\n",
      "precision for fold 3591:  0.4\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 3592:  0.5857142857142857\n",
      "f1  score for fold 3592:  0.43870967741935485\n",
      "recall for fold 3592:  0.4533333333333333\n",
      "precision for fold 3592:  0.425\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3593:  0.5097087378640777\n",
      "f1  score for fold 3593:  0.37267080745341613\n",
      "recall for fold 3593:  0.36585365853658536\n",
      "precision for fold 3593:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3594:  0.47668393782383417\n",
      "f1  score for fold 3594:  0.3726708074534162\n",
      "recall for fold 3594:  0.3448275862068966\n",
      "precision for fold 3594:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3595:  0.5023923444976076\n",
      "f1  score for fold 3595:  0.34177215189873417\n",
      "recall for fold 3595:  0.34615384615384615\n",
      "precision for fold 3595:  0.3375\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3596:  0.47368421052631576\n",
      "f1  score for fold 3596:  0.28571428571428575\n",
      "recall for fold 3596:  0.2972972972972973\n",
      "precision for fold 3596:  0.275\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3597:  0.5476190476190477\n",
      "f1  score for fold 3597:  0.38709677419354843\n",
      "recall for fold 3597:  0.4\n",
      "precision for fold 3597:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3598:  0.529126213592233\n",
      "f1  score for fold 3598:  0.39751552795031053\n",
      "recall for fold 3598:  0.3902439024390244\n",
      "precision for fold 3598:  0.4050632911392405\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3599:  0.46632124352331605\n",
      "f1  score for fold 3599:  0.36024844720496896\n",
      "recall for fold 3599:  0.3333333333333333\n",
      "precision for fold 3599:  0.3918918918918919\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3600:  0.49282296650717705\n",
      "f1  score for fold 3600:  0.32911392405063294\n",
      "recall for fold 3600:  0.3333333333333333\n",
      "precision for fold 3600:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3601:  0.5215311004784688\n",
      "f1  score for fold 3601:  0.3506493506493507\n",
      "recall for fold 3601:  0.36486486486486486\n",
      "precision for fold 3601:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3602:  0.5285714285714286\n",
      "f1  score for fold 3602:  0.3612903225806451\n",
      "recall for fold 3602:  0.37333333333333335\n",
      "precision for fold 3602:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3603:  0.5097087378640777\n",
      "f1  score for fold 3603:  0.37267080745341613\n",
      "recall for fold 3603:  0.36585365853658536\n",
      "precision for fold 3603:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3604:  0.5284974093264249\n",
      "f1  score for fold 3604:  0.4347826086956522\n",
      "recall for fold 3604:  0.40229885057471265\n",
      "precision for fold 3604:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3605:  0.5119617224880383\n",
      "f1  score for fold 3605:  0.3544303797468355\n",
      "recall for fold 3605:  0.358974358974359\n",
      "precision for fold 3605:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3606:  0.5406698564593302\n",
      "f1  score for fold 3606:  0.37662337662337664\n",
      "recall for fold 3606:  0.3918918918918919\n",
      "precision for fold 3606:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3607:  0.5285714285714286\n",
      "f1  score for fold 3607:  0.3612903225806451\n",
      "recall for fold 3607:  0.37333333333333335\n",
      "precision for fold 3607:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3608:  0.5097087378640777\n",
      "f1  score for fold 3608:  0.37267080745341613\n",
      "recall for fold 3608:  0.36585365853658536\n",
      "precision for fold 3608:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 3609:  0.44559585492227977\n",
      "f1  score for fold 3609:  0.33540372670807456\n",
      "recall for fold 3609:  0.3103448275862069\n",
      "precision for fold 3609:  0.36486486486486486\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3610:  0.5598086124401914\n",
      "f1  score for fold 3610:  0.4177215189873418\n",
      "recall for fold 3610:  0.4230769230769231\n",
      "precision for fold 3610:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3611:  0.5215311004784688\n",
      "f1  score for fold 3611:  0.3506493506493507\n",
      "recall for fold 3611:  0.36486486486486486\n",
      "precision for fold 3611:  0.3375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3612:  0.5190476190476191\n",
      "f1  score for fold 3612:  0.34838709677419355\n",
      "recall for fold 3612:  0.36\n",
      "precision for fold 3612:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3613:  0.5097087378640777\n",
      "f1  score for fold 3613:  0.37267080745341613\n",
      "recall for fold 3613:  0.36585365853658536\n",
      "precision for fold 3613:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3614:  0.47668393782383417\n",
      "f1  score for fold 3614:  0.3726708074534162\n",
      "recall for fold 3614:  0.3448275862068966\n",
      "precision for fold 3614:  0.40540540540540543\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3615:  0.5502392344497608\n",
      "f1  score for fold 3615:  0.4050632911392405\n",
      "recall for fold 3615:  0.41025641025641024\n",
      "precision for fold 3615:  0.4\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3616:  0.5885167464114832\n",
      "f1  score for fold 3616:  0.44155844155844154\n",
      "recall for fold 3616:  0.4594594594594595\n",
      "precision for fold 3616:  0.425\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3617:  0.5095238095238095\n",
      "f1  score for fold 3617:  0.335483870967742\n",
      "recall for fold 3617:  0.3466666666666667\n",
      "precision for fold 3617:  0.325\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3618:  0.558252427184466\n",
      "f1  score for fold 3618:  0.43478260869565216\n",
      "recall for fold 3618:  0.4268292682926829\n",
      "precision for fold 3618:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3619:  0.5284974093264249\n",
      "f1  score for fold 3619:  0.4347826086956522\n",
      "recall for fold 3619:  0.40229885057471265\n",
      "precision for fold 3619:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3620:  0.5023923444976076\n",
      "f1  score for fold 3620:  0.34177215189873417\n",
      "recall for fold 3620:  0.34615384615384615\n",
      "precision for fold 3620:  0.3375\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3621:  0.47368421052631576\n",
      "f1  score for fold 3621:  0.28571428571428575\n",
      "recall for fold 3621:  0.2972972972972973\n",
      "precision for fold 3621:  0.275\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3622:  0.5190476190476191\n",
      "f1  score for fold 3622:  0.34838709677419355\n",
      "recall for fold 3622:  0.36\n",
      "precision for fold 3622:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3623:  0.558252427184466\n",
      "f1  score for fold 3623:  0.43478260869565216\n",
      "recall for fold 3623:  0.4268292682926829\n",
      "precision for fold 3623:  0.4430379746835443\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3624:  0.5077720207253886\n",
      "f1  score for fold 3624:  0.40993788819875776\n",
      "recall for fold 3624:  0.3793103448275862\n",
      "precision for fold 3624:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3625:  0.5023923444976076\n",
      "f1  score for fold 3625:  0.34177215189873417\n",
      "recall for fold 3625:  0.34615384615384615\n",
      "precision for fold 3625:  0.3375\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3626:  0.47368421052631576\n",
      "f1  score for fold 3626:  0.28571428571428575\n",
      "recall for fold 3626:  0.2972972972972973\n",
      "precision for fold 3626:  0.275\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3627:  0.5285714285714286\n",
      "f1  score for fold 3627:  0.3612903225806451\n",
      "recall for fold 3627:  0.37333333333333335\n",
      "precision for fold 3627:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3628:  0.5388349514563107\n",
      "f1  score for fold 3628:  0.40993788819875776\n",
      "recall for fold 3628:  0.4024390243902439\n",
      "precision for fold 3628:  0.4177215189873418\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3629:  0.5492227979274611\n",
      "f1  score for fold 3629:  0.45962732919254656\n",
      "recall for fold 3629:  0.42528735632183906\n",
      "precision for fold 3629:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3630:  0.5023923444976076\n",
      "f1  score for fold 3630:  0.34177215189873417\n",
      "recall for fold 3630:  0.34615384615384615\n",
      "precision for fold 3630:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3631:  0.5215311004784688\n",
      "f1  score for fold 3631:  0.3506493506493507\n",
      "recall for fold 3631:  0.36486486486486486\n",
      "precision for fold 3631:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 3632:  0.5857142857142857\n",
      "f1  score for fold 3632:  0.43870967741935485\n",
      "recall for fold 3632:  0.4533333333333333\n",
      "precision for fold 3632:  0.425\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3633:  0.5\n",
      "f1  score for fold 3633:  0.3602484472049689\n",
      "recall for fold 3633:  0.35365853658536583\n",
      "precision for fold 3633:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3634:  0.5077720207253886\n",
      "f1  score for fold 3634:  0.40993788819875776\n",
      "recall for fold 3634:  0.3793103448275862\n",
      "precision for fold 3634:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3635:  0.569377990430622\n",
      "f1  score for fold 3635:  0.43037974683544306\n",
      "recall for fold 3635:  0.4358974358974359\n",
      "precision for fold 3635:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3636:  0.5215311004784688\n",
      "f1  score for fold 3636:  0.3506493506493507\n",
      "recall for fold 3636:  0.36486486486486486\n",
      "precision for fold 3636:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3637:  0.5380952380952381\n",
      "f1  score for fold 3637:  0.3741935483870968\n",
      "recall for fold 3637:  0.38666666666666666\n",
      "precision for fold 3637:  0.3625\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 3638:  0.45145631067961167\n",
      "f1  score for fold 3638:  0.29813664596273287\n",
      "recall for fold 3638:  0.2926829268292683\n",
      "precision for fold 3638:  0.3037974683544304\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3639:  0.538860103626943\n",
      "f1  score for fold 3639:  0.4472049689440994\n",
      "recall for fold 3639:  0.41379310344827586\n",
      "precision for fold 3639:  0.4864864864864865\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3640:  0.5023923444976076\n",
      "f1  score for fold 3640:  0.34177215189873417\n",
      "recall for fold 3640:  0.34615384615384615\n",
      "precision for fold 3640:  0.3375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3641:  0.5789473684210527\n",
      "f1  score for fold 3641:  0.42857142857142855\n",
      "recall for fold 3641:  0.44594594594594594\n",
      "precision for fold 3641:  0.4125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3642:  0.5666666666666667\n",
      "f1  score for fold 3642:  0.41290322580645167\n",
      "recall for fold 3642:  0.4266666666666667\n",
      "precision for fold 3642:  0.4\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3643:  0.48058252427184467\n",
      "f1  score for fold 3643:  0.33540372670807456\n",
      "recall for fold 3643:  0.32926829268292684\n",
      "precision for fold 3643:  0.34177215189873417\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3644:  0.49740932642487046\n",
      "f1  score for fold 3644:  0.39751552795031053\n",
      "recall for fold 3644:  0.367816091954023\n",
      "precision for fold 3644:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3645:  0.569377990430622\n",
      "f1  score for fold 3645:  0.43037974683544306\n",
      "recall for fold 3645:  0.4358974358974359\n",
      "precision for fold 3645:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3646:  0.5215311004784688\n",
      "f1  score for fold 3646:  0.3506493506493507\n",
      "recall for fold 3646:  0.36486486486486486\n",
      "precision for fold 3646:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3647:  0.5380952380952381\n",
      "f1  score for fold 3647:  0.3741935483870968\n",
      "recall for fold 3647:  0.38666666666666666\n",
      "precision for fold 3647:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3648:  0.470873786407767\n",
      "f1  score for fold 3648:  0.3229813664596273\n",
      "recall for fold 3648:  0.3170731707317073\n",
      "precision for fold 3648:  0.3291139240506329\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3649:  0.5492227979274611\n",
      "f1  score for fold 3649:  0.45962732919254656\n",
      "recall for fold 3649:  0.42528735632183906\n",
      "precision for fold 3649:  0.5\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 3650:  0.47368421052631576\n",
      "f1  score for fold 3650:  0.3037974683544304\n",
      "recall for fold 3650:  0.3076923076923077\n",
      "precision for fold 3650:  0.3\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3651:  0.5789473684210527\n",
      "f1  score for fold 3651:  0.42857142857142855\n",
      "recall for fold 3651:  0.44594594594594594\n",
      "precision for fold 3651:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3652:  0.5285714285714286\n",
      "f1  score for fold 3652:  0.3612903225806451\n",
      "recall for fold 3652:  0.37333333333333335\n",
      "precision for fold 3652:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3653:  0.5485436893203883\n",
      "f1  score for fold 3653:  0.42236024844720493\n",
      "recall for fold 3653:  0.4146341463414634\n",
      "precision for fold 3653:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3654:  0.538860103626943\n",
      "f1  score for fold 3654:  0.4472049689440994\n",
      "recall for fold 3654:  0.41379310344827586\n",
      "precision for fold 3654:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3655:  0.5119617224880383\n",
      "f1  score for fold 3655:  0.3544303797468355\n",
      "recall for fold 3655:  0.358974358974359\n",
      "precision for fold 3655:  0.35\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3656:  0.5502392344497608\n",
      "f1  score for fold 3656:  0.3896103896103896\n",
      "recall for fold 3656:  0.40540540540540543\n",
      "precision for fold 3656:  0.375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 3657:  0.48095238095238096\n",
      "f1  score for fold 3657:  0.2967741935483871\n",
      "recall for fold 3657:  0.30666666666666664\n",
      "precision for fold 3657:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3658:  0.5388349514563107\n",
      "f1  score for fold 3658:  0.40993788819875776\n",
      "recall for fold 3658:  0.4024390243902439\n",
      "precision for fold 3658:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3659:  0.5284974093264249\n",
      "f1  score for fold 3659:  0.4347826086956522\n",
      "recall for fold 3659:  0.40229885057471265\n",
      "precision for fold 3659:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3660:  0.5502392344497608\n",
      "f1  score for fold 3660:  0.4050632911392405\n",
      "recall for fold 3660:  0.41025641025641024\n",
      "precision for fold 3660:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3661:  0.5119617224880383\n",
      "f1  score for fold 3661:  0.33766233766233766\n",
      "recall for fold 3661:  0.35135135135135137\n",
      "precision for fold 3661:  0.325\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 3662:  0.4714285714285714\n",
      "f1  score for fold 3662:  0.2838709677419355\n",
      "recall for fold 3662:  0.29333333333333333\n",
      "precision for fold 3662:  0.275\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3663:  0.5388349514563107\n",
      "f1  score for fold 3663:  0.40993788819875776\n",
      "recall for fold 3663:  0.4024390243902439\n",
      "precision for fold 3663:  0.4177215189873418\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 3664:  0.5595854922279793\n",
      "f1  score for fold 3664:  0.4720496894409938\n",
      "recall for fold 3664:  0.4367816091954023\n",
      "precision for fold 3664:  0.5135135135135135\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3665:  0.5311004784688995\n",
      "f1  score for fold 3665:  0.37974683544303806\n",
      "recall for fold 3665:  0.38461538461538464\n",
      "precision for fold 3665:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3666:  0.5502392344497608\n",
      "f1  score for fold 3666:  0.3896103896103896\n",
      "recall for fold 3666:  0.40540540540540543\n",
      "precision for fold 3666:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3667:  0.5380952380952381\n",
      "f1  score for fold 3667:  0.3741935483870968\n",
      "recall for fold 3667:  0.38666666666666666\n",
      "precision for fold 3667:  0.3625\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 3668:  0.46116504854368934\n",
      "f1  score for fold 3668:  0.31055900621118016\n",
      "recall for fold 3668:  0.3048780487804878\n",
      "precision for fold 3668:  0.31645569620253167\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3669:  0.5284974093264249\n",
      "f1  score for fold 3669:  0.4347826086956522\n",
      "recall for fold 3669:  0.40229885057471265\n",
      "precision for fold 3669:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3670:  0.5406698564593302\n",
      "f1  score for fold 3670:  0.3924050632911393\n",
      "recall for fold 3670:  0.3974358974358974\n",
      "precision for fold 3670:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3671:  0.49282296650717705\n",
      "f1  score for fold 3671:  0.3116883116883117\n",
      "recall for fold 3671:  0.32432432432432434\n",
      "precision for fold 3671:  0.3\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3672:  0.5761904761904761\n",
      "f1  score for fold 3672:  0.4258064516129032\n",
      "recall for fold 3672:  0.44\n",
      "precision for fold 3672:  0.4125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3673:  0.529126213592233\n",
      "f1  score for fold 3673:  0.39751552795031053\n",
      "recall for fold 3673:  0.3902439024390244\n",
      "precision for fold 3673:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3674:  0.49740932642487046\n",
      "f1  score for fold 3674:  0.39751552795031053\n",
      "recall for fold 3674:  0.367816091954023\n",
      "precision for fold 3674:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3675:  0.49282296650717705\n",
      "f1  score for fold 3675:  0.32911392405063294\n",
      "recall for fold 3675:  0.3333333333333333\n",
      "precision for fold 3675:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3676:  0.5406698564593302\n",
      "f1  score for fold 3676:  0.37662337662337664\n",
      "recall for fold 3676:  0.3918918918918919\n",
      "precision for fold 3676:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3677:  0.5190476190476191\n",
      "f1  score for fold 3677:  0.34838709677419355\n",
      "recall for fold 3677:  0.36\n",
      "precision for fold 3677:  0.3375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3678:  0.5097087378640777\n",
      "f1  score for fold 3678:  0.37267080745341613\n",
      "recall for fold 3678:  0.36585365853658536\n",
      "precision for fold 3678:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3679:  0.5077720207253886\n",
      "f1  score for fold 3679:  0.40993788819875776\n",
      "recall for fold 3679:  0.3793103448275862\n",
      "precision for fold 3679:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3680:  0.5215311004784688\n",
      "f1  score for fold 3680:  0.36708860759493667\n",
      "recall for fold 3680:  0.3717948717948718\n",
      "precision for fold 3680:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3681:  0.5311004784688995\n",
      "f1  score for fold 3681:  0.36363636363636365\n",
      "recall for fold 3681:  0.3783783783783784\n",
      "precision for fold 3681:  0.35\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3682:  0.5\n",
      "f1  score for fold 3682:  0.3225806451612903\n",
      "recall for fold 3682:  0.3333333333333333\n",
      "precision for fold 3682:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3683:  0.5485436893203883\n",
      "f1  score for fold 3683:  0.42236024844720493\n",
      "recall for fold 3683:  0.4146341463414634\n",
      "precision for fold 3683:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3684:  0.5077720207253886\n",
      "f1  score for fold 3684:  0.40993788819875776\n",
      "recall for fold 3684:  0.3793103448275862\n",
      "precision for fold 3684:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3685:  0.5598086124401914\n",
      "f1  score for fold 3685:  0.4177215189873418\n",
      "recall for fold 3685:  0.4230769230769231\n",
      "precision for fold 3685:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3686:  0.5598086124401914\n",
      "f1  score for fold 3686:  0.40259740259740256\n",
      "recall for fold 3686:  0.4189189189189189\n",
      "precision for fold 3686:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3687:  0.5285714285714286\n",
      "f1  score for fold 3687:  0.3612903225806451\n",
      "recall for fold 3687:  0.37333333333333335\n",
      "precision for fold 3687:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3688:  0.5679611650485437\n",
      "f1  score for fold 3688:  0.4472049689440994\n",
      "recall for fold 3688:  0.43902439024390244\n",
      "precision for fold 3688:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3689:  0.49740932642487046\n",
      "f1  score for fold 3689:  0.39751552795031053\n",
      "recall for fold 3689:  0.367816091954023\n",
      "precision for fold 3689:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3690:  0.5502392344497608\n",
      "f1  score for fold 3690:  0.4050632911392405\n",
      "recall for fold 3690:  0.41025641025641024\n",
      "precision for fold 3690:  0.4\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 3691:  0.48325358851674644\n",
      "f1  score for fold 3691:  0.29870129870129863\n",
      "recall for fold 3691:  0.3108108108108108\n",
      "precision for fold 3691:  0.2875\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 3692:  0.6047619047619047\n",
      "f1  score for fold 3692:  0.4645161290322581\n",
      "recall for fold 3692:  0.48\n",
      "precision for fold 3692:  0.45\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 3693:  0.441747572815534\n",
      "f1  score for fold 3693:  0.28571428571428575\n",
      "recall for fold 3693:  0.2804878048780488\n",
      "precision for fold 3693:  0.2911392405063291\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3694:  0.538860103626943\n",
      "f1  score for fold 3694:  0.4472049689440994\n",
      "recall for fold 3694:  0.41379310344827586\n",
      "precision for fold 3694:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3695:  0.5598086124401914\n",
      "f1  score for fold 3695:  0.4177215189873418\n",
      "recall for fold 3695:  0.4230769230769231\n",
      "precision for fold 3695:  0.4125\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 3696:  0.46411483253588515\n",
      "f1  score for fold 3696:  0.27272727272727276\n",
      "recall for fold 3696:  0.28378378378378377\n",
      "precision for fold 3696:  0.2625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3697:  0.5761904761904761\n",
      "f1  score for fold 3697:  0.4258064516129032\n",
      "recall for fold 3697:  0.44\n",
      "precision for fold 3697:  0.4125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3698:  0.49029126213592233\n",
      "f1  score for fold 3698:  0.3478260869565218\n",
      "recall for fold 3698:  0.34146341463414637\n",
      "precision for fold 3698:  0.35443037974683544\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 3699:  0.5699481865284974\n",
      "f1  score for fold 3699:  0.48447204968944096\n",
      "recall for fold 3699:  0.4482758620689655\n",
      "precision for fold 3699:  0.527027027027027\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3700:  0.5789473684210527\n",
      "f1  score for fold 3700:  0.44303797468354433\n",
      "recall for fold 3700:  0.44871794871794873\n",
      "precision for fold 3700:  0.4375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3701:  0.5023923444976076\n",
      "f1  score for fold 3701:  0.3246753246753247\n",
      "recall for fold 3701:  0.33783783783783783\n",
      "precision for fold 3701:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3702:  0.5380952380952381\n",
      "f1  score for fold 3702:  0.3741935483870968\n",
      "recall for fold 3702:  0.38666666666666666\n",
      "precision for fold 3702:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3703:  0.5\n",
      "f1  score for fold 3703:  0.3602484472049689\n",
      "recall for fold 3703:  0.35365853658536583\n",
      "precision for fold 3703:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3704:  0.5284974093264249\n",
      "f1  score for fold 3704:  0.4347826086956522\n",
      "recall for fold 3704:  0.40229885057471265\n",
      "precision for fold 3704:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3705:  0.5215311004784688\n",
      "f1  score for fold 3705:  0.36708860759493667\n",
      "recall for fold 3705:  0.3717948717948718\n",
      "precision for fold 3705:  0.3625\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 3706:  0.6076555023923444\n",
      "f1  score for fold 3706:  0.4675324675324675\n",
      "recall for fold 3706:  0.4864864864864865\n",
      "precision for fold 3706:  0.45\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 3707:  0.48095238095238096\n",
      "f1  score for fold 3707:  0.2967741935483871\n",
      "recall for fold 3707:  0.30666666666666664\n",
      "precision for fold 3707:  0.2875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3708:  0.5194174757281553\n",
      "f1  score for fold 3708:  0.38509316770186336\n",
      "recall for fold 3708:  0.3780487804878049\n",
      "precision for fold 3708:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3709:  0.48704663212435234\n",
      "f1  score for fold 3709:  0.3850931677018633\n",
      "recall for fold 3709:  0.3563218390804598\n",
      "precision for fold 3709:  0.4189189189189189\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3710:  0.5119617224880383\n",
      "f1  score for fold 3710:  0.3544303797468355\n",
      "recall for fold 3710:  0.358974358974359\n",
      "precision for fold 3710:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3711:  0.5406698564593302\n",
      "f1  score for fold 3711:  0.37662337662337664\n",
      "recall for fold 3711:  0.3918918918918919\n",
      "precision for fold 3711:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3712:  0.5285714285714286\n",
      "f1  score for fold 3712:  0.3612903225806451\n",
      "recall for fold 3712:  0.37333333333333335\n",
      "precision for fold 3712:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3713:  0.48058252427184467\n",
      "f1  score for fold 3713:  0.33540372670807456\n",
      "recall for fold 3713:  0.32926829268292684\n",
      "precision for fold 3713:  0.34177215189873417\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3714:  0.49740932642487046\n",
      "f1  score for fold 3714:  0.39751552795031053\n",
      "recall for fold 3714:  0.367816091954023\n",
      "precision for fold 3714:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3715:  0.49282296650717705\n",
      "f1  score for fold 3715:  0.32911392405063294\n",
      "recall for fold 3715:  0.3333333333333333\n",
      "precision for fold 3715:  0.325\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3716:  0.5311004784688995\n",
      "f1  score for fold 3716:  0.36363636363636365\n",
      "recall for fold 3716:  0.3783783783783784\n",
      "precision for fold 3716:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3717:  0.5476190476190477\n",
      "f1  score for fold 3717:  0.38709677419354843\n",
      "recall for fold 3717:  0.4\n",
      "precision for fold 3717:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3718:  0.5194174757281553\n",
      "f1  score for fold 3718:  0.38509316770186336\n",
      "recall for fold 3718:  0.3780487804878049\n",
      "precision for fold 3718:  0.3924050632911392\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 3719:  0.44559585492227977\n",
      "f1  score for fold 3719:  0.33540372670807456\n",
      "recall for fold 3719:  0.3103448275862069\n",
      "precision for fold 3719:  0.36486486486486486\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3720:  0.5023923444976076\n",
      "f1  score for fold 3720:  0.34177215189873417\n",
      "recall for fold 3720:  0.34615384615384615\n",
      "precision for fold 3720:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3721:  0.5311004784688995\n",
      "f1  score for fold 3721:  0.36363636363636365\n",
      "recall for fold 3721:  0.3783783783783784\n",
      "precision for fold 3721:  0.35\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 3722:  0.4523809523809524\n",
      "f1  score for fold 3722:  0.2580645161290323\n",
      "recall for fold 3722:  0.26666666666666666\n",
      "precision for fold 3722:  0.25\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3723:  0.5\n",
      "f1  score for fold 3723:  0.3602484472049689\n",
      "recall for fold 3723:  0.35365853658536583\n",
      "precision for fold 3723:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3724:  0.49740932642487046\n",
      "f1  score for fold 3724:  0.39751552795031053\n",
      "recall for fold 3724:  0.367816091954023\n",
      "precision for fold 3724:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3725:  0.5119617224880383\n",
      "f1  score for fold 3725:  0.3544303797468355\n",
      "recall for fold 3725:  0.358974358974359\n",
      "precision for fold 3725:  0.35\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3726:  0.5885167464114832\n",
      "f1  score for fold 3726:  0.44155844155844154\n",
      "recall for fold 3726:  0.4594594594594595\n",
      "precision for fold 3726:  0.425\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 3727:  0.5380952380952381\n",
      "f1  score for fold 3727:  0.3741935483870968\n",
      "recall for fold 3727:  0.38666666666666666\n",
      "precision for fold 3727:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3728:  0.5\n",
      "f1  score for fold 3728:  0.3602484472049689\n",
      "recall for fold 3728:  0.35365853658536583\n",
      "precision for fold 3728:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3729:  0.5284974093264249\n",
      "f1  score for fold 3729:  0.4347826086956522\n",
      "recall for fold 3729:  0.40229885057471265\n",
      "precision for fold 3729:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3730:  0.5598086124401914\n",
      "f1  score for fold 3730:  0.4177215189873418\n",
      "recall for fold 3730:  0.4230769230769231\n",
      "precision for fold 3730:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3731:  0.5406698564593302\n",
      "f1  score for fold 3731:  0.37662337662337664\n",
      "recall for fold 3731:  0.3918918918918919\n",
      "precision for fold 3731:  0.3625\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 3732:  0.6047619047619047\n",
      "f1  score for fold 3732:  0.4645161290322581\n",
      "recall for fold 3732:  0.48\n",
      "precision for fold 3732:  0.45\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3733:  0.5679611650485437\n",
      "f1  score for fold 3733:  0.4472049689440994\n",
      "recall for fold 3733:  0.43902439024390244\n",
      "precision for fold 3733:  0.45569620253164556\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3734:  0.47668393782383417\n",
      "f1  score for fold 3734:  0.3726708074534162\n",
      "recall for fold 3734:  0.3448275862068966\n",
      "precision for fold 3734:  0.40540540540540543\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3735:  0.5023923444976076\n",
      "f1  score for fold 3735:  0.34177215189873417\n",
      "recall for fold 3735:  0.34615384615384615\n",
      "precision for fold 3735:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3736:  0.5311004784688995\n",
      "f1  score for fold 3736:  0.36363636363636365\n",
      "recall for fold 3736:  0.3783783783783784\n",
      "precision for fold 3736:  0.35\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3737:  0.5761904761904761\n",
      "f1  score for fold 3737:  0.4258064516129032\n",
      "recall for fold 3737:  0.44\n",
      "precision for fold 3737:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3738:  0.5194174757281553\n",
      "f1  score for fold 3738:  0.38509316770186336\n",
      "recall for fold 3738:  0.3780487804878049\n",
      "precision for fold 3738:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3739:  0.5492227979274611\n",
      "f1  score for fold 3739:  0.45962732919254656\n",
      "recall for fold 3739:  0.42528735632183906\n",
      "precision for fold 3739:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3740:  0.5406698564593302\n",
      "f1  score for fold 3740:  0.3924050632911393\n",
      "recall for fold 3740:  0.3974358974358974\n",
      "precision for fold 3740:  0.3875\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3741:  0.5789473684210527\n",
      "f1  score for fold 3741:  0.42857142857142855\n",
      "recall for fold 3741:  0.44594594594594594\n",
      "precision for fold 3741:  0.4125\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 3742:  0.5952380952380952\n",
      "f1  score for fold 3742:  0.45161290322580644\n",
      "recall for fold 3742:  0.4666666666666667\n",
      "precision for fold 3742:  0.4375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3743:  0.5388349514563107\n",
      "f1  score for fold 3743:  0.40993788819875776\n",
      "recall for fold 3743:  0.4024390243902439\n",
      "precision for fold 3743:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3744:  0.538860103626943\n",
      "f1  score for fold 3744:  0.4472049689440994\n",
      "recall for fold 3744:  0.41379310344827586\n",
      "precision for fold 3744:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3745:  0.569377990430622\n",
      "f1  score for fold 3745:  0.43037974683544306\n",
      "recall for fold 3745:  0.4358974358974359\n",
      "precision for fold 3745:  0.425\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3746:  0.5406698564593302\n",
      "f1  score for fold 3746:  0.37662337662337664\n",
      "recall for fold 3746:  0.3918918918918919\n",
      "precision for fold 3746:  0.3625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3747:  0.5761904761904761\n",
      "f1  score for fold 3747:  0.4258064516129032\n",
      "recall for fold 3747:  0.44\n",
      "precision for fold 3747:  0.4125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3748:  0.558252427184466\n",
      "f1  score for fold 3748:  0.43478260869565216\n",
      "recall for fold 3748:  0.4268292682926829\n",
      "precision for fold 3748:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3749:  0.48704663212435234\n",
      "f1  score for fold 3749:  0.3850931677018633\n",
      "recall for fold 3749:  0.3563218390804598\n",
      "precision for fold 3749:  0.4189189189189189\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3750:  0.48325358851674644\n",
      "f1  score for fold 3750:  0.31645569620253167\n",
      "recall for fold 3750:  0.32051282051282054\n",
      "precision for fold 3750:  0.3125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3751:  0.5311004784688995\n",
      "f1  score for fold 3751:  0.36363636363636365\n",
      "recall for fold 3751:  0.3783783783783784\n",
      "precision for fold 3751:  0.35\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 3752:  0.5952380952380952\n",
      "f1  score for fold 3752:  0.45161290322580644\n",
      "recall for fold 3752:  0.4666666666666667\n",
      "precision for fold 3752:  0.4375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3753:  0.5388349514563107\n",
      "f1  score for fold 3753:  0.40993788819875776\n",
      "recall for fold 3753:  0.4024390243902439\n",
      "precision for fold 3753:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3754:  0.48704663212435234\n",
      "f1  score for fold 3754:  0.3850931677018633\n",
      "recall for fold 3754:  0.3563218390804598\n",
      "precision for fold 3754:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3755:  0.5598086124401914\n",
      "f1  score for fold 3755:  0.4177215189873418\n",
      "recall for fold 3755:  0.4230769230769231\n",
      "precision for fold 3755:  0.4125\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3756:  0.5406698564593302\n",
      "f1  score for fold 3756:  0.37662337662337664\n",
      "recall for fold 3756:  0.3918918918918919\n",
      "precision for fold 3756:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3757:  0.5095238095238095\n",
      "f1  score for fold 3757:  0.335483870967742\n",
      "recall for fold 3757:  0.3466666666666667\n",
      "precision for fold 3757:  0.325\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3758:  0.5485436893203883\n",
      "f1  score for fold 3758:  0.42236024844720493\n",
      "recall for fold 3758:  0.4146341463414634\n",
      "precision for fold 3758:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3759:  0.5284974093264249\n",
      "f1  score for fold 3759:  0.4347826086956522\n",
      "recall for fold 3759:  0.40229885057471265\n",
      "precision for fold 3759:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3760:  0.5215311004784688\n",
      "f1  score for fold 3760:  0.36708860759493667\n",
      "recall for fold 3760:  0.3717948717948718\n",
      "precision for fold 3760:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3761:  0.5502392344497608\n",
      "f1  score for fold 3761:  0.3896103896103896\n",
      "recall for fold 3761:  0.40540540540540543\n",
      "precision for fold 3761:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3762:  0.5285714285714286\n",
      "f1  score for fold 3762:  0.3612903225806451\n",
      "recall for fold 3762:  0.37333333333333335\n",
      "precision for fold 3762:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3763:  0.529126213592233\n",
      "f1  score for fold 3763:  0.39751552795031053\n",
      "recall for fold 3763:  0.3902439024390244\n",
      "precision for fold 3763:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3764:  0.47668393782383417\n",
      "f1  score for fold 3764:  0.3726708074534162\n",
      "recall for fold 3764:  0.3448275862068966\n",
      "precision for fold 3764:  0.40540540540540543\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3765:  0.48325358851674644\n",
      "f1  score for fold 3765:  0.31645569620253167\n",
      "recall for fold 3765:  0.32051282051282054\n",
      "precision for fold 3765:  0.3125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3766:  0.5023923444976076\n",
      "f1  score for fold 3766:  0.3246753246753247\n",
      "recall for fold 3766:  0.33783783783783783\n",
      "precision for fold 3766:  0.3125\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3767:  0.49047619047619045\n",
      "f1  score for fold 3767:  0.3096774193548387\n",
      "recall for fold 3767:  0.32\n",
      "precision for fold 3767:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3768:  0.558252427184466\n",
      "f1  score for fold 3768:  0.43478260869565216\n",
      "recall for fold 3768:  0.4268292682926829\n",
      "precision for fold 3768:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3769:  0.5284974093264249\n",
      "f1  score for fold 3769:  0.4347826086956522\n",
      "recall for fold 3769:  0.40229885057471265\n",
      "precision for fold 3769:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3770:  0.5502392344497608\n",
      "f1  score for fold 3770:  0.4050632911392405\n",
      "recall for fold 3770:  0.41025641025641024\n",
      "precision for fold 3770:  0.4\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3771:  0.5119617224880383\n",
      "f1  score for fold 3771:  0.33766233766233766\n",
      "recall for fold 3771:  0.35135135135135137\n",
      "precision for fold 3771:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3772:  0.5571428571428572\n",
      "f1  score for fold 3772:  0.4000000000000001\n",
      "recall for fold 3772:  0.41333333333333333\n",
      "precision for fold 3772:  0.3875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3773:  0.5679611650485437\n",
      "f1  score for fold 3773:  0.4472049689440994\n",
      "recall for fold 3773:  0.43902439024390244\n",
      "precision for fold 3773:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3774:  0.5284974093264249\n",
      "f1  score for fold 3774:  0.4347826086956522\n",
      "recall for fold 3774:  0.40229885057471265\n",
      "precision for fold 3774:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3775:  0.5311004784688995\n",
      "f1  score for fold 3775:  0.37974683544303806\n",
      "recall for fold 3775:  0.38461538461538464\n",
      "precision for fold 3775:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3776:  0.5598086124401914\n",
      "f1  score for fold 3776:  0.40259740259740256\n",
      "recall for fold 3776:  0.4189189189189189\n",
      "precision for fold 3776:  0.3875\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 3777:  0.5857142857142857\n",
      "f1  score for fold 3777:  0.43870967741935485\n",
      "recall for fold 3777:  0.4533333333333333\n",
      "precision for fold 3777:  0.425\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3778:  0.5\n",
      "f1  score for fold 3778:  0.3602484472049689\n",
      "recall for fold 3778:  0.35365853658536583\n",
      "precision for fold 3778:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3779:  0.49740932642487046\n",
      "f1  score for fold 3779:  0.39751552795031053\n",
      "recall for fold 3779:  0.367816091954023\n",
      "precision for fold 3779:  0.43243243243243246\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 3780:  0.48325358851674644\n",
      "f1  score for fold 3780:  0.31645569620253167\n",
      "recall for fold 3780:  0.32051282051282054\n",
      "precision for fold 3780:  0.3125\n",
      "    0   1\n",
      "0  20  54\n",
      "1  60  75\n",
      "Accuracy for fold 3781:  0.45454545454545453\n",
      "f1  score for fold 3781:  0.25974025974025977\n",
      "recall for fold 3781:  0.2702702702702703\n",
      "precision for fold 3781:  0.25\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3782:  0.5666666666666667\n",
      "f1  score for fold 3782:  0.41290322580645167\n",
      "recall for fold 3782:  0.4266666666666667\n",
      "precision for fold 3782:  0.4\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3783:  0.5485436893203883\n",
      "f1  score for fold 3783:  0.42236024844720493\n",
      "recall for fold 3783:  0.4146341463414634\n",
      "precision for fold 3783:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3784:  0.5284974093264249\n",
      "f1  score for fold 3784:  0.4347826086956522\n",
      "recall for fold 3784:  0.40229885057471265\n",
      "precision for fold 3784:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3785:  0.5598086124401914\n",
      "f1  score for fold 3785:  0.4177215189873418\n",
      "recall for fold 3785:  0.4230769230769231\n",
      "precision for fold 3785:  0.4125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3786:  0.5789473684210527\n",
      "f1  score for fold 3786:  0.42857142857142855\n",
      "recall for fold 3786:  0.44594594594594594\n",
      "precision for fold 3786:  0.4125\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3787:  0.5\n",
      "f1  score for fold 3787:  0.3225806451612903\n",
      "recall for fold 3787:  0.3333333333333333\n",
      "precision for fold 3787:  0.3125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3788:  0.49029126213592233\n",
      "f1  score for fold 3788:  0.3478260869565218\n",
      "recall for fold 3788:  0.34146341463414637\n",
      "precision for fold 3788:  0.35443037974683544\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3789:  0.5492227979274611\n",
      "f1  score for fold 3789:  0.45962732919254656\n",
      "recall for fold 3789:  0.42528735632183906\n",
      "precision for fold 3789:  0.5\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3790:  0.5215311004784688\n",
      "f1  score for fold 3790:  0.36708860759493667\n",
      "recall for fold 3790:  0.3717948717948718\n",
      "precision for fold 3790:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3791:  0.5215311004784688\n",
      "f1  score for fold 3791:  0.3506493506493507\n",
      "recall for fold 3791:  0.36486486486486486\n",
      "precision for fold 3791:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3792:  0.5285714285714286\n",
      "f1  score for fold 3792:  0.3612903225806451\n",
      "recall for fold 3792:  0.37333333333333335\n",
      "precision for fold 3792:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3793:  0.5388349514563107\n",
      "f1  score for fold 3793:  0.40993788819875776\n",
      "recall for fold 3793:  0.4024390243902439\n",
      "precision for fold 3793:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3794:  0.47668393782383417\n",
      "f1  score for fold 3794:  0.3726708074534162\n",
      "recall for fold 3794:  0.3448275862068966\n",
      "precision for fold 3794:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3795:  0.5598086124401914\n",
      "f1  score for fold 3795:  0.4177215189873418\n",
      "recall for fold 3795:  0.4230769230769231\n",
      "precision for fold 3795:  0.4125\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3796:  0.5789473684210527\n",
      "f1  score for fold 3796:  0.42857142857142855\n",
      "recall for fold 3796:  0.44594594594594594\n",
      "precision for fold 3796:  0.4125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3797:  0.5666666666666667\n",
      "f1  score for fold 3797:  0.41290322580645167\n",
      "recall for fold 3797:  0.4266666666666667\n",
      "precision for fold 3797:  0.4\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 3798:  0.587378640776699\n",
      "f1  score for fold 3798:  0.4720496894409938\n",
      "recall for fold 3798:  0.4634146341463415\n",
      "precision for fold 3798:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3799:  0.49740932642487046\n",
      "f1  score for fold 3799:  0.39751552795031053\n",
      "recall for fold 3799:  0.367816091954023\n",
      "precision for fold 3799:  0.43243243243243246\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3800:  0.569377990430622\n",
      "f1  score for fold 3800:  0.43037974683544306\n",
      "recall for fold 3800:  0.4358974358974359\n",
      "precision for fold 3800:  0.425\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3801:  0.49282296650717705\n",
      "f1  score for fold 3801:  0.3116883116883117\n",
      "recall for fold 3801:  0.32432432432432434\n",
      "precision for fold 3801:  0.3\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3802:  0.5190476190476191\n",
      "f1  score for fold 3802:  0.34838709677419355\n",
      "recall for fold 3802:  0.36\n",
      "precision for fold 3802:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3803:  0.5388349514563107\n",
      "f1  score for fold 3803:  0.40993788819875776\n",
      "recall for fold 3803:  0.4024390243902439\n",
      "precision for fold 3803:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3804:  0.5284974093264249\n",
      "f1  score for fold 3804:  0.4347826086956522\n",
      "recall for fold 3804:  0.40229885057471265\n",
      "precision for fold 3804:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3805:  0.5406698564593302\n",
      "f1  score for fold 3805:  0.3924050632911393\n",
      "recall for fold 3805:  0.3974358974358974\n",
      "precision for fold 3805:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 3806:  0.5119617224880383\n",
      "f1  score for fold 3806:  0.33766233766233766\n",
      "recall for fold 3806:  0.35135135135135137\n",
      "precision for fold 3806:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3807:  0.5190476190476191\n",
      "f1  score for fold 3807:  0.34838709677419355\n",
      "recall for fold 3807:  0.36\n",
      "precision for fold 3807:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3808:  0.5194174757281553\n",
      "f1  score for fold 3808:  0.38509316770186336\n",
      "recall for fold 3808:  0.3780487804878049\n",
      "precision for fold 3808:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3809:  0.5492227979274611\n",
      "f1  score for fold 3809:  0.45962732919254656\n",
      "recall for fold 3809:  0.42528735632183906\n",
      "precision for fold 3809:  0.5\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3810:  0.5502392344497608\n",
      "f1  score for fold 3810:  0.4050632911392405\n",
      "recall for fold 3810:  0.41025641025641024\n",
      "precision for fold 3810:  0.4\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 3811:  0.6172248803827751\n",
      "f1  score for fold 3811:  0.4805194805194805\n",
      "recall for fold 3811:  0.5\n",
      "precision for fold 3811:  0.4625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3812:  0.5761904761904761\n",
      "f1  score for fold 3812:  0.4258064516129032\n",
      "recall for fold 3812:  0.44\n",
      "precision for fold 3812:  0.4125\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3813:  0.49029126213592233\n",
      "f1  score for fold 3813:  0.3478260869565218\n",
      "recall for fold 3813:  0.34146341463414637\n",
      "precision for fold 3813:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3814:  0.5181347150259067\n",
      "f1  score for fold 3814:  0.422360248447205\n",
      "recall for fold 3814:  0.39080459770114945\n",
      "precision for fold 3814:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3815:  0.5502392344497608\n",
      "f1  score for fold 3815:  0.4050632911392405\n",
      "recall for fold 3815:  0.41025641025641024\n",
      "precision for fold 3815:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3816:  0.5406698564593302\n",
      "f1  score for fold 3816:  0.37662337662337664\n",
      "recall for fold 3816:  0.3918918918918919\n",
      "precision for fold 3816:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3817:  0.5666666666666667\n",
      "f1  score for fold 3817:  0.41290322580645167\n",
      "recall for fold 3817:  0.4266666666666667\n",
      "precision for fold 3817:  0.4\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3818:  0.5194174757281553\n",
      "f1  score for fold 3818:  0.38509316770186336\n",
      "recall for fold 3818:  0.3780487804878049\n",
      "precision for fold 3818:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3819:  0.5077720207253886\n",
      "f1  score for fold 3819:  0.40993788819875776\n",
      "recall for fold 3819:  0.3793103448275862\n",
      "precision for fold 3819:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3820:  0.5406698564593302\n",
      "f1  score for fold 3820:  0.3924050632911393\n",
      "recall for fold 3820:  0.3974358974358974\n",
      "precision for fold 3820:  0.3875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3821:  0.5406698564593302\n",
      "f1  score for fold 3821:  0.37662337662337664\n",
      "recall for fold 3821:  0.3918918918918919\n",
      "precision for fold 3821:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3822:  0.5285714285714286\n",
      "f1  score for fold 3822:  0.3612903225806451\n",
      "recall for fold 3822:  0.37333333333333335\n",
      "precision for fold 3822:  0.35\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3823:  0.470873786407767\n",
      "f1  score for fold 3823:  0.3229813664596273\n",
      "recall for fold 3823:  0.3170731707317073\n",
      "precision for fold 3823:  0.3291139240506329\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3824:  0.46632124352331605\n",
      "f1  score for fold 3824:  0.36024844720496896\n",
      "recall for fold 3824:  0.3333333333333333\n",
      "precision for fold 3824:  0.3918918918918919\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3825:  0.5406698564593302\n",
      "f1  score for fold 3825:  0.3924050632911393\n",
      "recall for fold 3825:  0.3974358974358974\n",
      "precision for fold 3825:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 3826:  0.48325358851674644\n",
      "f1  score for fold 3826:  0.29870129870129863\n",
      "recall for fold 3826:  0.3108108108108108\n",
      "precision for fold 3826:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3827:  0.5476190476190477\n",
      "f1  score for fold 3827:  0.38709677419354843\n",
      "recall for fold 3827:  0.4\n",
      "precision for fold 3827:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3828:  0.5194174757281553\n",
      "f1  score for fold 3828:  0.38509316770186336\n",
      "recall for fold 3828:  0.3780487804878049\n",
      "precision for fold 3828:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3829:  0.538860103626943\n",
      "f1  score for fold 3829:  0.4472049689440994\n",
      "recall for fold 3829:  0.41379310344827586\n",
      "precision for fold 3829:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3830:  0.5502392344497608\n",
      "f1  score for fold 3830:  0.4050632911392405\n",
      "recall for fold 3830:  0.41025641025641024\n",
      "precision for fold 3830:  0.4\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3831:  0.569377990430622\n",
      "f1  score for fold 3831:  0.4155844155844156\n",
      "recall for fold 3831:  0.43243243243243246\n",
      "precision for fold 3831:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3832:  0.5476190476190477\n",
      "f1  score for fold 3832:  0.38709677419354843\n",
      "recall for fold 3832:  0.4\n",
      "precision for fold 3832:  0.375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3833:  0.48058252427184467\n",
      "f1  score for fold 3833:  0.33540372670807456\n",
      "recall for fold 3833:  0.32926829268292684\n",
      "precision for fold 3833:  0.34177215189873417\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3834:  0.5284974093264249\n",
      "f1  score for fold 3834:  0.4347826086956522\n",
      "recall for fold 3834:  0.40229885057471265\n",
      "precision for fold 3834:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3835:  0.5023923444976076\n",
      "f1  score for fold 3835:  0.34177215189873417\n",
      "recall for fold 3835:  0.34615384615384615\n",
      "precision for fold 3835:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3836:  0.5406698564593302\n",
      "f1  score for fold 3836:  0.37662337662337664\n",
      "recall for fold 3836:  0.3918918918918919\n",
      "precision for fold 3836:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3837:  0.5190476190476191\n",
      "f1  score for fold 3837:  0.34838709677419355\n",
      "recall for fold 3837:  0.36\n",
      "precision for fold 3837:  0.3375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 3838:  0.558252427184466\n",
      "f1  score for fold 3838:  0.43478260869565216\n",
      "recall for fold 3838:  0.4268292682926829\n",
      "precision for fold 3838:  0.4430379746835443\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3839:  0.46632124352331605\n",
      "f1  score for fold 3839:  0.36024844720496896\n",
      "recall for fold 3839:  0.3333333333333333\n",
      "precision for fold 3839:  0.3918918918918919\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3840:  0.5215311004784688\n",
      "f1  score for fold 3840:  0.36708860759493667\n",
      "recall for fold 3840:  0.3717948717948718\n",
      "precision for fold 3840:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3841:  0.5598086124401914\n",
      "f1  score for fold 3841:  0.40259740259740256\n",
      "recall for fold 3841:  0.4189189189189189\n",
      "precision for fold 3841:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3842:  0.5476190476190477\n",
      "f1  score for fold 3842:  0.38709677419354843\n",
      "recall for fold 3842:  0.4\n",
      "precision for fold 3842:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3843:  0.5679611650485437\n",
      "f1  score for fold 3843:  0.4472049689440994\n",
      "recall for fold 3843:  0.43902439024390244\n",
      "precision for fold 3843:  0.45569620253164556\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 3844:  0.46632124352331605\n",
      "f1  score for fold 3844:  0.36024844720496896\n",
      "recall for fold 3844:  0.3333333333333333\n",
      "precision for fold 3844:  0.3918918918918919\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 3845:  0.5885167464114832\n",
      "f1  score for fold 3845:  0.45569620253164556\n",
      "recall for fold 3845:  0.46153846153846156\n",
      "precision for fold 3845:  0.45\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3846:  0.569377990430622\n",
      "f1  score for fold 3846:  0.4155844155844156\n",
      "recall for fold 3846:  0.43243243243243246\n",
      "precision for fold 3846:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 3847:  0.5095238095238095\n",
      "f1  score for fold 3847:  0.335483870967742\n",
      "recall for fold 3847:  0.3466666666666667\n",
      "precision for fold 3847:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3848:  0.5679611650485437\n",
      "f1  score for fold 3848:  0.4472049689440994\n",
      "recall for fold 3848:  0.43902439024390244\n",
      "precision for fold 3848:  0.45569620253164556\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3849:  0.538860103626943\n",
      "f1  score for fold 3849:  0.4472049689440994\n",
      "recall for fold 3849:  0.41379310344827586\n",
      "precision for fold 3849:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3850:  0.49282296650717705\n",
      "f1  score for fold 3850:  0.32911392405063294\n",
      "recall for fold 3850:  0.3333333333333333\n",
      "precision for fold 3850:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3851:  0.5406698564593302\n",
      "f1  score for fold 3851:  0.37662337662337664\n",
      "recall for fold 3851:  0.3918918918918919\n",
      "precision for fold 3851:  0.3625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3852:  0.5571428571428572\n",
      "f1  score for fold 3852:  0.4000000000000001\n",
      "recall for fold 3852:  0.41333333333333333\n",
      "precision for fold 3852:  0.3875\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3853:  0.48058252427184467\n",
      "f1  score for fold 3853:  0.33540372670807456\n",
      "recall for fold 3853:  0.32926829268292684\n",
      "precision for fold 3853:  0.34177215189873417\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3854:  0.47668393782383417\n",
      "f1  score for fold 3854:  0.3726708074534162\n",
      "recall for fold 3854:  0.3448275862068966\n",
      "precision for fold 3854:  0.40540540540540543\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 3855:  0.49282296650717705\n",
      "f1  score for fold 3855:  0.32911392405063294\n",
      "recall for fold 3855:  0.3333333333333333\n",
      "precision for fold 3855:  0.325\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3856:  0.5598086124401914\n",
      "f1  score for fold 3856:  0.40259740259740256\n",
      "recall for fold 3856:  0.4189189189189189\n",
      "precision for fold 3856:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3857:  0.5\n",
      "f1  score for fold 3857:  0.3225806451612903\n",
      "recall for fold 3857:  0.3333333333333333\n",
      "precision for fold 3857:  0.3125\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 3858:  0.5970873786407767\n",
      "f1  score for fold 3858:  0.484472049689441\n",
      "recall for fold 3858:  0.47560975609756095\n",
      "precision for fold 3858:  0.4936708860759494\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3859:  0.48704663212435234\n",
      "f1  score for fold 3859:  0.3850931677018633\n",
      "recall for fold 3859:  0.3563218390804598\n",
      "precision for fold 3859:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3860:  0.569377990430622\n",
      "f1  score for fold 3860:  0.43037974683544306\n",
      "recall for fold 3860:  0.4358974358974359\n",
      "precision for fold 3860:  0.425\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3861:  0.5406698564593302\n",
      "f1  score for fold 3861:  0.37662337662337664\n",
      "recall for fold 3861:  0.3918918918918919\n",
      "precision for fold 3861:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3862:  0.5190476190476191\n",
      "f1  score for fold 3862:  0.34838709677419355\n",
      "recall for fold 3862:  0.36\n",
      "precision for fold 3862:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3863:  0.5485436893203883\n",
      "f1  score for fold 3863:  0.42236024844720493\n",
      "recall for fold 3863:  0.4146341463414634\n",
      "precision for fold 3863:  0.43037974683544306\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3864:  0.5181347150259067\n",
      "f1  score for fold 3864:  0.422360248447205\n",
      "recall for fold 3864:  0.39080459770114945\n",
      "precision for fold 3864:  0.4594594594594595\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3865:  0.5502392344497608\n",
      "f1  score for fold 3865:  0.4050632911392405\n",
      "recall for fold 3865:  0.41025641025641024\n",
      "precision for fold 3865:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3866:  0.5502392344497608\n",
      "f1  score for fold 3866:  0.3896103896103896\n",
      "recall for fold 3866:  0.40540540540540543\n",
      "precision for fold 3866:  0.375\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 3867:  0.6142857142857143\n",
      "f1  score for fold 3867:  0.47741935483870973\n",
      "recall for fold 3867:  0.49333333333333335\n",
      "precision for fold 3867:  0.4625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3868:  0.5485436893203883\n",
      "f1  score for fold 3868:  0.42236024844720493\n",
      "recall for fold 3868:  0.4146341463414634\n",
      "precision for fold 3868:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3869:  0.538860103626943\n",
      "f1  score for fold 3869:  0.4472049689440994\n",
      "recall for fold 3869:  0.41379310344827586\n",
      "precision for fold 3869:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3870:  0.5311004784688995\n",
      "f1  score for fold 3870:  0.37974683544303806\n",
      "recall for fold 3870:  0.38461538461538464\n",
      "precision for fold 3870:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3871:  0.5215311004784688\n",
      "f1  score for fold 3871:  0.3506493506493507\n",
      "recall for fold 3871:  0.36486486486486486\n",
      "precision for fold 3871:  0.3375\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3872:  0.5666666666666667\n",
      "f1  score for fold 3872:  0.41290322580645167\n",
      "recall for fold 3872:  0.4266666666666667\n",
      "precision for fold 3872:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3873:  0.529126213592233\n",
      "f1  score for fold 3873:  0.39751552795031053\n",
      "recall for fold 3873:  0.3902439024390244\n",
      "precision for fold 3873:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3874:  0.5181347150259067\n",
      "f1  score for fold 3874:  0.422360248447205\n",
      "recall for fold 3874:  0.39080459770114945\n",
      "precision for fold 3874:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3875:  0.5023923444976076\n",
      "f1  score for fold 3875:  0.34177215189873417\n",
      "recall for fold 3875:  0.34615384615384615\n",
      "precision for fold 3875:  0.3375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3876:  0.5885167464114832\n",
      "f1  score for fold 3876:  0.44155844155844154\n",
      "recall for fold 3876:  0.4594594594594595\n",
      "precision for fold 3876:  0.425\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3877:  0.5285714285714286\n",
      "f1  score for fold 3877:  0.3612903225806451\n",
      "recall for fold 3877:  0.37333333333333335\n",
      "precision for fold 3877:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3878:  0.5485436893203883\n",
      "f1  score for fold 3878:  0.42236024844720493\n",
      "recall for fold 3878:  0.4146341463414634\n",
      "precision for fold 3878:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3879:  0.47668393782383417\n",
      "f1  score for fold 3879:  0.3726708074534162\n",
      "recall for fold 3879:  0.3448275862068966\n",
      "precision for fold 3879:  0.40540540540540543\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3880:  0.46411483253588515\n",
      "f1  score for fold 3880:  0.2911392405063291\n",
      "recall for fold 3880:  0.2948717948717949\n",
      "precision for fold 3880:  0.2875\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3881:  0.47368421052631576\n",
      "f1  score for fold 3881:  0.28571428571428575\n",
      "recall for fold 3881:  0.2972972972972973\n",
      "precision for fold 3881:  0.275\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3882:  0.5761904761904761\n",
      "f1  score for fold 3882:  0.4258064516129032\n",
      "recall for fold 3882:  0.44\n",
      "precision for fold 3882:  0.4125\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3883:  0.5776699029126213\n",
      "f1  score for fold 3883:  0.4596273291925466\n",
      "recall for fold 3883:  0.45121951219512196\n",
      "precision for fold 3883:  0.46835443037974683\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3884:  0.47668393782383417\n",
      "f1  score for fold 3884:  0.3726708074534162\n",
      "recall for fold 3884:  0.3448275862068966\n",
      "precision for fold 3884:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3885:  0.5598086124401914\n",
      "f1  score for fold 3885:  0.4177215189873418\n",
      "recall for fold 3885:  0.4230769230769231\n",
      "precision for fold 3885:  0.4125\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 3886:  0.5885167464114832\n",
      "f1  score for fold 3886:  0.44155844155844154\n",
      "recall for fold 3886:  0.4594594594594595\n",
      "precision for fold 3886:  0.425\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3887:  0.5571428571428572\n",
      "f1  score for fold 3887:  0.4000000000000001\n",
      "recall for fold 3887:  0.41333333333333333\n",
      "precision for fold 3887:  0.3875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 3888:  0.470873786407767\n",
      "f1  score for fold 3888:  0.3229813664596273\n",
      "recall for fold 3888:  0.3170731707317073\n",
      "precision for fold 3888:  0.3291139240506329\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3889:  0.5077720207253886\n",
      "f1  score for fold 3889:  0.40993788819875776\n",
      "recall for fold 3889:  0.3793103448275862\n",
      "precision for fold 3889:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3890:  0.5789473684210527\n",
      "f1  score for fold 3890:  0.44303797468354433\n",
      "recall for fold 3890:  0.44871794871794873\n",
      "precision for fold 3890:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3891:  0.5311004784688995\n",
      "f1  score for fold 3891:  0.36363636363636365\n",
      "recall for fold 3891:  0.3783783783783784\n",
      "precision for fold 3891:  0.35\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 3892:  0.4523809523809524\n",
      "f1  score for fold 3892:  0.2580645161290323\n",
      "recall for fold 3892:  0.26666666666666666\n",
      "precision for fold 3892:  0.25\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3893:  0.5097087378640777\n",
      "f1  score for fold 3893:  0.37267080745341613\n",
      "recall for fold 3893:  0.36585365853658536\n",
      "precision for fold 3893:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3894:  0.5077720207253886\n",
      "f1  score for fold 3894:  0.40993788819875776\n",
      "recall for fold 3894:  0.3793103448275862\n",
      "precision for fold 3894:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3895:  0.569377990430622\n",
      "f1  score for fold 3895:  0.43037974683544306\n",
      "recall for fold 3895:  0.4358974358974359\n",
      "precision for fold 3895:  0.425\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3896:  0.5789473684210527\n",
      "f1  score for fold 3896:  0.42857142857142855\n",
      "recall for fold 3896:  0.44594594594594594\n",
      "precision for fold 3896:  0.4125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3897:  0.5476190476190477\n",
      "f1  score for fold 3897:  0.38709677419354843\n",
      "recall for fold 3897:  0.4\n",
      "precision for fold 3897:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3898:  0.5194174757281553\n",
      "f1  score for fold 3898:  0.38509316770186336\n",
      "recall for fold 3898:  0.3780487804878049\n",
      "precision for fold 3898:  0.3924050632911392\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3899:  0.47668393782383417\n",
      "f1  score for fold 3899:  0.3726708074534162\n",
      "recall for fold 3899:  0.3448275862068966\n",
      "precision for fold 3899:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3900:  0.5311004784688995\n",
      "f1  score for fold 3900:  0.37974683544303806\n",
      "recall for fold 3900:  0.38461538461538464\n",
      "precision for fold 3900:  0.375\n",
      "    0   1\n",
      "0  20  54\n",
      "1  60  75\n",
      "Accuracy for fold 3901:  0.45454545454545453\n",
      "f1  score for fold 3901:  0.25974025974025977\n",
      "recall for fold 3901:  0.2702702702702703\n",
      "precision for fold 3901:  0.25\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3902:  0.5285714285714286\n",
      "f1  score for fold 3902:  0.3612903225806451\n",
      "recall for fold 3902:  0.37333333333333335\n",
      "precision for fold 3902:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3903:  0.529126213592233\n",
      "f1  score for fold 3903:  0.39751552795031053\n",
      "recall for fold 3903:  0.3902439024390244\n",
      "precision for fold 3903:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3904:  0.5181347150259067\n",
      "f1  score for fold 3904:  0.422360248447205\n",
      "recall for fold 3904:  0.39080459770114945\n",
      "precision for fold 3904:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3905:  0.5406698564593302\n",
      "f1  score for fold 3905:  0.3924050632911393\n",
      "recall for fold 3905:  0.3974358974358974\n",
      "precision for fold 3905:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 3906:  0.5311004784688995\n",
      "f1  score for fold 3906:  0.36363636363636365\n",
      "recall for fold 3906:  0.3783783783783784\n",
      "precision for fold 3906:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3907:  0.5476190476190477\n",
      "f1  score for fold 3907:  0.38709677419354843\n",
      "recall for fold 3907:  0.4\n",
      "precision for fold 3907:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3908:  0.5679611650485437\n",
      "f1  score for fold 3908:  0.4472049689440994\n",
      "recall for fold 3908:  0.43902439024390244\n",
      "precision for fold 3908:  0.45569620253164556\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3909:  0.5492227979274611\n",
      "f1  score for fold 3909:  0.45962732919254656\n",
      "recall for fold 3909:  0.42528735632183906\n",
      "precision for fold 3909:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3910:  0.5406698564593302\n",
      "f1  score for fold 3910:  0.3924050632911393\n",
      "recall for fold 3910:  0.3974358974358974\n",
      "precision for fold 3910:  0.3875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3911:  0.5215311004784688\n",
      "f1  score for fold 3911:  0.3506493506493507\n",
      "recall for fold 3911:  0.36486486486486486\n",
      "precision for fold 3911:  0.3375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3912:  0.5571428571428572\n",
      "f1  score for fold 3912:  0.4000000000000001\n",
      "recall for fold 3912:  0.41333333333333333\n",
      "precision for fold 3912:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3913:  0.5097087378640777\n",
      "f1  score for fold 3913:  0.37267080745341613\n",
      "recall for fold 3913:  0.36585365853658536\n",
      "precision for fold 3913:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3914:  0.5181347150259067\n",
      "f1  score for fold 3914:  0.422360248447205\n",
      "recall for fold 3914:  0.39080459770114945\n",
      "precision for fold 3914:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3915:  0.5406698564593302\n",
      "f1  score for fold 3915:  0.3924050632911393\n",
      "recall for fold 3915:  0.3974358974358974\n",
      "precision for fold 3915:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3916:  0.5598086124401914\n",
      "f1  score for fold 3916:  0.40259740259740256\n",
      "recall for fold 3916:  0.4189189189189189\n",
      "precision for fold 3916:  0.3875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 3917:  0.5\n",
      "f1  score for fold 3917:  0.3225806451612903\n",
      "recall for fold 3917:  0.3333333333333333\n",
      "precision for fold 3917:  0.3125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3918:  0.5\n",
      "f1  score for fold 3918:  0.3602484472049689\n",
      "recall for fold 3918:  0.35365853658536583\n",
      "precision for fold 3918:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3919:  0.5077720207253886\n",
      "f1  score for fold 3919:  0.40993788819875776\n",
      "recall for fold 3919:  0.3793103448275862\n",
      "precision for fold 3919:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3920:  0.569377990430622\n",
      "f1  score for fold 3920:  0.43037974683544306\n",
      "recall for fold 3920:  0.4358974358974359\n",
      "precision for fold 3920:  0.425\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3921:  0.5406698564593302\n",
      "f1  score for fold 3921:  0.37662337662337664\n",
      "recall for fold 3921:  0.3918918918918919\n",
      "precision for fold 3921:  0.3625\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3922:  0.5190476190476191\n",
      "f1  score for fold 3922:  0.34838709677419355\n",
      "recall for fold 3922:  0.36\n",
      "precision for fold 3922:  0.3375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 3923:  0.5485436893203883\n",
      "f1  score for fold 3923:  0.42236024844720493\n",
      "recall for fold 3923:  0.4146341463414634\n",
      "precision for fold 3923:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 3924:  0.5284974093264249\n",
      "f1  score for fold 3924:  0.4347826086956522\n",
      "recall for fold 3924:  0.40229885057471265\n",
      "precision for fold 3924:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3925:  0.5023923444976076\n",
      "f1  score for fold 3925:  0.34177215189873417\n",
      "recall for fold 3925:  0.34615384615384615\n",
      "precision for fold 3925:  0.3375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 3926:  0.5789473684210527\n",
      "f1  score for fold 3926:  0.42857142857142855\n",
      "recall for fold 3926:  0.44594594594594594\n",
      "precision for fold 3926:  0.4125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3927:  0.5666666666666667\n",
      "f1  score for fold 3927:  0.41290322580645167\n",
      "recall for fold 3927:  0.4266666666666667\n",
      "precision for fold 3927:  0.4\n",
      "    0   1\n",
      "0  24  58\n",
      "1  55  69\n",
      "Accuracy for fold 3928:  0.45145631067961167\n",
      "f1  score for fold 3928:  0.29813664596273287\n",
      "recall for fold 3928:  0.2926829268292683\n",
      "precision for fold 3928:  0.3037974683544304\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3929:  0.5077720207253886\n",
      "f1  score for fold 3929:  0.40993788819875776\n",
      "recall for fold 3929:  0.3793103448275862\n",
      "precision for fold 3929:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3930:  0.5215311004784688\n",
      "f1  score for fold 3930:  0.36708860759493667\n",
      "recall for fold 3930:  0.3717948717948718\n",
      "precision for fold 3930:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3931:  0.49282296650717705\n",
      "f1  score for fold 3931:  0.3116883116883117\n",
      "recall for fold 3931:  0.32432432432432434\n",
      "precision for fold 3931:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3932:  0.5476190476190477\n",
      "f1  score for fold 3932:  0.38709677419354843\n",
      "recall for fold 3932:  0.4\n",
      "precision for fold 3932:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3933:  0.529126213592233\n",
      "f1  score for fold 3933:  0.39751552795031053\n",
      "recall for fold 3933:  0.3902439024390244\n",
      "precision for fold 3933:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3934:  0.48704663212435234\n",
      "f1  score for fold 3934:  0.3850931677018633\n",
      "recall for fold 3934:  0.3563218390804598\n",
      "precision for fold 3934:  0.4189189189189189\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 3935:  0.46411483253588515\n",
      "f1  score for fold 3935:  0.2911392405063291\n",
      "recall for fold 3935:  0.2948717948717949\n",
      "precision for fold 3935:  0.2875\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3936:  0.5406698564593302\n",
      "f1  score for fold 3936:  0.37662337662337664\n",
      "recall for fold 3936:  0.3918918918918919\n",
      "precision for fold 3936:  0.3625\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3937:  0.49047619047619045\n",
      "f1  score for fold 3937:  0.3096774193548387\n",
      "recall for fold 3937:  0.32\n",
      "precision for fold 3937:  0.3\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3938:  0.5388349514563107\n",
      "f1  score for fold 3938:  0.40993788819875776\n",
      "recall for fold 3938:  0.4024390243902439\n",
      "precision for fold 3938:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3939:  0.47668393782383417\n",
      "f1  score for fold 3939:  0.3726708074534162\n",
      "recall for fold 3939:  0.3448275862068966\n",
      "precision for fold 3939:  0.40540540540540543\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3940:  0.5789473684210527\n",
      "f1  score for fold 3940:  0.44303797468354433\n",
      "recall for fold 3940:  0.44871794871794873\n",
      "precision for fold 3940:  0.4375\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 3941:  0.49282296650717705\n",
      "f1  score for fold 3941:  0.3116883116883117\n",
      "recall for fold 3941:  0.32432432432432434\n",
      "precision for fold 3941:  0.3\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 3942:  0.49047619047619045\n",
      "f1  score for fold 3942:  0.3096774193548387\n",
      "recall for fold 3942:  0.32\n",
      "precision for fold 3942:  0.3\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3943:  0.5679611650485437\n",
      "f1  score for fold 3943:  0.4472049689440994\n",
      "recall for fold 3943:  0.43902439024390244\n",
      "precision for fold 3943:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 3944:  0.49740932642487046\n",
      "f1  score for fold 3944:  0.39751552795031053\n",
      "recall for fold 3944:  0.367816091954023\n",
      "precision for fold 3944:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3945:  0.5215311004784688\n",
      "f1  score for fold 3945:  0.36708860759493667\n",
      "recall for fold 3945:  0.3717948717948718\n",
      "precision for fold 3945:  0.3625\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 3946:  0.48325358851674644\n",
      "f1  score for fold 3946:  0.29870129870129863\n",
      "recall for fold 3946:  0.3108108108108108\n",
      "precision for fold 3946:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3947:  0.5285714285714286\n",
      "f1  score for fold 3947:  0.3612903225806451\n",
      "recall for fold 3947:  0.37333333333333335\n",
      "precision for fold 3947:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3948:  0.5194174757281553\n",
      "f1  score for fold 3948:  0.38509316770186336\n",
      "recall for fold 3948:  0.3780487804878049\n",
      "precision for fold 3948:  0.3924050632911392\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 3949:  0.45595854922279794\n",
      "f1  score for fold 3949:  0.3478260869565218\n",
      "recall for fold 3949:  0.3218390804597701\n",
      "precision for fold 3949:  0.3783783783783784\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 3950:  0.5311004784688995\n",
      "f1  score for fold 3950:  0.37974683544303806\n",
      "recall for fold 3950:  0.38461538461538464\n",
      "precision for fold 3950:  0.375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3951:  0.5502392344497608\n",
      "f1  score for fold 3951:  0.3896103896103896\n",
      "recall for fold 3951:  0.40540540540540543\n",
      "precision for fold 3951:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 3952:  0.5571428571428572\n",
      "f1  score for fold 3952:  0.4000000000000001\n",
      "recall for fold 3952:  0.41333333333333333\n",
      "precision for fold 3952:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 3953:  0.5194174757281553\n",
      "f1  score for fold 3953:  0.38509316770186336\n",
      "recall for fold 3953:  0.3780487804878049\n",
      "precision for fold 3953:  0.3924050632911392\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3954:  0.5492227979274611\n",
      "f1  score for fold 3954:  0.45962732919254656\n",
      "recall for fold 3954:  0.42528735632183906\n",
      "precision for fold 3954:  0.5\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 3955:  0.569377990430622\n",
      "f1  score for fold 3955:  0.43037974683544306\n",
      "recall for fold 3955:  0.4358974358974359\n",
      "precision for fold 3955:  0.425\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 3956:  0.569377990430622\n",
      "f1  score for fold 3956:  0.4155844155844156\n",
      "recall for fold 3956:  0.43243243243243246\n",
      "precision for fold 3956:  0.4\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 3957:  0.5761904761904761\n",
      "f1  score for fold 3957:  0.4258064516129032\n",
      "recall for fold 3957:  0.44\n",
      "precision for fold 3957:  0.4125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 3958:  0.5388349514563107\n",
      "f1  score for fold 3958:  0.40993788819875776\n",
      "recall for fold 3958:  0.4024390243902439\n",
      "precision for fold 3958:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3959:  0.5077720207253886\n",
      "f1  score for fold 3959:  0.40993788819875776\n",
      "recall for fold 3959:  0.3793103448275862\n",
      "precision for fold 3959:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 3960:  0.5502392344497608\n",
      "f1  score for fold 3960:  0.4050632911392405\n",
      "recall for fold 3960:  0.41025641025641024\n",
      "precision for fold 3960:  0.4\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3961:  0.5598086124401914\n",
      "f1  score for fold 3961:  0.40259740259740256\n",
      "recall for fold 3961:  0.4189189189189189\n",
      "precision for fold 3961:  0.3875\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3962:  0.5666666666666667\n",
      "f1  score for fold 3962:  0.41290322580645167\n",
      "recall for fold 3962:  0.4266666666666667\n",
      "precision for fold 3962:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 3963:  0.5679611650485437\n",
      "f1  score for fold 3963:  0.4472049689440994\n",
      "recall for fold 3963:  0.43902439024390244\n",
      "precision for fold 3963:  0.45569620253164556\n",
      "    0   1\n",
      "0  43  44\n",
      "1  31  75\n",
      "Accuracy for fold 3964:  0.6113989637305699\n",
      "f1  score for fold 3964:  0.5341614906832297\n",
      "recall for fold 3964:  0.4942528735632184\n",
      "precision for fold 3964:  0.581081081081081\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 3965:  0.5406698564593302\n",
      "f1  score for fold 3965:  0.3924050632911393\n",
      "recall for fold 3965:  0.3974358974358974\n",
      "precision for fold 3965:  0.3875\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 3966:  0.5598086124401914\n",
      "f1  score for fold 3966:  0.40259740259740256\n",
      "recall for fold 3966:  0.4189189189189189\n",
      "precision for fold 3966:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 3967:  0.5285714285714286\n",
      "f1  score for fold 3967:  0.3612903225806451\n",
      "recall for fold 3967:  0.37333333333333335\n",
      "precision for fold 3967:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3968:  0.5097087378640777\n",
      "f1  score for fold 3968:  0.37267080745341613\n",
      "recall for fold 3968:  0.36585365853658536\n",
      "precision for fold 3968:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 3969:  0.48704663212435234\n",
      "f1  score for fold 3969:  0.3850931677018633\n",
      "recall for fold 3969:  0.3563218390804598\n",
      "precision for fold 3969:  0.4189189189189189\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 3970:  0.5789473684210527\n",
      "f1  score for fold 3970:  0.44303797468354433\n",
      "recall for fold 3970:  0.44871794871794873\n",
      "precision for fold 3970:  0.4375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3971:  0.5502392344497608\n",
      "f1  score for fold 3971:  0.3896103896103896\n",
      "recall for fold 3971:  0.40540540540540543\n",
      "precision for fold 3971:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3972:  0.5190476190476191\n",
      "f1  score for fold 3972:  0.34838709677419355\n",
      "recall for fold 3972:  0.36\n",
      "precision for fold 3972:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 3973:  0.529126213592233\n",
      "f1  score for fold 3973:  0.39751552795031053\n",
      "recall for fold 3973:  0.3902439024390244\n",
      "precision for fold 3973:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 3974:  0.47668393782383417\n",
      "f1  score for fold 3974:  0.3726708074534162\n",
      "recall for fold 3974:  0.3448275862068966\n",
      "precision for fold 3974:  0.40540540540540543\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 3975:  0.5119617224880383\n",
      "f1  score for fold 3975:  0.3544303797468355\n",
      "recall for fold 3975:  0.358974358974359\n",
      "precision for fold 3975:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 3976:  0.5406698564593302\n",
      "f1  score for fold 3976:  0.37662337662337664\n",
      "recall for fold 3976:  0.3918918918918919\n",
      "precision for fold 3976:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3977:  0.5476190476190477\n",
      "f1  score for fold 3977:  0.38709677419354843\n",
      "recall for fold 3977:  0.4\n",
      "precision for fold 3977:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 3978:  0.5097087378640777\n",
      "f1  score for fold 3978:  0.37267080745341613\n",
      "recall for fold 3978:  0.36585365853658536\n",
      "precision for fold 3978:  0.379746835443038\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 3979:  0.5595854922279793\n",
      "f1  score for fold 3979:  0.4720496894409938\n",
      "recall for fold 3979:  0.4367816091954023\n",
      "precision for fold 3979:  0.5135135135135135\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 3980:  0.5215311004784688\n",
      "f1  score for fold 3980:  0.36708860759493667\n",
      "recall for fold 3980:  0.3717948717948718\n",
      "precision for fold 3980:  0.3625\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 3981:  0.47368421052631576\n",
      "f1  score for fold 3981:  0.28571428571428575\n",
      "recall for fold 3981:  0.2972972972972973\n",
      "precision for fold 3981:  0.275\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3982:  0.5190476190476191\n",
      "f1  score for fold 3982:  0.34838709677419355\n",
      "recall for fold 3982:  0.36\n",
      "precision for fold 3982:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 3983:  0.48058252427184467\n",
      "f1  score for fold 3983:  0.33540372670807456\n",
      "recall for fold 3983:  0.32926829268292684\n",
      "precision for fold 3983:  0.34177215189873417\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 3984:  0.5492227979274611\n",
      "f1  score for fold 3984:  0.45962732919254656\n",
      "recall for fold 3984:  0.42528735632183906\n",
      "precision for fold 3984:  0.5\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 3985:  0.5885167464114832\n",
      "f1  score for fold 3985:  0.45569620253164556\n",
      "recall for fold 3985:  0.46153846153846156\n",
      "precision for fold 3985:  0.45\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 3986:  0.5215311004784688\n",
      "f1  score for fold 3986:  0.3506493506493507\n",
      "recall for fold 3986:  0.36486486486486486\n",
      "precision for fold 3986:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 3987:  0.5476190476190477\n",
      "f1  score for fold 3987:  0.38709677419354843\n",
      "recall for fold 3987:  0.4\n",
      "precision for fold 3987:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 3988:  0.49029126213592233\n",
      "f1  score for fold 3988:  0.3478260869565218\n",
      "recall for fold 3988:  0.34146341463414637\n",
      "precision for fold 3988:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 3989:  0.538860103626943\n",
      "f1  score for fold 3989:  0.4472049689440994\n",
      "recall for fold 3989:  0.41379310344827586\n",
      "precision for fold 3989:  0.4864864864864865\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 3990:  0.5598086124401914\n",
      "f1  score for fold 3990:  0.4177215189873418\n",
      "recall for fold 3990:  0.4230769230769231\n",
      "precision for fold 3990:  0.4125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 3991:  0.5502392344497608\n",
      "f1  score for fold 3991:  0.3896103896103896\n",
      "recall for fold 3991:  0.40540540540540543\n",
      "precision for fold 3991:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 3992:  0.5190476190476191\n",
      "f1  score for fold 3992:  0.34838709677419355\n",
      "recall for fold 3992:  0.36\n",
      "precision for fold 3992:  0.3375\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 3993:  0.5776699029126213\n",
      "f1  score for fold 3993:  0.4596273291925466\n",
      "recall for fold 3993:  0.45121951219512196\n",
      "precision for fold 3993:  0.46835443037974683\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 3994:  0.5181347150259067\n",
      "f1  score for fold 3994:  0.422360248447205\n",
      "recall for fold 3994:  0.39080459770114945\n",
      "precision for fold 3994:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 3995:  0.5023923444976076\n",
      "f1  score for fold 3995:  0.34177215189873417\n",
      "recall for fold 3995:  0.34615384615384615\n",
      "precision for fold 3995:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 3996:  0.5023923444976076\n",
      "f1  score for fold 3996:  0.3246753246753247\n",
      "recall for fold 3996:  0.33783783783783783\n",
      "precision for fold 3996:  0.3125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 3997:  0.5666666666666667\n",
      "f1  score for fold 3997:  0.41290322580645167\n",
      "recall for fold 3997:  0.4266666666666667\n",
      "precision for fold 3997:  0.4\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 3998:  0.5\n",
      "f1  score for fold 3998:  0.3602484472049689\n",
      "recall for fold 3998:  0.35365853658536583\n",
      "precision for fold 3998:  0.3670886075949367\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 3999:  0.5077720207253886\n",
      "f1  score for fold 3999:  0.40993788819875776\n",
      "recall for fold 3999:  0.3793103448275862\n",
      "precision for fold 3999:  0.44594594594594594\n",
      "    0   1\n",
      "0  21  57\n",
      "1  59  72\n",
      "Accuracy for fold 4000:  0.4449760765550239\n",
      "f1  score for fold 4000:  0.26582278481012656\n",
      "recall for fold 4000:  0.2692307692307692\n",
      "precision for fold 4000:  0.2625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4001:  0.5311004784688995\n",
      "f1  score for fold 4001:  0.36363636363636365\n",
      "recall for fold 4001:  0.3783783783783784\n",
      "precision for fold 4001:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4002:  0.5190476190476191\n",
      "f1  score for fold 4002:  0.34838709677419355\n",
      "recall for fold 4002:  0.36\n",
      "precision for fold 4002:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4003:  0.48058252427184467\n",
      "f1  score for fold 4003:  0.33540372670807456\n",
      "recall for fold 4003:  0.32926829268292684\n",
      "precision for fold 4003:  0.34177215189873417\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4004:  0.5492227979274611\n",
      "f1  score for fold 4004:  0.45962732919254656\n",
      "recall for fold 4004:  0.42528735632183906\n",
      "precision for fold 4004:  0.5\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4005:  0.49282296650717705\n",
      "f1  score for fold 4005:  0.32911392405063294\n",
      "recall for fold 4005:  0.3333333333333333\n",
      "precision for fold 4005:  0.325\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4006:  0.49282296650717705\n",
      "f1  score for fold 4006:  0.3116883116883117\n",
      "recall for fold 4006:  0.32432432432432434\n",
      "precision for fold 4006:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4007:  0.5\n",
      "f1  score for fold 4007:  0.3225806451612903\n",
      "recall for fold 4007:  0.3333333333333333\n",
      "precision for fold 4007:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4008:  0.5097087378640777\n",
      "f1  score for fold 4008:  0.37267080745341613\n",
      "recall for fold 4008:  0.36585365853658536\n",
      "precision for fold 4008:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4009:  0.5077720207253886\n",
      "f1  score for fold 4009:  0.40993788819875776\n",
      "recall for fold 4009:  0.3793103448275862\n",
      "precision for fold 4009:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4010:  0.5406698564593302\n",
      "f1  score for fold 4010:  0.3924050632911393\n",
      "recall for fold 4010:  0.3974358974358974\n",
      "precision for fold 4010:  0.3875\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 4011:  0.47368421052631576\n",
      "f1  score for fold 4011:  0.28571428571428575\n",
      "recall for fold 4011:  0.2972972972972973\n",
      "precision for fold 4011:  0.275\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4012:  0.5857142857142857\n",
      "f1  score for fold 4012:  0.43870967741935485\n",
      "recall for fold 4012:  0.4533333333333333\n",
      "precision for fold 4012:  0.425\n",
      "    0   1\n",
      "0  40  42\n",
      "1  39  85\n",
      "Accuracy for fold 4013:  0.6067961165048543\n",
      "f1  score for fold 4013:  0.49689440993788825\n",
      "recall for fold 4013:  0.4878048780487805\n",
      "precision for fold 4013:  0.5063291139240507\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4014:  0.5181347150259067\n",
      "f1  score for fold 4014:  0.422360248447205\n",
      "recall for fold 4014:  0.39080459770114945\n",
      "precision for fold 4014:  0.4594594594594595\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 4015:  0.45454545454545453\n",
      "f1  score for fold 4015:  0.27848101265822783\n",
      "recall for fold 4015:  0.28205128205128205\n",
      "precision for fold 4015:  0.275\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4016:  0.5502392344497608\n",
      "f1  score for fold 4016:  0.3896103896103896\n",
      "recall for fold 4016:  0.40540540540540543\n",
      "precision for fold 4016:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4017:  0.5285714285714286\n",
      "f1  score for fold 4017:  0.3612903225806451\n",
      "recall for fold 4017:  0.37333333333333335\n",
      "precision for fold 4017:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4018:  0.5097087378640777\n",
      "f1  score for fold 4018:  0.37267080745341613\n",
      "recall for fold 4018:  0.36585365853658536\n",
      "precision for fold 4018:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4019:  0.5181347150259067\n",
      "f1  score for fold 4019:  0.422360248447205\n",
      "recall for fold 4019:  0.39080459770114945\n",
      "precision for fold 4019:  0.4594594594594595\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 4020:  0.5980861244019139\n",
      "f1  score for fold 4020:  0.46835443037974683\n",
      "recall for fold 4020:  0.47435897435897434\n",
      "precision for fold 4020:  0.4625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4021:  0.49282296650717705\n",
      "f1  score for fold 4021:  0.3116883116883117\n",
      "recall for fold 4021:  0.32432432432432434\n",
      "precision for fold 4021:  0.3\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4022:  0.5571428571428572\n",
      "f1  score for fold 4022:  0.4000000000000001\n",
      "recall for fold 4022:  0.41333333333333333\n",
      "precision for fold 4022:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4023:  0.5\n",
      "f1  score for fold 4023:  0.3602484472049689\n",
      "recall for fold 4023:  0.35365853658536583\n",
      "precision for fold 4023:  0.3670886075949367\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4024:  0.47668393782383417\n",
      "f1  score for fold 4024:  0.3726708074534162\n",
      "recall for fold 4024:  0.3448275862068966\n",
      "precision for fold 4024:  0.40540540540540543\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4025:  0.5502392344497608\n",
      "f1  score for fold 4025:  0.4050632911392405\n",
      "recall for fold 4025:  0.41025641025641024\n",
      "precision for fold 4025:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4026:  0.5406698564593302\n",
      "f1  score for fold 4026:  0.37662337662337664\n",
      "recall for fold 4026:  0.3918918918918919\n",
      "precision for fold 4026:  0.3625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4027:  0.5761904761904761\n",
      "f1  score for fold 4027:  0.4258064516129032\n",
      "recall for fold 4027:  0.44\n",
      "precision for fold 4027:  0.4125\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4028:  0.5\n",
      "f1  score for fold 4028:  0.3602484472049689\n",
      "recall for fold 4028:  0.35365853658536583\n",
      "precision for fold 4028:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4029:  0.5181347150259067\n",
      "f1  score for fold 4029:  0.422360248447205\n",
      "recall for fold 4029:  0.39080459770114945\n",
      "precision for fold 4029:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4030:  0.5119617224880383\n",
      "f1  score for fold 4030:  0.3544303797468355\n",
      "recall for fold 4030:  0.358974358974359\n",
      "precision for fold 4030:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4031:  0.5119617224880383\n",
      "f1  score for fold 4031:  0.33766233766233766\n",
      "recall for fold 4031:  0.35135135135135137\n",
      "precision for fold 4031:  0.325\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4032:  0.48095238095238096\n",
      "f1  score for fold 4032:  0.2967741935483871\n",
      "recall for fold 4032:  0.30666666666666664\n",
      "precision for fold 4032:  0.2875\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4033:  0.5388349514563107\n",
      "f1  score for fold 4033:  0.40993788819875776\n",
      "recall for fold 4033:  0.4024390243902439\n",
      "precision for fold 4033:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4034:  0.47668393782383417\n",
      "f1  score for fold 4034:  0.3726708074534162\n",
      "recall for fold 4034:  0.3448275862068966\n",
      "precision for fold 4034:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4035:  0.5215311004784688\n",
      "f1  score for fold 4035:  0.36708860759493667\n",
      "recall for fold 4035:  0.3717948717948718\n",
      "precision for fold 4035:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4036:  0.5502392344497608\n",
      "f1  score for fold 4036:  0.3896103896103896\n",
      "recall for fold 4036:  0.40540540540540543\n",
      "precision for fold 4036:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4037:  0.5285714285714286\n",
      "f1  score for fold 4037:  0.3612903225806451\n",
      "recall for fold 4037:  0.37333333333333335\n",
      "precision for fold 4037:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4038:  0.5097087378640777\n",
      "f1  score for fold 4038:  0.37267080745341613\n",
      "recall for fold 4038:  0.36585365853658536\n",
      "precision for fold 4038:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4039:  0.538860103626943\n",
      "f1  score for fold 4039:  0.4472049689440994\n",
      "recall for fold 4039:  0.41379310344827586\n",
      "precision for fold 4039:  0.4864864864864865\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4040:  0.5789473684210527\n",
      "f1  score for fold 4040:  0.44303797468354433\n",
      "recall for fold 4040:  0.44871794871794873\n",
      "precision for fold 4040:  0.4375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4041:  0.5215311004784688\n",
      "f1  score for fold 4041:  0.3506493506493507\n",
      "recall for fold 4041:  0.36486486486486486\n",
      "precision for fold 4041:  0.3375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4042:  0.5476190476190477\n",
      "f1  score for fold 4042:  0.38709677419354843\n",
      "recall for fold 4042:  0.4\n",
      "precision for fold 4042:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4043:  0.5097087378640777\n",
      "f1  score for fold 4043:  0.37267080745341613\n",
      "recall for fold 4043:  0.36585365853658536\n",
      "precision for fold 4043:  0.379746835443038\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 4044:  0.42487046632124353\n",
      "f1  score for fold 4044:  0.3105590062111801\n",
      "recall for fold 4044:  0.28735632183908044\n",
      "precision for fold 4044:  0.33783783783783783\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4045:  0.569377990430622\n",
      "f1  score for fold 4045:  0.43037974683544306\n",
      "recall for fold 4045:  0.4358974358974359\n",
      "precision for fold 4045:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4046:  0.5311004784688995\n",
      "f1  score for fold 4046:  0.36363636363636365\n",
      "recall for fold 4046:  0.3783783783783784\n",
      "precision for fold 4046:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4047:  0.5285714285714286\n",
      "f1  score for fold 4047:  0.3612903225806451\n",
      "recall for fold 4047:  0.37333333333333335\n",
      "precision for fold 4047:  0.35\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4048:  0.470873786407767\n",
      "f1  score for fold 4048:  0.3229813664596273\n",
      "recall for fold 4048:  0.3170731707317073\n",
      "precision for fold 4048:  0.3291139240506329\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4049:  0.5284974093264249\n",
      "f1  score for fold 4049:  0.4347826086956522\n",
      "recall for fold 4049:  0.40229885057471265\n",
      "precision for fold 4049:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4050:  0.5215311004784688\n",
      "f1  score for fold 4050:  0.36708860759493667\n",
      "recall for fold 4050:  0.3717948717948718\n",
      "precision for fold 4050:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4051:  0.5311004784688995\n",
      "f1  score for fold 4051:  0.36363636363636365\n",
      "recall for fold 4051:  0.3783783783783784\n",
      "precision for fold 4051:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4052:  0.5285714285714286\n",
      "f1  score for fold 4052:  0.3612903225806451\n",
      "recall for fold 4052:  0.37333333333333335\n",
      "precision for fold 4052:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4053:  0.5097087378640777\n",
      "f1  score for fold 4053:  0.37267080745341613\n",
      "recall for fold 4053:  0.36585365853658536\n",
      "precision for fold 4053:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4054:  0.5284974093264249\n",
      "f1  score for fold 4054:  0.4347826086956522\n",
      "recall for fold 4054:  0.40229885057471265\n",
      "precision for fold 4054:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4055:  0.49282296650717705\n",
      "f1  score for fold 4055:  0.32911392405063294\n",
      "recall for fold 4055:  0.3333333333333333\n",
      "precision for fold 4055:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4056:  0.5502392344497608\n",
      "f1  score for fold 4056:  0.3896103896103896\n",
      "recall for fold 4056:  0.40540540540540543\n",
      "precision for fold 4056:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4057:  0.5\n",
      "f1  score for fold 4057:  0.3225806451612903\n",
      "recall for fold 4057:  0.3333333333333333\n",
      "precision for fold 4057:  0.3125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4058:  0.5485436893203883\n",
      "f1  score for fold 4058:  0.42236024844720493\n",
      "recall for fold 4058:  0.4146341463414634\n",
      "precision for fold 4058:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4059:  0.5077720207253886\n",
      "f1  score for fold 4059:  0.40993788819875776\n",
      "recall for fold 4059:  0.3793103448275862\n",
      "precision for fold 4059:  0.44594594594594594\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4060:  0.5598086124401914\n",
      "f1  score for fold 4060:  0.4177215189873418\n",
      "recall for fold 4060:  0.4230769230769231\n",
      "precision for fold 4060:  0.4125\n",
      "    0   1\n",
      "0  18  56\n",
      "1  62  73\n",
      "Accuracy for fold 4061:  0.4354066985645933\n",
      "f1  score for fold 4061:  0.23376623376623376\n",
      "recall for fold 4061:  0.24324324324324326\n",
      "precision for fold 4061:  0.225\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 4062:  0.6142857142857143\n",
      "f1  score for fold 4062:  0.47741935483870973\n",
      "recall for fold 4062:  0.49333333333333335\n",
      "precision for fold 4062:  0.4625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4063:  0.5485436893203883\n",
      "f1  score for fold 4063:  0.42236024844720493\n",
      "recall for fold 4063:  0.4146341463414634\n",
      "precision for fold 4063:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4064:  0.5492227979274611\n",
      "f1  score for fold 4064:  0.45962732919254656\n",
      "recall for fold 4064:  0.42528735632183906\n",
      "precision for fold 4064:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4065:  0.5023923444976076\n",
      "f1  score for fold 4065:  0.34177215189873417\n",
      "recall for fold 4065:  0.34615384615384615\n",
      "precision for fold 4065:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4066:  0.5119617224880383\n",
      "f1  score for fold 4066:  0.33766233766233766\n",
      "recall for fold 4066:  0.35135135135135137\n",
      "precision for fold 4066:  0.325\n",
      "    0   1\n",
      "0  20  55\n",
      "1  60  75\n",
      "Accuracy for fold 4067:  0.4523809523809524\n",
      "f1  score for fold 4067:  0.2580645161290323\n",
      "recall for fold 4067:  0.26666666666666666\n",
      "precision for fold 4067:  0.25\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4068:  0.5194174757281553\n",
      "f1  score for fold 4068:  0.38509316770186336\n",
      "recall for fold 4068:  0.3780487804878049\n",
      "precision for fold 4068:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4069:  0.5284974093264249\n",
      "f1  score for fold 4069:  0.4347826086956522\n",
      "recall for fold 4069:  0.40229885057471265\n",
      "precision for fold 4069:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4070:  0.5215311004784688\n",
      "f1  score for fold 4070:  0.36708860759493667\n",
      "recall for fold 4070:  0.3717948717948718\n",
      "precision for fold 4070:  0.3625\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 4071:  0.6076555023923444\n",
      "f1  score for fold 4071:  0.4675324675324675\n",
      "recall for fold 4071:  0.4864864864864865\n",
      "precision for fold 4071:  0.45\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4072:  0.48095238095238096\n",
      "f1  score for fold 4072:  0.2967741935483871\n",
      "recall for fold 4072:  0.30666666666666664\n",
      "precision for fold 4072:  0.2875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4073:  0.5485436893203883\n",
      "f1  score for fold 4073:  0.42236024844720493\n",
      "recall for fold 4073:  0.4146341463414634\n",
      "precision for fold 4073:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4074:  0.49740932642487046\n",
      "f1  score for fold 4074:  0.39751552795031053\n",
      "recall for fold 4074:  0.367816091954023\n",
      "precision for fold 4074:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4075:  0.5215311004784688\n",
      "f1  score for fold 4075:  0.36708860759493667\n",
      "recall for fold 4075:  0.3717948717948718\n",
      "precision for fold 4075:  0.3625\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4076:  0.5119617224880383\n",
      "f1  score for fold 4076:  0.33766233766233766\n",
      "recall for fold 4076:  0.35135135135135137\n",
      "precision for fold 4076:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4077:  0.5476190476190477\n",
      "f1  score for fold 4077:  0.38709677419354843\n",
      "recall for fold 4077:  0.4\n",
      "precision for fold 4077:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4078:  0.529126213592233\n",
      "f1  score for fold 4078:  0.39751552795031053\n",
      "recall for fold 4078:  0.3902439024390244\n",
      "precision for fold 4078:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4079:  0.5077720207253886\n",
      "f1  score for fold 4079:  0.40993788819875776\n",
      "recall for fold 4079:  0.3793103448275862\n",
      "precision for fold 4079:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4080:  0.5311004784688995\n",
      "f1  score for fold 4080:  0.37974683544303806\n",
      "recall for fold 4080:  0.38461538461538464\n",
      "precision for fold 4080:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4081:  0.569377990430622\n",
      "f1  score for fold 4081:  0.4155844155844156\n",
      "recall for fold 4081:  0.43243243243243246\n",
      "precision for fold 4081:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4082:  0.5380952380952381\n",
      "f1  score for fold 4082:  0.3741935483870968\n",
      "recall for fold 4082:  0.38666666666666666\n",
      "precision for fold 4082:  0.3625\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4083:  0.49029126213592233\n",
      "f1  score for fold 4083:  0.3478260869565218\n",
      "recall for fold 4083:  0.34146341463414637\n",
      "precision for fold 4083:  0.35443037974683544\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 4084:  0.43523316062176165\n",
      "f1  score for fold 4084:  0.3229813664596274\n",
      "recall for fold 4084:  0.2988505747126437\n",
      "precision for fold 4084:  0.35135135135135137\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4085:  0.5311004784688995\n",
      "f1  score for fold 4085:  0.37974683544303806\n",
      "recall for fold 4085:  0.38461538461538464\n",
      "precision for fold 4085:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4086:  0.5311004784688995\n",
      "f1  score for fold 4086:  0.36363636363636365\n",
      "recall for fold 4086:  0.3783783783783784\n",
      "precision for fold 4086:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4087:  0.49047619047619045\n",
      "f1  score for fold 4087:  0.3096774193548387\n",
      "recall for fold 4087:  0.32\n",
      "precision for fold 4087:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4088:  0.558252427184466\n",
      "f1  score for fold 4088:  0.43478260869565216\n",
      "recall for fold 4088:  0.4268292682926829\n",
      "precision for fold 4088:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4089:  0.5181347150259067\n",
      "f1  score for fold 4089:  0.422360248447205\n",
      "recall for fold 4089:  0.39080459770114945\n",
      "precision for fold 4089:  0.4594594594594595\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4090:  0.5215311004784688\n",
      "f1  score for fold 4090:  0.36708860759493667\n",
      "recall for fold 4090:  0.3717948717948718\n",
      "precision for fold 4090:  0.3625\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4091:  0.49282296650717705\n",
      "f1  score for fold 4091:  0.3116883116883117\n",
      "recall for fold 4091:  0.32432432432432434\n",
      "precision for fold 4091:  0.3\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4092:  0.5476190476190477\n",
      "f1  score for fold 4092:  0.38709677419354843\n",
      "recall for fold 4092:  0.4\n",
      "precision for fold 4092:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4093:  0.5194174757281553\n",
      "f1  score for fold 4093:  0.38509316770186336\n",
      "recall for fold 4093:  0.3780487804878049\n",
      "precision for fold 4093:  0.3924050632911392\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4094:  0.46632124352331605\n",
      "f1  score for fold 4094:  0.36024844720496896\n",
      "recall for fold 4094:  0.3333333333333333\n",
      "precision for fold 4094:  0.3918918918918919\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 4095:  0.46411483253588515\n",
      "f1  score for fold 4095:  0.2911392405063291\n",
      "recall for fold 4095:  0.2948717948717949\n",
      "precision for fold 4095:  0.2875\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4096:  0.5215311004784688\n",
      "f1  score for fold 4096:  0.3506493506493507\n",
      "recall for fold 4096:  0.36486486486486486\n",
      "precision for fold 4096:  0.3375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4097:  0.5761904761904761\n",
      "f1  score for fold 4097:  0.4258064516129032\n",
      "recall for fold 4097:  0.44\n",
      "precision for fold 4097:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4098:  0.5097087378640777\n",
      "f1  score for fold 4098:  0.37267080745341613\n",
      "recall for fold 4098:  0.36585365853658536\n",
      "precision for fold 4098:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4099:  0.5284974093264249\n",
      "f1  score for fold 4099:  0.4347826086956522\n",
      "recall for fold 4099:  0.40229885057471265\n",
      "precision for fold 4099:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4100:  0.5311004784688995\n",
      "f1  score for fold 4100:  0.37974683544303806\n",
      "recall for fold 4100:  0.38461538461538464\n",
      "precision for fold 4100:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4101:  0.5406698564593302\n",
      "f1  score for fold 4101:  0.37662337662337664\n",
      "recall for fold 4101:  0.3918918918918919\n",
      "precision for fold 4101:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4102:  0.5285714285714286\n",
      "f1  score for fold 4102:  0.3612903225806451\n",
      "recall for fold 4102:  0.37333333333333335\n",
      "precision for fold 4102:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4103:  0.49029126213592233\n",
      "f1  score for fold 4103:  0.3478260869565218\n",
      "recall for fold 4103:  0.34146341463414637\n",
      "precision for fold 4103:  0.35443037974683544\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4104:  0.5181347150259067\n",
      "f1  score for fold 4104:  0.422360248447205\n",
      "recall for fold 4104:  0.39080459770114945\n",
      "precision for fold 4104:  0.4594594594594595\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 4105:  0.5980861244019139\n",
      "f1  score for fold 4105:  0.46835443037974683\n",
      "recall for fold 4105:  0.47435897435897434\n",
      "precision for fold 4105:  0.4625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4106:  0.5406698564593302\n",
      "f1  score for fold 4106:  0.37662337662337664\n",
      "recall for fold 4106:  0.3918918918918919\n",
      "precision for fold 4106:  0.3625\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4107:  0.5761904761904761\n",
      "f1  score for fold 4107:  0.4258064516129032\n",
      "recall for fold 4107:  0.44\n",
      "precision for fold 4107:  0.4125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4108:  0.5097087378640777\n",
      "f1  score for fold 4108:  0.37267080745341613\n",
      "recall for fold 4108:  0.36585365853658536\n",
      "precision for fold 4108:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4109:  0.5181347150259067\n",
      "f1  score for fold 4109:  0.422360248447205\n",
      "recall for fold 4109:  0.39080459770114945\n",
      "precision for fold 4109:  0.4594594594594595\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4110:  0.5119617224880383\n",
      "f1  score for fold 4110:  0.3544303797468355\n",
      "recall for fold 4110:  0.358974358974359\n",
      "precision for fold 4110:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4111:  0.5119617224880383\n",
      "f1  score for fold 4111:  0.33766233766233766\n",
      "recall for fold 4111:  0.35135135135135137\n",
      "precision for fold 4111:  0.325\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4112:  0.6047619047619047\n",
      "f1  score for fold 4112:  0.4645161290322581\n",
      "recall for fold 4112:  0.48\n",
      "precision for fold 4112:  0.45\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4113:  0.5776699029126213\n",
      "f1  score for fold 4113:  0.4596273291925466\n",
      "recall for fold 4113:  0.45121951219512196\n",
      "precision for fold 4113:  0.46835443037974683\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4114:  0.5492227979274611\n",
      "f1  score for fold 4114:  0.45962732919254656\n",
      "recall for fold 4114:  0.42528735632183906\n",
      "precision for fold 4114:  0.5\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 4115:  0.47368421052631576\n",
      "f1  score for fold 4115:  0.3037974683544304\n",
      "recall for fold 4115:  0.3076923076923077\n",
      "precision for fold 4115:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4116:  0.5502392344497608\n",
      "f1  score for fold 4116:  0.3896103896103896\n",
      "recall for fold 4116:  0.40540540540540543\n",
      "precision for fold 4116:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4117:  0.5190476190476191\n",
      "f1  score for fold 4117:  0.34838709677419355\n",
      "recall for fold 4117:  0.36\n",
      "precision for fold 4117:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4118:  0.5679611650485437\n",
      "f1  score for fold 4118:  0.4472049689440994\n",
      "recall for fold 4118:  0.43902439024390244\n",
      "precision for fold 4118:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4119:  0.5284974093264249\n",
      "f1  score for fold 4119:  0.4347826086956522\n",
      "recall for fold 4119:  0.40229885057471265\n",
      "precision for fold 4119:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4120:  0.5311004784688995\n",
      "f1  score for fold 4120:  0.37974683544303806\n",
      "recall for fold 4120:  0.38461538461538464\n",
      "precision for fold 4120:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4121:  0.5406698564593302\n",
      "f1  score for fold 4121:  0.37662337662337664\n",
      "recall for fold 4121:  0.3918918918918919\n",
      "precision for fold 4121:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4122:  0.5095238095238095\n",
      "f1  score for fold 4122:  0.335483870967742\n",
      "recall for fold 4122:  0.3466666666666667\n",
      "precision for fold 4122:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4123:  0.5388349514563107\n",
      "f1  score for fold 4123:  0.40993788819875776\n",
      "recall for fold 4123:  0.4024390243902439\n",
      "precision for fold 4123:  0.4177215189873418\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4124:  0.5077720207253886\n",
      "f1  score for fold 4124:  0.40993788819875776\n",
      "recall for fold 4124:  0.3793103448275862\n",
      "precision for fold 4124:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4125:  0.5023923444976076\n",
      "f1  score for fold 4125:  0.34177215189873417\n",
      "recall for fold 4125:  0.34615384615384615\n",
      "precision for fold 4125:  0.3375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4126:  0.48325358851674644\n",
      "f1  score for fold 4126:  0.29870129870129863\n",
      "recall for fold 4126:  0.3108108108108108\n",
      "precision for fold 4126:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4127:  0.5571428571428572\n",
      "f1  score for fold 4127:  0.4000000000000001\n",
      "recall for fold 4127:  0.41333333333333333\n",
      "precision for fold 4127:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4128:  0.5\n",
      "f1  score for fold 4128:  0.3602484472049689\n",
      "recall for fold 4128:  0.35365853658536583\n",
      "precision for fold 4128:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4129:  0.49740932642487046\n",
      "f1  score for fold 4129:  0.39751552795031053\n",
      "recall for fold 4129:  0.367816091954023\n",
      "precision for fold 4129:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4130:  0.49282296650717705\n",
      "f1  score for fold 4130:  0.32911392405063294\n",
      "recall for fold 4130:  0.3333333333333333\n",
      "precision for fold 4130:  0.325\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4131:  0.5311004784688995\n",
      "f1  score for fold 4131:  0.36363636363636365\n",
      "recall for fold 4131:  0.3783783783783784\n",
      "precision for fold 4131:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4132:  0.49047619047619045\n",
      "f1  score for fold 4132:  0.3096774193548387\n",
      "recall for fold 4132:  0.32\n",
      "precision for fold 4132:  0.3\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 4133:  0.587378640776699\n",
      "f1  score for fold 4133:  0.4720496894409938\n",
      "recall for fold 4133:  0.4634146341463415\n",
      "precision for fold 4133:  0.4810126582278481\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4134:  0.5077720207253886\n",
      "f1  score for fold 4134:  0.40993788819875776\n",
      "recall for fold 4134:  0.3793103448275862\n",
      "precision for fold 4134:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4135:  0.5789473684210527\n",
      "f1  score for fold 4135:  0.44303797468354433\n",
      "recall for fold 4135:  0.44871794871794873\n",
      "precision for fold 4135:  0.4375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4136:  0.5023923444976076\n",
      "f1  score for fold 4136:  0.3246753246753247\n",
      "recall for fold 4136:  0.33783783783783783\n",
      "precision for fold 4136:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4137:  0.5190476190476191\n",
      "f1  score for fold 4137:  0.34838709677419355\n",
      "recall for fold 4137:  0.36\n",
      "precision for fold 4137:  0.3375\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 4138:  0.5970873786407767\n",
      "f1  score for fold 4138:  0.484472049689441\n",
      "recall for fold 4138:  0.47560975609756095\n",
      "precision for fold 4138:  0.4936708860759494\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4139:  0.5181347150259067\n",
      "f1  score for fold 4139:  0.422360248447205\n",
      "recall for fold 4139:  0.39080459770114945\n",
      "precision for fold 4139:  0.4594594594594595\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4140:  0.5406698564593302\n",
      "f1  score for fold 4140:  0.3924050632911393\n",
      "recall for fold 4140:  0.3974358974358974\n",
      "precision for fold 4140:  0.3875\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 4141:  0.5885167464114832\n",
      "f1  score for fold 4141:  0.44155844155844154\n",
      "recall for fold 4141:  0.4594594594594595\n",
      "precision for fold 4141:  0.425\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4142:  0.5476190476190477\n",
      "f1  score for fold 4142:  0.38709677419354843\n",
      "recall for fold 4142:  0.4\n",
      "precision for fold 4142:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4143:  0.5194174757281553\n",
      "f1  score for fold 4143:  0.38509316770186336\n",
      "recall for fold 4143:  0.3780487804878049\n",
      "precision for fold 4143:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4144:  0.49740932642487046\n",
      "f1  score for fold 4144:  0.39751552795031053\n",
      "recall for fold 4144:  0.367816091954023\n",
      "precision for fold 4144:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4145:  0.5023923444976076\n",
      "f1  score for fold 4145:  0.34177215189873417\n",
      "recall for fold 4145:  0.34615384615384615\n",
      "precision for fold 4145:  0.3375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 4146:  0.5885167464114832\n",
      "f1  score for fold 4146:  0.44155844155844154\n",
      "recall for fold 4146:  0.4594594594594595\n",
      "precision for fold 4146:  0.425\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4147:  0.5571428571428572\n",
      "f1  score for fold 4147:  0.4000000000000001\n",
      "recall for fold 4147:  0.41333333333333333\n",
      "precision for fold 4147:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4148:  0.5097087378640777\n",
      "f1  score for fold 4148:  0.37267080745341613\n",
      "recall for fold 4148:  0.36585365853658536\n",
      "precision for fold 4148:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4149:  0.5077720207253886\n",
      "f1  score for fold 4149:  0.40993788819875776\n",
      "recall for fold 4149:  0.3793103448275862\n",
      "precision for fold 4149:  0.44594594594594594\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 4150:  0.5885167464114832\n",
      "f1  score for fold 4150:  0.45569620253164556\n",
      "recall for fold 4150:  0.46153846153846156\n",
      "precision for fold 4150:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4151:  0.5406698564593302\n",
      "f1  score for fold 4151:  0.37662337662337664\n",
      "recall for fold 4151:  0.3918918918918919\n",
      "precision for fold 4151:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4152:  0.5285714285714286\n",
      "f1  score for fold 4152:  0.3612903225806451\n",
      "recall for fold 4152:  0.37333333333333335\n",
      "precision for fold 4152:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4153:  0.5388349514563107\n",
      "f1  score for fold 4153:  0.40993788819875776\n",
      "recall for fold 4153:  0.4024390243902439\n",
      "precision for fold 4153:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4154:  0.5284974093264249\n",
      "f1  score for fold 4154:  0.4347826086956522\n",
      "recall for fold 4154:  0.40229885057471265\n",
      "precision for fold 4154:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4155:  0.5119617224880383\n",
      "f1  score for fold 4155:  0.3544303797468355\n",
      "recall for fold 4155:  0.358974358974359\n",
      "precision for fold 4155:  0.35\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4156:  0.49282296650717705\n",
      "f1  score for fold 4156:  0.3116883116883117\n",
      "recall for fold 4156:  0.32432432432432434\n",
      "precision for fold 4156:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4157:  0.5095238095238095\n",
      "f1  score for fold 4157:  0.335483870967742\n",
      "recall for fold 4157:  0.3466666666666667\n",
      "precision for fold 4157:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4158:  0.529126213592233\n",
      "f1  score for fold 4158:  0.39751552795031053\n",
      "recall for fold 4158:  0.3902439024390244\n",
      "precision for fold 4158:  0.4050632911392405\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4159:  0.48704663212435234\n",
      "f1  score for fold 4159:  0.3850931677018633\n",
      "recall for fold 4159:  0.3563218390804598\n",
      "precision for fold 4159:  0.4189189189189189\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4160:  0.49282296650717705\n",
      "f1  score for fold 4160:  0.32911392405063294\n",
      "recall for fold 4160:  0.3333333333333333\n",
      "precision for fold 4160:  0.325\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4161:  0.5598086124401914\n",
      "f1  score for fold 4161:  0.40259740259740256\n",
      "recall for fold 4161:  0.4189189189189189\n",
      "precision for fold 4161:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4162:  0.5285714285714286\n",
      "f1  score for fold 4162:  0.3612903225806451\n",
      "recall for fold 4162:  0.37333333333333335\n",
      "precision for fold 4162:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4163:  0.48058252427184467\n",
      "f1  score for fold 4163:  0.33540372670807456\n",
      "recall for fold 4163:  0.32926829268292684\n",
      "precision for fold 4163:  0.34177215189873417\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4164:  0.5284974093264249\n",
      "f1  score for fold 4164:  0.4347826086956522\n",
      "recall for fold 4164:  0.40229885057471265\n",
      "precision for fold 4164:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4165:  0.5215311004784688\n",
      "f1  score for fold 4165:  0.36708860759493667\n",
      "recall for fold 4165:  0.3717948717948718\n",
      "precision for fold 4165:  0.3625\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4166:  0.48325358851674644\n",
      "f1  score for fold 4166:  0.29870129870129863\n",
      "recall for fold 4166:  0.3108108108108108\n",
      "precision for fold 4166:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4167:  0.5476190476190477\n",
      "f1  score for fold 4167:  0.38709677419354843\n",
      "recall for fold 4167:  0.4\n",
      "precision for fold 4167:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4168:  0.5194174757281553\n",
      "f1  score for fold 4168:  0.38509316770186336\n",
      "recall for fold 4168:  0.3780487804878049\n",
      "precision for fold 4168:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4169:  0.49740932642487046\n",
      "f1  score for fold 4169:  0.39751552795031053\n",
      "recall for fold 4169:  0.367816091954023\n",
      "precision for fold 4169:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4170:  0.5215311004784688\n",
      "f1  score for fold 4170:  0.36708860759493667\n",
      "recall for fold 4170:  0.3717948717948718\n",
      "precision for fold 4170:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4171:  0.5311004784688995\n",
      "f1  score for fold 4171:  0.36363636363636365\n",
      "recall for fold 4171:  0.3783783783783784\n",
      "precision for fold 4171:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4172:  0.5857142857142857\n",
      "f1  score for fold 4172:  0.43870967741935485\n",
      "recall for fold 4172:  0.4533333333333333\n",
      "precision for fold 4172:  0.425\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4173:  0.49029126213592233\n",
      "f1  score for fold 4173:  0.3478260869565218\n",
      "recall for fold 4173:  0.34146341463414637\n",
      "precision for fold 4173:  0.35443037974683544\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4174:  0.47668393782383417\n",
      "f1  score for fold 4174:  0.3726708074534162\n",
      "recall for fold 4174:  0.3448275862068966\n",
      "precision for fold 4174:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4175:  0.5215311004784688\n",
      "f1  score for fold 4175:  0.36708860759493667\n",
      "recall for fold 4175:  0.3717948717948718\n",
      "precision for fold 4175:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4176:  0.5598086124401914\n",
      "f1  score for fold 4176:  0.40259740259740256\n",
      "recall for fold 4176:  0.4189189189189189\n",
      "precision for fold 4176:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4177:  0.5476190476190477\n",
      "f1  score for fold 4177:  0.38709677419354843\n",
      "recall for fold 4177:  0.4\n",
      "precision for fold 4177:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4178:  0.5485436893203883\n",
      "f1  score for fold 4178:  0.42236024844720493\n",
      "recall for fold 4178:  0.4146341463414634\n",
      "precision for fold 4178:  0.43037974683544306\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4179:  0.5492227979274611\n",
      "f1  score for fold 4179:  0.45962732919254656\n",
      "recall for fold 4179:  0.42528735632183906\n",
      "precision for fold 4179:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4180:  0.5311004784688995\n",
      "f1  score for fold 4180:  0.37974683544303806\n",
      "recall for fold 4180:  0.38461538461538464\n",
      "precision for fold 4180:  0.375\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 4181:  0.5885167464114832\n",
      "f1  score for fold 4181:  0.44155844155844154\n",
      "recall for fold 4181:  0.4594594594594595\n",
      "precision for fold 4181:  0.425\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4182:  0.5285714285714286\n",
      "f1  score for fold 4182:  0.3612903225806451\n",
      "recall for fold 4182:  0.37333333333333335\n",
      "precision for fold 4182:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4183:  0.5\n",
      "f1  score for fold 4183:  0.3602484472049689\n",
      "recall for fold 4183:  0.35365853658536583\n",
      "precision for fold 4183:  0.3670886075949367\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4184:  0.46632124352331605\n",
      "f1  score for fold 4184:  0.36024844720496896\n",
      "recall for fold 4184:  0.3333333333333333\n",
      "precision for fold 4184:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4185:  0.5023923444976076\n",
      "f1  score for fold 4185:  0.34177215189873417\n",
      "recall for fold 4185:  0.34615384615384615\n",
      "precision for fold 4185:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4186:  0.5023923444976076\n",
      "f1  score for fold 4186:  0.3246753246753247\n",
      "recall for fold 4186:  0.33783783783783783\n",
      "precision for fold 4186:  0.3125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4187:  0.5476190476190477\n",
      "f1  score for fold 4187:  0.38709677419354843\n",
      "recall for fold 4187:  0.4\n",
      "precision for fold 4187:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4188:  0.558252427184466\n",
      "f1  score for fold 4188:  0.43478260869565216\n",
      "recall for fold 4188:  0.4268292682926829\n",
      "precision for fold 4188:  0.4430379746835443\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4189:  0.49740932642487046\n",
      "f1  score for fold 4189:  0.39751552795031053\n",
      "recall for fold 4189:  0.367816091954023\n",
      "precision for fold 4189:  0.43243243243243246\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4190:  0.5598086124401914\n",
      "f1  score for fold 4190:  0.4177215189873418\n",
      "recall for fold 4190:  0.4230769230769231\n",
      "precision for fold 4190:  0.4125\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4191:  0.5598086124401914\n",
      "f1  score for fold 4191:  0.40259740259740256\n",
      "recall for fold 4191:  0.4189189189189189\n",
      "precision for fold 4191:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4192:  0.5285714285714286\n",
      "f1  score for fold 4192:  0.3612903225806451\n",
      "recall for fold 4192:  0.37333333333333335\n",
      "precision for fold 4192:  0.35\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4193:  0.5194174757281553\n",
      "f1  score for fold 4193:  0.38509316770186336\n",
      "recall for fold 4193:  0.3780487804878049\n",
      "precision for fold 4193:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4194:  0.5284974093264249\n",
      "f1  score for fold 4194:  0.4347826086956522\n",
      "recall for fold 4194:  0.40229885057471265\n",
      "precision for fold 4194:  0.47297297297297297\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4195:  0.5789473684210527\n",
      "f1  score for fold 4195:  0.44303797468354433\n",
      "recall for fold 4195:  0.44871794871794873\n",
      "precision for fold 4195:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4196:  0.5311004784688995\n",
      "f1  score for fold 4196:  0.36363636363636365\n",
      "recall for fold 4196:  0.3783783783783784\n",
      "precision for fold 4196:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4197:  0.5285714285714286\n",
      "f1  score for fold 4197:  0.3612903225806451\n",
      "recall for fold 4197:  0.37333333333333335\n",
      "precision for fold 4197:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4198:  0.5097087378640777\n",
      "f1  score for fold 4198:  0.37267080745341613\n",
      "recall for fold 4198:  0.36585365853658536\n",
      "precision for fold 4198:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4199:  0.5077720207253886\n",
      "f1  score for fold 4199:  0.40993788819875776\n",
      "recall for fold 4199:  0.3793103448275862\n",
      "precision for fold 4199:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4200:  0.5023923444976076\n",
      "f1  score for fold 4200:  0.34177215189873417\n",
      "recall for fold 4200:  0.34615384615384615\n",
      "precision for fold 4200:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4201:  0.5406698564593302\n",
      "f1  score for fold 4201:  0.37662337662337664\n",
      "recall for fold 4201:  0.3918918918918919\n",
      "precision for fold 4201:  0.3625\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4202:  0.6047619047619047\n",
      "f1  score for fold 4202:  0.4645161290322581\n",
      "recall for fold 4202:  0.48\n",
      "precision for fold 4202:  0.45\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4203:  0.5\n",
      "f1  score for fold 4203:  0.3602484472049689\n",
      "recall for fold 4203:  0.35365853658536583\n",
      "precision for fold 4203:  0.3670886075949367\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 4204:  0.5595854922279793\n",
      "f1  score for fold 4204:  0.4720496894409938\n",
      "recall for fold 4204:  0.4367816091954023\n",
      "precision for fold 4204:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4205:  0.5502392344497608\n",
      "f1  score for fold 4205:  0.4050632911392405\n",
      "recall for fold 4205:  0.41025641025641024\n",
      "precision for fold 4205:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4206:  0.5023923444976076\n",
      "f1  score for fold 4206:  0.3246753246753247\n",
      "recall for fold 4206:  0.33783783783783783\n",
      "precision for fold 4206:  0.3125\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 4207:  0.4714285714285714\n",
      "f1  score for fold 4207:  0.2838709677419355\n",
      "recall for fold 4207:  0.29333333333333333\n",
      "precision for fold 4207:  0.275\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4208:  0.5194174757281553\n",
      "f1  score for fold 4208:  0.38509316770186336\n",
      "recall for fold 4208:  0.3780487804878049\n",
      "precision for fold 4208:  0.3924050632911392\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4209:  0.49740932642487046\n",
      "f1  score for fold 4209:  0.39751552795031053\n",
      "recall for fold 4209:  0.367816091954023\n",
      "precision for fold 4209:  0.43243243243243246\n",
      "    0   1\n",
      "0  39  39\n",
      "1  41  90\n",
      "Accuracy for fold 4210:  0.6172248803827751\n",
      "f1  score for fold 4210:  0.49367088607594933\n",
      "recall for fold 4210:  0.5\n",
      "precision for fold 4210:  0.4875\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4211:  0.5023923444976076\n",
      "f1  score for fold 4211:  0.3246753246753247\n",
      "recall for fold 4211:  0.33783783783783783\n",
      "precision for fold 4211:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4212:  0.5571428571428572\n",
      "f1  score for fold 4212:  0.4000000000000001\n",
      "recall for fold 4212:  0.41333333333333333\n",
      "precision for fold 4212:  0.3875\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4213:  0.5194174757281553\n",
      "f1  score for fold 4213:  0.38509316770186336\n",
      "recall for fold 4213:  0.3780487804878049\n",
      "precision for fold 4213:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 4214:  0.5595854922279793\n",
      "f1  score for fold 4214:  0.4720496894409938\n",
      "recall for fold 4214:  0.4367816091954023\n",
      "precision for fold 4214:  0.5135135135135135\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4215:  0.5119617224880383\n",
      "f1  score for fold 4215:  0.3544303797468355\n",
      "recall for fold 4215:  0.358974358974359\n",
      "precision for fold 4215:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4216:  0.5406698564593302\n",
      "f1  score for fold 4216:  0.37662337662337664\n",
      "recall for fold 4216:  0.3918918918918919\n",
      "precision for fold 4216:  0.3625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4217:  0.5380952380952381\n",
      "f1  score for fold 4217:  0.3741935483870968\n",
      "recall for fold 4217:  0.38666666666666666\n",
      "precision for fold 4217:  0.3625\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 4218:  0.441747572815534\n",
      "f1  score for fold 4218:  0.28571428571428575\n",
      "recall for fold 4218:  0.2804878048780488\n",
      "precision for fold 4218:  0.2911392405063291\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4219:  0.5077720207253886\n",
      "f1  score for fold 4219:  0.40993788819875776\n",
      "recall for fold 4219:  0.3793103448275862\n",
      "precision for fold 4219:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4220:  0.5215311004784688\n",
      "f1  score for fold 4220:  0.36708860759493667\n",
      "recall for fold 4220:  0.3717948717948718\n",
      "precision for fold 4220:  0.3625\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4221:  0.5598086124401914\n",
      "f1  score for fold 4221:  0.40259740259740256\n",
      "recall for fold 4221:  0.4189189189189189\n",
      "precision for fold 4221:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4222:  0.5190476190476191\n",
      "f1  score for fold 4222:  0.34838709677419355\n",
      "recall for fold 4222:  0.36\n",
      "precision for fold 4222:  0.3375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4223:  0.5\n",
      "f1  score for fold 4223:  0.3602484472049689\n",
      "recall for fold 4223:  0.35365853658536583\n",
      "precision for fold 4223:  0.3670886075949367\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4224:  0.49740932642487046\n",
      "f1  score for fold 4224:  0.39751552795031053\n",
      "recall for fold 4224:  0.367816091954023\n",
      "precision for fold 4224:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4225:  0.5311004784688995\n",
      "f1  score for fold 4225:  0.37974683544303806\n",
      "recall for fold 4225:  0.38461538461538464\n",
      "precision for fold 4225:  0.375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4226:  0.5789473684210527\n",
      "f1  score for fold 4226:  0.42857142857142855\n",
      "recall for fold 4226:  0.44594594594594594\n",
      "precision for fold 4226:  0.4125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4227:  0.5190476190476191\n",
      "f1  score for fold 4227:  0.34838709677419355\n",
      "recall for fold 4227:  0.36\n",
      "precision for fold 4227:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4228:  0.529126213592233\n",
      "f1  score for fold 4228:  0.39751552795031053\n",
      "recall for fold 4228:  0.3902439024390244\n",
      "precision for fold 4228:  0.4050632911392405\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 4229:  0.6010362694300518\n",
      "f1  score for fold 4229:  0.5217391304347826\n",
      "recall for fold 4229:  0.4827586206896552\n",
      "precision for fold 4229:  0.5675675675675675\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4230:  0.5406698564593302\n",
      "f1  score for fold 4230:  0.3924050632911393\n",
      "recall for fold 4230:  0.3974358974358974\n",
      "precision for fold 4230:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4231:  0.5119617224880383\n",
      "f1  score for fold 4231:  0.33766233766233766\n",
      "recall for fold 4231:  0.35135135135135137\n",
      "precision for fold 4231:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4232:  0.5285714285714286\n",
      "f1  score for fold 4232:  0.3612903225806451\n",
      "recall for fold 4232:  0.37333333333333335\n",
      "precision for fold 4232:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4233:  0.5\n",
      "f1  score for fold 4233:  0.3602484472049689\n",
      "recall for fold 4233:  0.35365853658536583\n",
      "precision for fold 4233:  0.3670886075949367\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4234:  0.44559585492227977\n",
      "f1  score for fold 4234:  0.33540372670807456\n",
      "recall for fold 4234:  0.3103448275862069\n",
      "precision for fold 4234:  0.36486486486486486\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 4235:  0.47368421052631576\n",
      "f1  score for fold 4235:  0.3037974683544304\n",
      "recall for fold 4235:  0.3076923076923077\n",
      "precision for fold 4235:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4236:  0.5502392344497608\n",
      "f1  score for fold 4236:  0.3896103896103896\n",
      "recall for fold 4236:  0.40540540540540543\n",
      "precision for fold 4236:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4237:  0.5761904761904761\n",
      "f1  score for fold 4237:  0.4258064516129032\n",
      "recall for fold 4237:  0.44\n",
      "precision for fold 4237:  0.4125\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4238:  0.5194174757281553\n",
      "f1  score for fold 4238:  0.38509316770186336\n",
      "recall for fold 4238:  0.3780487804878049\n",
      "precision for fold 4238:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4239:  0.5181347150259067\n",
      "f1  score for fold 4239:  0.422360248447205\n",
      "recall for fold 4239:  0.39080459770114945\n",
      "precision for fold 4239:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4240:  0.5311004784688995\n",
      "f1  score for fold 4240:  0.37974683544303806\n",
      "recall for fold 4240:  0.38461538461538464\n",
      "precision for fold 4240:  0.375\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 4241:  0.6172248803827751\n",
      "f1  score for fold 4241:  0.4805194805194805\n",
      "recall for fold 4241:  0.5\n",
      "precision for fold 4241:  0.4625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4242:  0.5285714285714286\n",
      "f1  score for fold 4242:  0.3612903225806451\n",
      "recall for fold 4242:  0.37333333333333335\n",
      "precision for fold 4242:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4243:  0.5388349514563107\n",
      "f1  score for fold 4243:  0.40993788819875776\n",
      "recall for fold 4243:  0.4024390243902439\n",
      "precision for fold 4243:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4244:  0.49740932642487046\n",
      "f1  score for fold 4244:  0.39751552795031053\n",
      "recall for fold 4244:  0.367816091954023\n",
      "precision for fold 4244:  0.43243243243243246\n",
      "    0   1\n",
      "0  37  41\n",
      "1  43  88\n",
      "Accuracy for fold 4245:  0.5980861244019139\n",
      "f1  score for fold 4245:  0.46835443037974683\n",
      "recall for fold 4245:  0.47435897435897434\n",
      "precision for fold 4245:  0.4625\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4246:  0.5789473684210527\n",
      "f1  score for fold 4246:  0.42857142857142855\n",
      "recall for fold 4246:  0.44594594594594594\n",
      "precision for fold 4246:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4247:  0.5380952380952381\n",
      "f1  score for fold 4247:  0.3741935483870968\n",
      "recall for fold 4247:  0.38666666666666666\n",
      "precision for fold 4247:  0.3625\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4248:  0.470873786407767\n",
      "f1  score for fold 4248:  0.3229813664596273\n",
      "recall for fold 4248:  0.3170731707317073\n",
      "precision for fold 4248:  0.3291139240506329\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 4249:  0.6010362694300518\n",
      "f1  score for fold 4249:  0.5217391304347826\n",
      "recall for fold 4249:  0.4827586206896552\n",
      "precision for fold 4249:  0.5675675675675675\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4250:  0.5119617224880383\n",
      "f1  score for fold 4250:  0.3544303797468355\n",
      "recall for fold 4250:  0.358974358974359\n",
      "precision for fold 4250:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4251:  0.5598086124401914\n",
      "f1  score for fold 4251:  0.40259740259740256\n",
      "recall for fold 4251:  0.4189189189189189\n",
      "precision for fold 4251:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4252:  0.5285714285714286\n",
      "f1  score for fold 4252:  0.3612903225806451\n",
      "recall for fold 4252:  0.37333333333333335\n",
      "precision for fold 4252:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4253:  0.5388349514563107\n",
      "f1  score for fold 4253:  0.40993788819875776\n",
      "recall for fold 4253:  0.4024390243902439\n",
      "precision for fold 4253:  0.4177215189873418\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4254:  0.49740932642487046\n",
      "f1  score for fold 4254:  0.39751552795031053\n",
      "recall for fold 4254:  0.367816091954023\n",
      "precision for fold 4254:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4255:  0.5406698564593302\n",
      "f1  score for fold 4255:  0.3924050632911393\n",
      "recall for fold 4255:  0.3974358974358974\n",
      "precision for fold 4255:  0.3875\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 4256:  0.5980861244019139\n",
      "f1  score for fold 4256:  0.45454545454545453\n",
      "recall for fold 4256:  0.47297297297297297\n",
      "precision for fold 4256:  0.4375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4257:  0.5380952380952381\n",
      "f1  score for fold 4257:  0.3741935483870968\n",
      "recall for fold 4257:  0.38666666666666666\n",
      "precision for fold 4257:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4258:  0.5097087378640777\n",
      "f1  score for fold 4258:  0.37267080745341613\n",
      "recall for fold 4258:  0.36585365853658536\n",
      "precision for fold 4258:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4259:  0.45595854922279794\n",
      "f1  score for fold 4259:  0.3478260869565218\n",
      "recall for fold 4259:  0.3218390804597701\n",
      "precision for fold 4259:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4260:  0.5406698564593302\n",
      "f1  score for fold 4260:  0.3924050632911393\n",
      "recall for fold 4260:  0.3974358974358974\n",
      "precision for fold 4260:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4261:  0.5119617224880383\n",
      "f1  score for fold 4261:  0.33766233766233766\n",
      "recall for fold 4261:  0.35135135135135137\n",
      "precision for fold 4261:  0.325\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 4262:  0.46190476190476193\n",
      "f1  score for fold 4262:  0.2709677419354839\n",
      "recall for fold 4262:  0.28\n",
      "precision for fold 4262:  0.2625\n",
      "    0   1\n",
      "0  22  60\n",
      "1  57  67\n",
      "Accuracy for fold 4263:  0.4320388349514563\n",
      "f1  score for fold 4263:  0.2732919254658385\n",
      "recall for fold 4263:  0.2682926829268293\n",
      "precision for fold 4263:  0.27848101265822783\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4264:  0.538860103626943\n",
      "f1  score for fold 4264:  0.4472049689440994\n",
      "recall for fold 4264:  0.41379310344827586\n",
      "precision for fold 4264:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4265:  0.5502392344497608\n",
      "f1  score for fold 4265:  0.4050632911392405\n",
      "recall for fold 4265:  0.41025641025641024\n",
      "precision for fold 4265:  0.4\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4266:  0.5789473684210527\n",
      "f1  score for fold 4266:  0.42857142857142855\n",
      "recall for fold 4266:  0.44594594594594594\n",
      "precision for fold 4266:  0.4125\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4267:  0.48095238095238096\n",
      "f1  score for fold 4267:  0.2967741935483871\n",
      "recall for fold 4267:  0.30666666666666664\n",
      "precision for fold 4267:  0.2875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4268:  0.529126213592233\n",
      "f1  score for fold 4268:  0.39751552795031053\n",
      "recall for fold 4268:  0.3902439024390244\n",
      "precision for fold 4268:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4269:  0.5077720207253886\n",
      "f1  score for fold 4269:  0.40993788819875776\n",
      "recall for fold 4269:  0.3793103448275862\n",
      "precision for fold 4269:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4270:  0.5789473684210527\n",
      "f1  score for fold 4270:  0.44303797468354433\n",
      "recall for fold 4270:  0.44871794871794873\n",
      "precision for fold 4270:  0.4375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4271:  0.569377990430622\n",
      "f1  score for fold 4271:  0.4155844155844156\n",
      "recall for fold 4271:  0.43243243243243246\n",
      "precision for fold 4271:  0.4\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4272:  0.5952380952380952\n",
      "f1  score for fold 4272:  0.45161290322580644\n",
      "recall for fold 4272:  0.4666666666666667\n",
      "precision for fold 4272:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4273:  0.5485436893203883\n",
      "f1  score for fold 4273:  0.42236024844720493\n",
      "recall for fold 4273:  0.4146341463414634\n",
      "precision for fold 4273:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4274:  0.5284974093264249\n",
      "f1  score for fold 4274:  0.4347826086956522\n",
      "recall for fold 4274:  0.40229885057471265\n",
      "precision for fold 4274:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4275:  0.5215311004784688\n",
      "f1  score for fold 4275:  0.36708860759493667\n",
      "recall for fold 4275:  0.3717948717948718\n",
      "precision for fold 4275:  0.3625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4276:  0.569377990430622\n",
      "f1  score for fold 4276:  0.4155844155844156\n",
      "recall for fold 4276:  0.43243243243243246\n",
      "precision for fold 4276:  0.4\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4277:  0.5666666666666667\n",
      "f1  score for fold 4277:  0.41290322580645167\n",
      "recall for fold 4277:  0.4266666666666667\n",
      "precision for fold 4277:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4278:  0.5679611650485437\n",
      "f1  score for fold 4278:  0.4472049689440994\n",
      "recall for fold 4278:  0.43902439024390244\n",
      "precision for fold 4278:  0.45569620253164556\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4279:  0.5699481865284974\n",
      "f1  score for fold 4279:  0.48447204968944096\n",
      "recall for fold 4279:  0.4482758620689655\n",
      "precision for fold 4279:  0.527027027027027\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4280:  0.5215311004784688\n",
      "f1  score for fold 4280:  0.36708860759493667\n",
      "recall for fold 4280:  0.3717948717948718\n",
      "precision for fold 4280:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4281:  0.5406698564593302\n",
      "f1  score for fold 4281:  0.37662337662337664\n",
      "recall for fold 4281:  0.3918918918918919\n",
      "precision for fold 4281:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4282:  0.5285714285714286\n",
      "f1  score for fold 4282:  0.3612903225806451\n",
      "recall for fold 4282:  0.37333333333333335\n",
      "precision for fold 4282:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4283:  0.5388349514563107\n",
      "f1  score for fold 4283:  0.40993788819875776\n",
      "recall for fold 4283:  0.4024390243902439\n",
      "precision for fold 4283:  0.4177215189873418\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4284:  0.44559585492227977\n",
      "f1  score for fold 4284:  0.33540372670807456\n",
      "recall for fold 4284:  0.3103448275862069\n",
      "precision for fold 4284:  0.36486486486486486\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4285:  0.5789473684210527\n",
      "f1  score for fold 4285:  0.44303797468354433\n",
      "recall for fold 4285:  0.44871794871794873\n",
      "precision for fold 4285:  0.4375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4286:  0.5119617224880383\n",
      "f1  score for fold 4286:  0.33766233766233766\n",
      "recall for fold 4286:  0.35135135135135137\n",
      "precision for fold 4286:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4287:  0.5190476190476191\n",
      "f1  score for fold 4287:  0.34838709677419355\n",
      "recall for fold 4287:  0.36\n",
      "precision for fold 4287:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4288:  0.5194174757281553\n",
      "f1  score for fold 4288:  0.38509316770186336\n",
      "recall for fold 4288:  0.3780487804878049\n",
      "precision for fold 4288:  0.3924050632911392\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 4289:  0.5803108808290155\n",
      "f1  score for fold 4289:  0.49689440993788814\n",
      "recall for fold 4289:  0.45977011494252873\n",
      "precision for fold 4289:  0.5405405405405406\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4290:  0.5023923444976076\n",
      "f1  score for fold 4290:  0.34177215189873417\n",
      "recall for fold 4290:  0.34615384615384615\n",
      "precision for fold 4290:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4291:  0.5406698564593302\n",
      "f1  score for fold 4291:  0.37662337662337664\n",
      "recall for fold 4291:  0.3918918918918919\n",
      "precision for fold 4291:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4292:  0.5476190476190477\n",
      "f1  score for fold 4292:  0.38709677419354843\n",
      "recall for fold 4292:  0.4\n",
      "precision for fold 4292:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4293:  0.49029126213592233\n",
      "f1  score for fold 4293:  0.3478260869565218\n",
      "recall for fold 4293:  0.34146341463414637\n",
      "precision for fold 4293:  0.35443037974683544\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4294:  0.45595854922279794\n",
      "f1  score for fold 4294:  0.3478260869565218\n",
      "recall for fold 4294:  0.3218390804597701\n",
      "precision for fold 4294:  0.3783783783783784\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4295:  0.5311004784688995\n",
      "f1  score for fold 4295:  0.37974683544303806\n",
      "recall for fold 4295:  0.38461538461538464\n",
      "precision for fold 4295:  0.375\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 4296:  0.6076555023923444\n",
      "f1  score for fold 4296:  0.4675324675324675\n",
      "recall for fold 4296:  0.4864864864864865\n",
      "precision for fold 4296:  0.45\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4297:  0.5857142857142857\n",
      "f1  score for fold 4297:  0.43870967741935485\n",
      "recall for fold 4297:  0.4533333333333333\n",
      "precision for fold 4297:  0.425\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4298:  0.470873786407767\n",
      "f1  score for fold 4298:  0.3229813664596273\n",
      "recall for fold 4298:  0.3170731707317073\n",
      "precision for fold 4298:  0.3291139240506329\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4299:  0.538860103626943\n",
      "f1  score for fold 4299:  0.4472049689440994\n",
      "recall for fold 4299:  0.41379310344827586\n",
      "precision for fold 4299:  0.4864864864864865\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 4300:  0.5885167464114832\n",
      "f1  score for fold 4300:  0.45569620253164556\n",
      "recall for fold 4300:  0.46153846153846156\n",
      "precision for fold 4300:  0.45\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4301:  0.5406698564593302\n",
      "f1  score for fold 4301:  0.37662337662337664\n",
      "recall for fold 4301:  0.3918918918918919\n",
      "precision for fold 4301:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4302:  0.5285714285714286\n",
      "f1  score for fold 4302:  0.3612903225806451\n",
      "recall for fold 4302:  0.37333333333333335\n",
      "precision for fold 4302:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4303:  0.5485436893203883\n",
      "f1  score for fold 4303:  0.42236024844720493\n",
      "recall for fold 4303:  0.4146341463414634\n",
      "precision for fold 4303:  0.43037974683544306\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 4304:  0.43523316062176165\n",
      "f1  score for fold 4304:  0.3229813664596274\n",
      "recall for fold 4304:  0.2988505747126437\n",
      "precision for fold 4304:  0.35135135135135137\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4305:  0.49282296650717705\n",
      "f1  score for fold 4305:  0.32911392405063294\n",
      "recall for fold 4305:  0.3333333333333333\n",
      "precision for fold 4305:  0.325\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4306:  0.5215311004784688\n",
      "f1  score for fold 4306:  0.3506493506493507\n",
      "recall for fold 4306:  0.36486486486486486\n",
      "precision for fold 4306:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4307:  0.5857142857142857\n",
      "f1  score for fold 4307:  0.43870967741935485\n",
      "recall for fold 4307:  0.4533333333333333\n",
      "precision for fold 4307:  0.425\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4308:  0.49029126213592233\n",
      "f1  score for fold 4308:  0.3478260869565218\n",
      "recall for fold 4308:  0.34146341463414637\n",
      "precision for fold 4308:  0.35443037974683544\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4309:  0.46632124352331605\n",
      "f1  score for fold 4309:  0.36024844720496896\n",
      "recall for fold 4309:  0.3333333333333333\n",
      "precision for fold 4309:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4310:  0.5023923444976076\n",
      "f1  score for fold 4310:  0.34177215189873417\n",
      "recall for fold 4310:  0.34615384615384615\n",
      "precision for fold 4310:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4311:  0.5119617224880383\n",
      "f1  score for fold 4311:  0.33766233766233766\n",
      "recall for fold 4311:  0.35135135135135137\n",
      "precision for fold 4311:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4312:  0.5571428571428572\n",
      "f1  score for fold 4312:  0.4000000000000001\n",
      "recall for fold 4312:  0.41333333333333333\n",
      "precision for fold 4312:  0.3875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4313:  0.470873786407767\n",
      "f1  score for fold 4313:  0.3229813664596273\n",
      "recall for fold 4313:  0.3170731707317073\n",
      "precision for fold 4313:  0.3291139240506329\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4314:  0.47668393782383417\n",
      "f1  score for fold 4314:  0.3726708074534162\n",
      "recall for fold 4314:  0.3448275862068966\n",
      "precision for fold 4314:  0.40540540540540543\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 4315:  0.5885167464114832\n",
      "f1  score for fold 4315:  0.45569620253164556\n",
      "recall for fold 4315:  0.46153846153846156\n",
      "precision for fold 4315:  0.45\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4316:  0.48325358851674644\n",
      "f1  score for fold 4316:  0.29870129870129863\n",
      "recall for fold 4316:  0.3108108108108108\n",
      "precision for fold 4316:  0.2875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4317:  0.5476190476190477\n",
      "f1  score for fold 4317:  0.38709677419354843\n",
      "recall for fold 4317:  0.4\n",
      "precision for fold 4317:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4318:  0.5194174757281553\n",
      "f1  score for fold 4318:  0.38509316770186336\n",
      "recall for fold 4318:  0.3780487804878049\n",
      "precision for fold 4318:  0.3924050632911392\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4319:  0.5077720207253886\n",
      "f1  score for fold 4319:  0.40993788819875776\n",
      "recall for fold 4319:  0.3793103448275862\n",
      "precision for fold 4319:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4320:  0.5119617224880383\n",
      "f1  score for fold 4320:  0.3544303797468355\n",
      "recall for fold 4320:  0.358974358974359\n",
      "precision for fold 4320:  0.35\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4321:  0.5406698564593302\n",
      "f1  score for fold 4321:  0.37662337662337664\n",
      "recall for fold 4321:  0.3918918918918919\n",
      "precision for fold 4321:  0.3625\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4322:  0.5\n",
      "f1  score for fold 4322:  0.3225806451612903\n",
      "recall for fold 4322:  0.3333333333333333\n",
      "precision for fold 4322:  0.3125\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4323:  0.5097087378640777\n",
      "f1  score for fold 4323:  0.37267080745341613\n",
      "recall for fold 4323:  0.36585365853658536\n",
      "precision for fold 4323:  0.379746835443038\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4324:  0.5181347150259067\n",
      "f1  score for fold 4324:  0.422360248447205\n",
      "recall for fold 4324:  0.39080459770114945\n",
      "precision for fold 4324:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4325:  0.49282296650717705\n",
      "f1  score for fold 4325:  0.32911392405063294\n",
      "recall for fold 4325:  0.3333333333333333\n",
      "precision for fold 4325:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4326:  0.5406698564593302\n",
      "f1  score for fold 4326:  0.37662337662337664\n",
      "recall for fold 4326:  0.3918918918918919\n",
      "precision for fold 4326:  0.3625\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4327:  0.5952380952380952\n",
      "f1  score for fold 4327:  0.45161290322580644\n",
      "recall for fold 4327:  0.4666666666666667\n",
      "precision for fold 4327:  0.4375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4328:  0.558252427184466\n",
      "f1  score for fold 4328:  0.43478260869565216\n",
      "recall for fold 4328:  0.4268292682926829\n",
      "precision for fold 4328:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4329:  0.538860103626943\n",
      "f1  score for fold 4329:  0.4472049689440994\n",
      "recall for fold 4329:  0.41379310344827586\n",
      "precision for fold 4329:  0.4864864864864865\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4330:  0.48325358851674644\n",
      "f1  score for fold 4330:  0.31645569620253167\n",
      "recall for fold 4330:  0.32051282051282054\n",
      "precision for fold 4330:  0.3125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4331:  0.5119617224880383\n",
      "f1  score for fold 4331:  0.33766233766233766\n",
      "recall for fold 4331:  0.35135135135135137\n",
      "precision for fold 4331:  0.325\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4332:  0.5476190476190477\n",
      "f1  score for fold 4332:  0.38709677419354843\n",
      "recall for fold 4332:  0.4\n",
      "precision for fold 4332:  0.375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4333:  0.5\n",
      "f1  score for fold 4333:  0.3602484472049689\n",
      "recall for fold 4333:  0.35365853658536583\n",
      "precision for fold 4333:  0.3670886075949367\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4334:  0.5181347150259067\n",
      "f1  score for fold 4334:  0.422360248447205\n",
      "recall for fold 4334:  0.39080459770114945\n",
      "precision for fold 4334:  0.4594594594594595\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4335:  0.5311004784688995\n",
      "f1  score for fold 4335:  0.37974683544303806\n",
      "recall for fold 4335:  0.38461538461538464\n",
      "precision for fold 4335:  0.375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4336:  0.5789473684210527\n",
      "f1  score for fold 4336:  0.42857142857142855\n",
      "recall for fold 4336:  0.44594594594594594\n",
      "precision for fold 4336:  0.4125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4337:  0.5380952380952381\n",
      "f1  score for fold 4337:  0.3741935483870968\n",
      "recall for fold 4337:  0.38666666666666666\n",
      "precision for fold 4337:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4338:  0.5\n",
      "f1  score for fold 4338:  0.3602484472049689\n",
      "recall for fold 4338:  0.35365853658536583\n",
      "precision for fold 4338:  0.3670886075949367\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4339:  0.47668393782383417\n",
      "f1  score for fold 4339:  0.3726708074534162\n",
      "recall for fold 4339:  0.3448275862068966\n",
      "precision for fold 4339:  0.40540540540540543\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4340:  0.5119617224880383\n",
      "f1  score for fold 4340:  0.3544303797468355\n",
      "recall for fold 4340:  0.358974358974359\n",
      "precision for fold 4340:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4341:  0.5598086124401914\n",
      "f1  score for fold 4341:  0.40259740259740256\n",
      "recall for fold 4341:  0.4189189189189189\n",
      "precision for fold 4341:  0.3875\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4342:  0.5761904761904761\n",
      "f1  score for fold 4342:  0.4258064516129032\n",
      "recall for fold 4342:  0.44\n",
      "precision for fold 4342:  0.4125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4343:  0.48058252427184467\n",
      "f1  score for fold 4343:  0.33540372670807456\n",
      "recall for fold 4343:  0.32926829268292684\n",
      "precision for fold 4343:  0.34177215189873417\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4344:  0.47668393782383417\n",
      "f1  score for fold 4344:  0.3726708074534162\n",
      "recall for fold 4344:  0.3448275862068966\n",
      "precision for fold 4344:  0.40540540540540543\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4345:  0.5215311004784688\n",
      "f1  score for fold 4345:  0.36708860759493667\n",
      "recall for fold 4345:  0.3717948717948718\n",
      "precision for fold 4345:  0.3625\n",
      "    0   1\n",
      "0  19  55\n",
      "1  61  74\n",
      "Accuracy for fold 4346:  0.4449760765550239\n",
      "f1  score for fold 4346:  0.24675324675324675\n",
      "recall for fold 4346:  0.25675675675675674\n",
      "precision for fold 4346:  0.2375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4347:  0.5285714285714286\n",
      "f1  score for fold 4347:  0.3612903225806451\n",
      "recall for fold 4347:  0.37333333333333335\n",
      "precision for fold 4347:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4348:  0.5485436893203883\n",
      "f1  score for fold 4348:  0.42236024844720493\n",
      "recall for fold 4348:  0.4146341463414634\n",
      "precision for fold 4348:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4349:  0.49740932642487046\n",
      "f1  score for fold 4349:  0.39751552795031053\n",
      "recall for fold 4349:  0.367816091954023\n",
      "precision for fold 4349:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4350:  0.49282296650717705\n",
      "f1  score for fold 4350:  0.32911392405063294\n",
      "recall for fold 4350:  0.3333333333333333\n",
      "precision for fold 4350:  0.325\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4351:  0.569377990430622\n",
      "f1  score for fold 4351:  0.4155844155844156\n",
      "recall for fold 4351:  0.43243243243243246\n",
      "precision for fold 4351:  0.4\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4352:  0.5666666666666667\n",
      "f1  score for fold 4352:  0.41290322580645167\n",
      "recall for fold 4352:  0.4266666666666667\n",
      "precision for fold 4352:  0.4\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4353:  0.5679611650485437\n",
      "f1  score for fold 4353:  0.4472049689440994\n",
      "recall for fold 4353:  0.43902439024390244\n",
      "precision for fold 4353:  0.45569620253164556\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4354:  0.5699481865284974\n",
      "f1  score for fold 4354:  0.48447204968944096\n",
      "recall for fold 4354:  0.4482758620689655\n",
      "precision for fold 4354:  0.527027027027027\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4355:  0.5311004784688995\n",
      "f1  score for fold 4355:  0.37974683544303806\n",
      "recall for fold 4355:  0.38461538461538464\n",
      "precision for fold 4355:  0.375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4356:  0.5406698564593302\n",
      "f1  score for fold 4356:  0.37662337662337664\n",
      "recall for fold 4356:  0.3918918918918919\n",
      "precision for fold 4356:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4357:  0.5095238095238095\n",
      "f1  score for fold 4357:  0.335483870967742\n",
      "recall for fold 4357:  0.3466666666666667\n",
      "precision for fold 4357:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4358:  0.49029126213592233\n",
      "f1  score for fold 4358:  0.3478260869565218\n",
      "recall for fold 4358:  0.34146341463414637\n",
      "precision for fold 4358:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4359:  0.5077720207253886\n",
      "f1  score for fold 4359:  0.40993788819875776\n",
      "recall for fold 4359:  0.3793103448275862\n",
      "precision for fold 4359:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4360:  0.569377990430622\n",
      "f1  score for fold 4360:  0.43037974683544306\n",
      "recall for fold 4360:  0.4358974358974359\n",
      "precision for fold 4360:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4361:  0.5215311004784688\n",
      "f1  score for fold 4361:  0.3506493506493507\n",
      "recall for fold 4361:  0.36486486486486486\n",
      "precision for fold 4361:  0.3375\n",
      "    0   1\n",
      "0  21  54\n",
      "1  59  76\n",
      "Accuracy for fold 4362:  0.46190476190476193\n",
      "f1  score for fold 4362:  0.2709677419354839\n",
      "recall for fold 4362:  0.28\n",
      "precision for fold 4362:  0.2625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4363:  0.5\n",
      "f1  score for fold 4363:  0.3602484472049689\n",
      "recall for fold 4363:  0.35365853658536583\n",
      "precision for fold 4363:  0.3670886075949367\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4364:  0.46632124352331605\n",
      "f1  score for fold 4364:  0.36024844720496896\n",
      "recall for fold 4364:  0.3333333333333333\n",
      "precision for fold 4364:  0.3918918918918919\n",
      "    0   1\n",
      "0  39  39\n",
      "1  41  90\n",
      "Accuracy for fold 4365:  0.6172248803827751\n",
      "f1  score for fold 4365:  0.49367088607594933\n",
      "recall for fold 4365:  0.5\n",
      "precision for fold 4365:  0.4875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4366:  0.5311004784688995\n",
      "f1  score for fold 4366:  0.36363636363636365\n",
      "recall for fold 4366:  0.3783783783783784\n",
      "precision for fold 4366:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4367:  0.49047619047619045\n",
      "f1  score for fold 4367:  0.3096774193548387\n",
      "recall for fold 4367:  0.32\n",
      "precision for fold 4367:  0.3\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4368:  0.529126213592233\n",
      "f1  score for fold 4368:  0.39751552795031053\n",
      "recall for fold 4368:  0.3902439024390244\n",
      "precision for fold 4368:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4369:  0.5284974093264249\n",
      "f1  score for fold 4369:  0.4347826086956522\n",
      "recall for fold 4369:  0.40229885057471265\n",
      "precision for fold 4369:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4370:  0.569377990430622\n",
      "f1  score for fold 4370:  0.43037974683544306\n",
      "recall for fold 4370:  0.4358974358974359\n",
      "precision for fold 4370:  0.425\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4371:  0.48325358851674644\n",
      "f1  score for fold 4371:  0.29870129870129863\n",
      "recall for fold 4371:  0.3108108108108108\n",
      "precision for fold 4371:  0.2875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4372:  0.5380952380952381\n",
      "f1  score for fold 4372:  0.3741935483870968\n",
      "recall for fold 4372:  0.38666666666666666\n",
      "precision for fold 4372:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4373:  0.5097087378640777\n",
      "f1  score for fold 4373:  0.37267080745341613\n",
      "recall for fold 4373:  0.36585365853658536\n",
      "precision for fold 4373:  0.379746835443038\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4374:  0.5699481865284974\n",
      "f1  score for fold 4374:  0.48447204968944096\n",
      "recall for fold 4374:  0.4482758620689655\n",
      "precision for fold 4374:  0.527027027027027\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4375:  0.5598086124401914\n",
      "f1  score for fold 4375:  0.4177215189873418\n",
      "recall for fold 4375:  0.4230769230769231\n",
      "precision for fold 4375:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4376:  0.5311004784688995\n",
      "f1  score for fold 4376:  0.36363636363636365\n",
      "recall for fold 4376:  0.3783783783783784\n",
      "precision for fold 4376:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4377:  0.5095238095238095\n",
      "f1  score for fold 4377:  0.335483870967742\n",
      "recall for fold 4377:  0.3466666666666667\n",
      "precision for fold 4377:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4378:  0.529126213592233\n",
      "f1  score for fold 4378:  0.39751552795031053\n",
      "recall for fold 4378:  0.3902439024390244\n",
      "precision for fold 4378:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4379:  0.5077720207253886\n",
      "f1  score for fold 4379:  0.40993788819875776\n",
      "recall for fold 4379:  0.3793103448275862\n",
      "precision for fold 4379:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4380:  0.5215311004784688\n",
      "f1  score for fold 4380:  0.36708860759493667\n",
      "recall for fold 4380:  0.3717948717948718\n",
      "precision for fold 4380:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4381:  0.5023923444976076\n",
      "f1  score for fold 4381:  0.3246753246753247\n",
      "recall for fold 4381:  0.33783783783783783\n",
      "precision for fold 4381:  0.3125\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4382:  0.5380952380952381\n",
      "f1  score for fold 4382:  0.3741935483870968\n",
      "recall for fold 4382:  0.38666666666666666\n",
      "precision for fold 4382:  0.3625\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4383:  0.5194174757281553\n",
      "f1  score for fold 4383:  0.38509316770186336\n",
      "recall for fold 4383:  0.3780487804878049\n",
      "precision for fold 4383:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4384:  0.5284974093264249\n",
      "f1  score for fold 4384:  0.4347826086956522\n",
      "recall for fold 4384:  0.40229885057471265\n",
      "precision for fold 4384:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4385:  0.49282296650717705\n",
      "f1  score for fold 4385:  0.32911392405063294\n",
      "recall for fold 4385:  0.3333333333333333\n",
      "precision for fold 4385:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4386:  0.5502392344497608\n",
      "f1  score for fold 4386:  0.3896103896103896\n",
      "recall for fold 4386:  0.40540540540540543\n",
      "precision for fold 4386:  0.375\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4387:  0.5571428571428572\n",
      "f1  score for fold 4387:  0.4000000000000001\n",
      "recall for fold 4387:  0.41333333333333333\n",
      "precision for fold 4387:  0.3875\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4388:  0.49029126213592233\n",
      "f1  score for fold 4388:  0.3478260869565218\n",
      "recall for fold 4388:  0.34146341463414637\n",
      "precision for fold 4388:  0.35443037974683544\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4389:  0.5284974093264249\n",
      "f1  score for fold 4389:  0.4347826086956522\n",
      "recall for fold 4389:  0.40229885057471265\n",
      "precision for fold 4389:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4390:  0.5119617224880383\n",
      "f1  score for fold 4390:  0.3544303797468355\n",
      "recall for fold 4390:  0.358974358974359\n",
      "precision for fold 4390:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4391:  0.569377990430622\n",
      "f1  score for fold 4391:  0.4155844155844156\n",
      "recall for fold 4391:  0.43243243243243246\n",
      "precision for fold 4391:  0.4\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4392:  0.49047619047619045\n",
      "f1  score for fold 4392:  0.3096774193548387\n",
      "recall for fold 4392:  0.32\n",
      "precision for fold 4392:  0.3\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4393:  0.5485436893203883\n",
      "f1  score for fold 4393:  0.42236024844720493\n",
      "recall for fold 4393:  0.4146341463414634\n",
      "precision for fold 4393:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4394:  0.5284974093264249\n",
      "f1  score for fold 4394:  0.4347826086956522\n",
      "recall for fold 4394:  0.40229885057471265\n",
      "precision for fold 4394:  0.47297297297297297\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4395:  0.49282296650717705\n",
      "f1  score for fold 4395:  0.32911392405063294\n",
      "recall for fold 4395:  0.3333333333333333\n",
      "precision for fold 4395:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4396:  0.5502392344497608\n",
      "f1  score for fold 4396:  0.3896103896103896\n",
      "recall for fold 4396:  0.40540540540540543\n",
      "precision for fold 4396:  0.375\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4397:  0.6047619047619047\n",
      "f1  score for fold 4397:  0.4645161290322581\n",
      "recall for fold 4397:  0.48\n",
      "precision for fold 4397:  0.45\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4398:  0.49029126213592233\n",
      "f1  score for fold 4398:  0.3478260869565218\n",
      "recall for fold 4398:  0.34146341463414637\n",
      "precision for fold 4398:  0.35443037974683544\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4399:  0.49740932642487046\n",
      "f1  score for fold 4399:  0.39751552795031053\n",
      "recall for fold 4399:  0.367816091954023\n",
      "precision for fold 4399:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4400:  0.5406698564593302\n",
      "f1  score for fold 4400:  0.3924050632911393\n",
      "recall for fold 4400:  0.3974358974358974\n",
      "precision for fold 4400:  0.3875\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4401:  0.5311004784688995\n",
      "f1  score for fold 4401:  0.36363636363636365\n",
      "recall for fold 4401:  0.3783783783783784\n",
      "precision for fold 4401:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4402:  0.5476190476190477\n",
      "f1  score for fold 4402:  0.38709677419354843\n",
      "recall for fold 4402:  0.4\n",
      "precision for fold 4402:  0.375\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4403:  0.5\n",
      "f1  score for fold 4403:  0.3602484472049689\n",
      "recall for fold 4403:  0.35365853658536583\n",
      "precision for fold 4403:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4404:  0.5492227979274611\n",
      "f1  score for fold 4404:  0.45962732919254656\n",
      "recall for fold 4404:  0.42528735632183906\n",
      "precision for fold 4404:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4405:  0.5023923444976076\n",
      "f1  score for fold 4405:  0.34177215189873417\n",
      "recall for fold 4405:  0.34615384615384615\n",
      "precision for fold 4405:  0.3375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4406:  0.5311004784688995\n",
      "f1  score for fold 4406:  0.36363636363636365\n",
      "recall for fold 4406:  0.3783783783783784\n",
      "precision for fold 4406:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4407:  0.5285714285714286\n",
      "f1  score for fold 4407:  0.3612903225806451\n",
      "recall for fold 4407:  0.37333333333333335\n",
      "precision for fold 4407:  0.35\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4408:  0.48058252427184467\n",
      "f1  score for fold 4408:  0.33540372670807456\n",
      "recall for fold 4408:  0.32926829268292684\n",
      "precision for fold 4408:  0.34177215189873417\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4409:  0.46632124352331605\n",
      "f1  score for fold 4409:  0.36024844720496896\n",
      "recall for fold 4409:  0.3333333333333333\n",
      "precision for fold 4409:  0.3918918918918919\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4410:  0.5311004784688995\n",
      "f1  score for fold 4410:  0.37974683544303806\n",
      "recall for fold 4410:  0.38461538461538464\n",
      "precision for fold 4410:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4411:  0.569377990430622\n",
      "f1  score for fold 4411:  0.4155844155844156\n",
      "recall for fold 4411:  0.43243243243243246\n",
      "precision for fold 4411:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4412:  0.5095238095238095\n",
      "f1  score for fold 4412:  0.335483870967742\n",
      "recall for fold 4412:  0.3466666666666667\n",
      "precision for fold 4412:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4413:  0.529126213592233\n",
      "f1  score for fold 4413:  0.39751552795031053\n",
      "recall for fold 4413:  0.3902439024390244\n",
      "precision for fold 4413:  0.4050632911392405\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4414:  0.5181347150259067\n",
      "f1  score for fold 4414:  0.422360248447205\n",
      "recall for fold 4414:  0.39080459770114945\n",
      "precision for fold 4414:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4415:  0.48325358851674644\n",
      "f1  score for fold 4415:  0.31645569620253167\n",
      "recall for fold 4415:  0.32051282051282054\n",
      "precision for fold 4415:  0.3125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4416:  0.5023923444976076\n",
      "f1  score for fold 4416:  0.3246753246753247\n",
      "recall for fold 4416:  0.33783783783783783\n",
      "precision for fold 4416:  0.3125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4417:  0.5666666666666667\n",
      "f1  score for fold 4417:  0.41290322580645167\n",
      "recall for fold 4417:  0.4266666666666667\n",
      "precision for fold 4417:  0.4\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4418:  0.5097087378640777\n",
      "f1  score for fold 4418:  0.37267080745341613\n",
      "recall for fold 4418:  0.36585365853658536\n",
      "precision for fold 4418:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4419:  0.538860103626943\n",
      "f1  score for fold 4419:  0.4472049689440994\n",
      "recall for fold 4419:  0.41379310344827586\n",
      "precision for fold 4419:  0.4864864864864865\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4420:  0.5789473684210527\n",
      "f1  score for fold 4420:  0.44303797468354433\n",
      "recall for fold 4420:  0.44871794871794873\n",
      "precision for fold 4420:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4421:  0.5311004784688995\n",
      "f1  score for fold 4421:  0.36363636363636365\n",
      "recall for fold 4421:  0.3783783783783784\n",
      "precision for fold 4421:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4422:  0.5285714285714286\n",
      "f1  score for fold 4422:  0.3612903225806451\n",
      "recall for fold 4422:  0.37333333333333335\n",
      "precision for fold 4422:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4423:  0.5097087378640777\n",
      "f1  score for fold 4423:  0.37267080745341613\n",
      "recall for fold 4423:  0.36585365853658536\n",
      "precision for fold 4423:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4424:  0.48704663212435234\n",
      "f1  score for fold 4424:  0.3850931677018633\n",
      "recall for fold 4424:  0.3563218390804598\n",
      "precision for fold 4424:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4425:  0.569377990430622\n",
      "f1  score for fold 4425:  0.43037974683544306\n",
      "recall for fold 4425:  0.4358974358974359\n",
      "precision for fold 4425:  0.425\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4426:  0.5502392344497608\n",
      "f1  score for fold 4426:  0.3896103896103896\n",
      "recall for fold 4426:  0.40540540540540543\n",
      "precision for fold 4426:  0.375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4427:  0.5761904761904761\n",
      "f1  score for fold 4427:  0.4258064516129032\n",
      "recall for fold 4427:  0.44\n",
      "precision for fold 4427:  0.4125\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 4428:  0.441747572815534\n",
      "f1  score for fold 4428:  0.28571428571428575\n",
      "recall for fold 4428:  0.2804878048780488\n",
      "precision for fold 4428:  0.2911392405063291\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4429:  0.44559585492227977\n",
      "f1  score for fold 4429:  0.33540372670807456\n",
      "recall for fold 4429:  0.3103448275862069\n",
      "precision for fold 4429:  0.36486486486486486\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4430:  0.569377990430622\n",
      "f1  score for fold 4430:  0.43037974683544306\n",
      "recall for fold 4430:  0.4358974358974359\n",
      "precision for fold 4430:  0.425\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4431:  0.5598086124401914\n",
      "f1  score for fold 4431:  0.40259740259740256\n",
      "recall for fold 4431:  0.4189189189189189\n",
      "precision for fold 4431:  0.3875\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4432:  0.49047619047619045\n",
      "f1  score for fold 4432:  0.3096774193548387\n",
      "recall for fold 4432:  0.32\n",
      "precision for fold 4432:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4433:  0.558252427184466\n",
      "f1  score for fold 4433:  0.43478260869565216\n",
      "recall for fold 4433:  0.4268292682926829\n",
      "precision for fold 4433:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4434:  0.5181347150259067\n",
      "f1  score for fold 4434:  0.422360248447205\n",
      "recall for fold 4434:  0.39080459770114945\n",
      "precision for fold 4434:  0.4594594594594595\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4435:  0.5023923444976076\n",
      "f1  score for fold 4435:  0.34177215189873417\n",
      "recall for fold 4435:  0.34615384615384615\n",
      "precision for fold 4435:  0.3375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4436:  0.5502392344497608\n",
      "f1  score for fold 4436:  0.3896103896103896\n",
      "recall for fold 4436:  0.40540540540540543\n",
      "precision for fold 4436:  0.375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4437:  0.5285714285714286\n",
      "f1  score for fold 4437:  0.3612903225806451\n",
      "recall for fold 4437:  0.37333333333333335\n",
      "precision for fold 4437:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4438:  0.5097087378640777\n",
      "f1  score for fold 4438:  0.37267080745341613\n",
      "recall for fold 4438:  0.36585365853658536\n",
      "precision for fold 4438:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4439:  0.5077720207253886\n",
      "f1  score for fold 4439:  0.40993788819875776\n",
      "recall for fold 4439:  0.3793103448275862\n",
      "precision for fold 4439:  0.44594594594594594\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4440:  0.48325358851674644\n",
      "f1  score for fold 4440:  0.31645569620253167\n",
      "recall for fold 4440:  0.32051282051282054\n",
      "precision for fold 4440:  0.3125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4441:  0.5215311004784688\n",
      "f1  score for fold 4441:  0.3506493506493507\n",
      "recall for fold 4441:  0.36486486486486486\n",
      "precision for fold 4441:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4442:  0.5095238095238095\n",
      "f1  score for fold 4442:  0.335483870967742\n",
      "recall for fold 4442:  0.3466666666666667\n",
      "precision for fold 4442:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4443:  0.5194174757281553\n",
      "f1  score for fold 4443:  0.38509316770186336\n",
      "recall for fold 4443:  0.3780487804878049\n",
      "precision for fold 4443:  0.3924050632911392\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4444:  0.5284974093264249\n",
      "f1  score for fold 4444:  0.4347826086956522\n",
      "recall for fold 4444:  0.40229885057471265\n",
      "precision for fold 4444:  0.47297297297297297\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4445:  0.5311004784688995\n",
      "f1  score for fold 4445:  0.37974683544303806\n",
      "recall for fold 4445:  0.38461538461538464\n",
      "precision for fold 4445:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4446:  0.5215311004784688\n",
      "f1  score for fold 4446:  0.3506493506493507\n",
      "recall for fold 4446:  0.36486486486486486\n",
      "precision for fold 4446:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4447:  0.5\n",
      "f1  score for fold 4447:  0.3225806451612903\n",
      "recall for fold 4447:  0.3333333333333333\n",
      "precision for fold 4447:  0.3125\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4448:  0.5388349514563107\n",
      "f1  score for fold 4448:  0.40993788819875776\n",
      "recall for fold 4448:  0.4024390243902439\n",
      "precision for fold 4448:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4449:  0.538860103626943\n",
      "f1  score for fold 4449:  0.4472049689440994\n",
      "recall for fold 4449:  0.41379310344827586\n",
      "precision for fold 4449:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4450:  0.569377990430622\n",
      "f1  score for fold 4450:  0.43037974683544306\n",
      "recall for fold 4450:  0.4358974358974359\n",
      "precision for fold 4450:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4451:  0.5023923444976076\n",
      "f1  score for fold 4451:  0.3246753246753247\n",
      "recall for fold 4451:  0.33783783783783783\n",
      "precision for fold 4451:  0.3125\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4452:  0.5952380952380952\n",
      "f1  score for fold 4452:  0.45161290322580644\n",
      "recall for fold 4452:  0.4666666666666667\n",
      "precision for fold 4452:  0.4375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4453:  0.5485436893203883\n",
      "f1  score for fold 4453:  0.42236024844720493\n",
      "recall for fold 4453:  0.4146341463414634\n",
      "precision for fold 4453:  0.43037974683544306\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4454:  0.47668393782383417\n",
      "f1  score for fold 4454:  0.3726708074534162\n",
      "recall for fold 4454:  0.3448275862068966\n",
      "precision for fold 4454:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4455:  0.5311004784688995\n",
      "f1  score for fold 4455:  0.37974683544303806\n",
      "recall for fold 4455:  0.38461538461538464\n",
      "precision for fold 4455:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4456:  0.5598086124401914\n",
      "f1  score for fold 4456:  0.40259740259740256\n",
      "recall for fold 4456:  0.4189189189189189\n",
      "precision for fold 4456:  0.3875\n",
      "    0   1\n",
      "0  18  57\n",
      "1  62  73\n",
      "Accuracy for fold 4457:  0.43333333333333335\n",
      "f1  score for fold 4457:  0.23225806451612904\n",
      "recall for fold 4457:  0.24\n",
      "precision for fold 4457:  0.225\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4458:  0.529126213592233\n",
      "f1  score for fold 4458:  0.39751552795031053\n",
      "recall for fold 4458:  0.3902439024390244\n",
      "precision for fold 4458:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4459:  0.49740932642487046\n",
      "f1  score for fold 4459:  0.39751552795031053\n",
      "recall for fold 4459:  0.367816091954023\n",
      "precision for fold 4459:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4460:  0.49282296650717705\n",
      "f1  score for fold 4460:  0.32911392405063294\n",
      "recall for fold 4460:  0.3333333333333333\n",
      "precision for fold 4460:  0.325\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4461:  0.5502392344497608\n",
      "f1  score for fold 4461:  0.3896103896103896\n",
      "recall for fold 4461:  0.40540540540540543\n",
      "precision for fold 4461:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4462:  0.5380952380952381\n",
      "f1  score for fold 4462:  0.3741935483870968\n",
      "recall for fold 4462:  0.38666666666666666\n",
      "precision for fold 4462:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4463:  0.5388349514563107\n",
      "f1  score for fold 4463:  0.40993788819875776\n",
      "recall for fold 4463:  0.4024390243902439\n",
      "precision for fold 4463:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4464:  0.538860103626943\n",
      "f1  score for fold 4464:  0.4472049689440994\n",
      "recall for fold 4464:  0.41379310344827586\n",
      "precision for fold 4464:  0.4864864864864865\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4465:  0.5119617224880383\n",
      "f1  score for fold 4465:  0.3544303797468355\n",
      "recall for fold 4465:  0.358974358974359\n",
      "precision for fold 4465:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4466:  0.5119617224880383\n",
      "f1  score for fold 4466:  0.33766233766233766\n",
      "recall for fold 4466:  0.35135135135135137\n",
      "precision for fold 4466:  0.325\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4467:  0.49047619047619045\n",
      "f1  score for fold 4467:  0.3096774193548387\n",
      "recall for fold 4467:  0.32\n",
      "precision for fold 4467:  0.3\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4468:  0.5097087378640777\n",
      "f1  score for fold 4468:  0.37267080745341613\n",
      "recall for fold 4468:  0.36585365853658536\n",
      "precision for fold 4468:  0.379746835443038\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4469:  0.45595854922279794\n",
      "f1  score for fold 4469:  0.3478260869565218\n",
      "recall for fold 4469:  0.3218390804597701\n",
      "precision for fold 4469:  0.3783783783783784\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4470:  0.49282296650717705\n",
      "f1  score for fold 4470:  0.32911392405063294\n",
      "recall for fold 4470:  0.3333333333333333\n",
      "precision for fold 4470:  0.325\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4471:  0.5789473684210527\n",
      "f1  score for fold 4471:  0.42857142857142855\n",
      "recall for fold 4471:  0.44594594594594594\n",
      "precision for fold 4471:  0.4125\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4472:  0.6047619047619047\n",
      "f1  score for fold 4472:  0.4645161290322581\n",
      "recall for fold 4472:  0.48\n",
      "precision for fold 4472:  0.45\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4473:  0.5194174757281553\n",
      "f1  score for fold 4473:  0.38509316770186336\n",
      "recall for fold 4473:  0.3780487804878049\n",
      "precision for fold 4473:  0.3924050632911392\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 4474:  0.42487046632124353\n",
      "f1  score for fold 4474:  0.3105590062111801\n",
      "recall for fold 4474:  0.28735632183908044\n",
      "precision for fold 4474:  0.33783783783783783\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4475:  0.5215311004784688\n",
      "f1  score for fold 4475:  0.36708860759493667\n",
      "recall for fold 4475:  0.3717948717948718\n",
      "precision for fold 4475:  0.3625\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4476:  0.5215311004784688\n",
      "f1  score for fold 4476:  0.3506493506493507\n",
      "recall for fold 4476:  0.36486486486486486\n",
      "precision for fold 4476:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4477:  0.49047619047619045\n",
      "f1  score for fold 4477:  0.3096774193548387\n",
      "recall for fold 4477:  0.32\n",
      "precision for fold 4477:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4478:  0.558252427184466\n",
      "f1  score for fold 4478:  0.43478260869565216\n",
      "recall for fold 4478:  0.4268292682926829\n",
      "precision for fold 4478:  0.4430379746835443\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4479:  0.49740932642487046\n",
      "f1  score for fold 4479:  0.39751552795031053\n",
      "recall for fold 4479:  0.367816091954023\n",
      "precision for fold 4479:  0.43243243243243246\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4480:  0.5119617224880383\n",
      "f1  score for fold 4480:  0.3544303797468355\n",
      "recall for fold 4480:  0.358974358974359\n",
      "precision for fold 4480:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4481:  0.5598086124401914\n",
      "f1  score for fold 4481:  0.40259740259740256\n",
      "recall for fold 4481:  0.4189189189189189\n",
      "precision for fold 4481:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4482:  0.5285714285714286\n",
      "f1  score for fold 4482:  0.3612903225806451\n",
      "recall for fold 4482:  0.37333333333333335\n",
      "precision for fold 4482:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4483:  0.5679611650485437\n",
      "f1  score for fold 4483:  0.4472049689440994\n",
      "recall for fold 4483:  0.43902439024390244\n",
      "precision for fold 4483:  0.45569620253164556\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4484:  0.47668393782383417\n",
      "f1  score for fold 4484:  0.3726708074534162\n",
      "recall for fold 4484:  0.3448275862068966\n",
      "precision for fold 4484:  0.40540540540540543\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4485:  0.5598086124401914\n",
      "f1  score for fold 4485:  0.4177215189873418\n",
      "recall for fold 4485:  0.4230769230769231\n",
      "precision for fold 4485:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4486:  0.5311004784688995\n",
      "f1  score for fold 4486:  0.36363636363636365\n",
      "recall for fold 4486:  0.3783783783783784\n",
      "precision for fold 4486:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4487:  0.5095238095238095\n",
      "f1  score for fold 4487:  0.335483870967742\n",
      "recall for fold 4487:  0.3466666666666667\n",
      "precision for fold 4487:  0.325\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4488:  0.5388349514563107\n",
      "f1  score for fold 4488:  0.40993788819875776\n",
      "recall for fold 4488:  0.4024390243902439\n",
      "precision for fold 4488:  0.4177215189873418\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4489:  0.47668393782383417\n",
      "f1  score for fold 4489:  0.3726708074534162\n",
      "recall for fold 4489:  0.3448275862068966\n",
      "precision for fold 4489:  0.40540540540540543\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4490:  0.5311004784688995\n",
      "f1  score for fold 4490:  0.37974683544303806\n",
      "recall for fold 4490:  0.38461538461538464\n",
      "precision for fold 4490:  0.375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4491:  0.569377990430622\n",
      "f1  score for fold 4491:  0.4155844155844156\n",
      "recall for fold 4491:  0.43243243243243246\n",
      "precision for fold 4491:  0.4\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4492:  0.5190476190476191\n",
      "f1  score for fold 4492:  0.34838709677419355\n",
      "recall for fold 4492:  0.36\n",
      "precision for fold 4492:  0.3375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4493:  0.5194174757281553\n",
      "f1  score for fold 4493:  0.38509316770186336\n",
      "recall for fold 4493:  0.3780487804878049\n",
      "precision for fold 4493:  0.3924050632911392\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4494:  0.48704663212435234\n",
      "f1  score for fold 4494:  0.3850931677018633\n",
      "recall for fold 4494:  0.3563218390804598\n",
      "precision for fold 4494:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4495:  0.5502392344497608\n",
      "f1  score for fold 4495:  0.4050632911392405\n",
      "recall for fold 4495:  0.41025641025641024\n",
      "precision for fold 4495:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4496:  0.5311004784688995\n",
      "f1  score for fold 4496:  0.36363636363636365\n",
      "recall for fold 4496:  0.3783783783783784\n",
      "precision for fold 4496:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4497:  0.5476190476190477\n",
      "f1  score for fold 4497:  0.38709677419354843\n",
      "recall for fold 4497:  0.4\n",
      "precision for fold 4497:  0.375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4498:  0.5679611650485437\n",
      "f1  score for fold 4498:  0.4472049689440994\n",
      "recall for fold 4498:  0.43902439024390244\n",
      "precision for fold 4498:  0.45569620253164556\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 4499:  0.5803108808290155\n",
      "f1  score for fold 4499:  0.49689440993788814\n",
      "recall for fold 4499:  0.45977011494252873\n",
      "precision for fold 4499:  0.5405405405405406\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4500:  0.49282296650717705\n",
      "f1  score for fold 4500:  0.32911392405063294\n",
      "recall for fold 4500:  0.3333333333333333\n",
      "precision for fold 4500:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4501:  0.5406698564593302\n",
      "f1  score for fold 4501:  0.37662337662337664\n",
      "recall for fold 4501:  0.3918918918918919\n",
      "precision for fold 4501:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4502:  0.5476190476190477\n",
      "f1  score for fold 4502:  0.38709677419354843\n",
      "recall for fold 4502:  0.4\n",
      "precision for fold 4502:  0.375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4503:  0.5097087378640777\n",
      "f1  score for fold 4503:  0.37267080745341613\n",
      "recall for fold 4503:  0.36585365853658536\n",
      "precision for fold 4503:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4504:  0.5077720207253886\n",
      "f1  score for fold 4504:  0.40993788819875776\n",
      "recall for fold 4504:  0.3793103448275862\n",
      "precision for fold 4504:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4505:  0.5119617224880383\n",
      "f1  score for fold 4505:  0.3544303797468355\n",
      "recall for fold 4505:  0.358974358974359\n",
      "precision for fold 4505:  0.35\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4506:  0.49282296650717705\n",
      "f1  score for fold 4506:  0.3116883116883117\n",
      "recall for fold 4506:  0.32432432432432434\n",
      "precision for fold 4506:  0.3\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4507:  0.5571428571428572\n",
      "f1  score for fold 4507:  0.4000000000000001\n",
      "recall for fold 4507:  0.41333333333333333\n",
      "precision for fold 4507:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4508:  0.5097087378640777\n",
      "f1  score for fold 4508:  0.37267080745341613\n",
      "recall for fold 4508:  0.36585365853658536\n",
      "precision for fold 4508:  0.379746835443038\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4509:  0.46632124352331605\n",
      "f1  score for fold 4509:  0.36024844720496896\n",
      "recall for fold 4509:  0.3333333333333333\n",
      "precision for fold 4509:  0.3918918918918919\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4510:  0.5023923444976076\n",
      "f1  score for fold 4510:  0.34177215189873417\n",
      "recall for fold 4510:  0.34615384615384615\n",
      "precision for fold 4510:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4511:  0.5119617224880383\n",
      "f1  score for fold 4511:  0.33766233766233766\n",
      "recall for fold 4511:  0.35135135135135137\n",
      "precision for fold 4511:  0.325\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4512:  0.5952380952380952\n",
      "f1  score for fold 4512:  0.45161290322580644\n",
      "recall for fold 4512:  0.4666666666666667\n",
      "precision for fold 4512:  0.4375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4513:  0.5679611650485437\n",
      "f1  score for fold 4513:  0.4472049689440994\n",
      "recall for fold 4513:  0.43902439024390244\n",
      "precision for fold 4513:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4514:  0.49740932642487046\n",
      "f1  score for fold 4514:  0.39751552795031053\n",
      "recall for fold 4514:  0.367816091954023\n",
      "precision for fold 4514:  0.43243243243243246\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4515:  0.49282296650717705\n",
      "f1  score for fold 4515:  0.32911392405063294\n",
      "recall for fold 4515:  0.3333333333333333\n",
      "precision for fold 4515:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4516:  0.5406698564593302\n",
      "f1  score for fold 4516:  0.37662337662337664\n",
      "recall for fold 4516:  0.3918918918918919\n",
      "precision for fold 4516:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4517:  0.5095238095238095\n",
      "f1  score for fold 4517:  0.335483870967742\n",
      "recall for fold 4517:  0.3466666666666667\n",
      "precision for fold 4517:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4518:  0.5097087378640777\n",
      "f1  score for fold 4518:  0.37267080745341613\n",
      "recall for fold 4518:  0.36585365853658536\n",
      "precision for fold 4518:  0.379746835443038\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4519:  0.47668393782383417\n",
      "f1  score for fold 4519:  0.3726708074534162\n",
      "recall for fold 4519:  0.3448275862068966\n",
      "precision for fold 4519:  0.40540540540540543\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4520:  0.49282296650717705\n",
      "f1  score for fold 4520:  0.32911392405063294\n",
      "recall for fold 4520:  0.3333333333333333\n",
      "precision for fold 4520:  0.325\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4521:  0.5789473684210527\n",
      "f1  score for fold 4521:  0.42857142857142855\n",
      "recall for fold 4521:  0.44594594594594594\n",
      "precision for fold 4521:  0.4125\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4522:  0.5666666666666667\n",
      "f1  score for fold 4522:  0.41290322580645167\n",
      "recall for fold 4522:  0.4266666666666667\n",
      "precision for fold 4522:  0.4\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4523:  0.5485436893203883\n",
      "f1  score for fold 4523:  0.42236024844720493\n",
      "recall for fold 4523:  0.4146341463414634\n",
      "precision for fold 4523:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4524:  0.49740932642487046\n",
      "f1  score for fold 4524:  0.39751552795031053\n",
      "recall for fold 4524:  0.367816091954023\n",
      "precision for fold 4524:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4525:  0.5406698564593302\n",
      "f1  score for fold 4525:  0.3924050632911393\n",
      "recall for fold 4525:  0.3974358974358974\n",
      "precision for fold 4525:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4526:  0.48325358851674644\n",
      "f1  score for fold 4526:  0.29870129870129863\n",
      "recall for fold 4526:  0.3108108108108108\n",
      "precision for fold 4526:  0.2875\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4527:  0.5\n",
      "f1  score for fold 4527:  0.3225806451612903\n",
      "recall for fold 4527:  0.3333333333333333\n",
      "precision for fold 4527:  0.3125\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4528:  0.48058252427184467\n",
      "f1  score for fold 4528:  0.33540372670807456\n",
      "recall for fold 4528:  0.32926829268292684\n",
      "precision for fold 4528:  0.34177215189873417\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4529:  0.5077720207253886\n",
      "f1  score for fold 4529:  0.40993788819875776\n",
      "recall for fold 4529:  0.3793103448275862\n",
      "precision for fold 4529:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 4530:  0.47368421052631576\n",
      "f1  score for fold 4530:  0.3037974683544304\n",
      "recall for fold 4530:  0.3076923076923077\n",
      "precision for fold 4530:  0.3\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4531:  0.5215311004784688\n",
      "f1  score for fold 4531:  0.3506493506493507\n",
      "recall for fold 4531:  0.36486486486486486\n",
      "precision for fold 4531:  0.3375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4532:  0.5095238095238095\n",
      "f1  score for fold 4532:  0.335483870967742\n",
      "recall for fold 4532:  0.3466666666666667\n",
      "precision for fold 4532:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4533:  0.5194174757281553\n",
      "f1  score for fold 4533:  0.38509316770186336\n",
      "recall for fold 4533:  0.3780487804878049\n",
      "precision for fold 4533:  0.3924050632911392\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4534:  0.46632124352331605\n",
      "f1  score for fold 4534:  0.36024844720496896\n",
      "recall for fold 4534:  0.3333333333333333\n",
      "precision for fold 4534:  0.3918918918918919\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4535:  0.5311004784688995\n",
      "f1  score for fold 4535:  0.37974683544303806\n",
      "recall for fold 4535:  0.38461538461538464\n",
      "precision for fold 4535:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4536:  0.5215311004784688\n",
      "f1  score for fold 4536:  0.3506493506493507\n",
      "recall for fold 4536:  0.36486486486486486\n",
      "precision for fold 4536:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4537:  0.5380952380952381\n",
      "f1  score for fold 4537:  0.3741935483870968\n",
      "recall for fold 4537:  0.38666666666666666\n",
      "precision for fold 4537:  0.3625\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4538:  0.5388349514563107\n",
      "f1  score for fold 4538:  0.40993788819875776\n",
      "recall for fold 4538:  0.4024390243902439\n",
      "precision for fold 4538:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4539:  0.48704663212435234\n",
      "f1  score for fold 4539:  0.3850931677018633\n",
      "recall for fold 4539:  0.3563218390804598\n",
      "precision for fold 4539:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4540:  0.5215311004784688\n",
      "f1  score for fold 4540:  0.36708860759493667\n",
      "recall for fold 4540:  0.3717948717948718\n",
      "precision for fold 4540:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4541:  0.5406698564593302\n",
      "f1  score for fold 4541:  0.37662337662337664\n",
      "recall for fold 4541:  0.3918918918918919\n",
      "precision for fold 4541:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4542:  0.5476190476190477\n",
      "f1  score for fold 4542:  0.38709677419354843\n",
      "recall for fold 4542:  0.4\n",
      "precision for fold 4542:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4543:  0.5388349514563107\n",
      "f1  score for fold 4543:  0.40993788819875776\n",
      "recall for fold 4543:  0.4024390243902439\n",
      "precision for fold 4543:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4544:  0.48704663212435234\n",
      "f1  score for fold 4544:  0.3850931677018633\n",
      "recall for fold 4544:  0.3563218390804598\n",
      "precision for fold 4544:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4545:  0.569377990430622\n",
      "f1  score for fold 4545:  0.43037974683544306\n",
      "recall for fold 4545:  0.4358974358974359\n",
      "precision for fold 4545:  0.425\n",
      "    0   1\n",
      "0  34  40\n",
      "1  46  89\n",
      "Accuracy for fold 4546:  0.5885167464114832\n",
      "f1  score for fold 4546:  0.44155844155844154\n",
      "recall for fold 4546:  0.4594594594594595\n",
      "precision for fold 4546:  0.425\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4547:  0.5476190476190477\n",
      "f1  score for fold 4547:  0.38709677419354843\n",
      "recall for fold 4547:  0.4\n",
      "precision for fold 4547:  0.375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4548:  0.5485436893203883\n",
      "f1  score for fold 4548:  0.42236024844720493\n",
      "recall for fold 4548:  0.4146341463414634\n",
      "precision for fold 4548:  0.43037974683544306\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4549:  0.46632124352331605\n",
      "f1  score for fold 4549:  0.36024844720496896\n",
      "recall for fold 4549:  0.3333333333333333\n",
      "precision for fold 4549:  0.3918918918918919\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4550:  0.5598086124401914\n",
      "f1  score for fold 4550:  0.4177215189873418\n",
      "recall for fold 4550:  0.4230769230769231\n",
      "precision for fold 4550:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4551:  0.5311004784688995\n",
      "f1  score for fold 4551:  0.36363636363636365\n",
      "recall for fold 4551:  0.3783783783783784\n",
      "precision for fold 4551:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4552:  0.5285714285714286\n",
      "f1  score for fold 4552:  0.3612903225806451\n",
      "recall for fold 4552:  0.37333333333333335\n",
      "precision for fold 4552:  0.35\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4553:  0.529126213592233\n",
      "f1  score for fold 4553:  0.39751552795031053\n",
      "recall for fold 4553:  0.3902439024390244\n",
      "precision for fold 4553:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4554:  0.538860103626943\n",
      "f1  score for fold 4554:  0.4472049689440994\n",
      "recall for fold 4554:  0.41379310344827586\n",
      "precision for fold 4554:  0.4864864864864865\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4555:  0.5789473684210527\n",
      "f1  score for fold 4555:  0.44303797468354433\n",
      "recall for fold 4555:  0.44871794871794873\n",
      "precision for fold 4555:  0.4375\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4556:  0.5502392344497608\n",
      "f1  score for fold 4556:  0.3896103896103896\n",
      "recall for fold 4556:  0.40540540540540543\n",
      "precision for fold 4556:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4557:  0.5476190476190477\n",
      "f1  score for fold 4557:  0.38709677419354843\n",
      "recall for fold 4557:  0.4\n",
      "precision for fold 4557:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4558:  0.5388349514563107\n",
      "f1  score for fold 4558:  0.40993788819875776\n",
      "recall for fold 4558:  0.4024390243902439\n",
      "precision for fold 4558:  0.4177215189873418\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4559:  0.538860103626943\n",
      "f1  score for fold 4559:  0.4472049689440994\n",
      "recall for fold 4559:  0.41379310344827586\n",
      "precision for fold 4559:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4560:  0.5311004784688995\n",
      "f1  score for fold 4560:  0.37974683544303806\n",
      "recall for fold 4560:  0.38461538461538464\n",
      "precision for fold 4560:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4561:  0.5598086124401914\n",
      "f1  score for fold 4561:  0.40259740259740256\n",
      "recall for fold 4561:  0.4189189189189189\n",
      "precision for fold 4561:  0.3875\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4562:  0.5476190476190477\n",
      "f1  score for fold 4562:  0.38709677419354843\n",
      "recall for fold 4562:  0.4\n",
      "precision for fold 4562:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4563:  0.5194174757281553\n",
      "f1  score for fold 4563:  0.38509316770186336\n",
      "recall for fold 4563:  0.3780487804878049\n",
      "precision for fold 4563:  0.3924050632911392\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4564:  0.5699481865284974\n",
      "f1  score for fold 4564:  0.48447204968944096\n",
      "recall for fold 4564:  0.4482758620689655\n",
      "precision for fold 4564:  0.527027027027027\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4565:  0.5598086124401914\n",
      "f1  score for fold 4565:  0.4177215189873418\n",
      "recall for fold 4565:  0.4230769230769231\n",
      "precision for fold 4565:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4566:  0.5311004784688995\n",
      "f1  score for fold 4566:  0.36363636363636365\n",
      "recall for fold 4566:  0.3783783783783784\n",
      "precision for fold 4566:  0.35\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4567:  0.5571428571428572\n",
      "f1  score for fold 4567:  0.4000000000000001\n",
      "recall for fold 4567:  0.41333333333333333\n",
      "precision for fold 4567:  0.3875\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4568:  0.5\n",
      "f1  score for fold 4568:  0.3602484472049689\n",
      "recall for fold 4568:  0.35365853658536583\n",
      "precision for fold 4568:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4569:  0.48704663212435234\n",
      "f1  score for fold 4569:  0.3850931677018633\n",
      "recall for fold 4569:  0.3563218390804598\n",
      "precision for fold 4569:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4570:  0.5406698564593302\n",
      "f1  score for fold 4570:  0.3924050632911393\n",
      "recall for fold 4570:  0.3974358974358974\n",
      "precision for fold 4570:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4571:  0.48325358851674644\n",
      "f1  score for fold 4571:  0.29870129870129863\n",
      "recall for fold 4571:  0.3108108108108108\n",
      "precision for fold 4571:  0.2875\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4572:  0.5571428571428572\n",
      "f1  score for fold 4572:  0.4000000000000001\n",
      "recall for fold 4572:  0.41333333333333333\n",
      "precision for fold 4572:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4573:  0.5485436893203883\n",
      "f1  score for fold 4573:  0.42236024844720493\n",
      "recall for fold 4573:  0.4146341463414634\n",
      "precision for fold 4573:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4574:  0.538860103626943\n",
      "f1  score for fold 4574:  0.4472049689440994\n",
      "recall for fold 4574:  0.41379310344827586\n",
      "precision for fold 4574:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4575:  0.5502392344497608\n",
      "f1  score for fold 4575:  0.4050632911392405\n",
      "recall for fold 4575:  0.41025641025641024\n",
      "precision for fold 4575:  0.4\n",
      "    0   1\n",
      "0  38  36\n",
      "1  42  93\n",
      "Accuracy for fold 4576:  0.6267942583732058\n",
      "f1  score for fold 4576:  0.4935064935064935\n",
      "recall for fold 4576:  0.5135135135135135\n",
      "precision for fold 4576:  0.475\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4577:  0.5666666666666667\n",
      "f1  score for fold 4577:  0.41290322580645167\n",
      "recall for fold 4577:  0.4266666666666667\n",
      "precision for fold 4577:  0.4\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4578:  0.5776699029126213\n",
      "f1  score for fold 4578:  0.4596273291925466\n",
      "recall for fold 4578:  0.45121951219512196\n",
      "precision for fold 4578:  0.46835443037974683\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4579:  0.5284974093264249\n",
      "f1  score for fold 4579:  0.4347826086956522\n",
      "recall for fold 4579:  0.40229885057471265\n",
      "precision for fold 4579:  0.47297297297297297\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4580:  0.5502392344497608\n",
      "f1  score for fold 4580:  0.4050632911392405\n",
      "recall for fold 4580:  0.41025641025641024\n",
      "precision for fold 4580:  0.4\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 4581:  0.5980861244019139\n",
      "f1  score for fold 4581:  0.45454545454545453\n",
      "recall for fold 4581:  0.47297297297297297\n",
      "precision for fold 4581:  0.4375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4582:  0.5476190476190477\n",
      "f1  score for fold 4582:  0.38709677419354843\n",
      "recall for fold 4582:  0.4\n",
      "precision for fold 4582:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4583:  0.558252427184466\n",
      "f1  score for fold 4583:  0.43478260869565216\n",
      "recall for fold 4583:  0.4268292682926829\n",
      "precision for fold 4583:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4584:  0.5284974093264249\n",
      "f1  score for fold 4584:  0.4347826086956522\n",
      "recall for fold 4584:  0.40229885057471265\n",
      "precision for fold 4584:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4585:  0.5023923444976076\n",
      "f1  score for fold 4585:  0.34177215189873417\n",
      "recall for fold 4585:  0.34615384615384615\n",
      "precision for fold 4585:  0.3375\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 4586:  0.46411483253588515\n",
      "f1  score for fold 4586:  0.27272727272727276\n",
      "recall for fold 4586:  0.28378378378378377\n",
      "precision for fold 4586:  0.2625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4587:  0.5571428571428572\n",
      "f1  score for fold 4587:  0.4000000000000001\n",
      "recall for fold 4587:  0.41333333333333333\n",
      "precision for fold 4587:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4588:  0.5097087378640777\n",
      "f1  score for fold 4588:  0.37267080745341613\n",
      "recall for fold 4588:  0.36585365853658536\n",
      "precision for fold 4588:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4589:  0.5077720207253886\n",
      "f1  score for fold 4589:  0.40993788819875776\n",
      "recall for fold 4589:  0.3793103448275862\n",
      "precision for fold 4589:  0.44594594594594594\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4590:  0.5311004784688995\n",
      "f1  score for fold 4590:  0.37974683544303806\n",
      "recall for fold 4590:  0.38461538461538464\n",
      "precision for fold 4590:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4591:  0.5119617224880383\n",
      "f1  score for fold 4591:  0.33766233766233766\n",
      "recall for fold 4591:  0.35135135135135137\n",
      "precision for fold 4591:  0.325\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4592:  0.5285714285714286\n",
      "f1  score for fold 4592:  0.3612903225806451\n",
      "recall for fold 4592:  0.37333333333333335\n",
      "precision for fold 4592:  0.35\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4593:  0.470873786407767\n",
      "f1  score for fold 4593:  0.3229813664596273\n",
      "recall for fold 4593:  0.3170731707317073\n",
      "precision for fold 4593:  0.3291139240506329\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4594:  0.45595854922279794\n",
      "f1  score for fold 4594:  0.3478260869565218\n",
      "recall for fold 4594:  0.3218390804597701\n",
      "precision for fold 4594:  0.3783783783783784\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4595:  0.5119617224880383\n",
      "f1  score for fold 4595:  0.3544303797468355\n",
      "recall for fold 4595:  0.358974358974359\n",
      "precision for fold 4595:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4596:  0.5598086124401914\n",
      "f1  score for fold 4596:  0.40259740259740256\n",
      "recall for fold 4596:  0.4189189189189189\n",
      "precision for fold 4596:  0.3875\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4597:  0.5190476190476191\n",
      "f1  score for fold 4597:  0.34838709677419355\n",
      "recall for fold 4597:  0.36\n",
      "precision for fold 4597:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4598:  0.5679611650485437\n",
      "f1  score for fold 4598:  0.4472049689440994\n",
      "recall for fold 4598:  0.43902439024390244\n",
      "precision for fold 4598:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4599:  0.5284974093264249\n",
      "f1  score for fold 4599:  0.4347826086956522\n",
      "recall for fold 4599:  0.40229885057471265\n",
      "precision for fold 4599:  0.47297297297297297\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4600:  0.5598086124401914\n",
      "f1  score for fold 4600:  0.4177215189873418\n",
      "recall for fold 4600:  0.4230769230769231\n",
      "precision for fold 4600:  0.4125\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4601:  0.5215311004784688\n",
      "f1  score for fold 4601:  0.3506493506493507\n",
      "recall for fold 4601:  0.36486486486486486\n",
      "precision for fold 4601:  0.3375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4602:  0.5380952380952381\n",
      "f1  score for fold 4602:  0.3741935483870968\n",
      "recall for fold 4602:  0.38666666666666666\n",
      "precision for fold 4602:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4603:  0.5097087378640777\n",
      "f1  score for fold 4603:  0.37267080745341613\n",
      "recall for fold 4603:  0.36585365853658536\n",
      "precision for fold 4603:  0.379746835443038\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4604:  0.49740932642487046\n",
      "f1  score for fold 4604:  0.39751552795031053\n",
      "recall for fold 4604:  0.367816091954023\n",
      "precision for fold 4604:  0.43243243243243246\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4605:  0.5215311004784688\n",
      "f1  score for fold 4605:  0.36708860759493667\n",
      "recall for fold 4605:  0.3717948717948718\n",
      "precision for fold 4605:  0.3625\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4606:  0.5311004784688995\n",
      "f1  score for fold 4606:  0.36363636363636365\n",
      "recall for fold 4606:  0.3783783783783784\n",
      "precision for fold 4606:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4607:  0.5285714285714286\n",
      "f1  score for fold 4607:  0.3612903225806451\n",
      "recall for fold 4607:  0.37333333333333335\n",
      "precision for fold 4607:  0.35\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4608:  0.5485436893203883\n",
      "f1  score for fold 4608:  0.42236024844720493\n",
      "recall for fold 4608:  0.4146341463414634\n",
      "precision for fold 4608:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4609:  0.49740932642487046\n",
      "f1  score for fold 4609:  0.39751552795031053\n",
      "recall for fold 4609:  0.367816091954023\n",
      "precision for fold 4609:  0.43243243243243246\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 4610:  0.5885167464114832\n",
      "f1  score for fold 4610:  0.45569620253164556\n",
      "recall for fold 4610:  0.46153846153846156\n",
      "precision for fold 4610:  0.45\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4611:  0.5311004784688995\n",
      "f1  score for fold 4611:  0.36363636363636365\n",
      "recall for fold 4611:  0.3783783783783784\n",
      "precision for fold 4611:  0.35\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4612:  0.5952380952380952\n",
      "f1  score for fold 4612:  0.45161290322580644\n",
      "recall for fold 4612:  0.4666666666666667\n",
      "precision for fold 4612:  0.4375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4613:  0.48058252427184467\n",
      "f1  score for fold 4613:  0.33540372670807456\n",
      "recall for fold 4613:  0.32926829268292684\n",
      "precision for fold 4613:  0.34177215189873417\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4614:  0.48704663212435234\n",
      "f1  score for fold 4614:  0.3850931677018633\n",
      "recall for fold 4614:  0.3563218390804598\n",
      "precision for fold 4614:  0.4189189189189189\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4615:  0.5502392344497608\n",
      "f1  score for fold 4615:  0.4050632911392405\n",
      "recall for fold 4615:  0.41025641025641024\n",
      "precision for fold 4615:  0.4\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4616:  0.5023923444976076\n",
      "f1  score for fold 4616:  0.3246753246753247\n",
      "recall for fold 4616:  0.33783783783783783\n",
      "precision for fold 4616:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4617:  0.5571428571428572\n",
      "f1  score for fold 4617:  0.4000000000000001\n",
      "recall for fold 4617:  0.41333333333333333\n",
      "precision for fold 4617:  0.3875\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4618:  0.5097087378640777\n",
      "f1  score for fold 4618:  0.37267080745341613\n",
      "recall for fold 4618:  0.36585365853658536\n",
      "precision for fold 4618:  0.379746835443038\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4619:  0.44559585492227977\n",
      "f1  score for fold 4619:  0.33540372670807456\n",
      "recall for fold 4619:  0.3103448275862069\n",
      "precision for fold 4619:  0.36486486486486486\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4620:  0.49282296650717705\n",
      "f1  score for fold 4620:  0.32911392405063294\n",
      "recall for fold 4620:  0.3333333333333333\n",
      "precision for fold 4620:  0.325\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4621:  0.5311004784688995\n",
      "f1  score for fold 4621:  0.36363636363636365\n",
      "recall for fold 4621:  0.3783783783783784\n",
      "precision for fold 4621:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4622:  0.5285714285714286\n",
      "f1  score for fold 4622:  0.3612903225806451\n",
      "recall for fold 4622:  0.37333333333333335\n",
      "precision for fold 4622:  0.35\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4623:  0.5097087378640777\n",
      "f1  score for fold 4623:  0.37267080745341613\n",
      "recall for fold 4623:  0.36585365853658536\n",
      "precision for fold 4623:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4624:  0.5077720207253886\n",
      "f1  score for fold 4624:  0.40993788819875776\n",
      "recall for fold 4624:  0.3793103448275862\n",
      "precision for fold 4624:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4625:  0.5119617224880383\n",
      "f1  score for fold 4625:  0.3544303797468355\n",
      "recall for fold 4625:  0.358974358974359\n",
      "precision for fold 4625:  0.35\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4626:  0.569377990430622\n",
      "f1  score for fold 4626:  0.4155844155844156\n",
      "recall for fold 4626:  0.43243243243243246\n",
      "precision for fold 4626:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4627:  0.5095238095238095\n",
      "f1  score for fold 4627:  0.335483870967742\n",
      "recall for fold 4627:  0.3466666666666667\n",
      "precision for fold 4627:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4628:  0.5194174757281553\n",
      "f1  score for fold 4628:  0.38509316770186336\n",
      "recall for fold 4628:  0.3780487804878049\n",
      "precision for fold 4628:  0.3924050632911392\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 4629:  0.5595854922279793\n",
      "f1  score for fold 4629:  0.4720496894409938\n",
      "recall for fold 4629:  0.4367816091954023\n",
      "precision for fold 4629:  0.5135135135135135\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4630:  0.5311004784688995\n",
      "f1  score for fold 4630:  0.37974683544303806\n",
      "recall for fold 4630:  0.38461538461538464\n",
      "precision for fold 4630:  0.375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4631:  0.5119617224880383\n",
      "f1  score for fold 4631:  0.33766233766233766\n",
      "recall for fold 4631:  0.35135135135135137\n",
      "precision for fold 4631:  0.325\n",
      "    0   1\n",
      "0  22  53\n",
      "1  58  77\n",
      "Accuracy for fold 4632:  0.4714285714285714\n",
      "f1  score for fold 4632:  0.2838709677419355\n",
      "recall for fold 4632:  0.29333333333333333\n",
      "precision for fold 4632:  0.275\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4633:  0.558252427184466\n",
      "f1  score for fold 4633:  0.43478260869565216\n",
      "recall for fold 4633:  0.4268292682926829\n",
      "precision for fold 4633:  0.4430379746835443\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4634:  0.48704663212435234\n",
      "f1  score for fold 4634:  0.3850931677018633\n",
      "recall for fold 4634:  0.3563218390804598\n",
      "precision for fold 4634:  0.4189189189189189\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4635:  0.5406698564593302\n",
      "f1  score for fold 4635:  0.3924050632911393\n",
      "recall for fold 4635:  0.3974358974358974\n",
      "precision for fold 4635:  0.3875\n",
      "    0   1\n",
      "0  38  36\n",
      "1  42  93\n",
      "Accuracy for fold 4636:  0.6267942583732058\n",
      "f1  score for fold 4636:  0.4935064935064935\n",
      "recall for fold 4636:  0.5135135135135135\n",
      "precision for fold 4636:  0.475\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4637:  0.49047619047619045\n",
      "f1  score for fold 4637:  0.3096774193548387\n",
      "recall for fold 4637:  0.32\n",
      "precision for fold 4637:  0.3\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4638:  0.5\n",
      "f1  score for fold 4638:  0.3602484472049689\n",
      "recall for fold 4638:  0.35365853658536583\n",
      "precision for fold 4638:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4639:  0.5284974093264249\n",
      "f1  score for fold 4639:  0.4347826086956522\n",
      "recall for fold 4639:  0.40229885057471265\n",
      "precision for fold 4639:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4640:  0.5023923444976076\n",
      "f1  score for fold 4640:  0.34177215189873417\n",
      "recall for fold 4640:  0.34615384615384615\n",
      "precision for fold 4640:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4641:  0.5406698564593302\n",
      "f1  score for fold 4641:  0.37662337662337664\n",
      "recall for fold 4641:  0.3918918918918919\n",
      "precision for fold 4641:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4642:  0.5095238095238095\n",
      "f1  score for fold 4642:  0.335483870967742\n",
      "recall for fold 4642:  0.3466666666666667\n",
      "precision for fold 4642:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4643:  0.5194174757281553\n",
      "f1  score for fold 4643:  0.38509316770186336\n",
      "recall for fold 4643:  0.3780487804878049\n",
      "precision for fold 4643:  0.3924050632911392\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4644:  0.44559585492227977\n",
      "f1  score for fold 4644:  0.33540372670807456\n",
      "recall for fold 4644:  0.3103448275862069\n",
      "precision for fold 4644:  0.36486486486486486\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4645:  0.5119617224880383\n",
      "f1  score for fold 4645:  0.3544303797468355\n",
      "recall for fold 4645:  0.358974358974359\n",
      "precision for fold 4645:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4646:  0.5119617224880383\n",
      "f1  score for fold 4646:  0.33766233766233766\n",
      "recall for fold 4646:  0.35135135135135137\n",
      "precision for fold 4646:  0.325\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4647:  0.5571428571428572\n",
      "f1  score for fold 4647:  0.4000000000000001\n",
      "recall for fold 4647:  0.41333333333333333\n",
      "precision for fold 4647:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4648:  0.529126213592233\n",
      "f1  score for fold 4648:  0.39751552795031053\n",
      "recall for fold 4648:  0.3902439024390244\n",
      "precision for fold 4648:  0.4050632911392405\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4649:  0.5492227979274611\n",
      "f1  score for fold 4649:  0.45962732919254656\n",
      "recall for fold 4649:  0.42528735632183906\n",
      "precision for fold 4649:  0.5\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4650:  0.5311004784688995\n",
      "f1  score for fold 4650:  0.37974683544303806\n",
      "recall for fold 4650:  0.38461538461538464\n",
      "precision for fold 4650:  0.375\n",
      "    0   1\n",
      "0  36  38\n",
      "1  44  91\n",
      "Accuracy for fold 4651:  0.6076555023923444\n",
      "f1  score for fold 4651:  0.4675324675324675\n",
      "recall for fold 4651:  0.4864864864864865\n",
      "precision for fold 4651:  0.45\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4652:  0.5857142857142857\n",
      "f1  score for fold 4652:  0.43870967741935485\n",
      "recall for fold 4652:  0.4533333333333333\n",
      "precision for fold 4652:  0.425\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4653:  0.5097087378640777\n",
      "f1  score for fold 4653:  0.37267080745341613\n",
      "recall for fold 4653:  0.36585365853658536\n",
      "precision for fold 4653:  0.379746835443038\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4654:  0.538860103626943\n",
      "f1  score for fold 4654:  0.4472049689440994\n",
      "recall for fold 4654:  0.41379310344827586\n",
      "precision for fold 4654:  0.4864864864864865\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4655:  0.49282296650717705\n",
      "f1  score for fold 4655:  0.32911392405063294\n",
      "recall for fold 4655:  0.3333333333333333\n",
      "precision for fold 4655:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4656:  0.5406698564593302\n",
      "f1  score for fold 4656:  0.37662337662337664\n",
      "recall for fold 4656:  0.3918918918918919\n",
      "precision for fold 4656:  0.3625\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4657:  0.5285714285714286\n",
      "f1  score for fold 4657:  0.3612903225806451\n",
      "recall for fold 4657:  0.37333333333333335\n",
      "precision for fold 4657:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4658:  0.5776699029126213\n",
      "f1  score for fold 4658:  0.4596273291925466\n",
      "recall for fold 4658:  0.45121951219512196\n",
      "precision for fold 4658:  0.46835443037974683\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4659:  0.5077720207253886\n",
      "f1  score for fold 4659:  0.40993788819875776\n",
      "recall for fold 4659:  0.3793103448275862\n",
      "precision for fold 4659:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 4660:  0.47368421052631576\n",
      "f1  score for fold 4660:  0.3037974683544304\n",
      "recall for fold 4660:  0.3076923076923077\n",
      "precision for fold 4660:  0.3\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4661:  0.5789473684210527\n",
      "f1  score for fold 4661:  0.42857142857142855\n",
      "recall for fold 4661:  0.44594594594594594\n",
      "precision for fold 4661:  0.4125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4662:  0.5571428571428572\n",
      "f1  score for fold 4662:  0.4000000000000001\n",
      "recall for fold 4662:  0.41333333333333333\n",
      "precision for fold 4662:  0.3875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4663:  0.529126213592233\n",
      "f1  score for fold 4663:  0.39751552795031053\n",
      "recall for fold 4663:  0.3902439024390244\n",
      "precision for fold 4663:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4664:  0.49740932642487046\n",
      "f1  score for fold 4664:  0.39751552795031053\n",
      "recall for fold 4664:  0.367816091954023\n",
      "precision for fold 4664:  0.43243243243243246\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4665:  0.5023923444976076\n",
      "f1  score for fold 4665:  0.34177215189873417\n",
      "recall for fold 4665:  0.34615384615384615\n",
      "precision for fold 4665:  0.3375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4666:  0.5215311004784688\n",
      "f1  score for fold 4666:  0.3506493506493507\n",
      "recall for fold 4666:  0.36486486486486486\n",
      "precision for fold 4666:  0.3375\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4667:  0.5285714285714286\n",
      "f1  score for fold 4667:  0.3612903225806451\n",
      "recall for fold 4667:  0.37333333333333335\n",
      "precision for fold 4667:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4668:  0.5776699029126213\n",
      "f1  score for fold 4668:  0.4596273291925466\n",
      "recall for fold 4668:  0.45121951219512196\n",
      "precision for fold 4668:  0.46835443037974683\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4669:  0.44559585492227977\n",
      "f1  score for fold 4669:  0.33540372670807456\n",
      "recall for fold 4669:  0.3103448275862069\n",
      "precision for fold 4669:  0.36486486486486486\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4670:  0.569377990430622\n",
      "f1  score for fold 4670:  0.43037974683544306\n",
      "recall for fold 4670:  0.4358974358974359\n",
      "precision for fold 4670:  0.425\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4671:  0.5598086124401914\n",
      "f1  score for fold 4671:  0.40259740259740256\n",
      "recall for fold 4671:  0.4189189189189189\n",
      "precision for fold 4671:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4672:  0.5285714285714286\n",
      "f1  score for fold 4672:  0.3612903225806451\n",
      "recall for fold 4672:  0.37333333333333335\n",
      "precision for fold 4672:  0.35\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4673:  0.5388349514563107\n",
      "f1  score for fold 4673:  0.40993788819875776\n",
      "recall for fold 4673:  0.4024390243902439\n",
      "precision for fold 4673:  0.4177215189873418\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4674:  0.45595854922279794\n",
      "f1  score for fold 4674:  0.3478260869565218\n",
      "recall for fold 4674:  0.3218390804597701\n",
      "precision for fold 4674:  0.3783783783783784\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4675:  0.5406698564593302\n",
      "f1  score for fold 4675:  0.3924050632911393\n",
      "recall for fold 4675:  0.3974358974358974\n",
      "precision for fold 4675:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4676:  0.5502392344497608\n",
      "f1  score for fold 4676:  0.3896103896103896\n",
      "recall for fold 4676:  0.40540540540540543\n",
      "precision for fold 4676:  0.375\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4677:  0.6047619047619047\n",
      "f1  score for fold 4677:  0.4645161290322581\n",
      "recall for fold 4677:  0.48\n",
      "precision for fold 4677:  0.45\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 4678:  0.46116504854368934\n",
      "f1  score for fold 4678:  0.31055900621118016\n",
      "recall for fold 4678:  0.3048780487804878\n",
      "precision for fold 4678:  0.31645569620253167\n",
      "    0   1\n",
      "0  40  47\n",
      "1  34  72\n",
      "Accuracy for fold 4679:  0.5803108808290155\n",
      "f1  score for fold 4679:  0.49689440993788814\n",
      "recall for fold 4679:  0.45977011494252873\n",
      "precision for fold 4679:  0.5405405405405406\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4680:  0.5789473684210527\n",
      "f1  score for fold 4680:  0.44303797468354433\n",
      "recall for fold 4680:  0.44871794871794873\n",
      "precision for fold 4680:  0.4375\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4681:  0.5789473684210527\n",
      "f1  score for fold 4681:  0.42857142857142855\n",
      "recall for fold 4681:  0.44594594594594594\n",
      "precision for fold 4681:  0.4125\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4682:  0.5285714285714286\n",
      "f1  score for fold 4682:  0.3612903225806451\n",
      "recall for fold 4682:  0.37333333333333335\n",
      "precision for fold 4682:  0.35\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 4683:  0.441747572815534\n",
      "f1  score for fold 4683:  0.28571428571428575\n",
      "recall for fold 4683:  0.2804878048780488\n",
      "precision for fold 4683:  0.2911392405063291\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4684:  0.5284974093264249\n",
      "f1  score for fold 4684:  0.4347826086956522\n",
      "recall for fold 4684:  0.40229885057471265\n",
      "precision for fold 4684:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4685:  0.5023923444976076\n",
      "f1  score for fold 4685:  0.34177215189873417\n",
      "recall for fold 4685:  0.34615384615384615\n",
      "precision for fold 4685:  0.3375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4686:  0.48325358851674644\n",
      "f1  score for fold 4686:  0.29870129870129863\n",
      "recall for fold 4686:  0.3108108108108108\n",
      "precision for fold 4686:  0.2875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4687:  0.5380952380952381\n",
      "f1  score for fold 4687:  0.3741935483870968\n",
      "recall for fold 4687:  0.38666666666666666\n",
      "precision for fold 4687:  0.3625\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4688:  0.5679611650485437\n",
      "f1  score for fold 4688:  0.4472049689440994\n",
      "recall for fold 4688:  0.43902439024390244\n",
      "precision for fold 4688:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4689:  0.49740932642487046\n",
      "f1  score for fold 4689:  0.39751552795031053\n",
      "recall for fold 4689:  0.367816091954023\n",
      "precision for fold 4689:  0.43243243243243246\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4690:  0.5502392344497608\n",
      "f1  score for fold 4690:  0.4050632911392405\n",
      "recall for fold 4690:  0.41025641025641024\n",
      "precision for fold 4690:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4691:  0.5502392344497608\n",
      "f1  score for fold 4691:  0.3896103896103896\n",
      "recall for fold 4691:  0.40540540540540543\n",
      "precision for fold 4691:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4692:  0.5190476190476191\n",
      "f1  score for fold 4692:  0.34838709677419355\n",
      "recall for fold 4692:  0.36\n",
      "precision for fold 4692:  0.3375\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4693:  0.48058252427184467\n",
      "f1  score for fold 4693:  0.33540372670807456\n",
      "recall for fold 4693:  0.32926829268292684\n",
      "precision for fold 4693:  0.34177215189873417\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4694:  0.5284974093264249\n",
      "f1  score for fold 4694:  0.4347826086956522\n",
      "recall for fold 4694:  0.40229885057471265\n",
      "precision for fold 4694:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4695:  0.5119617224880383\n",
      "f1  score for fold 4695:  0.3544303797468355\n",
      "recall for fold 4695:  0.358974358974359\n",
      "precision for fold 4695:  0.35\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4696:  0.49282296650717705\n",
      "f1  score for fold 4696:  0.3116883116883117\n",
      "recall for fold 4696:  0.32432432432432434\n",
      "precision for fold 4696:  0.3\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4697:  0.5857142857142857\n",
      "f1  score for fold 4697:  0.43870967741935485\n",
      "recall for fold 4697:  0.4533333333333333\n",
      "precision for fold 4697:  0.425\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4698:  0.5679611650485437\n",
      "f1  score for fold 4698:  0.4472049689440994\n",
      "recall for fold 4698:  0.43902439024390244\n",
      "precision for fold 4698:  0.45569620253164556\n",
      "    0   1\n",
      "0  42  45\n",
      "1  32  74\n",
      "Accuracy for fold 4699:  0.6010362694300518\n",
      "f1  score for fold 4699:  0.5217391304347826\n",
      "recall for fold 4699:  0.4827586206896552\n",
      "precision for fold 4699:  0.5675675675675675\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4700:  0.5502392344497608\n",
      "f1  score for fold 4700:  0.4050632911392405\n",
      "recall for fold 4700:  0.41025641025641024\n",
      "precision for fold 4700:  0.4\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4701:  0.5215311004784688\n",
      "f1  score for fold 4701:  0.3506493506493507\n",
      "recall for fold 4701:  0.36486486486486486\n",
      "precision for fold 4701:  0.3375\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4702:  0.5857142857142857\n",
      "f1  score for fold 4702:  0.43870967741935485\n",
      "recall for fold 4702:  0.4533333333333333\n",
      "precision for fold 4702:  0.425\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4703:  0.5\n",
      "f1  score for fold 4703:  0.3602484472049689\n",
      "recall for fold 4703:  0.35365853658536583\n",
      "precision for fold 4703:  0.3670886075949367\n",
      "    0   1\n",
      "0  28  59\n",
      "1  46  60\n",
      "Accuracy for fold 4704:  0.45595854922279794\n",
      "f1  score for fold 4704:  0.3478260869565218\n",
      "recall for fold 4704:  0.3218390804597701\n",
      "precision for fold 4704:  0.3783783783783784\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4705:  0.5502392344497608\n",
      "f1  score for fold 4705:  0.4050632911392405\n",
      "recall for fold 4705:  0.41025641025641024\n",
      "precision for fold 4705:  0.4\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4706:  0.5406698564593302\n",
      "f1  score for fold 4706:  0.37662337662337664\n",
      "recall for fold 4706:  0.3918918918918919\n",
      "precision for fold 4706:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4707:  0.5476190476190477\n",
      "f1  score for fold 4707:  0.38709677419354843\n",
      "recall for fold 4707:  0.4\n",
      "precision for fold 4707:  0.375\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4708:  0.5194174757281553\n",
      "f1  score for fold 4708:  0.38509316770186336\n",
      "recall for fold 4708:  0.3780487804878049\n",
      "precision for fold 4708:  0.3924050632911392\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4709:  0.538860103626943\n",
      "f1  score for fold 4709:  0.4472049689440994\n",
      "recall for fold 4709:  0.41379310344827586\n",
      "precision for fold 4709:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4710:  0.5502392344497608\n",
      "f1  score for fold 4710:  0.4050632911392405\n",
      "recall for fold 4710:  0.41025641025641024\n",
      "precision for fold 4710:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4711:  0.5502392344497608\n",
      "f1  score for fold 4711:  0.3896103896103896\n",
      "recall for fold 4711:  0.40540540540540543\n",
      "precision for fold 4711:  0.375\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4712:  0.48095238095238096\n",
      "f1  score for fold 4712:  0.2967741935483871\n",
      "recall for fold 4712:  0.30666666666666664\n",
      "precision for fold 4712:  0.2875\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4713:  0.5679611650485437\n",
      "f1  score for fold 4713:  0.4472049689440994\n",
      "recall for fold 4713:  0.43902439024390244\n",
      "precision for fold 4713:  0.45569620253164556\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4714:  0.5181347150259067\n",
      "f1  score for fold 4714:  0.422360248447205\n",
      "recall for fold 4714:  0.39080459770114945\n",
      "precision for fold 4714:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4715:  0.5598086124401914\n",
      "f1  score for fold 4715:  0.4177215189873418\n",
      "recall for fold 4715:  0.4230769230769231\n",
      "precision for fold 4715:  0.4125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4716:  0.5023923444976076\n",
      "f1  score for fold 4716:  0.3246753246753247\n",
      "recall for fold 4716:  0.33783783783783783\n",
      "precision for fold 4716:  0.3125\n",
      "    0   1\n",
      "0  36  39\n",
      "1  44  91\n",
      "Accuracy for fold 4717:  0.6047619047619047\n",
      "f1  score for fold 4717:  0.4645161290322581\n",
      "recall for fold 4717:  0.48\n",
      "precision for fold 4717:  0.45\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4718:  0.49029126213592233\n",
      "f1  score for fold 4718:  0.3478260869565218\n",
      "recall for fold 4718:  0.34146341463414637\n",
      "precision for fold 4718:  0.35443037974683544\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4719:  0.5077720207253886\n",
      "f1  score for fold 4719:  0.40993788819875776\n",
      "recall for fold 4719:  0.3793103448275862\n",
      "precision for fold 4719:  0.44594594594594594\n",
      "    0   1\n",
      "0  24  54\n",
      "1  56  75\n",
      "Accuracy for fold 4720:  0.47368421052631576\n",
      "f1  score for fold 4720:  0.3037974683544304\n",
      "recall for fold 4720:  0.3076923076923077\n",
      "precision for fold 4720:  0.3\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4721:  0.5502392344497608\n",
      "f1  score for fold 4721:  0.3896103896103896\n",
      "recall for fold 4721:  0.40540540540540543\n",
      "precision for fold 4721:  0.375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4722:  0.5\n",
      "f1  score for fold 4722:  0.3225806451612903\n",
      "recall for fold 4722:  0.3333333333333333\n",
      "precision for fold 4722:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4723:  0.529126213592233\n",
      "f1  score for fold 4723:  0.39751552795031053\n",
      "recall for fold 4723:  0.3902439024390244\n",
      "precision for fold 4723:  0.4050632911392405\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 4724:  0.43523316062176165\n",
      "f1  score for fold 4724:  0.3229813664596274\n",
      "recall for fold 4724:  0.2988505747126437\n",
      "precision for fold 4724:  0.35135135135135137\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4725:  0.5598086124401914\n",
      "f1  score for fold 4725:  0.4177215189873418\n",
      "recall for fold 4725:  0.4230769230769231\n",
      "precision for fold 4725:  0.4125\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4726:  0.5311004784688995\n",
      "f1  score for fold 4726:  0.36363636363636365\n",
      "recall for fold 4726:  0.3783783783783784\n",
      "precision for fold 4726:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4727:  0.5190476190476191\n",
      "f1  score for fold 4727:  0.34838709677419355\n",
      "recall for fold 4727:  0.36\n",
      "precision for fold 4727:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4728:  0.5388349514563107\n",
      "f1  score for fold 4728:  0.40993788819875776\n",
      "recall for fold 4728:  0.4024390243902439\n",
      "precision for fold 4728:  0.4177215189873418\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4729:  0.5699481865284974\n",
      "f1  score for fold 4729:  0.48447204968944096\n",
      "recall for fold 4729:  0.4482758620689655\n",
      "precision for fold 4729:  0.527027027027027\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4730:  0.5311004784688995\n",
      "f1  score for fold 4730:  0.37974683544303806\n",
      "recall for fold 4730:  0.38461538461538464\n",
      "precision for fold 4730:  0.375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4731:  0.5598086124401914\n",
      "f1  score for fold 4731:  0.40259740259740256\n",
      "recall for fold 4731:  0.4189189189189189\n",
      "precision for fold 4731:  0.3875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4732:  0.5095238095238095\n",
      "f1  score for fold 4732:  0.335483870967742\n",
      "recall for fold 4732:  0.3466666666666667\n",
      "precision for fold 4732:  0.325\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4733:  0.49029126213592233\n",
      "f1  score for fold 4733:  0.3478260869565218\n",
      "recall for fold 4733:  0.34146341463414637\n",
      "precision for fold 4733:  0.35443037974683544\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4734:  0.538860103626943\n",
      "f1  score for fold 4734:  0.4472049689440994\n",
      "recall for fold 4734:  0.41379310344827586\n",
      "precision for fold 4734:  0.4864864864864865\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4735:  0.569377990430622\n",
      "f1  score for fold 4735:  0.43037974683544306\n",
      "recall for fold 4735:  0.4358974358974359\n",
      "precision for fold 4735:  0.425\n",
      "    0   1\n",
      "0  35  39\n",
      "1  45  90\n",
      "Accuracy for fold 4736:  0.5980861244019139\n",
      "f1  score for fold 4736:  0.45454545454545453\n",
      "recall for fold 4736:  0.47297297297297297\n",
      "precision for fold 4736:  0.4375\n",
      "    0   1\n",
      "0  33  42\n",
      "1  47  88\n",
      "Accuracy for fold 4737:  0.5761904761904761\n",
      "f1  score for fold 4737:  0.4258064516129032\n",
      "recall for fold 4737:  0.44\n",
      "precision for fold 4737:  0.4125\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4738:  0.5485436893203883\n",
      "f1  score for fold 4738:  0.42236024844720493\n",
      "recall for fold 4738:  0.4146341463414634\n",
      "precision for fold 4738:  0.43037974683544306\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 4739:  0.42487046632124353\n",
      "f1  score for fold 4739:  0.3105590062111801\n",
      "recall for fold 4739:  0.28735632183908044\n",
      "precision for fold 4739:  0.33783783783783783\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4740:  0.5406698564593302\n",
      "f1  score for fold 4740:  0.3924050632911393\n",
      "recall for fold 4740:  0.3974358974358974\n",
      "precision for fold 4740:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4741:  0.5119617224880383\n",
      "f1  score for fold 4741:  0.33766233766233766\n",
      "recall for fold 4741:  0.35135135135135137\n",
      "precision for fold 4741:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4742:  0.5380952380952381\n",
      "f1  score for fold 4742:  0.3741935483870968\n",
      "recall for fold 4742:  0.38666666666666666\n",
      "precision for fold 4742:  0.3625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4743:  0.5097087378640777\n",
      "f1  score for fold 4743:  0.37267080745341613\n",
      "recall for fold 4743:  0.36585365853658536\n",
      "precision for fold 4743:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4744:  0.5077720207253886\n",
      "f1  score for fold 4744:  0.40993788819875776\n",
      "recall for fold 4744:  0.3793103448275862\n",
      "precision for fold 4744:  0.44594594594594594\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4745:  0.5119617224880383\n",
      "f1  score for fold 4745:  0.3544303797468355\n",
      "recall for fold 4745:  0.358974358974359\n",
      "precision for fold 4745:  0.35\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4746:  0.5023923444976076\n",
      "f1  score for fold 4746:  0.3246753246753247\n",
      "recall for fold 4746:  0.33783783783783783\n",
      "precision for fold 4746:  0.3125\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4747:  0.5476190476190477\n",
      "f1  score for fold 4747:  0.38709677419354843\n",
      "recall for fold 4747:  0.4\n",
      "precision for fold 4747:  0.375\n",
      "    0   1\n",
      "0  23  59\n",
      "1  56  68\n",
      "Accuracy for fold 4748:  0.441747572815534\n",
      "f1  score for fold 4748:  0.28571428571428575\n",
      "recall for fold 4748:  0.2804878048780488\n",
      "precision for fold 4748:  0.2911392405063291\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4749:  0.5181347150259067\n",
      "f1  score for fold 4749:  0.422360248447205\n",
      "recall for fold 4749:  0.39080459770114945\n",
      "precision for fold 4749:  0.4594594594594595\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4750:  0.5789473684210527\n",
      "f1  score for fold 4750:  0.44303797468354433\n",
      "recall for fold 4750:  0.44871794871794873\n",
      "precision for fold 4750:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4751:  0.5311004784688995\n",
      "f1  score for fold 4751:  0.36363636363636365\n",
      "recall for fold 4751:  0.3783783783783784\n",
      "precision for fold 4751:  0.35\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4752:  0.5190476190476191\n",
      "f1  score for fold 4752:  0.34838709677419355\n",
      "recall for fold 4752:  0.36\n",
      "precision for fold 4752:  0.3375\n",
      "    0   1\n",
      "0  22  60\n",
      "1  57  67\n",
      "Accuracy for fold 4753:  0.4320388349514563\n",
      "f1  score for fold 4753:  0.2732919254658385\n",
      "recall for fold 4753:  0.2682926829268293\n",
      "precision for fold 4753:  0.27848101265822783\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4754:  0.49740932642487046\n",
      "f1  score for fold 4754:  0.39751552795031053\n",
      "recall for fold 4754:  0.367816091954023\n",
      "precision for fold 4754:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4755:  0.5311004784688995\n",
      "f1  score for fold 4755:  0.37974683544303806\n",
      "recall for fold 4755:  0.38461538461538464\n",
      "precision for fold 4755:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4756:  0.5215311004784688\n",
      "f1  score for fold 4756:  0.3506493506493507\n",
      "recall for fold 4756:  0.36486486486486486\n",
      "precision for fold 4756:  0.3375\n",
      "    0   1\n",
      "0  35  40\n",
      "1  45  90\n",
      "Accuracy for fold 4757:  0.5952380952380952\n",
      "f1  score for fold 4757:  0.45161290322580644\n",
      "recall for fold 4757:  0.4666666666666667\n",
      "precision for fold 4757:  0.4375\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4758:  0.5097087378640777\n",
      "f1  score for fold 4758:  0.37267080745341613\n",
      "recall for fold 4758:  0.36585365853658536\n",
      "precision for fold 4758:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4759:  0.5284974093264249\n",
      "f1  score for fold 4759:  0.4347826086956522\n",
      "recall for fold 4759:  0.40229885057471265\n",
      "precision for fold 4759:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4760:  0.5023923444976076\n",
      "f1  score for fold 4760:  0.34177215189873417\n",
      "recall for fold 4760:  0.34615384615384615\n",
      "precision for fold 4760:  0.3375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4761:  0.5119617224880383\n",
      "f1  score for fold 4761:  0.33766233766233766\n",
      "recall for fold 4761:  0.35135135135135137\n",
      "precision for fold 4761:  0.325\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4762:  0.5190476190476191\n",
      "f1  score for fold 4762:  0.34838709677419355\n",
      "recall for fold 4762:  0.36\n",
      "precision for fold 4762:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4763:  0.5679611650485437\n",
      "f1  score for fold 4763:  0.4472049689440994\n",
      "recall for fold 4763:  0.43902439024390244\n",
      "precision for fold 4763:  0.45569620253164556\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4764:  0.48704663212435234\n",
      "f1  score for fold 4764:  0.3850931677018633\n",
      "recall for fold 4764:  0.3563218390804598\n",
      "precision for fold 4764:  0.4189189189189189\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4765:  0.5598086124401914\n",
      "f1  score for fold 4765:  0.4177215189873418\n",
      "recall for fold 4765:  0.4230769230769231\n",
      "precision for fold 4765:  0.4125\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4766:  0.5119617224880383\n",
      "f1  score for fold 4766:  0.33766233766233766\n",
      "recall for fold 4766:  0.35135135135135137\n",
      "precision for fold 4766:  0.325\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4767:  0.5857142857142857\n",
      "f1  score for fold 4767:  0.43870967741935485\n",
      "recall for fold 4767:  0.4533333333333333\n",
      "precision for fold 4767:  0.425\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4768:  0.5\n",
      "f1  score for fold 4768:  0.3602484472049689\n",
      "recall for fold 4768:  0.35365853658536583\n",
      "precision for fold 4768:  0.3670886075949367\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4769:  0.48704663212435234\n",
      "f1  score for fold 4769:  0.3850931677018633\n",
      "recall for fold 4769:  0.3563218390804598\n",
      "precision for fold 4769:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4770:  0.569377990430622\n",
      "f1  score for fold 4770:  0.43037974683544306\n",
      "recall for fold 4770:  0.4358974358974359\n",
      "precision for fold 4770:  0.425\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4771:  0.5406698564593302\n",
      "f1  score for fold 4771:  0.37662337662337664\n",
      "recall for fold 4771:  0.3918918918918919\n",
      "precision for fold 4771:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4772:  0.5476190476190477\n",
      "f1  score for fold 4772:  0.38709677419354843\n",
      "recall for fold 4772:  0.4\n",
      "precision for fold 4772:  0.375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4773:  0.529126213592233\n",
      "f1  score for fold 4773:  0.39751552795031053\n",
      "recall for fold 4773:  0.3902439024390244\n",
      "precision for fold 4773:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4774:  0.5284974093264249\n",
      "f1  score for fold 4774:  0.4347826086956522\n",
      "recall for fold 4774:  0.40229885057471265\n",
      "precision for fold 4774:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4775:  0.5215311004784688\n",
      "f1  score for fold 4775:  0.36708860759493667\n",
      "recall for fold 4775:  0.3717948717948718\n",
      "precision for fold 4775:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4776:  0.5023923444976076\n",
      "f1  score for fold 4776:  0.3246753246753247\n",
      "recall for fold 4776:  0.33783783783783783\n",
      "precision for fold 4776:  0.3125\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4777:  0.48095238095238096\n",
      "f1  score for fold 4777:  0.2967741935483871\n",
      "recall for fold 4777:  0.30666666666666664\n",
      "precision for fold 4777:  0.2875\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4778:  0.529126213592233\n",
      "f1  score for fold 4778:  0.39751552795031053\n",
      "recall for fold 4778:  0.3902439024390244\n",
      "precision for fold 4778:  0.4050632911392405\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4779:  0.5077720207253886\n",
      "f1  score for fold 4779:  0.40993788819875776\n",
      "recall for fold 4779:  0.3793103448275862\n",
      "precision for fold 4779:  0.44594594594594594\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4780:  0.5502392344497608\n",
      "f1  score for fold 4780:  0.4050632911392405\n",
      "recall for fold 4780:  0.41025641025641024\n",
      "precision for fold 4780:  0.4\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4781:  0.5502392344497608\n",
      "f1  score for fold 4781:  0.3896103896103896\n",
      "recall for fold 4781:  0.40540540540540543\n",
      "precision for fold 4781:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4782:  0.5190476190476191\n",
      "f1  score for fold 4782:  0.34838709677419355\n",
      "recall for fold 4782:  0.36\n",
      "precision for fold 4782:  0.3375\n",
      "    0   1\n",
      "0  25  57\n",
      "1  54  70\n",
      "Accuracy for fold 4783:  0.46116504854368934\n",
      "f1  score for fold 4783:  0.31055900621118016\n",
      "recall for fold 4783:  0.3048780487804878\n",
      "precision for fold 4783:  0.31645569620253167\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4784:  0.5077720207253886\n",
      "f1  score for fold 4784:  0.40993788819875776\n",
      "recall for fold 4784:  0.3793103448275862\n",
      "precision for fold 4784:  0.44594594594594594\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4785:  0.569377990430622\n",
      "f1  score for fold 4785:  0.43037974683544306\n",
      "recall for fold 4785:  0.4358974358974359\n",
      "precision for fold 4785:  0.425\n",
      "    0   1\n",
      "0  33  41\n",
      "1  47  88\n",
      "Accuracy for fold 4786:  0.5789473684210527\n",
      "f1  score for fold 4786:  0.42857142857142855\n",
      "recall for fold 4786:  0.44594594594594594\n",
      "precision for fold 4786:  0.4125\n",
      "    0   1\n",
      "0  19  56\n",
      "1  61  74\n",
      "Accuracy for fold 4787:  0.44285714285714284\n",
      "f1  score for fold 4787:  0.24516129032258063\n",
      "recall for fold 4787:  0.25333333333333335\n",
      "precision for fold 4787:  0.2375\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4788:  0.5485436893203883\n",
      "f1  score for fold 4788:  0.42236024844720493\n",
      "recall for fold 4788:  0.4146341463414634\n",
      "precision for fold 4788:  0.43037974683544306\n",
      "    0   1\n",
      "0  39  48\n",
      "1  35  71\n",
      "Accuracy for fold 4789:  0.5699481865284974\n",
      "f1  score for fold 4789:  0.48447204968944096\n",
      "recall for fold 4789:  0.4482758620689655\n",
      "precision for fold 4789:  0.527027027027027\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4790:  0.569377990430622\n",
      "f1  score for fold 4790:  0.43037974683544306\n",
      "recall for fold 4790:  0.4358974358974359\n",
      "precision for fold 4790:  0.425\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4791:  0.569377990430622\n",
      "f1  score for fold 4791:  0.4155844155844156\n",
      "recall for fold 4791:  0.43243243243243246\n",
      "precision for fold 4791:  0.4\n",
      "    0   1\n",
      "0  37  38\n",
      "1  43  92\n",
      "Accuracy for fold 4792:  0.6142857142857143\n",
      "f1  score for fold 4792:  0.47741935483870973\n",
      "recall for fold 4792:  0.49333333333333335\n",
      "precision for fold 4792:  0.4625\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4793:  0.5097087378640777\n",
      "f1  score for fold 4793:  0.37267080745341613\n",
      "recall for fold 4793:  0.36585365853658536\n",
      "precision for fold 4793:  0.379746835443038\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4794:  0.48704663212435234\n",
      "f1  score for fold 4794:  0.3850931677018633\n",
      "recall for fold 4794:  0.3563218390804598\n",
      "precision for fold 4794:  0.4189189189189189\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4795:  0.5023923444976076\n",
      "f1  score for fold 4795:  0.34177215189873417\n",
      "recall for fold 4795:  0.34615384615384615\n",
      "precision for fold 4795:  0.3375\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4796:  0.5023923444976076\n",
      "f1  score for fold 4796:  0.3246753246753247\n",
      "recall for fold 4796:  0.33783783783783783\n",
      "precision for fold 4796:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4797:  0.5571428571428572\n",
      "f1  score for fold 4797:  0.4000000000000001\n",
      "recall for fold 4797:  0.41333333333333333\n",
      "precision for fold 4797:  0.3875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4798:  0.5485436893203883\n",
      "f1  score for fold 4798:  0.42236024844720493\n",
      "recall for fold 4798:  0.4146341463414634\n",
      "precision for fold 4798:  0.43037974683544306\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4799:  0.538860103626943\n",
      "f1  score for fold 4799:  0.4472049689440994\n",
      "recall for fold 4799:  0.41379310344827586\n",
      "precision for fold 4799:  0.4864864864864865\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4800:  0.5311004784688995\n",
      "f1  score for fold 4800:  0.37974683544303806\n",
      "recall for fold 4800:  0.38461538461538464\n",
      "precision for fold 4800:  0.375\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4801:  0.5215311004784688\n",
      "f1  score for fold 4801:  0.3506493506493507\n",
      "recall for fold 4801:  0.36486486486486486\n",
      "precision for fold 4801:  0.3375\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4802:  0.5\n",
      "f1  score for fold 4802:  0.3225806451612903\n",
      "recall for fold 4802:  0.3333333333333333\n",
      "precision for fold 4802:  0.3125\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4803:  0.529126213592233\n",
      "f1  score for fold 4803:  0.39751552795031053\n",
      "recall for fold 4803:  0.3902439024390244\n",
      "precision for fold 4803:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4804:  0.5284974093264249\n",
      "f1  score for fold 4804:  0.4347826086956522\n",
      "recall for fold 4804:  0.40229885057471265\n",
      "precision for fold 4804:  0.47297297297297297\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4805:  0.5789473684210527\n",
      "f1  score for fold 4805:  0.44303797468354433\n",
      "recall for fold 4805:  0.44871794871794873\n",
      "precision for fold 4805:  0.4375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4806:  0.5311004784688995\n",
      "f1  score for fold 4806:  0.36363636363636365\n",
      "recall for fold 4806:  0.3783783783783784\n",
      "precision for fold 4806:  0.35\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4807:  0.5476190476190477\n",
      "f1  score for fold 4807:  0.38709677419354843\n",
      "recall for fold 4807:  0.4\n",
      "precision for fold 4807:  0.375\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4808:  0.49029126213592233\n",
      "f1  score for fold 4808:  0.3478260869565218\n",
      "recall for fold 4808:  0.34146341463414637\n",
      "precision for fold 4808:  0.35443037974683544\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4809:  0.5284974093264249\n",
      "f1  score for fold 4809:  0.4347826086956522\n",
      "recall for fold 4809:  0.40229885057471265\n",
      "precision for fold 4809:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4810:  0.5406698564593302\n",
      "f1  score for fold 4810:  0.3924050632911393\n",
      "recall for fold 4810:  0.3974358974358974\n",
      "precision for fold 4810:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4811:  0.48325358851674644\n",
      "f1  score for fold 4811:  0.29870129870129863\n",
      "recall for fold 4811:  0.3108108108108108\n",
      "precision for fold 4811:  0.2875\n",
      "    0   1\n",
      "0  23  52\n",
      "1  57  78\n",
      "Accuracy for fold 4812:  0.48095238095238096\n",
      "f1  score for fold 4812:  0.2967741935483871\n",
      "recall for fold 4812:  0.30666666666666664\n",
      "precision for fold 4812:  0.2875\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4813:  0.5485436893203883\n",
      "f1  score for fold 4813:  0.42236024844720493\n",
      "recall for fold 4813:  0.4146341463414634\n",
      "precision for fold 4813:  0.43037974683544306\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4814:  0.5077720207253886\n",
      "f1  score for fold 4814:  0.40993788819875776\n",
      "recall for fold 4814:  0.3793103448275862\n",
      "precision for fold 4814:  0.44594594594594594\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4815:  0.5215311004784688\n",
      "f1  score for fold 4815:  0.36708860759493667\n",
      "recall for fold 4815:  0.3717948717948718\n",
      "precision for fold 4815:  0.3625\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4816:  0.5502392344497608\n",
      "f1  score for fold 4816:  0.3896103896103896\n",
      "recall for fold 4816:  0.40540540540540543\n",
      "precision for fold 4816:  0.375\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4817:  0.5380952380952381\n",
      "f1  score for fold 4817:  0.3741935483870968\n",
      "recall for fold 4817:  0.38666666666666666\n",
      "precision for fold 4817:  0.3625\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 4818:  0.587378640776699\n",
      "f1  score for fold 4818:  0.4720496894409938\n",
      "recall for fold 4818:  0.4634146341463415\n",
      "precision for fold 4818:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4819:  0.49740932642487046\n",
      "f1  score for fold 4819:  0.39751552795031053\n",
      "recall for fold 4819:  0.367816091954023\n",
      "precision for fold 4819:  0.43243243243243246\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4820:  0.5311004784688995\n",
      "f1  score for fold 4820:  0.37974683544303806\n",
      "recall for fold 4820:  0.38461538461538464\n",
      "precision for fold 4820:  0.375\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4821:  0.48325358851674644\n",
      "f1  score for fold 4821:  0.29870129870129863\n",
      "recall for fold 4821:  0.3108108108108108\n",
      "precision for fold 4821:  0.2875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4822:  0.5285714285714286\n",
      "f1  score for fold 4822:  0.3612903225806451\n",
      "recall for fold 4822:  0.37333333333333335\n",
      "precision for fold 4822:  0.35\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4823:  0.5776699029126213\n",
      "f1  score for fold 4823:  0.4596273291925466\n",
      "recall for fold 4823:  0.45121951219512196\n",
      "precision for fold 4823:  0.46835443037974683\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4824:  0.5077720207253886\n",
      "f1  score for fold 4824:  0.40993788819875776\n",
      "recall for fold 4824:  0.3793103448275862\n",
      "precision for fold 4824:  0.44594594594594594\n",
      "    0   1\n",
      "0  35  43\n",
      "1  45  86\n",
      "Accuracy for fold 4825:  0.5789473684210527\n",
      "f1  score for fold 4825:  0.44303797468354433\n",
      "recall for fold 4825:  0.44871794871794873\n",
      "precision for fold 4825:  0.4375\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4826:  0.5119617224880383\n",
      "f1  score for fold 4826:  0.33766233766233766\n",
      "recall for fold 4826:  0.35135135135135137\n",
      "precision for fold 4826:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4827:  0.5380952380952381\n",
      "f1  score for fold 4827:  0.3741935483870968\n",
      "recall for fold 4827:  0.38666666666666666\n",
      "precision for fold 4827:  0.3625\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4828:  0.558252427184466\n",
      "f1  score for fold 4828:  0.43478260869565216\n",
      "recall for fold 4828:  0.4268292682926829\n",
      "precision for fold 4828:  0.4430379746835443\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4829:  0.538860103626943\n",
      "f1  score for fold 4829:  0.4472049689440994\n",
      "recall for fold 4829:  0.41379310344827586\n",
      "precision for fold 4829:  0.4864864864864865\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4830:  0.5502392344497608\n",
      "f1  score for fold 4830:  0.4050632911392405\n",
      "recall for fold 4830:  0.41025641025641024\n",
      "precision for fold 4830:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4831:  0.5311004784688995\n",
      "f1  score for fold 4831:  0.36363636363636365\n",
      "recall for fold 4831:  0.3783783783783784\n",
      "precision for fold 4831:  0.35\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4832:  0.5095238095238095\n",
      "f1  score for fold 4832:  0.335483870967742\n",
      "recall for fold 4832:  0.3466666666666667\n",
      "precision for fold 4832:  0.325\n",
      "    0   1\n",
      "0  31  51\n",
      "1  48  76\n",
      "Accuracy for fold 4833:  0.5194174757281553\n",
      "f1  score for fold 4833:  0.38509316770186336\n",
      "recall for fold 4833:  0.3780487804878049\n",
      "precision for fold 4833:  0.3924050632911392\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4834:  0.5181347150259067\n",
      "f1  score for fold 4834:  0.422360248447205\n",
      "recall for fold 4834:  0.39080459770114945\n",
      "precision for fold 4834:  0.4594594594594595\n",
      "    0   1\n",
      "0  33  45\n",
      "1  47  84\n",
      "Accuracy for fold 4835:  0.5598086124401914\n",
      "f1  score for fold 4835:  0.4177215189873418\n",
      "recall for fold 4835:  0.4230769230769231\n",
      "precision for fold 4835:  0.4125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4836:  0.5023923444976076\n",
      "f1  score for fold 4836:  0.3246753246753247\n",
      "recall for fold 4836:  0.33783783783783783\n",
      "precision for fold 4836:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4837:  0.5190476190476191\n",
      "f1  score for fold 4837:  0.34838709677419355\n",
      "recall for fold 4837:  0.36\n",
      "precision for fold 4837:  0.3375\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4838:  0.5679611650485437\n",
      "f1  score for fold 4838:  0.4472049689440994\n",
      "recall for fold 4838:  0.43902439024390244\n",
      "precision for fold 4838:  0.45569620253164556\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4839:  0.5077720207253886\n",
      "f1  score for fold 4839:  0.40993788819875776\n",
      "recall for fold 4839:  0.3793103448275862\n",
      "precision for fold 4839:  0.44594594594594594\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4840:  0.5023923444976076\n",
      "f1  score for fold 4840:  0.34177215189873417\n",
      "recall for fold 4840:  0.34615384615384615\n",
      "precision for fold 4840:  0.3375\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4841:  0.5598086124401914\n",
      "f1  score for fold 4841:  0.40259740259740256\n",
      "recall for fold 4841:  0.4189189189189189\n",
      "precision for fold 4841:  0.3875\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4842:  0.5285714285714286\n",
      "f1  score for fold 4842:  0.3612903225806451\n",
      "recall for fold 4842:  0.37333333333333335\n",
      "precision for fold 4842:  0.35\n",
      "    0   1\n",
      "0  28  54\n",
      "1  51  73\n",
      "Accuracy for fold 4843:  0.49029126213592233\n",
      "f1  score for fold 4843:  0.3478260869565218\n",
      "recall for fold 4843:  0.34146341463414637\n",
      "precision for fold 4843:  0.35443037974683544\n",
      "    0   1\n",
      "0  25  62\n",
      "1  49  57\n",
      "Accuracy for fold 4844:  0.42487046632124353\n",
      "f1  score for fold 4844:  0.3105590062111801\n",
      "recall for fold 4844:  0.28735632183908044\n",
      "precision for fold 4844:  0.33783783783783783\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4845:  0.49282296650717705\n",
      "f1  score for fold 4845:  0.32911392405063294\n",
      "recall for fold 4845:  0.3333333333333333\n",
      "precision for fold 4845:  0.325\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4846:  0.48325358851674644\n",
      "f1  score for fold 4846:  0.29870129870129863\n",
      "recall for fold 4846:  0.3108108108108108\n",
      "precision for fold 4846:  0.2875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4847:  0.5380952380952381\n",
      "f1  score for fold 4847:  0.3741935483870968\n",
      "recall for fold 4847:  0.38666666666666666\n",
      "precision for fold 4847:  0.3625\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4848:  0.5\n",
      "f1  score for fold 4848:  0.3602484472049689\n",
      "recall for fold 4848:  0.35365853658536583\n",
      "precision for fold 4848:  0.3670886075949367\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4849:  0.47668393782383417\n",
      "f1  score for fold 4849:  0.3726708074534162\n",
      "recall for fold 4849:  0.3448275862068966\n",
      "precision for fold 4849:  0.40540540540540543\n",
      "    0   1\n",
      "0  36  42\n",
      "1  44  87\n",
      "Accuracy for fold 4850:  0.5885167464114832\n",
      "f1  score for fold 4850:  0.45569620253164556\n",
      "recall for fold 4850:  0.46153846153846156\n",
      "precision for fold 4850:  0.45\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4851:  0.5502392344497608\n",
      "f1  score for fold 4851:  0.3896103896103896\n",
      "recall for fold 4851:  0.40540540540540543\n",
      "precision for fold 4851:  0.375\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4852:  0.5476190476190477\n",
      "f1  score for fold 4852:  0.38709677419354843\n",
      "recall for fold 4852:  0.4\n",
      "precision for fold 4852:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4853:  0.558252427184466\n",
      "f1  score for fold 4853:  0.43478260869565216\n",
      "recall for fold 4853:  0.4268292682926829\n",
      "precision for fold 4853:  0.4430379746835443\n",
      "    0   1\n",
      "0  26  61\n",
      "1  48  58\n",
      "Accuracy for fold 4854:  0.43523316062176165\n",
      "f1  score for fold 4854:  0.3229813664596274\n",
      "recall for fold 4854:  0.2988505747126437\n",
      "precision for fold 4854:  0.35135135135135137\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4855:  0.569377990430622\n",
      "f1  score for fold 4855:  0.43037974683544306\n",
      "recall for fold 4855:  0.4358974358974359\n",
      "precision for fold 4855:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4856:  0.5311004784688995\n",
      "f1  score for fold 4856:  0.36363636363636365\n",
      "recall for fold 4856:  0.3783783783783784\n",
      "precision for fold 4856:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4857:  0.5285714285714286\n",
      "f1  score for fold 4857:  0.3612903225806451\n",
      "recall for fold 4857:  0.37333333333333335\n",
      "precision for fold 4857:  0.35\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4858:  0.5\n",
      "f1  score for fold 4858:  0.3602484472049689\n",
      "recall for fold 4858:  0.35365853658536583\n",
      "precision for fold 4858:  0.3670886075949367\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4859:  0.5284974093264249\n",
      "f1  score for fold 4859:  0.4347826086956522\n",
      "recall for fold 4859:  0.40229885057471265\n",
      "precision for fold 4859:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4860:  0.569377990430622\n",
      "f1  score for fold 4860:  0.43037974683544306\n",
      "recall for fold 4860:  0.4358974358974359\n",
      "precision for fold 4860:  0.425\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4861:  0.5023923444976076\n",
      "f1  score for fold 4861:  0.3246753246753247\n",
      "recall for fold 4861:  0.33783783783783783\n",
      "precision for fold 4861:  0.3125\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4862:  0.5571428571428572\n",
      "f1  score for fold 4862:  0.4000000000000001\n",
      "recall for fold 4862:  0.41333333333333333\n",
      "precision for fold 4862:  0.3875\n",
      "    0   1\n",
      "0  27  55\n",
      "1  52  72\n",
      "Accuracy for fold 4863:  0.48058252427184467\n",
      "f1  score for fold 4863:  0.33540372670807456\n",
      "recall for fold 4863:  0.32926829268292684\n",
      "precision for fold 4863:  0.34177215189873417\n",
      "    0   1\n",
      "0  38  49\n",
      "1  36  70\n",
      "Accuracy for fold 4864:  0.5595854922279793\n",
      "f1  score for fold 4864:  0.4720496894409938\n",
      "recall for fold 4864:  0.4367816091954023\n",
      "precision for fold 4864:  0.5135135135135135\n",
      "    0   1\n",
      "0  32  46\n",
      "1  48  83\n",
      "Accuracy for fold 4865:  0.5502392344497608\n",
      "f1  score for fold 4865:  0.4050632911392405\n",
      "recall for fold 4865:  0.41025641025641024\n",
      "precision for fold 4865:  0.4\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4866:  0.5311004784688995\n",
      "f1  score for fold 4866:  0.36363636363636365\n",
      "recall for fold 4866:  0.3783783783783784\n",
      "precision for fold 4866:  0.35\n",
      "    0   1\n",
      "0  28  47\n",
      "1  52  83\n",
      "Accuracy for fold 4867:  0.5285714285714286\n",
      "f1  score for fold 4867:  0.3612903225806451\n",
      "recall for fold 4867:  0.37333333333333335\n",
      "precision for fold 4867:  0.35\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4868:  0.5679611650485437\n",
      "f1  score for fold 4868:  0.4472049689440994\n",
      "recall for fold 4868:  0.43902439024390244\n",
      "precision for fold 4868:  0.45569620253164556\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4869:  0.46632124352331605\n",
      "f1  score for fold 4869:  0.36024844720496896\n",
      "recall for fold 4869:  0.3333333333333333\n",
      "precision for fold 4869:  0.3918918918918919\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4870:  0.48325358851674644\n",
      "f1  score for fold 4870:  0.31645569620253167\n",
      "recall for fold 4870:  0.32051282051282054\n",
      "precision for fold 4870:  0.3125\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4871:  0.5502392344497608\n",
      "f1  score for fold 4871:  0.3896103896103896\n",
      "recall for fold 4871:  0.40540540540540543\n",
      "precision for fold 4871:  0.375\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4872:  0.5095238095238095\n",
      "f1  score for fold 4872:  0.335483870967742\n",
      "recall for fold 4872:  0.3466666666666667\n",
      "precision for fold 4872:  0.325\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4873:  0.5679611650485437\n",
      "f1  score for fold 4873:  0.4472049689440994\n",
      "recall for fold 4873:  0.43902439024390244\n",
      "precision for fold 4873:  0.45569620253164556\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4874:  0.49740932642487046\n",
      "f1  score for fold 4874:  0.39751552795031053\n",
      "recall for fold 4874:  0.367816091954023\n",
      "precision for fold 4874:  0.43243243243243246\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4875:  0.48325358851674644\n",
      "f1  score for fold 4875:  0.31645569620253167\n",
      "recall for fold 4875:  0.32051282051282054\n",
      "precision for fold 4875:  0.3125\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4876:  0.5023923444976076\n",
      "f1  score for fold 4876:  0.3246753246753247\n",
      "recall for fold 4876:  0.33783783783783783\n",
      "precision for fold 4876:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4877:  0.5190476190476191\n",
      "f1  score for fold 4877:  0.34838709677419355\n",
      "recall for fold 4877:  0.36\n",
      "precision for fold 4877:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4878:  0.5388349514563107\n",
      "f1  score for fold 4878:  0.40993788819875776\n",
      "recall for fold 4878:  0.4024390243902439\n",
      "precision for fold 4878:  0.4177215189873418\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4879:  0.5181347150259067\n",
      "f1  score for fold 4879:  0.422360248447205\n",
      "recall for fold 4879:  0.39080459770114945\n",
      "precision for fold 4879:  0.4594594594594595\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4880:  0.49282296650717705\n",
      "f1  score for fold 4880:  0.32911392405063294\n",
      "recall for fold 4880:  0.3333333333333333\n",
      "precision for fold 4880:  0.325\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4881:  0.5406698564593302\n",
      "f1  score for fold 4881:  0.37662337662337664\n",
      "recall for fold 4881:  0.3918918918918919\n",
      "precision for fold 4881:  0.3625\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4882:  0.5476190476190477\n",
      "f1  score for fold 4882:  0.38709677419354843\n",
      "recall for fold 4882:  0.4\n",
      "precision for fold 4882:  0.375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4883:  0.5388349514563107\n",
      "f1  score for fold 4883:  0.40993788819875776\n",
      "recall for fold 4883:  0.4024390243902439\n",
      "precision for fold 4883:  0.4177215189873418\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4884:  0.5492227979274611\n",
      "f1  score for fold 4884:  0.45962732919254656\n",
      "recall for fold 4884:  0.42528735632183906\n",
      "precision for fold 4884:  0.5\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4885:  0.5406698564593302\n",
      "f1  score for fold 4885:  0.3924050632911393\n",
      "recall for fold 4885:  0.3974358974358974\n",
      "precision for fold 4885:  0.3875\n",
      "    0   1\n",
      "0  37  37\n",
      "1  43  92\n",
      "Accuracy for fold 4886:  0.6172248803827751\n",
      "f1  score for fold 4886:  0.4805194805194805\n",
      "recall for fold 4886:  0.5\n",
      "precision for fold 4886:  0.4625\n",
      "    0   1\n",
      "0  31  44\n",
      "1  49  86\n",
      "Accuracy for fold 4887:  0.5571428571428572\n",
      "f1  score for fold 4887:  0.4000000000000001\n",
      "recall for fold 4887:  0.41333333333333333\n",
      "precision for fold 4887:  0.3875\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4888:  0.470873786407767\n",
      "f1  score for fold 4888:  0.3229813664596273\n",
      "recall for fold 4888:  0.3170731707317073\n",
      "precision for fold 4888:  0.3291139240506329\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4889:  0.5077720207253886\n",
      "f1  score for fold 4889:  0.40993788819875776\n",
      "recall for fold 4889:  0.3793103448275862\n",
      "precision for fold 4889:  0.44594594594594594\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4890:  0.5406698564593302\n",
      "f1  score for fold 4890:  0.3924050632911393\n",
      "recall for fold 4890:  0.3974358974358974\n",
      "precision for fold 4890:  0.3875\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4891:  0.5119617224880383\n",
      "f1  score for fold 4891:  0.33766233766233766\n",
      "recall for fold 4891:  0.35135135135135137\n",
      "precision for fold 4891:  0.325\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4892:  0.5380952380952381\n",
      "f1  score for fold 4892:  0.3741935483870968\n",
      "recall for fold 4892:  0.38666666666666666\n",
      "precision for fold 4892:  0.3625\n",
      "    0   1\n",
      "0  39  43\n",
      "1  40  84\n",
      "Accuracy for fold 4893:  0.5970873786407767\n",
      "f1  score for fold 4893:  0.484472049689441\n",
      "recall for fold 4893:  0.47560975609756095\n",
      "precision for fold 4893:  0.4936708860759494\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4894:  0.5181347150259067\n",
      "f1  score for fold 4894:  0.422360248447205\n",
      "recall for fold 4894:  0.39080459770114945\n",
      "precision for fold 4894:  0.4594594594594595\n",
      "    0   1\n",
      "0  25  53\n",
      "1  55  76\n",
      "Accuracy for fold 4895:  0.48325358851674644\n",
      "f1  score for fold 4895:  0.31645569620253167\n",
      "recall for fold 4895:  0.32051282051282054\n",
      "precision for fold 4895:  0.3125\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4896:  0.49282296650717705\n",
      "f1  score for fold 4896:  0.3116883116883117\n",
      "recall for fold 4896:  0.32432432432432434\n",
      "precision for fold 4896:  0.3\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4897:  0.5095238095238095\n",
      "f1  score for fold 4897:  0.335483870967742\n",
      "recall for fold 4897:  0.3466666666666667\n",
      "precision for fold 4897:  0.325\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4898:  0.529126213592233\n",
      "f1  score for fold 4898:  0.39751552795031053\n",
      "recall for fold 4898:  0.3902439024390244\n",
      "precision for fold 4898:  0.4050632911392405\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4899:  0.49740932642487046\n",
      "f1  score for fold 4899:  0.39751552795031053\n",
      "recall for fold 4899:  0.367816091954023\n",
      "precision for fold 4899:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4900:  0.5406698564593302\n",
      "f1  score for fold 4900:  0.3924050632911393\n",
      "recall for fold 4900:  0.3974358974358974\n",
      "precision for fold 4900:  0.3875\n",
      "    0   1\n",
      "0  23  51\n",
      "1  57  78\n",
      "Accuracy for fold 4901:  0.48325358851674644\n",
      "f1  score for fold 4901:  0.29870129870129863\n",
      "recall for fold 4901:  0.3108108108108108\n",
      "precision for fold 4901:  0.2875\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4902:  0.5095238095238095\n",
      "f1  score for fold 4902:  0.335483870967742\n",
      "recall for fold 4902:  0.3466666666666667\n",
      "precision for fold 4902:  0.325\n",
      "    0   1\n",
      "0  37  45\n",
      "1  42  82\n",
      "Accuracy for fold 4903:  0.5776699029126213\n",
      "f1  score for fold 4903:  0.4596273291925466\n",
      "recall for fold 4903:  0.45121951219512196\n",
      "precision for fold 4903:  0.46835443037974683\n",
      "    0   1\n",
      "0  29  58\n",
      "1  45  61\n",
      "Accuracy for fold 4904:  0.46632124352331605\n",
      "f1  score for fold 4904:  0.36024844720496896\n",
      "recall for fold 4904:  0.3333333333333333\n",
      "precision for fold 4904:  0.3918918918918919\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4905:  0.5215311004784688\n",
      "f1  score for fold 4905:  0.36708860759493667\n",
      "recall for fold 4905:  0.3717948717948718\n",
      "precision for fold 4905:  0.3625\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4906:  0.569377990430622\n",
      "f1  score for fold 4906:  0.4155844155844156\n",
      "recall for fold 4906:  0.43243243243243246\n",
      "precision for fold 4906:  0.4\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4907:  0.5380952380952381\n",
      "f1  score for fold 4907:  0.3741935483870968\n",
      "recall for fold 4907:  0.38666666666666666\n",
      "precision for fold 4907:  0.3625\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4908:  0.529126213592233\n",
      "f1  score for fold 4908:  0.39751552795031053\n",
      "recall for fold 4908:  0.3902439024390244\n",
      "precision for fold 4908:  0.4050632911392405\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4909:  0.5284974093264249\n",
      "f1  score for fold 4909:  0.4347826086956522\n",
      "recall for fold 4909:  0.40229885057471265\n",
      "precision for fold 4909:  0.47297297297297297\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4910:  0.5215311004784688\n",
      "f1  score for fold 4910:  0.36708860759493667\n",
      "recall for fold 4910:  0.3717948717948718\n",
      "precision for fold 4910:  0.3625\n",
      "    0   1\n",
      "0  25  49\n",
      "1  55  80\n",
      "Accuracy for fold 4911:  0.5023923444976076\n",
      "f1  score for fold 4911:  0.3246753246753247\n",
      "recall for fold 4911:  0.33783783783783783\n",
      "precision for fold 4911:  0.3125\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4912:  0.5190476190476191\n",
      "f1  score for fold 4912:  0.34838709677419355\n",
      "recall for fold 4912:  0.36\n",
      "precision for fold 4912:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4913:  0.5388349514563107\n",
      "f1  score for fold 4913:  0.40993788819875776\n",
      "recall for fold 4913:  0.4024390243902439\n",
      "precision for fold 4913:  0.4177215189873418\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4914:  0.5284974093264249\n",
      "f1  score for fold 4914:  0.4347826086956522\n",
      "recall for fold 4914:  0.40229885057471265\n",
      "precision for fold 4914:  0.47297297297297297\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4915:  0.5119617224880383\n",
      "f1  score for fold 4915:  0.3544303797468355\n",
      "recall for fold 4915:  0.358974358974359\n",
      "precision for fold 4915:  0.35\n",
      "    0   1\n",
      "0  31  43\n",
      "1  49  86\n",
      "Accuracy for fold 4916:  0.5598086124401914\n",
      "f1  score for fold 4916:  0.40259740259740256\n",
      "recall for fold 4916:  0.4189189189189189\n",
      "precision for fold 4916:  0.3875\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4917:  0.5380952380952381\n",
      "f1  score for fold 4917:  0.3741935483870968\n",
      "recall for fold 4917:  0.38666666666666666\n",
      "precision for fold 4917:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4918:  0.5485436893203883\n",
      "f1  score for fold 4918:  0.42236024844720493\n",
      "recall for fold 4918:  0.4146341463414634\n",
      "precision for fold 4918:  0.43037974683544306\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4919:  0.49740932642487046\n",
      "f1  score for fold 4919:  0.39751552795031053\n",
      "recall for fold 4919:  0.367816091954023\n",
      "precision for fold 4919:  0.43243243243243246\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4920:  0.5406698564593302\n",
      "f1  score for fold 4920:  0.3924050632911393\n",
      "recall for fold 4920:  0.3974358974358974\n",
      "precision for fold 4920:  0.3875\n",
      "    0   1\n",
      "0  24  50\n",
      "1  56  79\n",
      "Accuracy for fold 4921:  0.49282296650717705\n",
      "f1  score for fold 4921:  0.3116883116883117\n",
      "recall for fold 4921:  0.32432432432432434\n",
      "precision for fold 4921:  0.3\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4922:  0.5\n",
      "f1  score for fold 4922:  0.3225806451612903\n",
      "recall for fold 4922:  0.3333333333333333\n",
      "precision for fold 4922:  0.3125\n",
      "    0   1\n",
      "0  26  56\n",
      "1  53  71\n",
      "Accuracy for fold 4923:  0.470873786407767\n",
      "f1  score for fold 4923:  0.3229813664596273\n",
      "recall for fold 4923:  0.3170731707317073\n",
      "precision for fold 4923:  0.3291139240506329\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4924:  0.48704663212435234\n",
      "f1  score for fold 4924:  0.3850931677018633\n",
      "recall for fold 4924:  0.3563218390804598\n",
      "precision for fold 4924:  0.4189189189189189\n",
      "    0   1\n",
      "0  26  52\n",
      "1  54  77\n",
      "Accuracy for fold 4925:  0.49282296650717705\n",
      "f1  score for fold 4925:  0.32911392405063294\n",
      "recall for fold 4925:  0.3333333333333333\n",
      "precision for fold 4925:  0.325\n",
      "    0   1\n",
      "0  21  53\n",
      "1  59  76\n",
      "Accuracy for fold 4926:  0.46411483253588515\n",
      "f1  score for fold 4926:  0.27272727272727276\n",
      "recall for fold 4926:  0.28378378378378377\n",
      "precision for fold 4926:  0.2625\n",
      "    0   1\n",
      "0  29  46\n",
      "1  51  84\n",
      "Accuracy for fold 4927:  0.5380952380952381\n",
      "f1  score for fold 4927:  0.3741935483870968\n",
      "recall for fold 4927:  0.38666666666666666\n",
      "precision for fold 4927:  0.3625\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4928:  0.5485436893203883\n",
      "f1  score for fold 4928:  0.42236024844720493\n",
      "recall for fold 4928:  0.4146341463414634\n",
      "precision for fold 4928:  0.43037974683544306\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4929:  0.5284974093264249\n",
      "f1  score for fold 4929:  0.4347826086956522\n",
      "recall for fold 4929:  0.40229885057471265\n",
      "precision for fold 4929:  0.47297297297297297\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4930:  0.569377990430622\n",
      "f1  score for fold 4930:  0.43037974683544306\n",
      "recall for fold 4930:  0.4358974358974359\n",
      "precision for fold 4930:  0.425\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 4931:  0.47368421052631576\n",
      "f1  score for fold 4931:  0.28571428571428575\n",
      "recall for fold 4931:  0.2972972972972973\n",
      "precision for fold 4931:  0.275\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4932:  0.5857142857142857\n",
      "f1  score for fold 4932:  0.43870967741935485\n",
      "recall for fold 4932:  0.4533333333333333\n",
      "precision for fold 4932:  0.425\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4933:  0.5485436893203883\n",
      "f1  score for fold 4933:  0.42236024844720493\n",
      "recall for fold 4933:  0.4146341463414634\n",
      "precision for fold 4933:  0.43037974683544306\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4934:  0.48704663212435234\n",
      "f1  score for fold 4934:  0.3850931677018633\n",
      "recall for fold 4934:  0.3563218390804598\n",
      "precision for fold 4934:  0.4189189189189189\n",
      "    0   1\n",
      "0  29  49\n",
      "1  51  80\n",
      "Accuracy for fold 4935:  0.5215311004784688\n",
      "f1  score for fold 4935:  0.36708860759493667\n",
      "recall for fold 4935:  0.3717948717948718\n",
      "precision for fold 4935:  0.3625\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4936:  0.5406698564593302\n",
      "f1  score for fold 4936:  0.37662337662337664\n",
      "recall for fold 4936:  0.3918918918918919\n",
      "precision for fold 4936:  0.3625\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4937:  0.5666666666666667\n",
      "f1  score for fold 4937:  0.41290322580645167\n",
      "recall for fold 4937:  0.4266666666666667\n",
      "precision for fold 4937:  0.4\n",
      "    0   1\n",
      "0  34  48\n",
      "1  45  79\n",
      "Accuracy for fold 4938:  0.5485436893203883\n",
      "f1  score for fold 4938:  0.42236024844720493\n",
      "recall for fold 4938:  0.4146341463414634\n",
      "precision for fold 4938:  0.43037974683544306\n",
      "    0   1\n",
      "0  27  60\n",
      "1  47  59\n",
      "Accuracy for fold 4939:  0.44559585492227977\n",
      "f1  score for fold 4939:  0.33540372670807456\n",
      "recall for fold 4939:  0.3103448275862069\n",
      "precision for fold 4939:  0.36486486486486486\n",
      "    0   1\n",
      "0  30  48\n",
      "1  50  81\n",
      "Accuracy for fold 4940:  0.5311004784688995\n",
      "f1  score for fold 4940:  0.37974683544303806\n",
      "recall for fold 4940:  0.38461538461538464\n",
      "precision for fold 4940:  0.375\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4941:  0.5311004784688995\n",
      "f1  score for fold 4941:  0.36363636363636365\n",
      "recall for fold 4941:  0.3783783783783784\n",
      "precision for fold 4941:  0.35\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4942:  0.49047619047619045\n",
      "f1  score for fold 4942:  0.3096774193548387\n",
      "recall for fold 4942:  0.32\n",
      "precision for fold 4942:  0.3\n",
      "    0   1\n",
      "0  38  44\n",
      "1  41  83\n",
      "Accuracy for fold 4943:  0.587378640776699\n",
      "f1  score for fold 4943:  0.4720496894409938\n",
      "recall for fold 4943:  0.4634146341463415\n",
      "precision for fold 4943:  0.4810126582278481\n",
      "    0   1\n",
      "0  32  55\n",
      "1  42  64\n",
      "Accuracy for fold 4944:  0.49740932642487046\n",
      "f1  score for fold 4944:  0.39751552795031053\n",
      "recall for fold 4944:  0.367816091954023\n",
      "precision for fold 4944:  0.43243243243243246\n",
      "    0   1\n",
      "0  22  56\n",
      "1  58  73\n",
      "Accuracy for fold 4945:  0.45454545454545453\n",
      "f1  score for fold 4945:  0.27848101265822783\n",
      "recall for fold 4945:  0.28205128205128205\n",
      "precision for fold 4945:  0.275\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 4946:  0.47368421052631576\n",
      "f1  score for fold 4946:  0.28571428571428575\n",
      "recall for fold 4946:  0.2972972972972973\n",
      "precision for fold 4946:  0.275\n",
      "    0   1\n",
      "0  25  50\n",
      "1  55  80\n",
      "Accuracy for fold 4947:  0.5\n",
      "f1  score for fold 4947:  0.3225806451612903\n",
      "recall for fold 4947:  0.3333333333333333\n",
      "precision for fold 4947:  0.3125\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4948:  0.558252427184466\n",
      "f1  score for fold 4948:  0.43478260869565216\n",
      "recall for fold 4948:  0.4268292682926829\n",
      "precision for fold 4948:  0.4430379746835443\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4949:  0.5284974093264249\n",
      "f1  score for fold 4949:  0.4347826086956522\n",
      "recall for fold 4949:  0.40229885057471265\n",
      "precision for fold 4949:  0.47297297297297297\n",
      "    0   1\n",
      "0  31  47\n",
      "1  49  82\n",
      "Accuracy for fold 4950:  0.5406698564593302\n",
      "f1  score for fold 4950:  0.3924050632911393\n",
      "recall for fold 4950:  0.3974358974358974\n",
      "precision for fold 4950:  0.3875\n",
      "    0   1\n",
      "0  30  44\n",
      "1  50  85\n",
      "Accuracy for fold 4951:  0.5502392344497608\n",
      "f1  score for fold 4951:  0.3896103896103896\n",
      "recall for fold 4951:  0.40540540540540543\n",
      "precision for fold 4951:  0.375\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4952:  0.5190476190476191\n",
      "f1  score for fold 4952:  0.34838709677419355\n",
      "recall for fold 4952:  0.36\n",
      "precision for fold 4952:  0.3375\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4953:  0.529126213592233\n",
      "f1  score for fold 4953:  0.39751552795031053\n",
      "recall for fold 4953:  0.3902439024390244\n",
      "precision for fold 4953:  0.4050632911392405\n",
      "    0   1\n",
      "0  30  57\n",
      "1  44  62\n",
      "Accuracy for fold 4954:  0.47668393782383417\n",
      "f1  score for fold 4954:  0.3726708074534162\n",
      "recall for fold 4954:  0.3448275862068966\n",
      "precision for fold 4954:  0.40540540540540543\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4955:  0.569377990430622\n",
      "f1  score for fold 4955:  0.43037974683544306\n",
      "recall for fold 4955:  0.4358974358974359\n",
      "precision for fold 4955:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4956:  0.5311004784688995\n",
      "f1  score for fold 4956:  0.36363636363636365\n",
      "recall for fold 4956:  0.3783783783783784\n",
      "precision for fold 4956:  0.35\n",
      "    0   1\n",
      "0  32  43\n",
      "1  48  87\n",
      "Accuracy for fold 4957:  0.5666666666666667\n",
      "f1  score for fold 4957:  0.41290322580645167\n",
      "recall for fold 4957:  0.4266666666666667\n",
      "precision for fold 4957:  0.4\n",
      "    0   1\n",
      "0  32  50\n",
      "1  47  77\n",
      "Accuracy for fold 4958:  0.529126213592233\n",
      "f1  score for fold 4958:  0.39751552795031053\n",
      "recall for fold 4958:  0.3902439024390244\n",
      "precision for fold 4958:  0.4050632911392405\n",
      "    0   1\n",
      "0  36  51\n",
      "1  38  68\n",
      "Accuracy for fold 4959:  0.538860103626943\n",
      "f1  score for fold 4959:  0.4472049689440994\n",
      "recall for fold 4959:  0.41379310344827586\n",
      "precision for fold 4959:  0.4864864864864865\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4960:  0.5023923444976076\n",
      "f1  score for fold 4960:  0.34177215189873417\n",
      "recall for fold 4960:  0.34615384615384615\n",
      "precision for fold 4960:  0.3375\n",
      "    0   1\n",
      "0  29  45\n",
      "1  51  84\n",
      "Accuracy for fold 4961:  0.5406698564593302\n",
      "f1  score for fold 4961:  0.37662337662337664\n",
      "recall for fold 4961:  0.3918918918918919\n",
      "precision for fold 4961:  0.3625\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4962:  0.5095238095238095\n",
      "f1  score for fold 4962:  0.335483870967742\n",
      "recall for fold 4962:  0.3466666666666667\n",
      "precision for fold 4962:  0.325\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4963:  0.5097087378640777\n",
      "f1  score for fold 4963:  0.37267080745341613\n",
      "recall for fold 4963:  0.36585365853658536\n",
      "precision for fold 4963:  0.379746835443038\n",
      "    0   1\n",
      "0  33  54\n",
      "1  41  65\n",
      "Accuracy for fold 4964:  0.5077720207253886\n",
      "f1  score for fold 4964:  0.40993788819875776\n",
      "recall for fold 4964:  0.3793103448275862\n",
      "precision for fold 4964:  0.44594594594594594\n",
      "    0   1\n",
      "0  23  55\n",
      "1  57  74\n",
      "Accuracy for fold 4965:  0.46411483253588515\n",
      "f1  score for fold 4965:  0.2911392405063291\n",
      "recall for fold 4965:  0.2948717948717949\n",
      "precision for fold 4965:  0.2875\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4966:  0.569377990430622\n",
      "f1  score for fold 4966:  0.4155844155844156\n",
      "recall for fold 4966:  0.43243243243243246\n",
      "precision for fold 4966:  0.4\n",
      "    0   1\n",
      "0  30  45\n",
      "1  50  85\n",
      "Accuracy for fold 4967:  0.5476190476190477\n",
      "f1  score for fold 4967:  0.38709677419354843\n",
      "recall for fold 4967:  0.4\n",
      "precision for fold 4967:  0.375\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4968:  0.558252427184466\n",
      "f1  score for fold 4968:  0.43478260869565216\n",
      "recall for fold 4968:  0.4268292682926829\n",
      "precision for fold 4968:  0.4430379746835443\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4969:  0.5492227979274611\n",
      "f1  score for fold 4969:  0.45962732919254656\n",
      "recall for fold 4969:  0.42528735632183906\n",
      "precision for fold 4969:  0.5\n",
      "    0   1\n",
      "0  28  50\n",
      "1  52  79\n",
      "Accuracy for fold 4970:  0.5119617224880383\n",
      "f1  score for fold 4970:  0.3544303797468355\n",
      "recall for fold 4970:  0.358974358974359\n",
      "precision for fold 4970:  0.35\n",
      "    0   1\n",
      "0  26  48\n",
      "1  54  81\n",
      "Accuracy for fold 4971:  0.5119617224880383\n",
      "f1  score for fold 4971:  0.33766233766233766\n",
      "recall for fold 4971:  0.35135135135135137\n",
      "precision for fold 4971:  0.325\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4972:  0.5857142857142857\n",
      "f1  score for fold 4972:  0.43870967741935485\n",
      "recall for fold 4972:  0.4533333333333333\n",
      "precision for fold 4972:  0.425\n",
      "    0   1\n",
      "0  36  46\n",
      "1  43  81\n",
      "Accuracy for fold 4973:  0.5679611650485437\n",
      "f1  score for fold 4973:  0.4472049689440994\n",
      "recall for fold 4973:  0.43902439024390244\n",
      "precision for fold 4973:  0.45569620253164556\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4974:  0.5284974093264249\n",
      "f1  score for fold 4974:  0.4347826086956522\n",
      "recall for fold 4974:  0.40229885057471265\n",
      "precision for fold 4974:  0.47297297297297297\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4975:  0.5023923444976076\n",
      "f1  score for fold 4975:  0.34177215189873417\n",
      "recall for fold 4975:  0.34615384615384615\n",
      "precision for fold 4975:  0.3375\n",
      "    0   1\n",
      "0  32  42\n",
      "1  48  87\n",
      "Accuracy for fold 4976:  0.569377990430622\n",
      "f1  score for fold 4976:  0.4155844155844156\n",
      "recall for fold 4976:  0.43243243243243246\n",
      "precision for fold 4976:  0.4\n",
      "    0   1\n",
      "0  26  49\n",
      "1  54  81\n",
      "Accuracy for fold 4977:  0.5095238095238095\n",
      "f1  score for fold 4977:  0.335483870967742\n",
      "recall for fold 4977:  0.3466666666666667\n",
      "precision for fold 4977:  0.325\n",
      "    0   1\n",
      "0  29  53\n",
      "1  50  74\n",
      "Accuracy for fold 4978:  0.5\n",
      "f1  score for fold 4978:  0.3602484472049689\n",
      "recall for fold 4978:  0.35365853658536583\n",
      "precision for fold 4978:  0.3670886075949367\n",
      "    0   1\n",
      "0  37  50\n",
      "1  37  69\n",
      "Accuracy for fold 4979:  0.5492227979274611\n",
      "f1  score for fold 4979:  0.45962732919254656\n",
      "recall for fold 4979:  0.42528735632183906\n",
      "precision for fold 4979:  0.5\n",
      "    0   1\n",
      "0  27  51\n",
      "1  53  78\n",
      "Accuracy for fold 4980:  0.5023923444976076\n",
      "f1  score for fold 4980:  0.34177215189873417\n",
      "recall for fold 4980:  0.34615384615384615\n",
      "precision for fold 4980:  0.3375\n",
      "    0   1\n",
      "0  22  52\n",
      "1  58  77\n",
      "Accuracy for fold 4981:  0.47368421052631576\n",
      "f1  score for fold 4981:  0.28571428571428575\n",
      "recall for fold 4981:  0.2972972972972973\n",
      "precision for fold 4981:  0.275\n",
      "    0   1\n",
      "0  27  48\n",
      "1  53  82\n",
      "Accuracy for fold 4982:  0.5190476190476191\n",
      "f1  score for fold 4982:  0.34838709677419355\n",
      "recall for fold 4982:  0.36\n",
      "precision for fold 4982:  0.3375\n",
      "    0   1\n",
      "0  33  49\n",
      "1  46  78\n",
      "Accuracy for fold 4983:  0.5388349514563107\n",
      "f1  score for fold 4983:  0.40993788819875776\n",
      "recall for fold 4983:  0.4024390243902439\n",
      "precision for fold 4983:  0.4177215189873418\n",
      "    0   1\n",
      "0  31  56\n",
      "1  43  63\n",
      "Accuracy for fold 4984:  0.48704663212435234\n",
      "f1  score for fold 4984:  0.3850931677018633\n",
      "recall for fold 4984:  0.3563218390804598\n",
      "precision for fold 4984:  0.4189189189189189\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4985:  0.569377990430622\n",
      "f1  score for fold 4985:  0.43037974683544306\n",
      "recall for fold 4985:  0.4358974358974359\n",
      "precision for fold 4985:  0.425\n",
      "    0   1\n",
      "0  27  47\n",
      "1  53  82\n",
      "Accuracy for fold 4986:  0.5215311004784688\n",
      "f1  score for fold 4986:  0.3506493506493507\n",
      "recall for fold 4986:  0.36486486486486486\n",
      "precision for fold 4986:  0.3375\n",
      "    0   1\n",
      "0  24  51\n",
      "1  56  79\n",
      "Accuracy for fold 4987:  0.49047619047619045\n",
      "f1  score for fold 4987:  0.3096774193548387\n",
      "recall for fold 4987:  0.32\n",
      "precision for fold 4987:  0.3\n",
      "    0   1\n",
      "0  35  47\n",
      "1  44  80\n",
      "Accuracy for fold 4988:  0.558252427184466\n",
      "f1  score for fold 4988:  0.43478260869565216\n",
      "recall for fold 4988:  0.4268292682926829\n",
      "precision for fold 4988:  0.4430379746835443\n",
      "    0   1\n",
      "0  34  53\n",
      "1  40  66\n",
      "Accuracy for fold 4989:  0.5181347150259067\n",
      "f1  score for fold 4989:  0.422360248447205\n",
      "recall for fold 4989:  0.39080459770114945\n",
      "precision for fold 4989:  0.4594594594594595\n",
      "    0   1\n",
      "0  34  44\n",
      "1  46  85\n",
      "Accuracy for fold 4990:  0.569377990430622\n",
      "f1  score for fold 4990:  0.43037974683544306\n",
      "recall for fold 4990:  0.4358974358974359\n",
      "precision for fold 4990:  0.425\n",
      "    0   1\n",
      "0  28  46\n",
      "1  52  83\n",
      "Accuracy for fold 4991:  0.5311004784688995\n",
      "f1  score for fold 4991:  0.36363636363636365\n",
      "recall for fold 4991:  0.3783783783783784\n",
      "precision for fold 4991:  0.35\n",
      "    0   1\n",
      "0  34  41\n",
      "1  46  89\n",
      "Accuracy for fold 4992:  0.5857142857142857\n",
      "f1  score for fold 4992:  0.43870967741935485\n",
      "recall for fold 4992:  0.4533333333333333\n",
      "precision for fold 4992:  0.425\n",
      "    0   1\n",
      "0  30  52\n",
      "1  49  75\n",
      "Accuracy for fold 4993:  0.5097087378640777\n",
      "f1  score for fold 4993:  0.37267080745341613\n",
      "recall for fold 4993:  0.36585365853658536\n",
      "precision for fold 4993:  0.379746835443038\n",
      "    0   1\n",
      "0  35  52\n",
      "1  39  67\n",
      "Accuracy for fold 4994:  0.5284974093264249\n",
      "f1  score for fold 4994:  0.4347826086956522\n",
      "recall for fold 4994:  0.40229885057471265\n",
      "precision for fold 4994:  0.47297297297297297\n",
      "[0.31645569620253167, 0.42857142857142855, 0.41290322580645167, 0.39751552795031053, 0.3726708074534162, 0.37974683544303806, 0.3896103896103896, 0.3612903225806451, 0.37267080745341613, 0.3478260869565218, 0.37974683544303806, 0.37662337662337664, 0.43870967741935485, 0.37267080745341613, 0.4347826086956522, 0.4050632911392405, 0.37662337662337664, 0.3225806451612903, 0.38509316770186336, 0.4472049689440994, 0.45569620253164556, 0.37662337662337664, 0.3741935483870968, 0.37267080745341613, 0.39751552795031053, 0.37974683544303806, 0.33766233766233766, 0.3741935483870968, 0.4472049689440994, 0.422360248447205, 0.36708860759493667, 0.40259740259740256, 0.3741935483870968, 0.40993788819875776, 0.40993788819875776, 0.3924050632911393, 0.37662337662337664, 0.34838709677419355, 0.43478260869565216, 0.3850931677018633, 0.43037974683544306, 0.40259740259740256, 0.4258064516129032, 0.37267080745341613, 0.4472049689440994, 0.36708860759493667, 0.3896103896103896, 0.3741935483870968, 0.4472049689440994, 0.40993788819875776, 0.4177215189873418, 0.37662337662337664, 0.41290322580645167, 0.43478260869565216, 0.3726708074534162, 0.37974683544303806, 0.3506493506493507, 0.3741935483870968, 0.33540372670807456, 0.39751552795031053, 0.37974683544303806, 0.27272727272727276, 0.34838709677419355, 0.3602484472049689, 0.3850931677018633, 0.3544303797468355, 0.36363636363636365, 0.49032258064516127, 0.3602484472049689, 0.4472049689440994, 0.31645569620253167, 0.40259740259740256, 0.2838709677419355, 0.38509316770186336, 0.3726708074534162, 0.32911392405063294, 0.3896103896103896, 0.2838709677419355, 0.40993788819875776, 0.36024844720496896, 0.31645569620253167, 0.40259740259740256, 0.43870967741935485, 0.40993788819875776, 0.422360248447205, 0.34177215189873417, 0.33766233766233766, 0.2967741935483871, 0.38509316770186336, 0.4472049689440994, 0.37974683544303806, 0.3246753246753247, 0.3741935483870968, 0.31055900621118016, 0.39751552795031053, 0.3544303797468355, 0.3116883116883117, 0.4000000000000001, 0.42236024844720493, 0.3726708074534162, 0.3037974683544304, 0.37662337662337664, 0.34838709677419355, 0.33540372670807456, 0.3726708074534162, 0.4050632911392405, 0.37662337662337664, 0.3741935483870968, 0.43478260869565216, 0.3850931677018633, 0.4177215189873418, 0.40259740259740256, 0.43870967741935485, 0.3229813664596273, 0.4472049689440994, 0.4177215189873418, 0.37662337662337664, 0.3612903225806451, 0.3602484472049689, 0.39751552795031053, 0.43037974683544306, 0.3896103896103896, 0.3225806451612903, 0.43478260869565216, 0.4347826086956522, 0.36708860759493667, 0.37662337662337664, 0.2838709677419355, 0.24844720496894412, 0.45962732919254656, 0.32911392405063294, 0.3896103896103896, 0.38709677419354843, 0.39751552795031053, 0.4720496894409938, 0.3924050632911393, 0.4155844155844156, 0.3225806451612903, 0.3602484472049689, 0.3478260869565218, 0.3924050632911393, 0.3506493506493507, 0.3225806451612903, 0.3602484472049689, 0.45962732919254656, 0.36708860759493667, 0.33766233766233766, 0.4000000000000001, 0.42236024844720493, 0.4347826086956522, 0.45569620253164556, 0.40259740259740256, 0.43870967741935485, 0.40993788819875776, 0.3850931677018633, 0.49367088607594933, 0.44155844155844154, 0.335483870967742, 0.4720496894409938, 0.4347826086956522, 0.37974683544303806, 0.37662337662337664, 0.45161290322580644, 0.4472049689440994, 0.4347826086956522, 0.43037974683544306, 0.3896103896103896, 0.38709677419354843, 0.42236024844720493, 0.45962732919254656, 0.4050632911392405, 0.3896103896103896, 0.3612903225806451, 0.43478260869565216, 0.3850931677018633, 0.3924050632911393, 0.3246753246753247, 0.3225806451612903, 0.37267080745341613, 0.4720496894409938, 0.34177215189873417, 0.3246753246753247, 0.3612903225806451, 0.3602484472049689, 0.3229813664596274, 0.37974683544303806, 0.33766233766233766, 0.34838709677419355, 0.4472049689440994, 0.3850931677018633, 0.3544303797468355, 0.29870129870129863, 0.335483870967742, 0.3602484472049689, 0.3726708074534162, 0.3037974683544304, 0.3896103896103896, 0.335483870967742, 0.3602484472049689, 0.4347826086956522, 0.37974683544303806, 0.36363636363636365, 0.43870967741935485, 0.38509316770186336, 0.45962732919254656, 0.32911392405063294, 0.36363636363636365, 0.335483870967742, 0.39751552795031053, 0.422360248447205, 0.31645569620253167, 0.37662337662337664, 0.47741935483870973, 0.4596273291925466, 0.33540372670807456, 0.3924050632911393, 0.40259740259740256, 0.2967741935483871, 0.38509316770186336, 0.3478260869565218, 0.44303797468354433, 0.4805194805194805, 0.3612903225806451, 0.4472049689440994, 0.4347826086956522, 0.32911392405063294, 0.3896103896103896, 0.4000000000000001, 0.37267080745341613, 0.3850931677018633, 0.4177215189873418, 0.4155844155844156, 0.4000000000000001, 0.38509316770186336, 0.45962732919254656, 0.4177215189873418, 0.3896103896103896, 0.3612903225806451, 0.42236024844720493, 0.40993788819875776, 0.4050632911392405, 0.3506493506493507, 0.34838709677419355, 0.39751552795031053, 0.39751552795031053, 0.3924050632911393, 0.36363636363636365, 0.335483870967742, 0.3602484472049689, 0.422360248447205, 0.32911392405063294, 0.3896103896103896, 0.4000000000000001, 0.43478260869565216, 0.4347826086956522, 0.4177215189873418, 0.33766233766233766, 0.3612903225806451, 0.43478260869565216, 0.45962732919254656, 0.32911392405063294, 0.37662337662337664, 0.4000000000000001, 0.40993788819875776, 0.40993788819875776, 0.31645569620253167, 0.36363636363636365, 0.4000000000000001, 0.37267080745341613, 0.33540372670807456, 0.36708860759493667, 0.3116883116883117, 0.38709677419354843, 0.39751552795031053, 0.4472049689440994, 0.43037974683544306, 0.40259740259740256, 0.3741935483870968, 0.3478260869565218, 0.3726708074534162, 0.4177215189873418, 0.27272727272727276, 0.4645161290322581, 0.37267080745341613, 0.40993788819875776, 0.44303797468354433, 0.3116883116883117, 0.38709677419354843, 0.42236024844720493, 0.4720496894409938, 0.4177215189873418, 0.3896103896103896, 0.3225806451612903, 0.484472049689441, 0.4472049689440994, 0.36708860759493667, 0.36363636363636365, 0.3741935483870968, 0.4596273291925466, 0.39751552795031053, 0.46835443037974683, 0.33766233766233766, 0.34838709677419355, 0.42236024844720493, 0.4472049689440994, 0.4050632911392405, 0.3116883116883117, 0.2967741935483871, 0.33540372670807456, 0.3478260869565218, 0.34177215189873417, 0.37662337662337664, 0.335483870967742, 0.43478260869565216, 0.40993788819875776, 0.34177215189873417, 0.3246753246753247, 0.34838709677419355, 0.3478260869565218, 0.3726708074534162, 0.4177215189873418, 0.3896103896103896, 0.335483870967742, 0.3602484472049689, 0.39751552795031053, 0.43037974683544306, 0.42857142857142855, 0.2838709677419355, 0.39751552795031053, 0.4720496894409938, 0.3924050632911393, 0.33766233766233766, 0.335483870967742, 0.39751552795031053, 0.422360248447205, 0.34177215189873417, 0.36363636363636365, 0.3612903225806451, 0.3478260869565218, 0.39751552795031053, 0.37974683544303806, 0.4155844155844156, 0.3225806451612903, 0.39751552795031053, 0.49689440993788814, 0.4177215189873418, 0.42857142857142855, 0.3612903225806451, 0.39751552795031053, 0.40993788819875776, 0.36708860759493667, 0.3896103896103896, 0.335483870967742, 0.5093167701863354, 0.39751552795031053, 0.3924050632911393, 0.3246753246753247, 0.43870967741935485, 0.40993788819875776, 0.3478260869565218, 0.4050632911392405, 0.4155844155844156, 0.34838709677419355, 0.3602484472049689, 0.3478260869565218, 0.37974683544303806, 0.33766233766233766, 0.3741935483870968, 0.3602484472049689, 0.40993788819875776, 0.4810126582278481, 0.40259740259740256, 0.3741935483870968, 0.42236024844720493, 0.5217391304347826, 0.4050632911392405, 0.42857142857142855, 0.4000000000000001, 0.43478260869565216, 0.4347826086956522, 0.34177215189873417, 0.36363636363636365, 0.38709677419354843, 0.37267080745341613, 0.40993788819875776, 0.37974683544303806, 0.3896103896103896, 0.34838709677419355, 0.4472049689440994, 0.36024844720496896, 0.4050632911392405, 0.42857142857142855, 0.335483870967742, 0.43478260869565216, 0.422360248447205, 0.4050632911392405, 0.37662337662337664, 0.3612903225806451, 0.43478260869565216, 0.3726708074534162, 0.43037974683544306, 0.33766233766233766, 0.4000000000000001, 0.37267080745341613, 0.3850931677018633, 0.31645569620253167, 0.3116883116883117, 0.335483870967742, 0.484472049689441, 0.3850931677018633, 0.4050632911392405, 0.36363636363636365, 0.3096774193548387, 0.40993788819875776, 0.4472049689440994, 0.32911392405063294, 0.4155844155844156, 0.4000000000000001, 0.37267080745341613, 0.4347826086956522, 0.34177215189873417, 0.4155844155844156, 0.34838709677419355, 0.3478260869565218, 0.45962732919254656, 0.34177215189873417, 0.3246753246753247, 0.45161290322580644, 0.29813664596273287, 0.4347826086956522, 0.4050632911392405, 0.3116883116883117, 0.335483870967742, 0.33540372670807456, 0.40993788819875776, 0.3544303797468355, 0.40259740259740256, 0.38709677419354843, 0.4596273291925466, 0.3726708074534162, 0.3924050632911393, 0.4155844155844156, 0.43870967741935485, 0.43478260869565216, 0.36024844720496896, 0.4050632911392405, 0.4155844155844156, 0.38709677419354843, 0.40993788819875776, 0.40993788819875776, 0.4050632911392405, 0.36363636363636365, 0.4000000000000001, 0.4472049689440994, 0.40993788819875776, 0.43037974683544306, 0.42857142857142855, 0.3741935483870968, 0.484472049689441, 0.422360248447205, 0.3544303797468355, 0.4155844155844156, 0.4258064516129032, 0.3602484472049689, 0.3105590062111801, 0.43037974683544306, 0.33766233766233766, 0.3612903225806451, 0.4596273291925466, 0.3726708074534162, 0.34177215189873417, 0.3896103896103896, 0.3225806451612903, 0.38509316770186336, 0.40993788819875776, 0.34177215189873417, 0.3506493506493507, 0.4000000000000001, 0.42236024844720493, 0.45962732919254656, 0.37974683544303806, 0.29870129870129863, 0.3612903225806451, 0.39751552795031053, 0.4720496894409938, 0.31645569620253167, 0.4675324675324675, 0.3225806451612903, 0.31055900621118016, 0.422360248447205, 0.3924050632911393, 0.3116883116883117, 0.2580645161290323, 0.4472049689440994, 0.422360248447205, 0.36708860759493667, 0.4155844155844156, 0.3612903225806451, 0.39751552795031053, 0.39751552795031053, 0.3544303797468355, 0.36363636363636365, 0.3741935483870968, 0.38509316770186336, 0.39751552795031053, 0.4177215189873418, 0.40259740259740256, 0.3741935483870968, 0.37267080745341613, 0.40993788819875776, 0.2911392405063291, 0.4805194805194805, 0.335483870967742, 0.38509316770186336, 0.4347826086956522, 0.34177215189873417, 0.3896103896103896, 0.3741935483870968, 0.42236024844720493, 0.422360248447205, 0.45569620253164556, 0.3506493506493507, 0.34838709677419355, 0.37267080745341613, 0.422360248447205, 0.3924050632911393, 0.4675324675324675, 0.3225806451612903, 0.4596273291925466, 0.4720496894409938, 0.32911392405063294, 0.3116883116883117, 0.335483870967742, 0.3478260869565218, 0.4720496894409938, 0.4050632911392405, 0.29870129870129863, 0.41290322580645167, 0.31055900621118016, 0.39751552795031053, 0.45569620253164556, 0.3896103896103896, 0.45161290322580644, 0.29813664596273287, 0.39751552795031053, 0.4050632911392405, 0.3506493506493507, 0.3225806451612903, 0.43478260869565216, 0.40993788819875776, 0.37974683544303806, 0.3506493506493507, 0.4000000000000001, 0.3602484472049689, 0.45962732919254656, 0.37974683544303806, 0.36363636363636365, 0.47741935483870973, 0.42236024844720493, 0.3478260869565218, 0.3924050632911393, 0.3116883116883117, 0.3225806451612903, 0.43478260869565216, 0.45962732919254656, 0.36708860759493667, 0.42857142857142855, 0.38709677419354843, 0.33540372670807456, 0.422360248447205, 0.3544303797468355, 0.45454545454545453, 0.3225806451612903, 0.42236024844720493, 0.422360248447205, 0.31645569620253167, 0.40259740259740256, 0.3225806451612903, 0.3478260869565218, 0.4472049689440994, 0.3924050632911393, 0.3506493506493507, 0.3741935483870968, 0.40993788819875776, 0.422360248447205, 0.3544303797468355, 0.29870129870129863, 0.38709677419354843, 0.4472049689440994, 0.422360248447205, 0.36708860759493667, 0.36363636363636365, 0.3741935483870968, 0.42236024844720493, 0.4720496894409938, 0.37974683544303806, 0.42857142857142855, 0.43870967741935485, 0.33540372670807456, 0.39751552795031053, 0.32911392405063294, 0.44155844155844154, 0.4258064516129032, 0.42236024844720493, 0.4347826086956522, 0.3924050632911393, 0.37662337662337664, 0.41290322580645167, 0.38509316770186336, 0.39751552795031053, 0.4050632911392405, 0.40259740259740256, 0.335483870967742, 0.4472049689440994, 0.422360248447205, 0.26582278481012656, 0.36363636363636365, 0.34838709677419355, 0.37267080745341613, 0.4347826086956522, 0.27848101265822783, 0.42857142857142855, 0.38709677419354843, 0.40993788819875776, 0.39751552795031053, 0.3924050632911393, 0.37662337662337664, 0.3741935483870968, 0.4720496894409938, 0.2981366459627329, 0.37974683544303806, 0.3246753246753247, 0.2967741935483871, 0.43478260869565216, 0.3726708074534162, 0.3924050632911393, 0.4155844155844156, 0.3741935483870968, 0.3478260869565218, 0.422360248447205, 0.37974683544303806, 0.3246753246753247, 0.4000000000000001, 0.39751552795031053, 0.39751552795031053, 0.3544303797468355, 0.36363636363636365, 0.335483870967742, 0.40993788819875776, 0.3850931677018633, 0.3544303797468355, 0.3506493506493507, 0.2967741935483871, 0.43478260869565216, 0.4720496894409938, 0.36708860759493667, 0.42857142857142855, 0.3741935483870968, 0.38509316770186336, 0.3726708074534162, 0.3037974683544304, 0.3506493506493507, 0.335483870967742, 0.37267080745341613, 0.39751552795031053, 0.3544303797468355, 0.40259740259740256, 0.3225806451612903, 0.42236024844720493, 0.3850931677018633, 0.32911392405063294, 0.44155844155844154, 0.38709677419354843, 0.31055900621118016, 0.3229813664596274, 0.3924050632911393, 0.3116883116883117, 0.2709677419354839, 0.40993788819875776, 0.3850931677018633, 0.37974683544303806, 0.33766233766233766, 0.4258064516129032, 0.37267080745341613, 0.39751552795031053, 0.4177215189873418, 0.3116883116883117, 0.3096774193548387, 0.33540372670807456, 0.4720496894409938, 0.34177215189873417, 0.3246753246753247, 0.3225806451612903, 0.4472049689440994, 0.45962732919254656, 0.3924050632911393, 0.3506493506493507, 0.3225806451612903, 0.40993788819875776, 0.40993788819875776, 0.4050632911392405, 0.33766233766233766, 0.3612903225806451, 0.37267080745341613, 0.422360248447205, 0.3924050632911393, 0.3896103896103896, 0.34838709677419355, 0.37267080745341613, 0.3478260869565218, 0.4050632911392405, 0.33766233766233766, 0.3741935483870968, 0.43478260869565216, 0.4472049689440994, 0.3924050632911393, 0.42857142857142855, 0.4000000000000001, 0.39751552795031053, 0.422360248447205, 0.36708860759493667, 0.28571428571428575, 0.4645161290322581, 0.33540372670807456, 0.45962732919254656, 0.3037974683544304, 0.37662337662337664, 0.2967741935483871, 0.39751552795031053, 0.3850931677018633, 0.31645569620253167, 0.4805194805194805, 0.335483870967742, 0.39751552795031053, 0.4472049689440994, 0.36708860759493667, 0.37662337662337664, 0.3612903225806451, 0.38509316770186336, 0.4720496894409938, 0.4177215189873418, 0.29870129870129863, 0.4258064516129032, 0.3602484472049689, 0.4347826086956522, 0.37974683544303806, 0.40259740259740256, 0.38709677419354843, 0.33540372670807456, 0.36024844720496896, 0.32911392405063294, 0.3506493506493507, 0.2967741935483871, 0.42236024844720493, 0.4472049689440994, 0.3544303797468355, 0.37662337662337664, 0.3225806451612903, 0.39751552795031053, 0.3850931677018633, 0.36708860759493667, 0.42857142857142855, 0.3741935483870968, 0.43478260869565216, 0.4347826086956522, 0.37974683544303806, 0.4155844155844156, 0.47741935483870973, 0.37267080745341613, 0.36024844720496896, 0.36708860759493667, 0.3896103896103896, 0.335483870967742, 0.4472049689440994, 0.4347826086956522, 0.3544303797468355, 0.3896103896103896, 0.3741935483870968, 0.40993788819875776, 0.3850931677018633, 0.37974683544303806, 0.36363636363636365, 0.4258064516129032, 0.4720496894409938, 0.4347826086956522, 0.3037974683544304, 0.3896103896103896, 0.3612903225806451, 0.43478260869565216, 0.3478260869565218, 0.3924050632911393, 0.37662337662337664, 0.45161290322580644, 0.42236024844720493, 0.39751552795031053, 0.37974683544303806, 0.3896103896103896, 0.38709677419354843, 0.3602484472049689, 0.3229813664596274, 0.3037974683544304, 0.3116883116883117, 0.335483870967742, 0.28571428571428575, 0.4472049689440994, 0.3924050632911393, 0.36363636363636365, 0.38709677419354843, 0.3229813664596273, 0.4472049689440994, 0.43037974683544306, 0.3116883116883117, 0.3612903225806451, 0.38509316770186336, 0.3478260869565218, 0.4177215189873418, 0.3896103896103896, 0.4000000000000001, 0.37267080745341613, 0.39751552795031053, 0.37974683544303806, 0.3506493506493507, 0.47741935483870973, 0.38509316770186336, 0.39751552795031053, 0.3544303797468355, 0.36363636363636365, 0.41290322580645167, 0.5093167701863354, 0.4347826086956522, 0.3924050632911393, 0.36363636363636365, 0.34838709677419355, 0.37267080745341613, 0.4347826086956522, 0.3544303797468355, 0.33766233766233766, 0.2967741935483871, 0.3602484472049689, 0.3850931677018633, 0.44303797468354433, 0.3246753246753247, 0.3096774193548387, 0.38509316770186336, 0.3105590062111801, 0.3544303797468355, 0.42857142857142855, 0.3612903225806451, 0.43478260869565216, 0.3850931677018633, 0.43037974683544306, 0.3246753246753247, 0.4000000000000001, 0.3478260869565218, 0.45962732919254656, 0.36708860759493667, 0.3896103896103896, 0.34838709677419355, 0.39751552795031053, 0.3726708074534162, 0.2531645569620253, 0.4155844155844156, 0.41290322580645167, 0.31055900621118016, 0.36024844720496896, 0.46835443037974683, 0.4155844155844156, 0.3741935483870968, 0.29813664596273287, 0.36024844720496896, 0.37974683544303806, 0.29870129870129863, 0.3612903225806451, 0.3602484472049689, 0.36024844720496896, 0.32911392405063294, 0.33766233766233766, 0.4000000000000001, 0.42236024844720493, 0.39751552795031053, 0.32911392405063294, 0.37662337662337664, 0.34838709677419355, 0.43478260869565216, 0.4720496894409938, 0.3544303797468355, 0.36363636363636365, 0.3096774193548387, 0.3478260869565218, 0.40993788819875776, 0.3037974683544304, 0.37662337662337664, 0.335483870967742, 0.33540372670807456, 0.33540372670807456, 0.31645569620253167, 0.3506493506493507, 0.3612903225806451, 0.38509316770186336, 0.40993788819875776, 0.4050632911392405, 0.3116883116883117, 0.3225806451612903, 0.33540372670807456, 0.3726708074534162, 0.43037974683544306, 0.40259740259740256, 0.45161290322580644, 0.38509316770186336, 0.4720496894409938, 0.36708860759493667, 0.3116883116883117, 0.38709677419354843, 0.38509316770186336, 0.40993788819875776, 0.43037974683544306, 0.3896103896103896, 0.3096774193548387, 0.42236024844720493, 0.39751552795031053, 0.34177215189873417, 0.4935064935064935, 0.4000000000000001, 0.39751552795031053, 0.45962732919254656, 0.32911392405063294, 0.29870129870129863, 0.4258064516129032, 0.38509316770186336, 0.3229813664596274, 0.4177215189873418, 0.3896103896103896, 0.3612903225806451, 0.3478260869565218, 0.422360248447205, 0.36708860759493667, 0.3116883116883117, 0.45161290322580644, 0.38509316770186336, 0.4347826086956522, 0.4050632911392405, 0.36363636363636365, 0.3612903225806451, 0.31055900621118016, 0.39751552795031053, 0.3544303797468355, 0.3896103896103896, 0.38709677419354843, 0.3229813664596273, 0.4347826086956522, 0.32911392405063294, 0.37662337662337664, 0.2838709677419355, 0.3602484472049689, 0.422360248447205, 0.34177215189873417, 0.3506493506493507, 0.34838709677419355, 0.37267080745341613, 0.422360248447205, 0.31645569620253167, 0.3506493506493507, 0.4000000000000001, 0.4720496894409938, 0.45962732919254656, 0.36708860759493667, 0.3506493506493507, 0.34838709677419355, 0.3602484472049689, 0.40993788819875776, 0.4177215189873418, 0.3506493506493507, 0.3612903225806451, 0.33540372670807456, 0.3478260869565218, 0.45569620253164556, 0.3506493506493507, 0.3612903225806451, 0.38509316770186336, 0.40993788819875776, 0.3924050632911393, 0.3896103896103896, 0.43870967741935485, 0.4720496894409938, 0.39751552795031053, 0.3924050632911393, 0.27272727272727276, 0.3741935483870968, 0.3602484472049689, 0.40993788819875776, 0.36708860759493667, 0.4155844155844156, 0.335483870967742, 0.42236024844720493, 0.40993788819875776, 0.3544303797468355, 0.3896103896103896, 0.335483870967742, 0.42236024844720493, 0.40993788819875776, 0.3544303797468355, 0.33766233766233766, 0.41290322580645167, 0.3229813664596273, 0.3726708074534162, 0.34177215189873417, 0.40259740259740256, 0.3741935483870968, 0.29813664596273287, 0.3105590062111801, 0.26582278481012656, 0.3506493506493507, 0.3096774193548387, 0.3602484472049689, 0.3850931677018633, 0.36708860759493667, 0.36363636363636365, 0.335483870967742, 0.43478260869565216, 0.4472049689440994, 0.37974683544303806, 0.3116883116883117, 0.335483870967742, 0.39751552795031053, 0.3105590062111801, 0.37974683544303806, 0.4155844155844156, 0.34838709677419355, 0.43478260869565216, 0.422360248447205, 0.2911392405063291, 0.33766233766233766, 0.38709677419354843, 0.40993788819875776, 0.40993788819875776, 0.46835443037974683, 0.3896103896103896, 0.3741935483870968, 0.4472049689440994, 0.39751552795031053, 0.34177215189873417, 0.37662337662337664, 0.38709677419354843, 0.4472049689440994, 0.3850931677018633, 0.3924050632911393, 0.3116883116883117, 0.38709677419354843, 0.40993788819875776, 0.45962732919254656, 0.32911392405063294, 0.40259740259740256, 0.34838709677419355, 0.39751552795031053, 0.4720496894409938, 0.4050632911392405, 0.4155844155844156, 0.3612903225806451, 0.43478260869565216, 0.4472049689440994, 0.3924050632911393, 0.45454545454545453, 0.2967741935483871, 0.43478260869565216, 0.3478260869565218, 0.34177215189873417, 0.40259740259740256, 0.335483870967742, 0.4596273291925466, 0.3850931677018633, 0.36708860759493667, 0.45454545454545453, 0.335483870967742, 0.42236024844720493, 0.4347826086956522, 0.49367088607594933, 0.33766233766233766, 0.3225806451612903, 0.39751552795031053, 0.39751552795031053, 0.3924050632911393, 0.36363636363636365, 0.335483870967742, 0.484472049689441, 0.48447204968944096, 0.4050632911392405, 0.3246753246753247, 0.4258064516129032, 0.38509316770186336, 0.4347826086956522, 0.36708860759493667, 0.3506493506493507, 0.41290322580645167, 0.4720496894409938, 0.36024844720496896, 0.4177215189873418, 0.29870129870129863, 0.4000000000000001, 0.3602484472049689, 0.45962732919254656, 0.36708860759493667, 0.3116883116883117, 0.3225806451612903, 0.42236024844720493, 0.39751552795031053, 0.3924050632911393, 0.37662337662337664, 0.2580645161290323, 0.40993788819875776, 0.4347826086956522, 0.36708860759493667, 0.37662337662337664, 0.3741935483870968, 0.3478260869565218, 0.39751552795031053, 0.3924050632911393, 0.37662337662337664, 0.3741935483870968, 0.38509316770186336, 0.4472049689440994, 0.4177215189873418, 0.40259740259740256, 0.3741935483870968, 0.28571428571428575, 0.40993788819875776, 0.4050632911392405, 0.36363636363636365, 0.3612903225806451, 0.42236024844720493, 0.3726708074534162, 0.43037974683544306, 0.4675324675324675, 0.3612903225806451, 0.42236024844720493, 0.3726708074534162, 0.3037974683544304, 0.45454545454545453, 0.4258064516129032, 0.40993788819875776, 0.3850931677018633, 0.43037974683544306, 0.3506493506493507, 0.4258064516129032, 0.38509316770186336, 0.422360248447205, 0.4050632911392405, 0.33766233766233766, 0.38709677419354843, 0.37267080745341613, 0.3478260869565218, 0.36708860759493667, 0.3896103896103896, 0.38709677419354843, 0.37267080745341613, 0.40993788819875776, 0.32911392405063294, 0.3506493506493507, 0.2838709677419355, 0.37267080745341613, 0.39751552795031053, 0.3544303797468355, 0.37662337662337664, 0.34838709677419355, 0.37267080745341613, 0.3850931677018633, 0.4177215189873418, 0.40259740259740256, 0.34838709677419355, 0.33540372670807456, 0.3850931677018633, 0.34177215189873417, 0.33766233766233766, 0.3225806451612903, 0.42236024844720493, 0.4720496894409938, 0.3037974683544304, 0.23376623376623376, 0.335483870967742, 0.4720496894409938, 0.39751552795031053, 0.37974683544303806, 0.33766233766233766, 0.45161290322580644, 0.38509316770186336, 0.40993788819875776, 0.44303797468354433, 0.3896103896103896, 0.3096774193548387, 0.3602484472049689, 0.39751552795031053, 0.4177215189873418, 0.36363636363636365, 0.38709677419354843, 0.38509316770186336, 0.422360248447205, 0.36708860759493667, 0.3896103896103896, 0.3741935483870968, 0.3229813664596273, 0.3726708074534162, 0.37974683544303806, 0.3896103896103896, 0.34838709677419355, 0.33540372670807456, 0.4472049689440994, 0.37974683544303806, 0.36363636363636365, 0.4000000000000001, 0.39751552795031053, 0.422360248447205, 0.31645569620253167, 0.29870129870129863, 0.3612903225806451, 0.37267080745341613, 0.422360248447205, 0.37974683544303806, 0.3896103896103896, 0.41290322580645167, 0.37267080745341613, 0.45962732919254656, 0.4177215189873418, 0.3506493506493507, 0.41290322580645167, 0.38509316770186336, 0.3850931677018633, 0.36708860759493667, 0.3506493506493507, 0.34838709677419355, 0.40993788819875776, 0.3850931677018633, 0.45569620253164556, 0.33766233766233766, 0.3612903225806451, 0.484472049689441, 0.36024844720496896, 0.31645569620253167, 0.4155844155844156, 0.3612903225806451, 0.42236024844720493, 0.422360248447205, 0.36708860759493667, 0.3896103896103896, 0.43870967741935485, 0.33540372670807456, 0.4472049689440994, 0.37974683544303806, 0.40259740259740256, 0.3612903225806451, 0.31055900621118016, 0.48447204968944096, 0.34177215189873417, 0.3896103896103896, 0.2967741935483871, 0.38509316770186336, 0.4472049689440994, 0.45569620253164556, 0.37662337662337664, 0.41290322580645167, 0.3602484472049689, 0.39751552795031053, 0.4050632911392405, 0.3896103896103896, 0.3225806451612903, 0.3602484472049689, 0.48447204968944096, 0.4050632911392405, 0.44155844155844154, 0.34838709677419355, 0.39751552795031053, 0.36024844720496896, 0.3924050632911393, 0.40259740259740256, 0.3096774193548387, 0.37267080745341613, 0.4720496894409938, 0.4177215189873418, 0.40259740259740256, 0.5032258064516129, 0.3478260869565218, 0.4472049689440994, 0.37974683544303806, 0.36363636363636365, 0.3225806451612903, 0.40993788819875776, 0.4347826086956522, 0.36708860759493667, 0.45454545454545453, 0.4258064516129032, 0.37267080745341613, 0.422360248447205, 0.37974683544303806, 0.3116883116883117, 0.38709677419354843, 0.43478260869565216, 0.3478260869565218, 0.36708860759493667, 0.40259740259740256, 0.34838709677419355, 0.3602484472049689, 0.3850931677018633, 0.37974683544303806, 0.29870129870129863, 0.4000000000000001, 0.42236024844720493, 0.3850931677018633, 0.37974683544303806, 0.3896103896103896, 0.4645161290322581, 0.3602484472049689, 0.45962732919254656, 0.32911392405063294, 0.37662337662337664, 0.3096774193548387, 0.40993788819875776, 0.422360248447205, 0.3544303797468355, 0.37662337662337664, 0.3612903225806451, 0.3478260869565218, 0.3850931677018633, 0.31645569620253167, 0.3506493506493507, 0.38709677419354843, 0.3478260869565218, 0.45962732919254656, 0.3924050632911393, 0.3506493506493507, 0.47741935483870973, 0.4596273291925466, 0.3850931677018633, 0.34177215189873417, 0.37662337662337664, 0.2967741935483871, 0.40993788819875776, 0.40993788819875776, 0.3544303797468355, 0.36363636363636365, 0.43870967741935485, 0.33540372670807456, 0.4720496894409938, 0.4177215189873418, 0.36363636363636365, 0.335483870967742, 0.38509316770186336, 0.3850931677018633, 0.32911392405063294, 0.37662337662337664, 0.3612903225806451, 0.37267080745341613, 0.422360248447205, 0.4177215189873418, 0.3246753246753247, 0.38709677419354843, 0.4472049689440994, 0.40993788819875776, 0.43037974683544306, 0.29870129870129863, 0.3225806451612903, 0.37267080745341613, 0.422360248447205, 0.37974683544303806, 0.40259740259740256, 0.335483870967742, 0.43478260869565216, 0.422360248447205, 0.3037974683544304, 0.37662337662337664, 0.335483870967742, 0.3478260869565218, 0.3850931677018633, 0.43037974683544306, 0.3246753246753247, 0.335483870967742, 0.39751552795031053, 0.4472049689440994, 0.4177215189873418, 0.4155844155844156, 0.34838709677419355, 0.3478260869565218, 0.422360248447205, 0.37974683544303806, 0.3246753246753247, 0.335483870967742, 0.40993788819875776, 0.48447204968944096, 0.31645569620253167, 0.40259740259740256, 0.4000000000000001, 0.37267080745341613, 0.33540372670807456, 0.36708860759493667, 0.33766233766233766, 0.3225806451612903, 0.37267080745341613, 0.4472049689440994, 0.3924050632911393, 0.36363636363636365, 0.4000000000000001, 0.3602484472049689, 0.4347826086956522, 0.3544303797468355, 0.3896103896103896, 0.4000000000000001, 0.42236024844720493, 0.39751552795031053, 0.36708860759493667, 0.36363636363636365, 0.3741935483870968, 0.37267080745341613, 0.45962732919254656, 0.37974683544303806, 0.3246753246753247, 0.335483870967742, 0.40993788819875776, 0.33540372670807456, 0.3924050632911393, 0.4805194805194805, 0.41290322580645167, 0.39751552795031053, 0.422360248447205, 0.32911392405063294, 0.4155844155844156, 0.3741935483870968, 0.3602484472049689, 0.40993788819875776, 0.3544303797468355, 0.3896103896103896, 0.3225806451612903, 0.42236024844720493, 0.45962732919254656, 0.3924050632911393, 0.3116883116883117, 0.3225806451612903, 0.37267080745341613, 0.4347826086956522, 0.2911392405063291, 0.3246753246753247, 0.3612903225806451, 0.40993788819875776, 0.40993788819875776, 0.4177215189873418, 0.37662337662337664, 0.3741935483870968, 0.3602484472049689, 0.39751552795031053, 0.4050632911392405, 0.40259740259740256, 0.3225806451612903, 0.42236024844720493, 0.3850931677018633, 0.4050632911392405, 0.3896103896103896, 0.38709677419354843, 0.4472049689440994, 0.39751552795031053, 0.34177215189873417, 0.3896103896103896, 0.45161290322580644, 0.42236024844720493, 0.3850931677018633, 0.2911392405063291, 0.25974025974025977, 0.4645161290322581, 0.37267080745341613, 0.33540372670807456, 0.4050632911392405, 0.3896103896103896, 0.3225806451612903, 0.38509316770186336, 0.422360248447205, 0.37974683544303806, 0.33766233766233766, 0.3096774193548387, 0.37267080745341613, 0.422360248447205, 0.43037974683544306, 0.36363636363636365, 0.4258064516129032, 0.38509316770186336, 0.5093167701863355, 0.3544303797468355, 0.42857142857142855, 0.3225806451612903, 0.39751552795031053, 0.3229813664596274, 0.4177215189873418, 0.36363636363636365, 0.4258064516129032, 0.3602484472049689, 0.4720496894409938, 0.37974683544303806, 0.33766233766233766, 0.38709677419354843, 0.39751552795031053, 0.3850931677018633, 0.3924050632911393, 0.33766233766233766, 0.34838709677419355, 0.42236024844720493, 0.4347826086956522, 0.4050632911392405, 0.3896103896103896, 0.41290322580645167, 0.4472049689440994, 0.45962732919254656, 0.3544303797468355, 0.37662337662337664, 0.45161290322580644, 0.31055900621118016, 0.40993788819875776, 0.3544303797468355, 0.4155844155844156, 0.34838709677419355, 0.3229813664596273, 0.4472049689440994, 0.43037974683544306, 0.3246753246753247, 0.335483870967742, 0.37267080745341613, 0.3478260869565218, 0.3037974683544304, 0.3896103896103896, 0.41290322580645167, 0.42236024844720493, 0.33540372670807456, 0.4177215189873418, 0.36363636363636365, 0.3612903225806451, 0.4596273291925466, 0.4472049689440994, 0.37974683544303806, 0.4675324675324675, 0.2967741935483871, 0.4472049689440994, 0.422360248447205, 0.37974683544303806, 0.42857142857142855, 0.38709677419354843, 0.33540372670807456, 0.4472049689440994, 0.3924050632911393, 0.3896103896103896, 0.2967741935483871, 0.3478260869565218, 0.3850931677018633, 0.43037974683544306, 0.36363636363636365, 0.335483870967742, 0.42236024844720493, 0.36024844720496896, 0.36708860759493667, 0.37662337662337664, 0.41290322580645167, 0.484472049689441, 0.49689440993788814, 0.4050632911392405, 0.28571428571428575, 0.2709677419354839, 0.3602484472049689, 0.3850931677018633, 0.4050632911392405, 0.37662337662337664, 0.41290322580645167, 0.33540372670807456, 0.3478260869565218, 0.43037974683544306, 0.4155844155844156, 0.38709677419354843, 0.3478260869565218, 0.4347826086956522, 0.37974683544303806, 0.4155844155844156, 0.3612903225806451, 0.39751552795031053, 0.3726708074534162, 0.37974683544303806, 0.3116883116883117, 0.3741935483870968, 0.3478260869565218, 0.422360248447205, 0.43037974683544306, 0.3896103896103896, 0.3741935483870968, 0.37267080745341613, 0.3726708074534162, 0.37974683544303806, 0.3896103896103896, 0.38709677419354843, 0.40993788819875776, 0.3850931677018633, 0.3544303797468355, 0.36363636363636365, 0.43870967741935485, 0.2608695652173913, 0.4347826086956522, 0.3544303797468355, 0.3506493506493507, 0.2967741935483871, 0.37267080745341613, 0.39751552795031053, 0.44303797468354433, 0.36363636363636365, 0.3225806451612903, 0.43478260869565216, 0.4472049689440994, 0.44303797468354433, 0.28571428571428575, 0.4000000000000001, 0.4720496894409938, 0.40993788819875776, 0.3544303797468355, 0.3896103896103896, 0.3225806451612903, 0.31055900621118016, 0.3478260869565218, 0.4810126582278481, 0.28571428571428575, 0.4258064516129032, 0.40993788819875776, 0.4472049689440994, 0.32911392405063294, 0.42857142857142855, 0.2838709677419355, 0.3478260869565218, 0.4720496894409938, 0.4050632911392405, 0.40259740259740256, 0.3741935483870968, 0.3602484472049689, 0.49689440993788814, 0.37974683544303806, 0.3506493506493507, 0.38709677419354843, 0.37267080745341613, 0.4720496894409938, 0.4177215189873418, 0.37662337662337664, 0.2838709677419355, 0.33540372670807456, 0.5093167701863355, 0.36708860759493667, 0.3506493506493507, 0.2967741935483871, 0.3229813664596273, 0.422360248447205, 0.44303797468354433, 0.44155844155844154, 0.3225806451612903, 0.38509316770186336, 0.4472049689440994, 0.37974683544303806, 0.3506493506493507, 0.34838709677419355, 0.39751552795031053, 0.40993788819875776, 0.3037974683544304, 0.28571428571428575, 0.47741935483870973, 0.38509316770186336, 0.40993788819875776, 0.36708860759493667, 0.40259740259740256, 0.3741935483870968, 0.43478260869565216, 0.36024844720496896, 0.3544303797468355, 0.3506493506493507, 0.3096774193548387, 0.43478260869565216, 0.422360248447205, 0.37974683544303806, 0.3246753246753247, 0.4000000000000001, 0.38509316770186336, 0.422360248447205, 0.37974683544303806, 0.3896103896103896, 0.41290322580645167, 0.37267080745341613, 0.4347826086956522, 0.45569620253164556, 0.37662337662337664, 0.3612903225806451, 0.3478260869565218, 0.3726708074534162, 0.3924050632911393, 0.3506493506493507, 0.34838709677419355, 0.3229813664596273, 0.45962732919254656, 0.3544303797468355, 0.3506493506493507, 0.3096774193548387, 0.39751552795031053, 0.39751552795031053, 0.43037974683544306, 0.29870129870129863, 0.38709677419354843, 0.4472049689440994, 0.3478260869565218, 0.4177215189873418, 0.3116883116883117, 0.38709677419354843, 0.40993788819875776, 0.3726708074534162, 0.45569620253164556, 0.33766233766233766, 0.3612903225806451, 0.39751552795031053, 0.4720496894409938, 0.34177215189873417, 0.4155844155844156, 0.38709677419354843, 0.38509316770186336, 0.3726708074534162, 0.3544303797468355, 0.3896103896103896, 0.3741935483870968, 0.3229813664596273, 0.4347826086956522, 0.3544303797468355, 0.36363636363636365, 0.34838709677419355, 0.37267080745341613, 0.39751552795031053, 0.3924050632911393, 0.3506493506493507, 0.4645161290322581, 0.43478260869565216, 0.36024844720496896, 0.31645569620253167, 0.36363636363636365, 0.4258064516129032, 0.4472049689440994, 0.4720496894409938, 0.4050632911392405, 0.45454545454545453, 0.335483870967742, 0.43478260869565216, 0.40993788819875776, 0.36708860759493667, 0.45454545454545453, 0.3225806451612903, 0.4596273291925466, 0.40993788819875776, 0.44303797468354433, 0.29870129870129863, 0.43870967741935485, 0.3602484472049689, 0.4472049689440994, 0.4177215189873418, 0.36363636363636365, 0.3225806451612903, 0.37267080745341613, 0.422360248447205, 0.4177215189873418, 0.3506493506493507, 0.3612903225806451, 0.43478260869565216, 0.4347826086956522, 0.45569620253164556, 0.3116883116883117, 0.3741935483870968, 0.38509316770186336, 0.40993788819875776, 0.46835443037974683, 0.3896103896103896, 0.43870967741935485, 0.3478260869565218, 0.3478260869565218, 0.3544303797468355, 0.37662337662337664, 0.34838709677419355, 0.42236024844720493, 0.39751552795031053, 0.37974683544303806, 0.37662337662337664, 0.3612903225806451, 0.3602484472049689, 0.4472049689440994, 0.3544303797468355, 0.36363636363636365, 0.4000000000000001, 0.39751552795031053, 0.40993788819875776, 0.3544303797468355, 0.3896103896103896, 0.34838709677419355, 0.31055900621118016, 0.422360248447205, 0.36708860759493667, 0.28571428571428575, 0.45161290322580644, 0.37267080745341613, 0.422360248447205, 0.31645569620253167, 0.37662337662337664, 0.38709677419354843, 0.39751552795031053, 0.4472049689440994, 0.3544303797468355, 0.3896103896103896, 0.2838709677419355, 0.37267080745341613, 0.4347826086956522, 0.36708860759493667, 0.44155844155844154, 0.4000000000000001, 0.42236024844720493, 0.40993788819875776, 0.4177215189873418, 0.3896103896103896, 0.34838709677419355, 0.37267080745341613, 0.5217391304347826, 0.37974683544303806, 0.3896103896103896, 0.3741935483870968, 0.39751552795031053, 0.3726708074534162, 0.3544303797468355, 0.3896103896103896, 0.3612903225806451, 0.33540372670807456, 0.422360248447205, 0.34177215189873417, 0.4155844155844156, 0.335483870967742, 0.3602484472049689, 0.40993788819875776, 0.3924050632911393, 0.44155844155844154, 0.4258064516129032, 0.31055900621118016, 0.422360248447205, 0.3544303797468355, 0.36363636363636365, 0.335483870967742, 0.37267080745341613, 0.39751552795031053, 0.3544303797468355, 0.3246753246753247, 0.34838709677419355, 0.39751552795031053, 0.4472049689440994, 0.4177215189873418, 0.37662337662337664, 0.38709677419354843, 0.37267080745341613, 0.36024844720496896, 0.34177215189873417, 0.42857142857142855, 0.4258064516129032, 0.4472049689440994, 0.4472049689440994, 0.36708860759493667, 0.3896103896103896, 0.34838709677419355, 0.39751552795031053, 0.422360248447205, 0.3924050632911393, 0.42857142857142855, 0.3741935483870968, 0.31055900621118016, 0.45962732919254656, 0.2911392405063291, 0.36363636363636365, 0.34838709677419355, 0.37267080745341613, 0.422360248447205, 0.37974683544303806, 0.3896103896103896, 0.335483870967742, 0.38509316770186336, 0.3478260869565218, 0.36708860759493667, 0.33766233766233766, 0.45161290322580644, 0.3229813664596273, 0.48447204968944096, 0.4050632911392405, 0.4675324675324675, 0.4000000000000001, 0.4472049689440994, 0.3726708074534162, 0.3924050632911393, 0.44155844155844154, 0.43870967741935485, 0.40993788819875776, 0.4347826086956522, 0.36708860759493667, 0.37662337662337664, 0.43870967741935485, 0.4720496894409938, 0.48447204968944096, 0.34177215189873417, 0.3246753246753247, 0.34838709677419355, 0.38509316770186336, 0.40993788819875776, 0.4050632911392405, 0.40259740259740256, 0.4258064516129032, 0.37267080745341613, 0.33540372670807456, 0.37974683544303806, 0.4155844155844156, 0.38709677419354843, 0.39751552795031053, 0.422360248447205, 0.3544303797468355, 0.40259740259740256, 0.45161290322580644, 0.39751552795031053, 0.33540372670807456, 0.44303797468354433, 0.27272727272727276, 0.4258064516129032, 0.3478260869565218, 0.3850931677018633, 0.37974683544303806, 0.40259740259740256, 0.4000000000000001, 0.42236024844720493, 0.40993788819875776, 0.37974683544303806, 0.33766233766233766, 0.38709677419354843, 0.38509316770186336, 0.422360248447205, 0.4050632911392405, 0.33766233766233766, 0.335483870967742, 0.4596273291925466, 0.4472049689440994, 0.32911392405063294, 0.3506493506493507, 0.4000000000000001, 0.40993788819875776, 0.4720496894409938, 0.44303797468354433, 0.3506493506493507, 0.38709677419354843, 0.43478260869565216, 0.4347826086956522, 0.36708860759493667, 0.3116883116883117, 0.38709677419354843, 0.33540372670807456, 0.40993788819875776, 0.43037974683544306, 0.3896103896103896, 0.41290322580645167, 0.33540372670807456, 0.3478260869565218, 0.46835443037974683, 0.3116883116883117, 0.3612903225806451, 0.39751552795031053, 0.3850931677018633, 0.4177215189873418, 0.4155844155844156, 0.335483870967742, 0.37267080745341613, 0.3726708074534162, 0.43037974683544306, 0.45454545454545453, 0.38709677419354843, 0.42236024844720493, 0.4347826086956522, 0.3924050632911393, 0.3506493506493507, 0.41290322580645167, 0.31055900621118016, 0.4347826086956522, 0.44303797468354433, 0.3246753246753247, 0.3225806451612903, 0.40993788819875776, 0.45962732919254656, 0.4050632911392405, 0.33766233766233766, 0.3741935483870968, 0.40993788819875776, 0.45962732919254656, 0.4177215189873418, 0.3506493506493507, 0.3096774193548387, 0.37267080745341613, 0.39751552795031053, 0.4050632911392405, 0.33766233766233766, 0.38709677419354843, 0.38509316770186336, 0.39751552795031053, 0.3924050632911393, 0.36363636363636365, 0.3741935483870968, 0.3602484472049689, 0.40993788819875776, 0.3037974683544304, 0.33766233766233766, 0.41290322580645167, 0.38509316770186336, 0.4347826086956522, 0.34177215189873417, 0.37662337662337664, 0.4645161290322581, 0.39751552795031053, 0.422360248447205, 0.4177215189873418, 0.3246753246753247, 0.3741935483870968, 0.31055900621118016, 0.39751552795031053, 0.4050632911392405, 0.3246753246753247, 0.4000000000000001, 0.3602484472049689, 0.39751552795031053, 0.32911392405063294, 0.4155844155844156, 0.34838709677419355, 0.43478260869565216, 0.3850931677018633, 0.34177215189873417, 0.37662337662337664, 0.3612903225806451, 0.4596273291925466, 0.4347826086956522, 0.43037974683544306, 0.36363636363636365, 0.2709677419354839, 0.33540372670807456, 0.39751552795031053, 0.32911392405063294, 0.3246753246753247, 0.3096774193548387, 0.4472049689440994, 0.4347826086956522, 0.34177215189873417, 0.3116883116883117, 0.3612903225806451, 0.39751552795031053, 0.5093167701863355, 0.46835443037974683, 0.3506493506493507, 0.34838709677419355, 0.42236024844720493, 0.40993788819875776, 0.4177215189873418, 0.36363636363636365, 0.34838709677419355, 0.39751552795031053, 0.33540372670807456, 0.3924050632911393, 0.3896103896103896, 0.3225806451612903, 0.40993788819875776, 0.39751552795031053, 0.3924050632911393, 0.37662337662337664, 0.3612903225806451, 0.3229813664596273, 0.40993788819875776, 0.3924050632911393, 0.44155844155844154, 0.3096774193548387, 0.3602484472049689, 0.4347826086956522, 0.4050632911392405, 0.3896103896103896, 0.335483870967742, 0.4472049689440994, 0.5341614906832297, 0.32911392405063294, 0.3506493506493507, 0.3741935483870968, 0.39751552795031053, 0.422360248447205, 0.32911392405063294, 0.3506493506493507, 0.43870967741935485, 0.4720496894409938, 0.39751552795031053, 0.43037974683544306, 0.3246753246753247, 0.34838709677419355, 0.4472049689440994, 0.39751552795031053, 0.34177215189873417, 0.3506493506493507, 0.34838709677419355, 0.38509316770186336, 0.3726708074534162, 0.36708860759493667, 0.3506493506493507, 0.3741935483870968, 0.4596273291925466, 0.4347826086956522, 0.4050632911392405, 0.29870129870129863, 0.4000000000000001, 0.39751552795031053, 0.4347826086956522, 0.3924050632911393, 0.40259740259740256, 0.3612903225806451, 0.4472049689440994, 0.4472049689440994, 0.3037974683544304, 0.33766233766233766, 0.3612903225806451, 0.42236024844720493, 0.4347826086956522, 0.3544303797468355, 0.45454545454545453, 0.335483870967742, 0.37267080745341613, 0.4472049689440994, 0.3544303797468355, 0.33766233766233766, 0.335483870967742, 0.3478260869565218, 0.39751552795031053, 0.37974683544303806, 0.3246753246753247, 0.3741935483870968, 0.39751552795031053, 0.4347826086956522, 0.32911392405063294, 0.3896103896103896, 0.3741935483870968, 0.3602484472049689, 0.39751552795031053, 0.37974683544303806, 0.37662337662337664, 0.3741935483870968, 0.3602484472049689, 0.3850931677018633, 0.31645569620253167, 0.25974025974025977, 0.41290322580645167, 0.3478260869565218, 0.422360248447205, 0.43037974683544306, 0.4155844155844156, 0.3612903225806451, 0.3602484472049689, 0.4347826086956522, 0.3924050632911393, 0.40259740259740256, 0.3741935483870968, 0.38509316770186336, 0.48447204968944096, 0.34177215189873417, 0.37662337662337664, 0.4000000000000001, 0.3602484472049689, 0.48447204968944096, 0.3544303797468355, 0.4805194805194805, 0.335483870967742, 0.40993788819875776, 0.39751552795031053, 0.2911392405063291, 0.36363636363636365, 0.3096774193548387, 0.37267080745341613, 0.40993788819875776, 0.44303797468354433, 0.3896103896103896, 0.41290322580645167, 0.40993788819875776, 0.4347826086956522, 0.3924050632911393, 0.3896103896103896, 0.41290322580645167, 0.3478260869565218, 0.3726708074534162, 0.37974683544303806, 0.3246753246753247, 0.3096774193548387, 0.43478260869565216, 0.36024844720496896, 0.3544303797468355, 0.3246753246753247, 0.34838709677419355, 0.42236024844720493, 0.4472049689440994, 0.36708860759493667, 0.3116883116883117, 0.3225806451612903, 0.40993788819875776, 0.4472049689440994, 0.45569620253164556, 0.37662337662337664, 0.3096774193548387, 0.3478260869565218, 0.4347826086956522, 0.3037974683544304, 0.33766233766233766, 0.3741935483870968, 0.42236024844720493, 0.4472049689440994, 0.3924050632911393, 0.33766233766233766, 0.4258064516129032, 0.3602484472049689, 0.422360248447205, 0.34177215189873417, 0.3506493506493507, 0.4258064516129032, 0.33540372670807456, 0.40993788819875776, 0.44303797468354433, 0.44155844155844154, 0.4000000000000001, 0.39751552795031053, 0.3850931677018633, 0.4177215189873418, 0.37662337662337664, 0.34838709677419355, 0.3478260869565218, 0.3850931677018633, 0.31645569620253167, 0.33766233766233766, 0.45161290322580644, 0.37267080745341613, 0.3229813664596274, 0.43037974683544306, 0.3896103896103896, 0.4258064516129032, 0.37267080745341613, 0.48447204968944096, 0.4050632911392405, 0.4155844155844156, 0.45161290322580644, 0.42236024844720493, 0.45962732919254656, 0.36708860759493667, 0.33766233766233766, 0.3225806451612903, 0.42236024844720493, 0.48447204968944096, 0.36708860759493667, 0.29870129870129863, 0.3612903225806451, 0.37267080745341613, 0.422360248447205, 0.44303797468354433, 0.40259740259740256, 0.2967741935483871, 0.40993788819875776, 0.4720496894409938, 0.36708860759493667, 0.28571428571428575, 0.3612903225806451, 0.28571428571428575, 0.33540372670807456, 0.37974683544303806, 0.3506493506493507, 0.335483870967742, 0.4596273291925466, 0.5465838509316772, 0.37974683544303806, 0.42857142857142855, 0.3612903225806451, 0.4472049689440994, 0.3726708074534162, 0.36708860759493667, 0.4675324675324675, 0.2967741935483871, 0.40993788819875776, 0.4720496894409938, 0.43037974683544306, 0.3506493506493507, 0.3741935483870968, 0.43478260869565216, 0.40993788819875776, 0.4050632911392405, 0.40259740259740256, 0.335483870967742, 0.37267080745341613, 0.4472049689440994, 0.36708860759493667, 0.40259740259740256, 0.3612903225806451, 0.38509316770186336, 0.4720496894409938, 0.31645569620253167, 0.3116883116883117, 0.4000000000000001, 0.40993788819875776, 0.39751552795031053, 0.31645569620253167, 0.37662337662337664, 0.335483870967742, 0.37267080745341613, 0.3850931677018633, 0.31645569620253167, 0.40259740259740256, 0.45161290322580644, 0.3602484472049689, 0.39751552795031053, 0.44303797468354433, 0.29870129870129863, 0.34838709677419355, 0.42236024844720493, 0.3726708074534162, 0.34177215189873417, 0.40259740259740256, 0.3741935483870968, 0.3229813664596273, 0.39751552795031053, 0.4050632911392405, 0.27272727272727276, 0.4000000000000001, 0.37267080745341613, 0.40993788819875776, 0.45569620253164556, 0.3896103896103896, 0.34838709677419355, 0.3602484472049689, 0.36024844720496896, 0.34177215189873417, 0.3246753246753247, 0.3612903225806451, 0.38509316770186336, 0.3850931677018633, 0.3924050632911393, 0.37662337662337664, 0.38709677419354843, 0.37267080745341613, 0.40993788819875776, 0.34177215189873417, 0.3506493506493507, 0.3741935483870968, 0.3602484472049689, 0.39751552795031053, 0.4177215189873418, 0.44155844155844154, 0.38709677419354843, 0.3229813664596273, 0.4347826086956522, 0.31645569620253167, 0.3246753246753247, 0.3225806451612903, 0.40993788819875776, 0.4720496894409938, 0.4050632911392405, 0.40259740259740256, 0.3612903225806451, 0.39751552795031053, 0.48447204968944096, 0.34177215189873417, 0.40259740259740256, 0.3741935483870968, 0.42236024844720493, 0.3850931677018633, 0.2911392405063291, 0.37662337662337664, 0.41290322580645167, 0.37267080745341613, 0.422360248447205, 0.3544303797468355, 0.3506493506493507, 0.335483870967742, 0.38509316770186336, 0.4720496894409938, 0.31645569620253167, 0.37662337662337664, 0.4000000000000001, 0.3229813664596273, 0.4472049689440994, 0.4177215189873418, 0.33766233766233766, 0.3741935483870968, 0.3229813664596273, 0.40993788819875776, 0.3544303797468355, 0.37662337662337664, 0.34838709677419355, 0.3602484472049689, 0.3850931677018633, 0.43037974683544306, 0.3506493506493507, 0.3741935483870968, 0.33540372670807456, 0.4472049689440994, 0.37974683544303806, 0.27272727272727276, 0.335483870967742, 0.42236024844720493, 0.3478260869565218, 0.34177215189873417, 0.37662337662337664, 0.3225806451612903, 0.37267080745341613, 0.422360248447205, 0.4177215189873418, 0.40259740259740256, 0.3225806451612903, 0.38509316770186336, 0.39751552795031053, 0.36708860759493667, 0.3246753246753247, 0.3612903225806451, 0.38509316770186336, 0.36024844720496896, 0.37974683544303806, 0.40259740259740256, 0.3096774193548387, 0.37267080745341613, 0.3105590062111801, 0.36708860759493667, 0.3506493506493507, 0.38709677419354843, 0.3478260869565218, 0.40993788819875776, 0.32911392405063294, 0.33766233766233766, 0.3612903225806451, 0.3602484472049689, 0.4347826086956522, 0.4177215189873418, 0.3896103896103896, 0.41290322580645167, 0.3602484472049689, 0.4347826086956522, 0.32911392405063294, 0.40259740259740256, 0.4000000000000001, 0.38509316770186336, 0.3850931677018633, 0.44303797468354433, 0.3116883116883117, 0.34838709677419355, 0.37267080745341613, 0.3850931677018633, 0.3544303797468355, 0.3896103896103896, 0.38709677419354843, 0.3602484472049689, 0.40993788819875776, 0.4050632911392405, 0.37662337662337664, 0.335483870967742, 0.40993788819875776, 0.422360248447205, 0.3544303797468355, 0.40259740259740256, 0.3612903225806451, 0.39751552795031053, 0.40993788819875776, 0.44303797468354433, 0.4155844155844156, 0.3612903225806451, 0.3602484472049689, 0.422360248447205, 0.43037974683544306, 0.3506493506493507, 0.34838709677419355, 0.37267080745341613, 0.36024844720496896, 0.32911392405063294, 0.33766233766233766, 0.38709677419354843, 0.38509316770186336, 0.45962732919254656, 0.4177215189873418, 0.3506493506493507, 0.41290322580645167, 0.4596273291925466, 0.422360248447205, 0.36708860759493667, 0.3246753246753247, 0.45161290322580644, 0.3478260869565218, 0.4472049689440994, 0.4177215189873418, 0.37662337662337664, 0.3612903225806451, 0.3478260869565218, 0.40993788819875776, 0.34177215189873417, 0.3116883116883117, 0.3225806451612903, 0.4472049689440994, 0.48447204968944096, 0.4050632911392405, 0.3246753246753247, 0.34838709677419355, 0.3478260869565218, 0.3850931677018633, 0.44303797468354433, 0.37662337662337664, 0.3096774193548387, 0.42236024844720493, 0.4720496894409938, 0.45569620253164556, 0.3506493506493507, 0.4258064516129032, 0.484472049689441, 0.422360248447205, 0.43037974683544306, 0.45454545454545453, 0.34838709677419355, 0.40993788819875776, 0.40993788819875776, 0.3544303797468355, 0.36363636363636365, 0.3612903225806451, 0.4472049689440994, 0.4472049689440994, 0.4177215189873418, 0.37662337662337664, 0.4000000000000001, 0.40993788819875776, 0.40993788819875776, 0.36708860759493667, 0.3506493506493507, 0.34838709677419355, 0.3602484472049689, 0.45962732919254656, 0.36708860759493667, 0.3896103896103896, 0.43870967741935485, 0.39751552795031053, 0.39751552795031053, 0.4050632911392405, 0.4155844155844156, 0.4000000000000001, 0.42236024844720493, 0.422360248447205, 0.27848101265822783, 0.37662337662337664, 0.34838709677419355, 0.31055900621118016, 0.3726708074534162, 0.32911392405063294, 0.33766233766233766, 0.3741935483870968, 0.42236024844720493, 0.4472049689440994, 0.31645569620253167, 0.42857142857142855, 0.34838709677419355, 0.37267080745341613, 0.45962732919254656, 0.36708860759493667, 0.3506493506493507, 0.38709677419354843, 0.3602484472049689, 0.3726708074534162, 0.4177215189873418, 0.33766233766233766, 0.4000000000000001, 0.39751552795031053, 0.4347826086956522, 0.31645569620253167, 0.37662337662337664, 0.3741935483870968, 0.43478260869565216, 0.40993788819875776, 0.34177215189873417, 0.33766233766233766, 0.3096774193548387, 0.38509316770186336, 0.49689440993788814, 0.4050632911392405, 0.36363636363636365, 0.3741935483870968, 0.4720496894409938, 0.36024844720496896, 0.34177215189873417, 0.3896103896103896, 0.4258064516129032, 0.3229813664596273, 0.40993788819875776, 0.3924050632911393, 0.36363636363636365, 0.34838709677419355, 0.38509316770186336, 0.36024844720496896, 0.32911392405063294, 0.4155844155844156, 0.3741935483870968, 0.43478260869565216, 0.40993788819875776, 0.3544303797468355, 0.33766233766233766, 0.3741935483870968, 0.43478260869565216, 0.4347826086956522, 0.44303797468354433, 0.42857142857142855, 0.3612903225806451, 0.42236024844720493, 0.39751552795031053, 0.31645569620253167, 0.3506493506493507, 0.41290322580645167, 0.40993788819875776, 0.3850931677018633, 0.27848101265822783, 0.3246753246753247, 0.3612903225806451, 0.40993788819875776, 0.3229813664596274, 0.4177215189873418, 0.36363636363636365, 0.34838709677419355, 0.40993788819875776, 0.3850931677018633, 0.4177215189873418, 0.37662337662337664, 0.3612903225806451, 0.33540372670807456, 0.4720496894409938, 0.4810126582278481, 0.37662337662337664, 0.43870967741935485, 0.38509316770186336, 0.422360248447205, 0.3924050632911393, 0.3506493506493507, 0.38709677419354843, 0.38509316770186336, 0.49689440993788814, 0.4177215189873418, 0.36363636363636365, 0.38709677419354843, 0.3229813664596273, 0.36024844720496896, 0.32911392405063294, 0.3116883116883117, 0.335483870967742, 0.4472049689440994, 0.36024844720496896, 0.36708860759493667, 0.4155844155844156, 0.43870967741935485, 0.4472049689440994, 0.48447204968944096, 0.36708860759493667, 0.3506493506493507, 0.3225806451612903, 0.4472049689440994, 0.48447204968944096, 0.32911392405063294, 0.4675324675324675, 0.3612903225806451, 0.3478260869565218, 0.39751552795031053, 0.37974683544303806, 0.37662337662337664, 0.41290322580645167, 0.39751552795031053, 0.33540372670807456, 0.34177215189873417, 0.36363636363636365, 0.3225806451612903, 0.39751552795031053, 0.33540372670807456, 0.3924050632911393, 0.3506493506493507, 0.3612903225806451, 0.40993788819875776, 0.3229813664596274, 0.36708860759493667, 0.3896103896103896, 0.38709677419354843, 0.40993788819875776, 0.4472049689440994, 0.36708860759493667, 0.40259740259740256, 0.34838709677419355, 0.40993788819875776, 0.422360248447205, 0.3924050632911393, 0.3506493506493507, 0.43870967741935485, 0.39751552795031053, 0.45962732919254656, 0.31645569620253167, 0.29870129870129863, 0.335483870967742, 0.38509316770186336, 0.39751552795031053, 0.3924050632911393, 0.3506493506493507, 0.3612903225806451, 0.4472049689440994, 0.4347826086956522, 0.27848101265822783, 0.3246753246753247, 0.38709677419354843, 0.43478260869565216, 0.40993788819875776, 0.36708860759493667, 0.3506493506493507, 0.34838709677419355, 0.40993788819875776, 0.4347826086956522, 0.4177215189873418, 0.36363636363636365, 0.38709677419354843, 0.39751552795031053, 0.3726708074534162, 0.32911392405063294, 0.37662337662337664, 0.34838709677419355, 0.3602484472049689, 0.422360248447205, 0.34177215189873417, 0.36363636363636365, 0.2967741935483871, 0.4472049689440994, 0.39751552795031053, 0.4050632911392405, 0.3246753246753247, 0.4000000000000001, 0.37267080745341613, 0.4347826086956522, 0.3544303797468355, 0.4155844155844156, 0.38709677419354843, 0.4720496894409938, 0.422360248447205, 0.3924050632911393, 0.3246753246753247, 0.43870967741935485, 0.38509316770186336, 0.45962732919254656, 0.37974683544303806, 0.29870129870129863, 0.3096774193548387, 0.3602484472049689, 0.3478260869565218, 0.3924050632911393, 0.3506493506493507, 0.3741935483870968, 0.39751552795031053, 0.3478260869565218, 0.34177215189873417, 0.3246753246753247, 0.41290322580645167, 0.39751552795031053, 0.3850931677018633, 0.4177215189873418, 0.3506493506493507, 0.4000000000000001, 0.3229813664596273, 0.4720496894409938, 0.3544303797468355, 0.45454545454545453, 0.3225806451612903, 0.40993788819875776, 0.422360248447205, 0.34177215189873417, 0.3116883116883117, 0.38709677419354843, 0.4596273291925466, 0.422360248447205, 0.32911392405063294, 0.42857142857142855, 0.34838709677419355, 0.38509316770186336, 0.5217391304347826, 0.37974683544303806, 0.3246753246753247, 0.335483870967742, 0.3602484472049689, 0.4347826086956522, 0.34177215189873417, 0.3896103896103896, 0.335483870967742, 0.38509316770186336, 0.39751552795031053, 0.3544303797468355, 0.40259740259740256, 0.38709677419354843, 0.4472049689440994, 0.4472049689440994, 0.36708860759493667, 0.3506493506493507, 0.335483870967742, 0.37267080745341613, 0.3850931677018633, 0.37974683544303806, 0.3506493506493507, 0.4000000000000001, 0.40993788819875776, 0.4347826086956522, 0.32911392405063294, 0.42857142857142855, 0.5161290322580646, 0.3602484472049689, 0.40993788819875776, 0.37974683544303806, 0.40259740259740256, 0.38709677419354843, 0.31055900621118016, 0.39751552795031053, 0.4177215189873418, 0.45454545454545453, 0.2967741935483871, 0.33540372670807456, 0.3478260869565218, 0.4177215189873418, 0.3246753246753247, 0.41290322580645167, 0.37267080745341613, 0.3478260869565218, 0.36708860759493667, 0.36363636363636365, 0.41290322580645167, 0.38509316770186336, 0.422360248447205, 0.3924050632911393, 0.29870129870129863, 0.4000000000000001, 0.3602484472049689, 0.422360248447205, 0.32911392405063294, 0.44155844155844154, 0.3096774193548387, 0.3478260869565218, 0.39751552795031053, 0.4050632911392405, 0.3116883116883117, 0.3225806451612903, 0.43478260869565216, 0.36024844720496896, 0.3924050632911393, 0.40259740259740256, 0.2967741935483871, 0.38509316770186336, 0.39751552795031053, 0.37974683544303806, 0.36363636363636365, 0.335483870967742, 0.3478260869565218, 0.40993788819875776, 0.36708860759493667, 0.42857142857142855, 0.3612903225806451, 0.3602484472049689, 0.40993788819875776, 0.4177215189873418, 0.36363636363636365, 0.335483870967742, 0.38509316770186336, 0.422360248447205, 0.4810126582278481, 0.42857142857142855, 0.43870967741935485, 0.4596273291925466, 0.40993788819875776, 0.4050632911392405, 0.36363636363636365, 0.2580645161290323, 0.3602484472049689, 0.4472049689440994, 0.36708860759493667, 0.36363636363636365, 0.2838709677419355, 0.38509316770186336, 0.4347826086956522, 0.43037974683544306, 0.3246753246753247, 0.3741935483870968, 0.42236024844720493, 0.4472049689440994, 0.32911392405063294, 0.36363636363636365, 0.4258064516129032, 0.37267080745341613, 0.3850931677018633, 0.37974683544303806, 0.3896103896103896, 0.4000000000000001, 0.43478260869565216, 0.4347826086956522, 0.2911392405063291, 0.40259740259740256, 0.3096774193548387, 0.484472049689441, 0.5093167701863355, 0.36708860759493667, 0.40259740259740256, 0.3096774193548387, 0.3602484472049689, 0.39751552795031053, 0.4177215189873418, 0.3896103896103896, 0.335483870967742, 0.42236024844720493, 0.4472049689440994, 0.3544303797468355, 0.3246753246753247, 0.5161290322580646, 0.3602484472049689, 0.45962732919254656, 0.34177215189873417, 0.3246753246753247, 0.335483870967742, 0.42236024844720493, 0.3850931677018633, 0.3544303797468355, 0.36363636363636365, 0.3612903225806451, 0.43478260869565216, 0.3850931677018633, 0.3924050632911393, 0.37662337662337664, 0.38709677419354843, 0.4472049689440994, 0.39751552795031053, 0.4050632911392405, 0.3896103896103896, 0.38709677419354843, 0.39751552795031053, 0.40993788819875776, 0.4050632911392405, 0.33766233766233766, 0.38709677419354843, 0.42236024844720493, 0.40993788819875776, 0.3544303797468355, 0.33766233766233766, 0.34838709677419355, 0.3229813664596273, 0.3850931677018633, 0.3924050632911393, 0.3246753246753247, 0.43870967741935485, 0.39751552795031053, 0.3850931677018633, 0.4050632911392405, 0.36363636363636365, 0.335483870967742, 0.4472049689440994, 0.422360248447205, 0.36708860759493667, 0.28571428571428575, 0.4000000000000001, 0.3478260869565218, 0.422360248447205, 0.31645569620253167, 0.3896103896103896, 0.3225806451612903, 0.39751552795031053, 0.40993788819875776, 0.4050632911392405, 0.37662337662337664, 0.38709677419354843, 0.29813664596273287, 0.3850931677018633, 0.36708860759493667, 0.37662337662337664, 0.2967741935483871, 0.37267080745341613, 0.4347826086956522, 0.36708860759493667, 0.28571428571428575, 0.4000000000000001, 0.43478260869565216, 0.39751552795031053, 0.4177215189873418, 0.40259740259740256, 0.38709677419354843, 0.38509316770186336, 0.45962732919254656, 0.44303797468354433, 0.29870129870129863, 0.34838709677419355, 0.42236024844720493, 0.422360248447205, 0.4050632911392405, 0.3506493506493507, 0.4000000000000001, 0.40993788819875776, 0.3726708074534162, 0.34177215189873417, 0.29870129870129863, 0.4258064516129032, 0.4720496894409938, 0.39751552795031053, 0.4050632911392405, 0.33766233766233766, 0.335483870967742, 0.4596273291925466, 0.4472049689440994, 0.37974683544303806, 0.3506493506493507, 0.4000000000000001, 0.3478260869565218, 0.40993788819875776, 0.4177215189873418, 0.40259740259740256, 0.4000000000000001, 0.39751552795031053, 0.5093167701863355, 0.37974683544303806, 0.4155844155844156, 0.3612903225806451, 0.38509316770186336, 0.39751552795031053, 0.44303797468354433, 0.3246753246753247, 0.38709677419354843, 0.38509316770186336, 0.5093167701863355, 0.34177215189873417, 0.3896103896103896, 0.4258064516129032, 0.3478260869565218, 0.40993788819875776, 0.27848101265822783, 0.36363636363636365, 0.3225806451612903, 0.33540372670807456, 0.422360248447205, 0.43037974683544306, 0.33766233766233766, 0.4000000000000001, 0.31055900621118016, 0.48447204968944096, 0.37974683544303806, 0.44155844155844154, 0.34838709677419355, 0.33540372670807456, 0.4472049689440994, 0.3924050632911393, 0.36363636363636365, 0.3612903225806451, 0.4596273291925466, 0.39751552795031053, 0.34177215189873417, 0.4155844155844156, 0.3612903225806451, 0.37267080745341613, 0.4347826086956522, 0.34177215189873417, 0.42857142857142855, 0.3096774193548387, 0.37267080745341613, 0.3105590062111801, 0.3924050632911393, 0.36363636363636365, 0.335483870967742, 0.4720496894409938, 0.3478260869565218, 0.4050632911392405, 0.28571428571428575, 0.4000000000000001, 0.33540372670807456, 0.40993788819875776, 0.4177215189873418, 0.3506493506493507, 0.3741935483870968, 0.40993788819875776, 0.4720496894409938, 0.4177215189873418, 0.36363636363636365, 0.4000000000000001, 0.42236024844720493, 0.45962732919254656, 0.4050632911392405, 0.3896103896103896, 0.38709677419354843, 0.31055900621118016, 0.3229813664596274, 0.3544303797468355, 0.33766233766233766, 0.3741935483870968, 0.3602484472049689, 0.3850931677018633, 0.37974683544303806, 0.37662337662337664, 0.3225806451612903, 0.39751552795031053, 0.422360248447205, 0.46835443037974683, 0.44155844155844154, 0.3612903225806451, 0.40993788819875776, 0.3726708074534162, 0.31645569620253167, 0.40259740259740256, 0.2580645161290323, 0.4472049689440994, 0.36024844720496896, 0.34177215189873417, 0.37662337662337664, 0.38709677419354843, 0.4596273291925466, 0.4347826086956522, 0.36708860759493667, 0.40259740259740256, 0.3741935483870968, 0.38509316770186336, 0.422360248447205, 0.46835443037974683, 0.37662337662337664, 0.4258064516129032, 0.39751552795031053, 0.4347826086956522, 0.37974683544303806, 0.3896103896103896, 0.3096774193548387, 0.39751552795031053, 0.3726708074534162, 0.3544303797468355, 0.3506493506493507, 0.3612903225806451, 0.39751552795031053, 0.39751552795031053, 0.34177215189873417, 0.3896103896103896, 0.38709677419354843, 0.3229813664596273, 0.4472049689440994, 0.3924050632911393, 0.29870129870129863, 0.38709677419354843, 0.4596273291925466, 0.4472049689440994, 0.3544303797468355, 0.37662337662337664, 0.3741935483870968, 0.3602484472049689, 0.4347826086956522, 0.37974683544303806, 0.3896103896103896, 0.4000000000000001, 0.4596273291925466, 0.3478260869565218, 0.36708860759493667, 0.3506493506493507, 0.3612903225806451, 0.42236024844720493, 0.4472049689440994, 0.3544303797468355, 0.27272727272727276, 0.3612903225806451, 0.39751552795031053, 0.39751552795031053, 0.4050632911392405, 0.33766233766233766, 0.38709677419354843, 0.40993788819875776, 0.40993788819875776, 0.36708860759493667, 0.36363636363636365, 0.41290322580645167, 0.43478260869565216, 0.4472049689440994, 0.32911392405063294, 0.3116883116883117, 0.3225806451612903, 0.3602484472049689, 0.39751552795031053, 0.32911392405063294, 0.45454545454545453, 0.4000000000000001, 0.28571428571428575, 0.4347826086956522, 0.4050632911392405, 0.36363636363636365, 0.2838709677419355, 0.4720496894409938, 0.4347826086956522, 0.32911392405063294, 0.3246753246753247, 0.3741935483870968, 0.43478260869565216, 0.3726708074534162, 0.37974683544303806, 0.3506493506493507, 0.3612903225806451, 0.39751552795031053, 0.39751552795031053, 0.36708860759493667, 0.36363636363636365, 0.43870967741935485, 0.43478260869565216, 0.3850931677018633, 0.4050632911392405, 0.42857142857142855, 0.38709677419354843, 0.28571428571428575, 0.33540372670807456, 0.4050632911392405, 0.3506493506493507, 0.4258064516129032, 0.40993788819875776, 0.3726708074534162, 0.4810126582278481, 0.33766233766233766, 0.3612903225806451, 0.42236024844720493, 0.4472049689440994, 0.34177215189873417, 0.37662337662337664, 0.24516129032258063, 0.4472049689440994, 0.4347826086956522, 0.36708860759493667, 0.40259740259740256, 0.38709677419354843, 0.42236024844720493, 0.40993788819875776, 0.32911392405063294, 0.28571428571428575, 0.4000000000000001, 0.31055900621118016, 0.3850931677018633, 0.37974683544303806, 0.33766233766233766, 0.3225806451612903, 0.3229813664596273, 0.4720496894409938, 0.3544303797468355, 0.37662337662337664, 0.38709677419354843, 0.3229813664596273, 0.4347826086956522, 0.3924050632911393, 0.42857142857142855, 0.34838709677419355, 0.38509316770186336, 0.39751552795031053, 0.36708860759493667, 0.42857142857142855, 0.3096774193548387, 0.40993788819875776, 0.4347826086956522, 0.31645569620253167, 0.3506493506493507, 0.43870967741935485, 0.39751552795031053, 0.3478260869565218, 0.34177215189873417, 0.44155844155844154, 0.3612903225806451, 0.42236024844720493, 0.48447204968944096, 0.2911392405063291, 0.37662337662337664, 0.3096774193548387, 0.37267080745341613, 0.4347826086956522, 0.37974683544303806, 0.33766233766233766, 0.34838709677419355, 0.3478260869565218, 0.39751552795031053, 0.43037974683544306, 0.36363636363636365, 0.41290322580645167, 0.43478260869565216, 0.422360248447205, 0.4050632911392405, 0.36363636363636365, 0.4258064516129032, 0.33540372670807456, 0.422360248447205, 0.4050632911392405, 0.36363636363636365, 0.3612903225806451, 0.37267080745341613, 0.36024844720496896, 0.43037974683544306, 0.37662337662337664, 0.335483870967742, 0.37267080745341613, 0.48447204968944096, 0.37974683544303806, 0.4155844155844156, 0.41290322580645167, 0.4472049689440994, 0.45962732919254656, 0.2911392405063291, 0.36363636363636365, 0.38709677419354843, 0.38509316770186336, 0.5217391304347826, 0.37974683544303806, 0.36363636363636365, 0.2967741935483871, 0.40993788819875776, 0.40993788819875776, 0.34177215189873417, 0.3896103896103896, 0.3741935483870968, 0.42236024844720493, 0.49689440993788814, 0.3037974683544304, 0.40259740259740256, 0.34838709677419355, 0.40993788819875776, 0.39751552795031053, 0.4177215189873418, 0.40259740259740256, 0.3096774193548387, 0.38509316770186336, 0.4347826086956522, 0.34177215189873417, 0.37662337662337664, 0.3741935483870968, 0.49689440993788825, 0.39751552795031053, 0.3924050632911393, 0.3506493506493507, 0.4000000000000001, 0.3478260869565218, 0.422360248447205, 0.34177215189873417, 0.37662337662337664, 0.335483870967742, 0.37267080745341613, 0.36024844720496896, 0.44303797468354433, 0.3896103896103896, 0.4000000000000001, 0.43478260869565216, 0.40993788819875776, 0.32911392405063294, 0.3896103896103896, 0.41290322580645167, 0.31055900621118016, 0.4472049689440994, 0.4177215189873418, 0.3896103896103896, 0.34838709677419355, 0.40993788819875776, 0.39751552795031053, 0.3544303797468355, 0.3246753246753247, 0.4258064516129032, 0.39751552795031053, 0.4472049689440994, 0.3544303797468355, 0.42857142857142855, 0.4645161290322581, 0.29813664596273287, 0.39751552795031053, 0.36708860759493667, 0.3246753246753247, 0.3096774193548387, 0.33540372670807456, 0.4347826086956522, 0.3924050632911393, 0.45454545454545453, 0.4000000000000001, 0.40993788819875776, 0.40993788819875776, 0.4177215189873418, 0.37662337662337664, 0.41290322580645167, 0.37267080745341613, 0.4347826086956522, 0.3924050632911393, 0.36363636363636365, 0.4000000000000001, 0.39751552795031053, 0.4347826086956522, 0.34177215189873417, 0.33766233766233766, 0.34838709677419355, 0.39751552795031053, 0.422360248447205, 0.4810126582278481, 0.36363636363636365, 0.335483870967742, 0.42236024844720493, 0.3229813664596274, 0.32911392405063294, 0.3896103896103896, 0.3741935483870968, 0.38509316770186336, 0.40993788819875776, 0.3544303797468355, 0.3896103896103896, 0.335483870967742, 0.4720496894409938, 0.40993788819875776, 0.37974683544303806, 0.37662337662337664, 0.45161290322580644, 0.40993788819875776, 0.4472049689440994, 0.37974683544303806, 0.33766233766233766, 0.3741935483870968, 0.39751552795031053, 0.3850931677018633, 0.31645569620253167, 0.3896103896103896, 0.4258064516129032, 0.29813664596273287, 0.39751552795031053, 0.2911392405063291, 0.3506493506493507, 0.41290322580645167, 0.33540372670807456, 0.3850931677018633, 0.37974683544303806, 0.37662337662337664, 0.3741935483870968, 0.3478260869565218, 0.4472049689440994, 0.32911392405063294, 0.45454545454545453, 0.4000000000000001, 0.4596273291925466, 0.422360248447205, 0.34177215189873417, 0.40259740259740256, 0.4000000000000001, 0.38509316770186336, 0.3850931677018633, 0.37974683544303806, 0.3246753246753247, 0.3741935483870968, 0.40993788819875776, 0.4347826086956522, 0.3544303797468355, 0.3246753246753247, 0.41290322580645167, 0.4472049689440994, 0.3850931677018633, 0.4177215189873418, 0.3896103896103896, 0.3225806451612903, 0.3602484472049689, 0.422360248447205, 0.4050632911392405, 0.33766233766233766, 0.41290322580645167, 0.31055900621118016, 0.3229813664596274, 0.45569620253164556, 0.33766233766233766, 0.38709677419354843, 0.38509316770186336, 0.4472049689440994, 0.36708860759493667, 0.42857142857142855, 0.34838709677419355, 0.3602484472049689, 0.36024844720496896, 0.31645569620253167, 0.3246753246753247, 0.4258064516129032, 0.42236024844720493, 0.3726708074534162, 0.37974683544303806, 0.3506493506493507, 0.3096774193548387, 0.4472049689440994, 0.422360248447205, 0.2911392405063291, 0.3116883116883117, 0.3225806451612903, 0.37267080745341613, 0.3726708074534162, 0.36708860759493667, 0.3246753246753247, 0.3741935483870968, 0.42236024844720493, 0.3850931677018633, 0.36708860759493667, 0.3246753246753247, 0.4258064516129032, 0.42236024844720493, 0.3850931677018633, 0.3544303797468355, 0.4155844155844156, 0.4000000000000001, 0.4596273291925466, 0.4472049689440994, 0.3544303797468355, 0.3896103896103896, 0.3225806451612903, 0.3478260869565218, 0.45962732919254656, 0.4177215189873418, 0.4155844155844156, 0.3612903225806451, 0.37267080745341613, 0.45962732919254656, 0.36708860759493667, 0.3896103896103896, 0.3096774193548387, 0.38509316770186336, 0.422360248447205, 0.3544303797468355, 0.29870129870129863, 0.335483870967742, 0.42236024844720493, 0.3478260869565218, 0.31645569620253167, 0.33766233766233766, 0.45161290322580644, 0.42236024844720493, 0.3478260869565218, 0.36708860759493667, 0.36363636363636365, 0.2838709677419355, 0.4720496894409938, 0.39751552795031053, 0.36708860759493667, 0.3116883116883117, 0.34838709677419355, 0.39751552795031053, 0.39751552795031053, 0.4050632911392405, 0.37662337662337664, 0.3096774193548387, 0.38509316770186336, 0.40993788819875776, 0.4177215189873418, 0.42857142857142855, 0.3612903225806451, 0.42236024844720493, 0.39751552795031053, 0.3924050632911393, 0.3506493506493507, 0.4000000000000001, 0.40993788819875776, 0.40993788819875776, 0.37974683544303806, 0.3506493506493507, 0.4000000000000001, 0.38509316770186336, 0.48447204968944096, 0.4050632911392405, 0.3896103896103896, 0.3225806451612903, 0.38509316770186336, 0.39751552795031053, 0.4050632911392405, 0.3246753246753247, 0.2709677419354839, 0.40993788819875776, 0.36024844720496896, 0.4177215189873418, 0.3896103896103896, 0.4258064516129032, 0.38509316770186336, 0.3478260869565218, 0.4177215189873418, 0.37662337662337664, 0.4258064516129032, 0.43478260869565216, 0.33540372670807456, 0.3544303797468355, 0.36363636363636365, 0.38709677419354843, 0.3478260869565218, 0.422360248447205, 0.36708860759493667, 0.3506493506493507, 0.2838709677419355, 0.3478260869565218, 0.4472049689440994, 0.2911392405063291, 0.42857142857142855, 0.38709677419354843, 0.3478260869565218, 0.4472049689440994, 0.31645569620253167, 0.33766233766233766, 0.3741935483870968, 0.3478260869565218, 0.39751552795031053, 0.34177215189873417, 0.3896103896103896, 0.2967741935483871, 0.42236024844720493, 0.36024844720496896, 0.3924050632911393, 0.33766233766233766, 0.4000000000000001, 0.4596273291925466, 0.36024844720496896, 0.3544303797468355, 0.4155844155844156, 0.43870967741935485, 0.37267080745341613, 0.3726708074534162, 0.34177215189873417, 0.28571428571428575, 0.38709677419354843, 0.39751552795031053, 0.36024844720496896, 0.32911392405063294, 0.3506493506493507, 0.3612903225806451, 0.37267080745341613, 0.4347826086956522, 0.3544303797468355, 0.37662337662337664, 0.3612903225806451, 0.37267080745341613, 0.33540372670807456, 0.4177215189873418, 0.3506493506493507, 0.34838709677419355, 0.37267080745341613, 0.3726708074534162, 0.4050632911392405, 0.44155844155844154, 0.335483870967742, 0.43478260869565216, 0.4347826086956522, 0.34177215189873417, 0.28571428571428575, 0.34838709677419355, 0.43478260869565216, 0.40993788819875776, 0.34177215189873417, 0.28571428571428575, 0.3612903225806451, 0.40993788819875776, 0.45962732919254656, 0.34177215189873417, 0.3506493506493507, 0.43870967741935485, 0.3602484472049689, 0.40993788819875776, 0.43037974683544306, 0.3506493506493507, 0.3741935483870968, 0.29813664596273287, 0.4472049689440994, 0.34177215189873417, 0.42857142857142855, 0.41290322580645167, 0.33540372670807456, 0.39751552795031053, 0.43037974683544306, 0.3506493506493507, 0.3741935483870968, 0.3229813664596273, 0.45962732919254656, 0.3037974683544304, 0.42857142857142855, 0.3612903225806451, 0.42236024844720493, 0.4472049689440994, 0.3544303797468355, 0.3896103896103896, 0.2967741935483871, 0.40993788819875776, 0.4347826086956522, 0.4050632911392405, 0.33766233766233766, 0.2838709677419355, 0.40993788819875776, 0.4720496894409938, 0.37974683544303806, 0.3896103896103896, 0.3741935483870968, 0.31055900621118016, 0.4347826086956522, 0.3924050632911393, 0.3116883116883117, 0.4258064516129032, 0.39751552795031053, 0.39751552795031053, 0.32911392405063294, 0.37662337662337664, 0.34838709677419355, 0.37267080745341613, 0.40993788819875776, 0.36708860759493667, 0.36363636363636365, 0.3225806451612903, 0.42236024844720493, 0.40993788819875776, 0.4177215189873418, 0.40259740259740256, 0.3612903225806451, 0.4472049689440994, 0.39751552795031053, 0.4050632911392405, 0.29870129870129863, 0.4645161290322581, 0.28571428571428575, 0.4472049689440994, 0.4177215189873418, 0.27272727272727276, 0.4258064516129032, 0.3478260869565218, 0.48447204968944096, 0.44303797468354433, 0.3246753246753247, 0.3741935483870968, 0.3602484472049689, 0.4347826086956522, 0.36708860759493667, 0.4675324675324675, 0.2967741935483871, 0.38509316770186336, 0.3850931677018633, 0.3544303797468355, 0.37662337662337664, 0.3612903225806451, 0.33540372670807456, 0.39751552795031053, 0.32911392405063294, 0.36363636363636365, 0.38709677419354843, 0.38509316770186336, 0.33540372670807456, 0.34177215189873417, 0.36363636363636365, 0.2580645161290323, 0.3602484472049689, 0.39751552795031053, 0.3544303797468355, 0.44155844155844154, 0.3741935483870968, 0.3602484472049689, 0.4347826086956522, 0.4177215189873418, 0.37662337662337664, 0.4645161290322581, 0.4472049689440994, 0.3726708074534162, 0.34177215189873417, 0.36363636363636365, 0.4258064516129032, 0.38509316770186336, 0.45962732919254656, 0.3924050632911393, 0.42857142857142855, 0.45161290322580644, 0.40993788819875776, 0.4472049689440994, 0.43037974683544306, 0.37662337662337664, 0.4258064516129032, 0.43478260869565216, 0.3850931677018633, 0.31645569620253167, 0.36363636363636365, 0.45161290322580644, 0.40993788819875776, 0.3850931677018633, 0.4177215189873418, 0.37662337662337664, 0.335483870967742, 0.42236024844720493, 0.4347826086956522, 0.36708860759493667, 0.3896103896103896, 0.3612903225806451, 0.39751552795031053, 0.3726708074534162, 0.31645569620253167, 0.3246753246753247, 0.3096774193548387, 0.43478260869565216, 0.4347826086956522, 0.4050632911392405, 0.33766233766233766, 0.4000000000000001, 0.4472049689440994, 0.4347826086956522, 0.37974683544303806, 0.40259740259740256, 0.43870967741935485, 0.3602484472049689, 0.39751552795031053, 0.31645569620253167, 0.25974025974025977, 0.41290322580645167, 0.42236024844720493, 0.4347826086956522, 0.4177215189873418, 0.42857142857142855, 0.3225806451612903, 0.3478260869565218, 0.45962732919254656, 0.36708860759493667, 0.3506493506493507, 0.3612903225806451, 0.40993788819875776, 0.3726708074534162, 0.4177215189873418, 0.42857142857142855, 0.41290322580645167, 0.4720496894409938, 0.39751552795031053, 0.43037974683544306, 0.3116883116883117, 0.34838709677419355, 0.40993788819875776, 0.4347826086956522, 0.3924050632911393, 0.33766233766233766, 0.34838709677419355, 0.38509316770186336, 0.45962732919254656, 0.4050632911392405, 0.4805194805194805, 0.4258064516129032, 0.3478260869565218, 0.422360248447205, 0.4050632911392405, 0.37662337662337664, 0.41290322580645167, 0.38509316770186336, 0.40993788819875776, 0.3924050632911393, 0.37662337662337664, 0.3612903225806451, 0.3229813664596273, 0.36024844720496896, 0.3924050632911393, 0.29870129870129863, 0.38709677419354843, 0.38509316770186336, 0.4472049689440994, 0.4050632911392405, 0.4155844155844156, 0.38709677419354843, 0.33540372670807456, 0.4347826086956522, 0.34177215189873417, 0.37662337662337664, 0.34838709677419355, 0.43478260869565216, 0.36024844720496896, 0.36708860759493667, 0.40259740259740256, 0.38709677419354843, 0.4472049689440994, 0.36024844720496896, 0.45569620253164556, 0.4155844155844156, 0.335483870967742, 0.4472049689440994, 0.4472049689440994, 0.32911392405063294, 0.37662337662337664, 0.4000000000000001, 0.33540372670807456, 0.3726708074534162, 0.32911392405063294, 0.40259740259740256, 0.3225806451612903, 0.484472049689441, 0.3850931677018633, 0.43037974683544306, 0.37662337662337664, 0.34838709677419355, 0.42236024844720493, 0.422360248447205, 0.4050632911392405, 0.3896103896103896, 0.47741935483870973, 0.42236024844720493, 0.4472049689440994, 0.37974683544303806, 0.3506493506493507, 0.41290322580645167, 0.39751552795031053, 0.422360248447205, 0.34177215189873417, 0.44155844155844154, 0.3612903225806451, 0.42236024844720493, 0.3726708074534162, 0.2911392405063291, 0.28571428571428575, 0.4258064516129032, 0.4596273291925466, 0.3726708074534162, 0.4177215189873418, 0.44155844155844154, 0.4000000000000001, 0.3229813664596273, 0.40993788819875776, 0.44303797468354433, 0.36363636363636365, 0.2580645161290323, 0.37267080745341613, 0.40993788819875776, 0.43037974683544306, 0.42857142857142855, 0.38709677419354843, 0.38509316770186336, 0.3726708074534162, 0.37974683544303806, 0.25974025974025977, 0.3612903225806451, 0.39751552795031053, 0.422360248447205, 0.3924050632911393, 0.36363636363636365, 0.38709677419354843, 0.4472049689440994, 0.45962732919254656, 0.3924050632911393, 0.3506493506493507, 0.4000000000000001, 0.37267080745341613, 0.422360248447205, 0.3924050632911393, 0.40259740259740256, 0.3225806451612903, 0.3602484472049689, 0.40993788819875776, 0.43037974683544306, 0.37662337662337664, 0.34838709677419355, 0.42236024844720493, 0.4347826086956522, 0.34177215189873417, 0.42857142857142855, 0.41290322580645167, 0.29813664596273287, 0.40993788819875776, 0.36708860759493667, 0.3116883116883117, 0.38709677419354843, 0.39751552795031053, 0.3850931677018633, 0.2911392405063291, 0.37662337662337664, 0.3096774193548387, 0.40993788819875776, 0.3726708074534162, 0.44303797468354433, 0.3116883116883117, 0.3096774193548387, 0.4472049689440994, 0.39751552795031053, 0.36708860759493667, 0.29870129870129863, 0.3612903225806451, 0.38509316770186336, 0.3478260869565218, 0.37974683544303806, 0.3896103896103896, 0.4000000000000001, 0.38509316770186336, 0.45962732919254656, 0.43037974683544306, 0.4155844155844156, 0.4258064516129032, 0.40993788819875776, 0.40993788819875776, 0.4050632911392405, 0.40259740259740256, 0.41290322580645167, 0.4472049689440994, 0.5341614906832297, 0.3924050632911393, 0.40259740259740256, 0.3612903225806451, 0.37267080745341613, 0.3850931677018633, 0.44303797468354433, 0.3896103896103896, 0.34838709677419355, 0.39751552795031053, 0.3726708074534162, 0.3544303797468355, 0.37662337662337664, 0.38709677419354843, 0.37267080745341613, 0.4720496894409938, 0.36708860759493667, 0.28571428571428575, 0.34838709677419355, 0.33540372670807456, 0.45962732919254656, 0.45569620253164556, 0.3506493506493507, 0.38709677419354843, 0.3478260869565218, 0.4472049689440994, 0.4177215189873418, 0.3896103896103896, 0.34838709677419355, 0.4596273291925466, 0.422360248447205, 0.34177215189873417, 0.3246753246753247, 0.41290322580645167, 0.3602484472049689, 0.40993788819875776, 0.26582278481012656, 0.36363636363636365, 0.34838709677419355, 0.33540372670807456, 0.45962732919254656, 0.32911392405063294, 0.3116883116883117, 0.3225806451612903, 0.37267080745341613, 0.40993788819875776, 0.3924050632911393, 0.28571428571428575, 0.43870967741935485, 0.49689440993788825, 0.422360248447205, 0.27848101265822783, 0.3896103896103896, 0.3612903225806451, 0.37267080745341613, 0.422360248447205, 0.46835443037974683, 0.3116883116883117, 0.4000000000000001, 0.3602484472049689, 0.3726708074534162, 0.4050632911392405, 0.37662337662337664, 0.4258064516129032, 0.3602484472049689, 0.422360248447205, 0.3544303797468355, 0.33766233766233766, 0.2967741935483871, 0.40993788819875776, 0.3726708074534162, 0.36708860759493667, 0.3896103896103896, 0.3612903225806451, 0.37267080745341613, 0.4472049689440994, 0.44303797468354433, 0.3506493506493507, 0.38709677419354843, 0.37267080745341613, 0.3105590062111801, 0.43037974683544306, 0.36363636363636365, 0.3612903225806451, 0.3229813664596273, 0.4347826086956522, 0.36708860759493667, 0.36363636363636365, 0.3612903225806451, 0.37267080745341613, 0.4347826086956522, 0.32911392405063294, 0.3896103896103896, 0.3225806451612903, 0.42236024844720493, 0.40993788819875776, 0.4177215189873418, 0.23376623376623376, 0.47741935483870973, 0.42236024844720493, 0.45962732919254656, 0.34177215189873417, 0.33766233766233766, 0.2580645161290323, 0.38509316770186336, 0.4347826086956522, 0.36708860759493667, 0.4675324675324675, 0.2967741935483871, 0.42236024844720493, 0.39751552795031053, 0.36708860759493667, 0.33766233766233766, 0.38709677419354843, 0.39751552795031053, 0.40993788819875776, 0.37974683544303806, 0.4155844155844156, 0.3741935483870968, 0.3478260869565218, 0.3229813664596274, 0.37974683544303806, 0.36363636363636365, 0.3096774193548387, 0.43478260869565216, 0.422360248447205, 0.36708860759493667, 0.3116883116883117, 0.38709677419354843, 0.38509316770186336, 0.36024844720496896, 0.2911392405063291, 0.3506493506493507, 0.4258064516129032, 0.37267080745341613, 0.4347826086956522, 0.37974683544303806, 0.37662337662337664, 0.3612903225806451, 0.3478260869565218, 0.422360248447205, 0.46835443037974683, 0.37662337662337664, 0.4258064516129032, 0.37267080745341613, 0.422360248447205, 0.3544303797468355, 0.33766233766233766, 0.4645161290322581, 0.4596273291925466, 0.45962732919254656, 0.3037974683544304, 0.3896103896103896, 0.34838709677419355, 0.4472049689440994, 0.4347826086956522, 0.37974683544303806, 0.37662337662337664, 0.335483870967742, 0.40993788819875776, 0.40993788819875776, 0.34177215189873417, 0.29870129870129863, 0.4000000000000001, 0.3602484472049689, 0.39751552795031053, 0.32911392405063294, 0.36363636363636365, 0.3096774193548387, 0.4720496894409938, 0.40993788819875776, 0.44303797468354433, 0.3246753246753247, 0.34838709677419355, 0.484472049689441, 0.422360248447205, 0.3924050632911393, 0.44155844155844154, 0.38709677419354843, 0.38509316770186336, 0.39751552795031053, 0.34177215189873417, 0.44155844155844154, 0.4000000000000001, 0.37267080745341613, 0.40993788819875776, 0.45569620253164556, 0.37662337662337664, 0.3612903225806451, 0.40993788819875776, 0.4347826086956522, 0.3544303797468355, 0.3116883116883117, 0.335483870967742, 0.39751552795031053, 0.3850931677018633, 0.32911392405063294, 0.40259740259740256, 0.3612903225806451, 0.33540372670807456, 0.4347826086956522, 0.36708860759493667, 0.29870129870129863, 0.38709677419354843, 0.38509316770186336, 0.39751552795031053, 0.36708860759493667, 0.36363636363636365, 0.43870967741935485, 0.3478260869565218, 0.3726708074534162, 0.36708860759493667, 0.40259740259740256, 0.38709677419354843, 0.42236024844720493, 0.45962732919254656, 0.37974683544303806, 0.44155844155844154, 0.3612903225806451, 0.3602484472049689, 0.36024844720496896, 0.34177215189873417, 0.3246753246753247, 0.38709677419354843, 0.43478260869565216, 0.39751552795031053, 0.4177215189873418, 0.40259740259740256, 0.3612903225806451, 0.38509316770186336, 0.4347826086956522, 0.44303797468354433, 0.36363636363636365, 0.3612903225806451, 0.37267080745341613, 0.40993788819875776, 0.34177215189873417, 0.37662337662337664, 0.4645161290322581, 0.3602484472049689, 0.4720496894409938, 0.4050632911392405, 0.3246753246753247, 0.2838709677419355, 0.38509316770186336, 0.39751552795031053, 0.49367088607594933, 0.3246753246753247, 0.4000000000000001, 0.38509316770186336, 0.4720496894409938, 0.3544303797468355, 0.37662337662337664, 0.3741935483870968, 0.28571428571428575, 0.40993788819875776, 0.36708860759493667, 0.40259740259740256, 0.34838709677419355, 0.3602484472049689, 0.39751552795031053, 0.37974683544303806, 0.42857142857142855, 0.34838709677419355, 0.39751552795031053, 0.5217391304347826, 0.3924050632911393, 0.33766233766233766, 0.3612903225806451, 0.3602484472049689, 0.33540372670807456, 0.3037974683544304, 0.3896103896103896, 0.4258064516129032, 0.38509316770186336, 0.422360248447205, 0.37974683544303806, 0.4805194805194805, 0.3612903225806451, 0.40993788819875776, 0.39751552795031053, 0.46835443037974683, 0.42857142857142855, 0.3741935483870968, 0.3229813664596273, 0.5217391304347826, 0.3544303797468355, 0.40259740259740256, 0.3612903225806451, 0.40993788819875776, 0.39751552795031053, 0.3924050632911393, 0.45454545454545453, 0.3741935483870968, 0.37267080745341613, 0.3478260869565218, 0.3924050632911393, 0.33766233766233766, 0.2709677419354839, 0.2732919254658385, 0.4472049689440994, 0.4050632911392405, 0.42857142857142855, 0.2967741935483871, 0.39751552795031053, 0.40993788819875776, 0.44303797468354433, 0.4155844155844156, 0.45161290322580644, 0.42236024844720493, 0.4347826086956522, 0.36708860759493667, 0.4155844155844156, 0.41290322580645167, 0.4472049689440994, 0.48447204968944096, 0.36708860759493667, 0.37662337662337664, 0.3612903225806451, 0.40993788819875776, 0.33540372670807456, 0.44303797468354433, 0.33766233766233766, 0.34838709677419355, 0.38509316770186336, 0.49689440993788814, 0.34177215189873417, 0.37662337662337664, 0.38709677419354843, 0.3478260869565218, 0.3478260869565218, 0.37974683544303806, 0.4675324675324675, 0.43870967741935485, 0.3229813664596273, 0.4472049689440994, 0.45569620253164556, 0.37662337662337664, 0.3612903225806451, 0.42236024844720493, 0.3229813664596274, 0.32911392405063294, 0.3506493506493507, 0.43870967741935485, 0.3478260869565218, 0.36024844720496896, 0.34177215189873417, 0.33766233766233766, 0.4000000000000001, 0.3229813664596273, 0.3726708074534162, 0.45569620253164556, 0.29870129870129863, 0.38709677419354843, 0.38509316770186336, 0.40993788819875776, 0.3544303797468355, 0.37662337662337664, 0.3225806451612903, 0.37267080745341613, 0.422360248447205, 0.32911392405063294, 0.37662337662337664, 0.45161290322580644, 0.43478260869565216, 0.4472049689440994, 0.31645569620253167, 0.33766233766233766, 0.38709677419354843, 0.3602484472049689, 0.422360248447205, 0.37974683544303806, 0.42857142857142855, 0.3741935483870968, 0.3602484472049689, 0.3726708074534162, 0.3544303797468355, 0.40259740259740256, 0.4258064516129032, 0.33540372670807456, 0.3726708074534162, 0.36708860759493667, 0.24675324675324675, 0.3612903225806451, 0.42236024844720493, 0.39751552795031053, 0.32911392405063294, 0.4155844155844156, 0.41290322580645167, 0.4472049689440994, 0.48447204968944096, 0.37974683544303806, 0.37662337662337664, 0.335483870967742, 0.3478260869565218, 0.40993788819875776, 0.43037974683544306, 0.3506493506493507, 0.2709677419354839, 0.3602484472049689, 0.36024844720496896, 0.49367088607594933, 0.36363636363636365, 0.3096774193548387, 0.39751552795031053, 0.4347826086956522, 0.43037974683544306, 0.29870129870129863, 0.3741935483870968, 0.37267080745341613, 0.48447204968944096, 0.4177215189873418, 0.36363636363636365, 0.335483870967742, 0.39751552795031053, 0.40993788819875776, 0.36708860759493667, 0.3246753246753247, 0.3741935483870968, 0.38509316770186336, 0.4347826086956522, 0.32911392405063294, 0.3896103896103896, 0.4000000000000001, 0.3478260869565218, 0.4347826086956522, 0.3544303797468355, 0.4155844155844156, 0.3096774193548387, 0.42236024844720493, 0.4347826086956522, 0.32911392405063294, 0.3896103896103896, 0.4645161290322581, 0.3478260869565218, 0.39751552795031053, 0.3924050632911393, 0.36363636363636365, 0.38709677419354843, 0.3602484472049689, 0.45962732919254656, 0.34177215189873417, 0.36363636363636365, 0.3612903225806451, 0.33540372670807456, 0.36024844720496896, 0.37974683544303806, 0.4155844155844156, 0.335483870967742, 0.39751552795031053, 0.422360248447205, 0.31645569620253167, 0.3246753246753247, 0.41290322580645167, 0.37267080745341613, 0.4472049689440994, 0.44303797468354433, 0.36363636363636365, 0.3612903225806451, 0.37267080745341613, 0.3850931677018633, 0.43037974683544306, 0.3896103896103896, 0.4258064516129032, 0.28571428571428575, 0.33540372670807456, 0.43037974683544306, 0.40259740259740256, 0.3096774193548387, 0.43478260869565216, 0.422360248447205, 0.34177215189873417, 0.3896103896103896, 0.3612903225806451, 0.37267080745341613, 0.40993788819875776, 0.31645569620253167, 0.3506493506493507, 0.335483870967742, 0.38509316770186336, 0.4347826086956522, 0.37974683544303806, 0.3506493506493507, 0.3225806451612903, 0.40993788819875776, 0.4472049689440994, 0.43037974683544306, 0.3246753246753247, 0.45161290322580644, 0.42236024844720493, 0.3726708074534162, 0.37974683544303806, 0.40259740259740256, 0.23225806451612904, 0.39751552795031053, 0.39751552795031053, 0.32911392405063294, 0.3896103896103896, 0.3741935483870968, 0.40993788819875776, 0.4472049689440994, 0.3544303797468355, 0.33766233766233766, 0.3096774193548387, 0.37267080745341613, 0.3478260869565218, 0.32911392405063294, 0.42857142857142855, 0.4645161290322581, 0.38509316770186336, 0.3105590062111801, 0.36708860759493667, 0.3506493506493507, 0.3096774193548387, 0.43478260869565216, 0.39751552795031053, 0.3544303797468355, 0.40259740259740256, 0.3612903225806451, 0.4472049689440994, 0.3726708074534162, 0.4177215189873418, 0.36363636363636365, 0.335483870967742, 0.40993788819875776, 0.3726708074534162, 0.37974683544303806, 0.4155844155844156, 0.34838709677419355, 0.38509316770186336, 0.3850931677018633, 0.4050632911392405, 0.36363636363636365, 0.38709677419354843, 0.4472049689440994, 0.49689440993788814, 0.32911392405063294, 0.37662337662337664, 0.38709677419354843, 0.37267080745341613, 0.40993788819875776, 0.3544303797468355, 0.3116883116883117, 0.4000000000000001, 0.37267080745341613, 0.36024844720496896, 0.34177215189873417, 0.33766233766233766, 0.45161290322580644, 0.4472049689440994, 0.39751552795031053, 0.32911392405063294, 0.37662337662337664, 0.335483870967742, 0.37267080745341613, 0.3726708074534162, 0.32911392405063294, 0.42857142857142855, 0.41290322580645167, 0.42236024844720493, 0.39751552795031053, 0.3924050632911393, 0.29870129870129863, 0.3225806451612903, 0.33540372670807456, 0.40993788819875776, 0.3037974683544304, 0.3506493506493507, 0.335483870967742, 0.38509316770186336, 0.36024844720496896, 0.37974683544303806, 0.3506493506493507, 0.3741935483870968, 0.40993788819875776, 0.3850931677018633, 0.36708860759493667, 0.37662337662337664, 0.38709677419354843, 0.40993788819875776, 0.3850931677018633, 0.43037974683544306, 0.44155844155844154, 0.38709677419354843, 0.42236024844720493, 0.36024844720496896, 0.4177215189873418, 0.36363636363636365, 0.3612903225806451, 0.39751552795031053, 0.4472049689440994, 0.44303797468354433, 0.3896103896103896, 0.38709677419354843, 0.40993788819875776, 0.4472049689440994, 0.37974683544303806, 0.40259740259740256, 0.38709677419354843, 0.38509316770186336, 0.48447204968944096, 0.4177215189873418, 0.36363636363636365, 0.4000000000000001, 0.3602484472049689, 0.3850931677018633, 0.3924050632911393, 0.29870129870129863, 0.4000000000000001, 0.42236024844720493, 0.4472049689440994, 0.4050632911392405, 0.4935064935064935, 0.41290322580645167, 0.4596273291925466, 0.4347826086956522, 0.4050632911392405, 0.45454545454545453, 0.38709677419354843, 0.43478260869565216, 0.4347826086956522, 0.34177215189873417, 0.27272727272727276, 0.4000000000000001, 0.37267080745341613, 0.40993788819875776, 0.37974683544303806, 0.33766233766233766, 0.3612903225806451, 0.3229813664596273, 0.3478260869565218, 0.3544303797468355, 0.40259740259740256, 0.34838709677419355, 0.4472049689440994, 0.4347826086956522, 0.4177215189873418, 0.3506493506493507, 0.3741935483870968, 0.37267080745341613, 0.39751552795031053, 0.36708860759493667, 0.36363636363636365, 0.3612903225806451, 0.42236024844720493, 0.39751552795031053, 0.45569620253164556, 0.36363636363636365, 0.45161290322580644, 0.33540372670807456, 0.3850931677018633, 0.4050632911392405, 0.3246753246753247, 0.4000000000000001, 0.37267080745341613, 0.33540372670807456, 0.32911392405063294, 0.36363636363636365, 0.3612903225806451, 0.37267080745341613, 0.40993788819875776, 0.3544303797468355, 0.4155844155844156, 0.335483870967742, 0.38509316770186336, 0.4720496894409938, 0.37974683544303806, 0.33766233766233766, 0.2838709677419355, 0.43478260869565216, 0.3850931677018633, 0.3924050632911393, 0.4935064935064935, 0.3096774193548387, 0.3602484472049689, 0.4347826086956522, 0.34177215189873417, 0.37662337662337664, 0.335483870967742, 0.38509316770186336, 0.33540372670807456, 0.3544303797468355, 0.33766233766233766, 0.4000000000000001, 0.39751552795031053, 0.45962732919254656, 0.37974683544303806, 0.4675324675324675, 0.43870967741935485, 0.37267080745341613, 0.4472049689440994, 0.32911392405063294, 0.37662337662337664, 0.3612903225806451, 0.4596273291925466, 0.40993788819875776, 0.3037974683544304, 0.42857142857142855, 0.4000000000000001, 0.39751552795031053, 0.39751552795031053, 0.34177215189873417, 0.3506493506493507, 0.3612903225806451, 0.4596273291925466, 0.33540372670807456, 0.43037974683544306, 0.40259740259740256, 0.3612903225806451, 0.40993788819875776, 0.3478260869565218, 0.3924050632911393, 0.3896103896103896, 0.4645161290322581, 0.31055900621118016, 0.49689440993788814, 0.44303797468354433, 0.42857142857142855, 0.3612903225806451, 0.28571428571428575, 0.4347826086956522, 0.34177215189873417, 0.29870129870129863, 0.3741935483870968, 0.4472049689440994, 0.39751552795031053, 0.4050632911392405, 0.3896103896103896, 0.34838709677419355, 0.33540372670807456, 0.4347826086956522, 0.3544303797468355, 0.3116883116883117, 0.43870967741935485, 0.4472049689440994, 0.5217391304347826, 0.4050632911392405, 0.3506493506493507, 0.43870967741935485, 0.3602484472049689, 0.3478260869565218, 0.4050632911392405, 0.37662337662337664, 0.38709677419354843, 0.38509316770186336, 0.4472049689440994, 0.4050632911392405, 0.3896103896103896, 0.2967741935483871, 0.4472049689440994, 0.422360248447205, 0.4177215189873418, 0.3246753246753247, 0.4645161290322581, 0.3478260869565218, 0.40993788819875776, 0.3037974683544304, 0.3896103896103896, 0.3225806451612903, 0.39751552795031053, 0.3229813664596274, 0.4177215189873418, 0.36363636363636365, 0.34838709677419355, 0.40993788819875776, 0.48447204968944096, 0.37974683544303806, 0.40259740259740256, 0.335483870967742, 0.3478260869565218, 0.4472049689440994, 0.43037974683544306, 0.45454545454545453, 0.4258064516129032, 0.42236024844720493, 0.3105590062111801, 0.3924050632911393, 0.33766233766233766, 0.3741935483870968, 0.37267080745341613, 0.40993788819875776, 0.3544303797468355, 0.3246753246753247, 0.38709677419354843, 0.28571428571428575, 0.422360248447205, 0.44303797468354433, 0.36363636363636365, 0.34838709677419355, 0.2732919254658385, 0.39751552795031053, 0.37974683544303806, 0.3506493506493507, 0.45161290322580644, 0.37267080745341613, 0.4347826086956522, 0.34177215189873417, 0.33766233766233766, 0.34838709677419355, 0.4472049689440994, 0.3850931677018633, 0.4177215189873418, 0.33766233766233766, 0.43870967741935485, 0.3602484472049689, 0.3850931677018633, 0.43037974683544306, 0.37662337662337664, 0.38709677419354843, 0.39751552795031053, 0.4347826086956522, 0.36708860759493667, 0.3246753246753247, 0.2967741935483871, 0.39751552795031053, 0.40993788819875776, 0.4050632911392405, 0.3896103896103896, 0.34838709677419355, 0.31055900621118016, 0.40993788819875776, 0.43037974683544306, 0.42857142857142855, 0.24516129032258063, 0.42236024844720493, 0.48447204968944096, 0.43037974683544306, 0.4155844155844156, 0.47741935483870973, 0.37267080745341613, 0.3850931677018633, 0.34177215189873417, 0.3246753246753247, 0.4000000000000001, 0.42236024844720493, 0.4472049689440994, 0.37974683544303806, 0.3506493506493507, 0.3225806451612903, 0.39751552795031053, 0.4347826086956522, 0.44303797468354433, 0.36363636363636365, 0.38709677419354843, 0.3478260869565218, 0.4347826086956522, 0.3924050632911393, 0.29870129870129863, 0.2967741935483871, 0.42236024844720493, 0.40993788819875776, 0.36708860759493667, 0.3896103896103896, 0.3741935483870968, 0.4720496894409938, 0.39751552795031053, 0.37974683544303806, 0.29870129870129863, 0.3612903225806451, 0.4596273291925466, 0.40993788819875776, 0.44303797468354433, 0.33766233766233766, 0.3741935483870968, 0.43478260869565216, 0.4472049689440994, 0.4050632911392405, 0.36363636363636365, 0.335483870967742, 0.38509316770186336, 0.422360248447205, 0.4177215189873418, 0.3246753246753247, 0.34838709677419355, 0.4472049689440994, 0.40993788819875776, 0.34177215189873417, 0.40259740259740256, 0.3612903225806451, 0.3478260869565218, 0.3105590062111801, 0.32911392405063294, 0.29870129870129863, 0.3741935483870968, 0.3602484472049689, 0.3726708074534162, 0.45569620253164556, 0.3896103896103896, 0.38709677419354843, 0.43478260869565216, 0.3229813664596274, 0.43037974683544306, 0.36363636363636365, 0.3612903225806451, 0.3602484472049689, 0.4347826086956522, 0.43037974683544306, 0.3246753246753247, 0.4000000000000001, 0.33540372670807456, 0.4720496894409938, 0.4050632911392405, 0.36363636363636365, 0.3612903225806451, 0.4472049689440994, 0.36024844720496896, 0.31645569620253167, 0.3896103896103896, 0.335483870967742, 0.4472049689440994, 0.39751552795031053, 0.31645569620253167, 0.3246753246753247, 0.34838709677419355, 0.40993788819875776, 0.422360248447205, 0.32911392405063294, 0.37662337662337664, 0.38709677419354843, 0.40993788819875776, 0.45962732919254656, 0.3924050632911393, 0.4805194805194805, 0.4000000000000001, 0.3229813664596273, 0.40993788819875776, 0.3924050632911393, 0.33766233766233766, 0.3741935483870968, 0.484472049689441, 0.422360248447205, 0.31645569620253167, 0.3116883116883117, 0.335483870967742, 0.39751552795031053, 0.39751552795031053, 0.3924050632911393, 0.29870129870129863, 0.335483870967742, 0.4596273291925466, 0.36024844720496896, 0.36708860759493667, 0.4155844155844156, 0.3741935483870968, 0.39751552795031053, 0.4347826086956522, 0.36708860759493667, 0.3246753246753247, 0.34838709677419355, 0.40993788819875776, 0.4347826086956522, 0.3544303797468355, 0.40259740259740256, 0.3741935483870968, 0.42236024844720493, 0.39751552795031053, 0.3924050632911393, 0.3116883116883117, 0.3225806451612903, 0.3229813664596273, 0.3850931677018633, 0.32911392405063294, 0.27272727272727276, 0.3741935483870968, 0.42236024844720493, 0.4347826086956522, 0.43037974683544306, 0.28571428571428575, 0.43870967741935485, 0.42236024844720493, 0.3850931677018633, 0.36708860759493667, 0.37662337662337664, 0.41290322580645167, 0.42236024844720493, 0.33540372670807456, 0.37974683544303806, 0.36363636363636365, 0.3096774193548387, 0.4720496894409938, 0.39751552795031053, 0.27848101265822783, 0.28571428571428575, 0.3225806451612903, 0.43478260869565216, 0.4347826086956522, 0.3924050632911393, 0.3896103896103896, 0.34838709677419355, 0.39751552795031053, 0.3726708074534162, 0.43037974683544306, 0.36363636363636365, 0.41290322580645167, 0.39751552795031053, 0.4472049689440994, 0.34177215189873417, 0.37662337662337664, 0.335483870967742, 0.37267080745341613, 0.40993788819875776, 0.2911392405063291, 0.4155844155844156, 0.38709677419354843, 0.43478260869565216, 0.45962732919254656, 0.3544303797468355, 0.33766233766233766, 0.43870967741935485, 0.4472049689440994, 0.4347826086956522, 0.34177215189873417, 0.4155844155844156, 0.335483870967742, 0.3602484472049689, 0.45962732919254656, 0.34177215189873417, 0.28571428571428575, 0.34838709677419355, 0.40993788819875776, 0.3850931677018633, 0.43037974683544306, 0.3506493506493507, 0.3096774193548387, 0.43478260869565216, 0.422360248447205, 0.43037974683544306, 0.36363636363636365, 0.43870967741935485, 0.37267080745341613, 0.4347826086956522]\n",
      "Our mean fold accurancy_scores is 0.5267\n",
      "Our mean fold f1 score is 0.3840\n",
      "Our mean fold recall is 0.3829\n",
      "Our mean fold precisionis 0.3867\n"
     ]
    }
   ],
   "source": [
    "##################### Baseline with 38.% MW ##################### \n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "auc_pr_score = [] \n",
    "\n",
    "### stratifies group k fold\n",
    "for i in range(1, 1000):\n",
    "    for train_index, test_index in sgk.split(X, y, groups):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        \n",
    "        # Fit Model on Train\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        # create baseline \n",
    "        # 38.55891% von y_pred should be MW, MW = 0\n",
    "        baseline = np.ones(len(y_pred))\n",
    "        mw_size = 38.55891/100  * len(y_pred)\n",
    "        baseline[:int(mw_size)] = 0\n",
    "        np.random.shuffle(baseline)\n",
    "        baseline = baseline.astype(int)\n",
    "        \n",
    "\n",
    "        f1 = f1_score(y_test, baseline,pos_label = 0)\n",
    "        precision = precision_score(y_test, baseline,pos_label = 0)\n",
    "        recall = recall_score(y_test, baseline, pos_label = 0)\n",
    "\n",
    "\n",
    "        print(pd.DataFrame(confusion_matrix(y_test, baseline)))\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "\n",
    "        print(f\"f1  score for fold {fold}: \", f1)\n",
    "        print(f\"recall for fold {fold}: \", recall)\n",
    "        print(f\"precision for fold {fold}: \", precision)\n",
    "        \n",
    "     # Precision- recall curve\n",
    "        fpr, tpr, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "      \n",
    "        # calculate AUC-PR using the precision-recall curve\n",
    "        auc_pr = auc( tpr,fpr) \n",
    "        auc_pr_score.append(auc_pr)\n",
    "      \n",
    "        print((f\"auc for fold {fold}: \", auc_pr))\n",
    "      \n",
    "        fold += 1\n",
    "\n",
    "mean_auc = np.mean(auc_pr_score)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "\n",
    "print(f'Our mean fold f1 score is {mean_f1:0.4f}')\n",
    "print(f'Our mean fold recall is {mean_recall:0.4f}')\n",
    "print(f'Our mean fold precision is {mean_precision:0.4f}')\n",
    "print(f'Our mean fold auc pr is {mean_auc:0.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "#################################### FEATURE IMPORTANCE ########################################################################\n",
    "\n",
    "\n",
    "##################### preprocessing with pipleline #####################\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "over = SMOTE(random_state= 27) \n",
    "\n",
    "# classifier getuned\n",
    "#model = GaussianNB(var_smoothing=  1.5199110829529332e-05) \n",
    "\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 3, n_estimators = 500, subsample = 1)\n",
    "#auch gut\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 15, n_estimators = 220, learning_rate = 0.014, alpha = 0, reg_lambda = 1)\n",
    "\n",
    "#model = RandomForestClassifier(random_state=3) #, bootstrap = True, max_depth = 50, max_features = 'auto',min_samples_leaf = 6, min_samples_split= 2, n_estimators = 200)\n",
    "\n",
    "# {'model__C': 0.004, 'model__gamma': 0.1, 'model__kernel': 'rbf'}\n",
    "model = SVC(kernel= \"linear\", C = 10, gamma = 1) \n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler), ('over', over), ('model', model)] \n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Feature Importance  Random Forrest #####################\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import set_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "data = []\n",
    "### stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # model performance\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # print(pipe.steps[3][1].feature_importances_)\n",
    "    clf = pipe[-1]\n",
    "    \n",
    "    # making a pandas dataframe\n",
    "    data.append(list(zip(clf.feature_names_in_, clf.feature_importances_))) #tupel\n",
    "  \n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Fixation Duration Std [ms]</td>\n",
       "      <td>0.005756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blink Duration Kurtosis [ms]</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Saccade Acceleration Average [°/s²] Mean</td>\n",
       "      <td>0.005679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Max</td>\n",
       "      <td>0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Quantil 25]</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Saccade Length Mean [px]</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Mean</td>\n",
       "      <td>0.005525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Saccade Acceleration Peak [°/s²] Quantil 75]</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Saccade Duration Mean [ms]</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saccade Duration Quantil 75 [ms]</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Std</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Median</td>\n",
       "      <td>0.005315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blink Number</td>\n",
       "      <td>0.005259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Quantil 25]</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Fixation Duration Mean [ms]</td>\n",
       "      <td>0.005173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fixation Dispersion X Median [px]</td>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Saccade Amplitude Mean [°]</td>\n",
       "      <td>0.005095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Quantil 75]</td>\n",
       "      <td>0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Mean</td>\n",
       "      <td>0.004844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Median</td>\n",
       "      <td>0.004586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Feature  Importance\n",
       "45                     Fixation Duration Std [ms]    0.005756\n",
       "0                    Blink Duration Kurtosis [ms]    0.005736\n",
       "58       Saccade Acceleration Average [°/s²] Mean    0.005679\n",
       "111           Saccade Velocity Average [°/s²] Max    0.005643\n",
       "133      Saccade Velocity Peak [°/s²] Quantil 25]    0.005602\n",
       "103                      Saccade Length Mean [px]    0.005600\n",
       "85          Saccade Deceleration Peak [°/s²] Mean    0.005525\n",
       "71   Saccade Acceleration Peak [°/s²] Quantil 75]    0.005524\n",
       "94                     Saccade Duration Mean [ms]    0.005524\n",
       "98               Saccade Duration Quantil 75 [ms]    0.005379\n",
       "118           Saccade Velocity Average [°/s²] Std    0.005361\n",
       "131           Saccade Velocity Peak [°/s²] Median    0.005315\n",
       "9                                    Blink Number    0.005259\n",
       "115   Saccade Velocity Average [°/s²] Quantil 25]    0.005242\n",
       "39                    Fixation Duration Mean [ms]    0.005173\n",
       "22              Fixation Dispersion X Median [px]    0.005119\n",
       "76                     Saccade Amplitude Mean [°]    0.005095\n",
       "134      Saccade Velocity Peak [°/s²] Quantil 75]    0.005020\n",
       "112          Saccade Velocity Average [°/s²] Mean    0.004844\n",
       "113        Saccade Velocity Average [°/s²] Median    0.004586"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get average of all folds\n",
    "df = pd.DataFrame(data[0], columns=['Feature', 'Importance'])\n",
    "for i in range(1,len(data)):\n",
    "    fold = pd.DataFrame(data[i], columns=['Feature', 'Importance'])\n",
    "    df = pd.concat([df, fold])\n",
    "\n",
    "# to see feature importance\n",
    "df_importances = df.groupby(\"Feature\").mean().reset_index().sort_values(by='Importance', ascending=False)\n",
    "df_importances\n",
    "df_importances.head(20)\n",
    "df_importances.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Feature'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_importances.head(20).plot.barh(x='Feature', y='Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    " print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "features_names = ['input1', 'input2']\n",
    "svm = svm.SVC(kernel='linear')\n",
    "svm.fit(X, Y)\n",
    "f_importances(svm.coef_, features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_names = ['Fixation Duration Mean', 'Fixation Duration Max', 'Fixation Duration Min', 'Fixation Duration Median', 'Fixation Duration Std', 'Fixation Duration Skew', 'Fixation Duration Quantil 25', 'Fixation Duration Quantil 75',\n",
    "        'Saccade Duration Mean', 'Saccade Duration Max', 'Saccade Duration Min', 'Saccade Duration Median', 'Saccade Duration Std', 'Saccade Duration Skew', 'Saccade Duration Quantil 25', 'Saccade Duration Quantil 75', \n",
    "        'Blink Duration Mean', 'Blink Duration Max', 'Blink Duration Min', 'Blink Duration Median', 'Blink Duration Std', 'Blink Duration Skew', 'Blink Duration Quantil 25', 'Blink Duration Quantil 75', 'Fixation Duration Kurtosis',\n",
    "        'Saccade Duration Kurtosis',\n",
    "        'Blink Duration Kurtosis', \n",
    "        'Fixation Saccade Ratio Mean', 'Fixation Saccade Ratio Max', 'Fixation Saccade Ratio Min', 'Fixation Saccade Ratio Median', 'Fixation Saccade Ratio Std', 'Fixation Saccade Ratio Skew', 'Fixation Saccade Ratio Kurtosis', \n",
    "        'Fixation Number', 'Blink Number', \n",
    "        'Fixation Dispersion X Mean', 'Fixation Dispersion X Max', 'Fixation Dispersion X Min', 'Fixation Dispersion X Median', 'Fixation Dispersion X Std', 'Fixation Dispersion X Skew', 'Fixation Dispersion X Quantil 25', 'Fixation Dispersion X Quantil 75', \n",
    "        'Fixation Dispersion Y Mean', 'Fixation Dispersion Y Max', 'Fixation Dispersion Y Min', 'Fixation Dispersion Y Median', 'Fixation Dispersion Y Std', 'Fixation Dispersion Y Skew', 'Fixation Dispersion Y Quantil 25', 'Fixation Dispersion Y Quantil 75', 'Fixation Dispersion X Kurtosis', 'Fixation Dispersion Y Kurtosis', \n",
    "        'Saccade Amplitude Mean', 'Saccade Amplitude Max', 'Saccade Amplitude Min', 'Saccade Amplitude Median', 'Saccade Amplitude Std', 'Saccade Amplitude Skew', 'Saccade Amplitude Quantil 25', 'Saccade Amplitude Quantil 75', 'Saccade Amplitude Kurtosis',\n",
    "        'Saccade Acceleration Average Mean', 'Saccade Acceleration Average Max', 'Saccade Acceleration Average Min', 'Saccade Acceleration Average Median', 'Saccade Acceleration Average Std', 'Saccade Acceleration Average Skew]', 'Saccade Acceleration Average Quantil 25', 'Saccade Acceleration Average Quantil 75',\n",
    "        'Saccade Acceleration Peak Mean', 'Saccade Acceleration Peak Max', 'Saccade Acceleration Peak Min', 'Saccade Acceleration Peak Median', 'Saccade Acceleration Peak Std', 'Saccade Acceleration Peak Skew', 'Saccade Acceleration Peak Quantil 25', 'Saccade Acceleration Peak Quantil 75', 'Saccade Deceleration Peak Mean', \n",
    "        'Saccade Deceleration Peak Max', 'Saccade Deceleration Peak Min', 'Saccade Deceleration Peak Median', 'Saccade Deceleration Peak Std', 'Saccade Deceleration Peak Skew]', 'Saccade Deceleration Peak Quantil 25', 'Saccade Deceleration Peak Quantil 75', \n",
    "        'Saccade Velocity Average Mean', 'Saccade Velocity Average Max', 'Saccade Velocity Average Min', 'Saccade Velocity Average Median', 'Saccade Velocity Average Std', 'Saccade Velocity Average Skew', 'Saccade Velocity Average Quantil 25', 'Saccade Velocity Average Quantil 75', \n",
    "        'Saccade Velocity Peak  Mean', 'Saccade Velocity Peak Max', 'Saccade Velocity Peak Min', 'Saccade Velocity Peak Median', 'Saccade Velocity Peak Std', 'Saccade Velocity Peak Skew', 'Saccade Velocity Peak Quantil 25', 'Saccade Velocity Peak Quantil 75', \n",
    "        'Saccade Velocity Peak Prozent Mean', 'Saccade Velocity Peak Prozent Max', 'Saccade Velocity Peak Prozent Min', 'Saccade Velocity Peak Prozent Median', 'Saccade Velocity Peak Prozent Std', 'Saccade Velocity Peak Prozent Skew', 'Saccade Velocity Peak Prozent Quantil 25', 'Saccade Velocity Peak Prozent Quantil 75', \n",
    "        'Saccade Acceleration Average Kurtosis', 'Saccade Acceleration Peak Kurtosis', 'Saccade Deceleration Peak Kurtosis', 'Saccade Velocity Average Kurtosis', 'Saccade Velocity Peak Kurtosis', 'Saccade Velocity Peak Prozent Kurtosis', \n",
    "        'Saccade Length Mean', 'Saccade Length Max', 'Saccade Length Min', 'Saccade Length Median', 'Saccade Length Std', 'Saccade Length Skew', 'Saccade Length Quantil 25', 'Saccade Length Quantil 75', 'Saccade Length Kurtosis', \n",
    "        'Fixation Average Pupil Diameter Mean', 'Fixation Average Pupil Diameter Max', 'Fixation Average Pupil Diameter Min', 'Fixation Average Pupil Diameter Median', 'Fixation Average Pupil Diameter Std', 'Fixation Average Pupil Diameter Skew', 'Fixation Average Pupil Diameter Quantil25', 'Fixation Average Pupil Diameter Quantil75',\n",
    "        'Fixation Average Pupil Diameter Kurtosis', \n",
    "        'Veregence Angles Mean', 'Veregence Angles Std', \n",
    "        'Pupil Distance Mean', 'Pupil Distance Std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.68      0.55        78\n",
      "           1       0.73      0.52      0.61       131\n",
      "\n",
      "    accuracy                           0.58       209\n",
      "   macro avg       0.59      0.60      0.58       209\n",
      "weighted avg       0.63      0.58      0.58       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################### Feature Importance SVC #####################\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "data = []\n",
    "### stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # model performance\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    svm = pipe[-1]\n",
    "\n",
    "    # making a pandas dataframe\n",
    "    data.append(list(zip(new_feature_names,svm.coef_[0]))) #tupel\n",
    "  \n",
    "    fold += 1\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Saccade Velocity Average Mean</td>\n",
       "      <td>4.892333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Saccade Amplitude Mean</td>\n",
       "      <td>4.860110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fixation Average Pupil Diameter Mean</td>\n",
       "      <td>2.075939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Saccade Acceleration Average Quantil 75</td>\n",
       "      <td>1.755443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Saccade Deceleration Peak Mean</td>\n",
       "      <td>1.697922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Saccade Velocity Peak Prozent Mean</td>\n",
       "      <td>1.692270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Saccade Amplitude Kurtosis</td>\n",
       "      <td>1.640402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Saccade Velocity Peak Median</td>\n",
       "      <td>1.560467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Saccade Acceleration Average Std</td>\n",
       "      <td>1.528995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blink Duration Quantil 75</td>\n",
       "      <td>1.473810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blink Duration Quantil 25</td>\n",
       "      <td>1.453962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Saccade Length Std</td>\n",
       "      <td>1.442903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Saccade Length Skew</td>\n",
       "      <td>1.428306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blink Duration Median</td>\n",
       "      <td>1.395553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fixation Dispersion X Std</td>\n",
       "      <td>1.169624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fixation Dispersion Y Quantil 25</td>\n",
       "      <td>1.040571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fixation Dispersion X Median</td>\n",
       "      <td>0.988012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Saccade Deceleration Peak Median</td>\n",
       "      <td>0.985705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Saccade Velocity Average Kurtosis</td>\n",
       "      <td>0.946042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Saccade Velocity Peak Min</td>\n",
       "      <td>0.913493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Feature  Importance\n",
       "112            Saccade Velocity Average Mean    4.892333\n",
       "76                    Saccade Amplitude Mean    4.860110\n",
       "12      Fixation Average Pupil Diameter Mean    2.075939\n",
       "62   Saccade Acceleration Average Quantil 75    1.755443\n",
       "85            Saccade Deceleration Peak Mean    1.697922\n",
       "126       Saccade Velocity Peak Prozent Mean    1.692270\n",
       "74                Saccade Amplitude Kurtosis    1.640402\n",
       "122             Saccade Velocity Peak Median    1.560467\n",
       "64          Saccade Acceleration Average Std    1.528995\n",
       "6                  Blink Duration Quantil 75    1.473810\n",
       "5                  Blink Duration Quantil 25    1.453962\n",
       "109                       Saccade Length Std    1.442903\n",
       "108                      Saccade Length Skew    1.428306\n",
       "3                      Blink Duration Median    1.395553\n",
       "27                 Fixation Dispersion X Std    1.169624\n",
       "33          Fixation Dispersion Y Quantil 25    1.040571\n",
       "22              Fixation Dispersion X Median    0.988012\n",
       "86          Saccade Deceleration Peak Median    0.985705\n",
       "110        Saccade Velocity Average Kurtosis    0.946042\n",
       "123                Saccade Velocity Peak Min    0.913493"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get average of all folds\n",
    "df = pd.DataFrame(data[0], columns=['Feature', 'Importance'])\n",
    "for i in range(1,len(data)):\n",
    "    fold = pd.DataFrame(data[i], columns=['Feature', 'Importance'])\n",
    "    df = pd.concat([df, fold])\n",
    "\n",
    "# to see feature importance\n",
    "df_importances = df.groupby(\"Feature\").mean().reset_index().sort_values(by='Importance', ascending=False)\n",
    "df_importances\n",
    "df_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Saccade Velocity Peak Prozent Std</td>\n",
       "      <td>-0.906674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Saccade Velocity Peak Std</td>\n",
       "      <td>-0.921923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Saccade Deceleration Peak Quantil 25</td>\n",
       "      <td>-1.022614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Saccade Amplitude Min</td>\n",
       "      <td>-1.028817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Saccade Duration Mean</td>\n",
       "      <td>-1.089374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Saccade Deceleration Peak Min</td>\n",
       "      <td>-1.159010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fixation Average Pupil Diameter Max</td>\n",
       "      <td>-1.232185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Saccade Amplitude Skew</td>\n",
       "      <td>-1.247454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Saccade Amplitude Median</td>\n",
       "      <td>-1.272871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Saccade Velocity Average Quantil 25</td>\n",
       "      <td>-1.303431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Saccade Velocity Average Max</td>\n",
       "      <td>-1.418051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Saccade Length Kurtosis</td>\n",
       "      <td>-1.832690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Saccade Deceleration Peak Quantil 75</td>\n",
       "      <td>-2.053587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Fixation Dispersion Y Mean</td>\n",
       "      <td>-2.185659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Saccade Amplitude Std</td>\n",
       "      <td>-2.242965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Saccade Velocity Average Quantil 75</td>\n",
       "      <td>-2.516623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Saccade Length Mean</td>\n",
       "      <td>-2.754165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blink Duration Mean</td>\n",
       "      <td>-3.767358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Saccade Acceleration Average Mean</td>\n",
       "      <td>-5.744987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Fixation Saccade Ratio Kurtosis</td>\n",
       "      <td>-13.852400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Feature  Importance\n",
       "132     Saccade Velocity Peak Prozent Std   -0.906674\n",
       "136             Saccade Velocity Peak Std   -0.921923\n",
       "88   Saccade Deceleration Peak Quantil 25   -1.022614\n",
       "78                  Saccade Amplitude Min   -1.028817\n",
       "94                  Saccade Duration Mean   -1.089374\n",
       "87          Saccade Deceleration Peak Min   -1.159010\n",
       "11    Fixation Average Pupil Diameter Max   -1.232185\n",
       "81                 Saccade Amplitude Skew   -1.247454\n",
       "77               Saccade Amplitude Median   -1.272871\n",
       "115   Saccade Velocity Average Quantil 25   -1.303431\n",
       "111          Saccade Velocity Average Max   -1.418051\n",
       "101               Saccade Length Kurtosis   -1.832690\n",
       "89   Saccade Deceleration Peak Quantil 75   -2.053587\n",
       "30             Fixation Dispersion Y Mean   -2.185659\n",
       "82                  Saccade Amplitude Std   -2.242965\n",
       "116   Saccade Velocity Average Quantil 75   -2.516623\n",
       "103                   Saccade Length Mean   -2.754165\n",
       "2                     Blink Duration Mean   -3.767358\n",
       "58      Saccade Acceleration Average Mean   -5.744987\n",
       "47        Fixation Saccade Ratio Kurtosis  -13.852400"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importances.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Feature'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_importances.tail(20).plot.barh(x='Feature', y='Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_feature_names = ['Fixation Duration Mean', 'Fixation Duration Max', 'Fixation Duration Min', 'Fixation Duration Median', 'Fixation Duration Std', 'Fixation Duration Skew', 'Fixation Duration Quantil 25', 'Fixation Duration Quantil 75',\n",
    "#         'Saccade Duration Mean', 'Saccade Duration Max', 'Saccade Duration Min', 'Saccade Duration Median', 'Saccade Duration Std', 'Saccade Duration Skew', 'Saccade Duration Quantil 25', 'Saccade Duration Quantil 75', \n",
    "#         'Blink Duration Mean', 'Blink Duration Max', 'Blink Duration Min', 'Blink Duration Median', 'Blink Duration Std', 'Blink Duration Skew', 'Blink Duration Quantil 25', 'Blink Duration Quantil 75', 'Fixation Duration Kurtosis',\n",
    "#         'Saccade Duration Kurtosis',\n",
    "#         'Blink Duration Kurtosis', \n",
    "#         'Fixation Saccade Ratio Mean', 'Fixation Saccade Ratio Max', 'Fixation Saccade Ratio Min', 'Fixation Saccade Ratio Median', 'Fixation Saccade Ratio Std', 'Fixation Saccade Ratio Skew', 'Fixation Saccade Ratio Kurtosis', \n",
    "#         'Fixation Number', 'Blink Number', \n",
    "#         'Fixation Dispersion X Mean', 'Fixation Dispersion X Max', 'Fixation Dispersion X Min', 'Fixation Dispersion X Median', 'Fixation Dispersion X Std', 'Fixation Dispersion X Skew', 'Fixation Dispersion X Quantil 25', 'Fixation Dispersion X Quantil 75', \n",
    "#         'Fixation Dispersion Y Mean', 'Fixation Dispersion Y Max', 'Fixation Dispersion Y Min', 'Fixation Dispersion Y Median', 'Fixation Dispersion Y Std', 'Fixation Dispersion Y Skew', 'Fixation Dispersion Y Quantil 25', 'Fixation Dispersion Y Quantil 75', 'Fixation Dispersion X Kurtosis', 'Fixation Dispersion Y Kurtosis', \n",
    "#         'Saccade Amplitude Mean', 'Saccade Amplitude Max', 'Saccade Amplitude Min', 'Saccade Amplitude Median', 'Saccade Amplitude Std', 'Saccade Amplitude Skew', 'Saccade Amplitude Quantil 25', 'Saccade Amplitude Quantil 75', 'Saccade Amplitude Kurtosis',\n",
    "#         'Saccade Acceleration Average Mean', 'Saccade Acceleration Average Max', 'Saccade Acceleration Average Min', 'Saccade Acceleration Average Median', 'Saccade Acceleration Average Std', 'Saccade Acceleration Average Skew]', 'Saccade Acceleration Average Quantil 25', 'Saccade Acceleration Average Quantil 75',\n",
    "#         'Saccade Acceleration Peak Mean', 'Saccade Acceleration Peak Max', 'Saccade Acceleration Peak Min', 'Saccade Acceleration Peak Median', 'Saccade Acceleration Peak Std', 'Saccade Acceleration Peak Skew', 'Saccade Acceleration Peak Quantil 25', 'Saccade Acceleration Peak Quantil 75', 'Saccade Deceleration Peak Mean', \n",
    "#         'Saccade Deceleration Peak Max', 'Saccade Deceleration Peak Min', 'Saccade Deceleration Peak Median', 'Saccade Deceleration Peak Std', 'Saccade Deceleration Peak Skew]', 'Saccade Deceleration Peak Quantil 25', 'Saccade Deceleration Peak Quantil 75', \n",
    "#         'Saccade Velocity Average Mean', 'Saccade Velocity Average Max', 'Saccade Velocity Average Min', 'Saccade Velocity Average Median', 'Saccade Velocity Average Std', 'Saccade Velocity Average Skew', 'Saccade Velocity Average Quantil 25', 'Saccade Velocity Average Quantil 75', \n",
    "#         'Saccade Velocity Peak  Mean', 'Saccade Velocity Peak Max', 'Saccade Velocity Peak Min', 'Saccade Velocity Peak Median', 'Saccade Velocity Peak Std', 'Saccade Velocity Peak Skew', 'Saccade Velocity Peak Quantil 25', 'Saccade Velocity Peak Quantil 75', \n",
    "#         'Saccade Velocity Peak Prozent Mean', 'Saccade Velocity Peak Prozent Max', 'Saccade Velocity Peak Prozent Min', 'Saccade Velocity Peak Prozent Median', 'Saccade Velocity Peak Prozent Std', 'Saccade Velocity Peak Prozent Skew', 'Saccade Velocity Peak Prozent Quantil 25', 'Saccade Velocity Peak Prozent Quantil 75', \n",
    "#         'Saccade Acceleration Average Kurtosis', 'Saccade Acceleration Peak Kurtosis', 'Saccade Deceleration Peak Kurtosis', 'Saccade Velocity Average Kurtosis', 'Saccade Velocity Peak Kurtosis', 'Saccade Velocity Peak Prozent Kurtosis', \n",
    "#         'Saccade Length Mean', 'Saccade Length Max', 'Saccade Length Min', 'Saccade Length Median', 'Saccade Length Std', 'Saccade Length Skew', 'Saccade Length Quantil 25', 'Saccade Length Quantil 75', 'Saccade Length Kurtosis', \n",
    "#         'Fixation Average Pupil Diameter Mean', 'Fixation Average Pupil Diameter Max', 'Fixation Average Pupil Diameter Min', 'Fixation Average Pupil Diameter Median', 'Fixation Average Pupil Diameter Std', 'Fixation Average Pupil Diameter Skew', 'Fixation Average Pupil Diameter Quantil25', 'Fixation Average Pupil Diameter Quantil75',\n",
    "#         'Fixation Average Pupil Diameter Kurtosis', \n",
    "#         'Veregence Angles Mean', 'Veregence Angles Std', \n",
    "#         'Pupil Distance Mean', 'Pupil Distance Std']\n",
    "# for i in range(len(new_feature_names)):\n",
    "#         new_feature_names[i] = new_feature_names[i].replace(\" \",\"\")\n",
    "\n",
    "# new_feature_names\n",
    "# X.set_axis(new_feature_names, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fixation Duration Mean</td>\n",
       "      <td>0.134434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fixation Duration Max</td>\n",
       "      <td>0.542763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fixation Duration Min</td>\n",
       "      <td>-0.271851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fixation Duration Median</td>\n",
       "      <td>-0.317495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fixation Duration Std</td>\n",
       "      <td>-0.809606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Fixation Average Pupil Diameter Kurtosis</td>\n",
       "      <td>0.066914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Veregence Angles Mean</td>\n",
       "      <td>0.129518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Veregence Angles Std</td>\n",
       "      <td>-0.119982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Pupil Distance Mean</td>\n",
       "      <td>-0.052287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Pupil Distance Std</td>\n",
       "      <td>0.102590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Feature  Importance\n",
       "0                      Fixation Duration Mean    0.134434\n",
       "1                       Fixation Duration Max    0.542763\n",
       "2                       Fixation Duration Min   -0.271851\n",
       "3                    Fixation Duration Median   -0.317495\n",
       "4                       Fixation Duration Std   -0.809606\n",
       "..                                        ...         ...\n",
       "134  Fixation Average Pupil Diameter Kurtosis    0.066914\n",
       "135                     Veregence Angles Mean    0.129518\n",
       "136                      Veregence Angles Std   -0.119982\n",
       "137                       Pupil Distance Mean   -0.052287\n",
       "138                        Pupil Distance Std    0.102590\n",
       "\n",
       "[139 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### compare MW\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### preprocessing with pipleline #####################\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# For classification: chi2, f_classif, mutual_info_classif\n",
    "\n",
    "# 75 features we want to select\n",
    "# reihenfolge nach SMOTE paper, selection vor smote\n",
    "selector = SelectKBest(f_classif, k= 75)\n",
    "\n",
    "# Balancing \n",
    "# over Sampling \n",
    "over = SMOTE(random_state= 4) \n",
    "#over = RandomOverSampler()\n",
    "\n",
    "#weighted data (Small classes have higher weight)\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 3, n_estimators = 500, subsample = 1)\n",
    "#model = RandomForestClassifier(random_state=3, class_weight=\"balanced\")\n",
    "#model = SVC(kernel= \"linear\", C = 0.004, gamma = 0.005, class_weight= \"balanced\" )\n",
    "#model = SVC(kernel= \"linear\", C = 10, gamma = 1, class_weight= \"balanced\" )\n",
    "#steps = [('imputer', imputer), ('scaler',scaler), ('model', model)]\n",
    "\n",
    "\n",
    "# classifier getuned\n",
    "#model = GaussianNB(var_smoothing=  1.5199110829529332e-05) \n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 3, n_estimators = 500, subsample = 1)\n",
    "#auch gut\n",
    "#model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, max_depth = 15, n_estimators = 220, learning_rate = 0.014, alpha = 0, reg_lambda = 1)\n",
    "#model = RandomForestClassifier(random_state=3) #, bootstrap = True, max_depth = 50, max_features = 'auto',min_samples_leaf = 6, min_samples_split= 2, n_estimators = 200)\n",
    "\n",
    "model = SVC(kernel= \"linear\", C = 10, gamma = 1) # {'model__C': 0.004, 'model__gamma': 0.1, 'model__kernel': 'rbf'}\n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler),('selector',selector), ('over', over), ('model', model)]\n",
    "\n",
    "selectBest_pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.05671748   0.02549981   0.0392245    0.09724215   0.2291522\n",
      "   -0.17815265  -0.27174132  -0.33283802   0.36212191  -0.17139954\n",
      "    0.17962003  -0.11954756 -11.24511682   0.35171943  -0.22372251\n",
      "    0.42185219  -0.28348652  -0.13675383  -0.25101444  -0.09411983\n",
      "   -1.30291466  -0.37049168  -0.06317753   0.06428996   0.62413163\n",
      "   -4.47839882  -0.86685719   0.39785825  -0.52773463   2.26449313\n",
      "   -0.17619339   1.82251248   0.78333472  -0.22492104  -0.85219643\n",
      "    0.9146104   -0.28228747  -0.50270995   0.11869162  -3.18506567\n",
      "   -0.19310939  -1.21301236   0.27625215  -0.12936825   2.83766874\n",
      "    1.10762488  -0.16457195   0.78066185  -1.78068261  -1.11065884\n",
      "   -0.36251465  -1.16365615   1.26976479   0.88292427  -0.6379606\n",
      "    0.6066072   -0.49268368   1.34616234  -1.00644206  -0.27979296\n",
      "   -0.28998044   0.19786438  -0.65168321  -0.84773067   0.30953098\n",
      "    0.20529409  -0.20851603   0.09303734   0.19857225  -0.24057829\n",
      "   -0.73844727  -0.15854716   0.53219486  -0.18933623   0.04946726]]\n",
      "                                 Features   F_Scores\n",
      "73             Veregence Angles Std [rad]  10.152555\n",
      "38  Saccade Deceleration Peak [°/s²] Mean   8.560988\n",
      "41   Saccade Deceleration Peak [°/s²] Std   8.508311\n",
      "61          Saccade Velocity Peak [%] Std   8.469369\n",
      "7                 Blink Duration Std [ms]   8.180086\n",
      "..                                    ...        ...\n",
      "15      Fixation Dispersion X Median [px]   0.965857\n",
      "53    Saccade Velocity Peak [°/s²] Median   0.948839\n",
      "21           Saccade Amplitude Median [°]   0.943096\n",
      "23       Saccade Amplitude Quantil 25 [°]   0.910914\n",
      "0              Fixation Duration Min [ms]   0.852951\n",
      "\n",
      "[75 rows x 2 columns]\n",
      "f1  score for fold 0:  0.5621621621621622\n",
      "recall for fold 0:  0.6666666666666666\n",
      "precision for fold 0:  0.48598130841121495\n",
      "('auc for fold 0: ', 0.7942043028541268)\n",
      "Our mean fold f1 score is 0.5622\n",
      "Our mean fold recall is 0.6667\n",
      "Our mean fold precision is 0.4860\n",
      "Our mean fold auc pr is 0.7942\n"
     ]
    }
   ],
   "source": [
    "##################### Feature seelction and imporatence #####################\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "auc_pr_score = []\n",
    "### stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    # sample weights\n",
    "    # sample_weights = class_weight.compute_sample_weight(class_weight = 'balanced',  y = y_train)\n",
    "    # # Fit Model on Train\n",
    "    # pipe.fit(X_train, y_train, **{'model__sample_weight': sample_weights})\n",
    "\n",
    "    # Fit Model on Train\n",
    "    selectBest_pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = selectBest_pipe.predict(X_test)\n",
    "\n",
    "    print(selectBest_pipe[-1].coef_)\n",
    "\n",
    "    # to get dataframe with importance and name \n",
    "    names = X_train.columns.values[selector.get_support()]\n",
    "    scores = selector.scores_[selector.get_support()]\n",
    "    names_scores = list(zip(names, scores))\n",
    "    df_best_features_with_score = pd.DataFrame(data = names_scores, columns=['Features', 'F_Scores'])\n",
    "    #Sort the dataframe for better visualization\n",
    "    df_best_features_with_score = df_best_features_with_score.sort_values(['F_Scores', 'Features'], ascending = [False, True])\n",
    "    print(df_best_features_with_score)\n",
    "\n",
    "\n",
    "    # new datafram ewith only the best features\n",
    "    cols_idxs = selector.get_support(indices=True)\n",
    "    df_best_features = X_test.iloc[:,cols_idxs]\n",
    "    #print(df_best_features)\n",
    "\n",
    "    # Calcualte different metrics\n",
    "    # f1 score\n",
    "    f1 = f1_score(y_test, y_pred, pos_label = 0)\n",
    "    precision = precision_score(y_test, y_pred, pos_label = 0)\n",
    "    recall = recall_score(y_test, y_pred, pos_label = 0)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    print(f\"f1  score for fold {fold}: \", f1)\n",
    "    print(f\"recall for fold {fold}: \", recall)\n",
    "    print(f\"precision for fold {fold}: \", precision)\n",
    "\n",
    "    # Precision- recall curve\n",
    "    fpr, tpr, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "    # calculate AUC-PR using the precision-recall curve\n",
    "    auc_pr = auc( tpr,fpr) \n",
    "    auc_pr_score.append(auc_pr)\n",
    "\n",
    "    print((f\"auc for fold {fold}: \", auc_pr))\n",
    "   \n",
    "    fold += 1\n",
    "    break\n",
    "\n",
    "mean_auc = np.mean(auc_pr_score)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "\n",
    "print(f'Our mean fold f1 score is {mean_f1:0.4f}')\n",
    "print(f'Our mean fold recall is {mean_recall:0.4f}')\n",
    "print(f'Our mean fold precision is {mean_precision:0.4f}')\n",
    "print(f'Our mean fold auc pr is {mean_auc:0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fixation Duration Min [ms]</th>\n",
       "      <th>Fixation Duration Std [ms]</th>\n",
       "      <th>Fixation Duration Skew [ms]</th>\n",
       "      <th>Saccade Duration Max [ms]</th>\n",
       "      <th>Saccade Duration Std [ms]</th>\n",
       "      <th>Blink Duration Max [ms]</th>\n",
       "      <th>Blink Duration Min [ms]</th>\n",
       "      <th>Blink Duration Std [ms]</th>\n",
       "      <th>Blink Duration Quantil 75 [ms]</th>\n",
       "      <th>Fixation Duration Kurtosis [ms]</th>\n",
       "      <th>...</th>\n",
       "      <th>Saccade Velocity Peak [%] Kurtosis</th>\n",
       "      <th>Saccade Length Max [px]</th>\n",
       "      <th>Saccade Length Std [px]</th>\n",
       "      <th>Saccade Length Skew [px]]</th>\n",
       "      <th>Saccade Length Kurtosis [px]</th>\n",
       "      <th>Fixation Average Pupil Diameter [mm] Max</th>\n",
       "      <th>Fixation Average Pupil Diameter [mm] Std</th>\n",
       "      <th>Fixation Average Pupil Diameter [mm] Quantil75</th>\n",
       "      <th>Veregence Angles Std [rad]</th>\n",
       "      <th>Pupil Distance Std [px]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1873.7450</td>\n",
       "      <td>1011.718705</td>\n",
       "      <td>3.173523</td>\n",
       "      <td>56.0080</td>\n",
       "      <td>21.214495</td>\n",
       "      <td>316.0965</td>\n",
       "      <td>140.1370</td>\n",
       "      <td>97.468689</td>\n",
       "      <td>284.121250</td>\n",
       "      <td>10.331107</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.097560</td>\n",
       "      <td>409.359982</td>\n",
       "      <td>276.729303</td>\n",
       "      <td>1.019967</td>\n",
       "      <td>-0.233616</td>\n",
       "      <td>0.271641</td>\n",
       "      <td>1.332215</td>\n",
       "      <td>-0.334359</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>355.018021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>151.9895</td>\n",
       "      <td>800.042298</td>\n",
       "      <td>1.230280</td>\n",
       "      <td>77.9780</td>\n",
       "      <td>15.190723</td>\n",
       "      <td>202.0885</td>\n",
       "      <td>110.0790</td>\n",
       "      <td>65.060541</td>\n",
       "      <td>179.086125</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>...</td>\n",
       "      <td>2.686147</td>\n",
       "      <td>663.674985</td>\n",
       "      <td>248.028586</td>\n",
       "      <td>1.219855</td>\n",
       "      <td>0.968253</td>\n",
       "      <td>0.315141</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>0.244266</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>51.405672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>132.0700</td>\n",
       "      <td>943.831847</td>\n",
       "      <td>1.606019</td>\n",
       "      <td>81.8875</td>\n",
       "      <td>16.892143</td>\n",
       "      <td>289.6475</td>\n",
       "      <td>113.9645</td>\n",
       "      <td>91.786011</td>\n",
       "      <td>194.323375</td>\n",
       "      <td>2.716543</td>\n",
       "      <td>...</td>\n",
       "      <td>2.345367</td>\n",
       "      <td>1144.758042</td>\n",
       "      <td>344.839091</td>\n",
       "      <td>2.077634</td>\n",
       "      <td>4.323120</td>\n",
       "      <td>0.564641</td>\n",
       "      <td>0.316681</td>\n",
       "      <td>0.454891</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>257.319271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>107.9430</td>\n",
       "      <td>868.559968</td>\n",
       "      <td>2.276932</td>\n",
       "      <td>59.9860</td>\n",
       "      <td>12.334705</td>\n",
       "      <td>252.0815</td>\n",
       "      <td>230.0860</td>\n",
       "      <td>12.292138</td>\n",
       "      <td>250.126500</td>\n",
       "      <td>3.917568</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140372</td>\n",
       "      <td>606.721482</td>\n",
       "      <td>202.365506</td>\n",
       "      <td>0.704152</td>\n",
       "      <td>-1.040127</td>\n",
       "      <td>-0.054961</td>\n",
       "      <td>0.127198</td>\n",
       "      <td>-0.130711</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>70.026819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>85.9770</td>\n",
       "      <td>961.214162</td>\n",
       "      <td>2.220278</td>\n",
       "      <td>69.9070</td>\n",
       "      <td>14.725075</td>\n",
       "      <td>329.9055</td>\n",
       "      <td>235.9240</td>\n",
       "      <td>66.454956</td>\n",
       "      <td>306.410125</td>\n",
       "      <td>4.800117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.448982</td>\n",
       "      <td>895.862268</td>\n",
       "      <td>257.678741</td>\n",
       "      <td>2.035361</td>\n",
       "      <td>4.246652</td>\n",
       "      <td>-0.090961</td>\n",
       "      <td>0.065377</td>\n",
       "      <td>-0.204711</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>58.771618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>101.9995</td>\n",
       "      <td>248.337427</td>\n",
       "      <td>1.136750</td>\n",
       "      <td>88.0785</td>\n",
       "      <td>16.569230</td>\n",
       "      <td>349.9165</td>\n",
       "      <td>146.0390</td>\n",
       "      <td>80.470759</td>\n",
       "      <td>287.878500</td>\n",
       "      <td>0.215747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619014</td>\n",
       "      <td>1145.003742</td>\n",
       "      <td>298.250174</td>\n",
       "      <td>1.799903</td>\n",
       "      <td>3.185775</td>\n",
       "      <td>-0.225461</td>\n",
       "      <td>0.064668</td>\n",
       "      <td>-0.339586</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>88.994922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>98.0240</td>\n",
       "      <td>223.867392</td>\n",
       "      <td>1.267630</td>\n",
       "      <td>85.9285</td>\n",
       "      <td>14.931760</td>\n",
       "      <td>259.9400</td>\n",
       "      <td>259.9400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.940000</td>\n",
       "      <td>0.944152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648045</td>\n",
       "      <td>1097.186009</td>\n",
       "      <td>276.851685</td>\n",
       "      <td>2.083199</td>\n",
       "      <td>3.903025</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.133986</td>\n",
       "      <td>-0.134836</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>36.298896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>59.9540</td>\n",
       "      <td>443.232896</td>\n",
       "      <td>1.790886</td>\n",
       "      <td>89.9965</td>\n",
       "      <td>15.235908</td>\n",
       "      <td>295.9165</td>\n",
       "      <td>193.9770</td>\n",
       "      <td>52.903009</td>\n",
       "      <td>265.932875</td>\n",
       "      <td>2.513531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532956</td>\n",
       "      <td>1181.211594</td>\n",
       "      <td>295.486876</td>\n",
       "      <td>2.108216</td>\n",
       "      <td>4.993062</td>\n",
       "      <td>-0.162461</td>\n",
       "      <td>0.108304</td>\n",
       "      <td>-0.302836</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>78.084723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fixation Duration Min [ms]  Fixation Duration Std [ms]  \\\n",
       "180                    1873.7450                 1011.718705   \n",
       "181                     151.9895                  800.042298   \n",
       "182                     132.0700                  943.831847   \n",
       "183                          NaN                         NaN   \n",
       "184                          NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "1022                    107.9430                  868.559968   \n",
       "1023                     85.9770                  961.214162   \n",
       "1024                    101.9995                  248.337427   \n",
       "1025                     98.0240                  223.867392   \n",
       "1026                     59.9540                  443.232896   \n",
       "\n",
       "      Fixation Duration Skew [ms]  Saccade Duration Max [ms]  \\\n",
       "180                      3.173523                    56.0080   \n",
       "181                      1.230280                    77.9780   \n",
       "182                      1.606019                    81.8875   \n",
       "183                           NaN                        NaN   \n",
       "184                           NaN                        NaN   \n",
       "...                           ...                        ...   \n",
       "1022                     2.276932                    59.9860   \n",
       "1023                     2.220278                    69.9070   \n",
       "1024                     1.136750                    88.0785   \n",
       "1025                     1.267630                    85.9285   \n",
       "1026                     1.790886                    89.9965   \n",
       "\n",
       "      Saccade Duration Std [ms]  Blink Duration Max [ms]  \\\n",
       "180                   21.214495                 316.0965   \n",
       "181                   15.190723                 202.0885   \n",
       "182                   16.892143                 289.6475   \n",
       "183                         NaN                      NaN   \n",
       "184                         NaN                      NaN   \n",
       "...                         ...                      ...   \n",
       "1022                  12.334705                 252.0815   \n",
       "1023                  14.725075                 329.9055   \n",
       "1024                  16.569230                 349.9165   \n",
       "1025                  14.931760                 259.9400   \n",
       "1026                  15.235908                 295.9165   \n",
       "\n",
       "      Blink Duration Min [ms]  Blink Duration Std [ms]  \\\n",
       "180                  140.1370                97.468689   \n",
       "181                  110.0790                65.060541   \n",
       "182                  113.9645                91.786011   \n",
       "183                       NaN                      NaN   \n",
       "184                       NaN                      NaN   \n",
       "...                       ...                      ...   \n",
       "1022                 230.0860                12.292138   \n",
       "1023                 235.9240                66.454956   \n",
       "1024                 146.0390                80.470759   \n",
       "1025                 259.9400                      NaN   \n",
       "1026                 193.9770                52.903009   \n",
       "\n",
       "      Blink Duration Quantil 75 [ms]  Fixation Duration Kurtosis [ms]  ...  \\\n",
       "180                       284.121250                        10.331107  ...   \n",
       "181                       179.086125                         0.643214  ...   \n",
       "182                       194.323375                         2.716543  ...   \n",
       "183                              NaN                              NaN  ...   \n",
       "184                              NaN                              NaN  ...   \n",
       "...                              ...                              ...  ...   \n",
       "1022                      250.126500                         3.917568  ...   \n",
       "1023                      306.410125                         4.800117  ...   \n",
       "1024                      287.878500                         0.215747  ...   \n",
       "1025                      259.940000                         0.944152  ...   \n",
       "1026                      265.932875                         2.513531  ...   \n",
       "\n",
       "      Saccade Velocity Peak [%] Kurtosis  Saccade Length Max [px]  \\\n",
       "180                            -1.097560               409.359982   \n",
       "181                             2.686147               663.674985   \n",
       "182                             2.345367              1144.758042   \n",
       "183                                  NaN                      NaN   \n",
       "184                                  NaN                      NaN   \n",
       "...                                  ...                      ...   \n",
       "1022                           -1.140372               606.721482   \n",
       "1023                           -0.448982               895.862268   \n",
       "1024                           -0.619014              1145.003742   \n",
       "1025                           -0.648045              1097.186009   \n",
       "1026                            0.532956              1181.211594   \n",
       "\n",
       "      Saccade Length Std [px]  Saccade Length Skew [px]]  \\\n",
       "180                276.729303                   1.019967   \n",
       "181                248.028586                   1.219855   \n",
       "182                344.839091                   2.077634   \n",
       "183                       NaN                        NaN   \n",
       "184                       NaN                        NaN   \n",
       "...                       ...                        ...   \n",
       "1022               202.365506                   0.704152   \n",
       "1023               257.678741                   2.035361   \n",
       "1024               298.250174                   1.799903   \n",
       "1025               276.851685                   2.083199   \n",
       "1026               295.486876                   2.108216   \n",
       "\n",
       "      Saccade Length Kurtosis [px]  Fixation Average Pupil Diameter [mm] Max  \\\n",
       "180                      -0.233616                                  0.271641   \n",
       "181                       0.968253                                  0.315141   \n",
       "182                       4.323120                                  0.564641   \n",
       "183                            NaN                                       NaN   \n",
       "184                            NaN                                       NaN   \n",
       "...                            ...                                       ...   \n",
       "1022                     -1.040127                                 -0.054961   \n",
       "1023                      4.246652                                 -0.090961   \n",
       "1024                      3.185775                                 -0.225461   \n",
       "1025                      3.903025                                  0.003039   \n",
       "1026                      4.993062                                 -0.162461   \n",
       "\n",
       "      Fixation Average Pupil Diameter [mm] Std  \\\n",
       "180                                   1.332215   \n",
       "181                                   0.057714   \n",
       "182                                   0.316681   \n",
       "183                                        NaN   \n",
       "184                                        NaN   \n",
       "...                                        ...   \n",
       "1022                                  0.127198   \n",
       "1023                                  0.065377   \n",
       "1024                                  0.064668   \n",
       "1025                                  0.133986   \n",
       "1026                                  0.108304   \n",
       "\n",
       "      Fixation Average Pupil Diameter [mm] Quantil75  \\\n",
       "180                                        -0.334359   \n",
       "181                                         0.244266   \n",
       "182                                         0.454891   \n",
       "183                                              NaN   \n",
       "184                                              NaN   \n",
       "...                                              ...   \n",
       "1022                                       -0.130711   \n",
       "1023                                       -0.204711   \n",
       "1024                                       -0.339586   \n",
       "1025                                       -0.134836   \n",
       "1026                                       -0.302836   \n",
       "\n",
       "      Veregence Angles Std [rad]  Pupil Distance Std [px]  \n",
       "180                     0.012578               355.018021  \n",
       "181                     0.009350                51.405672  \n",
       "182                     0.005061               257.319271  \n",
       "183                          NaN                      NaN  \n",
       "184                          NaN                      NaN  \n",
       "...                          ...                      ...  \n",
       "1022                    0.006715                70.026819  \n",
       "1023                    0.005560                58.771618  \n",
       "1024                    0.008152                88.994922  \n",
       "1025                    0.008049                36.298896  \n",
       "1026                    0.008470                78.084723  \n",
       "\n",
       "[209 rows x 75 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>F_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Veregence Angles Std [rad]</td>\n",
       "      <td>10.152555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Mean</td>\n",
       "      <td>8.560988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Std</td>\n",
       "      <td>8.508311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Saccade Velocity Peak [%] Std</td>\n",
       "      <td>8.469369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blink Duration Std [ms]</td>\n",
       "      <td>8.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fixation Dispersion X Median [px]</td>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Median</td>\n",
       "      <td>0.948839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Saccade Amplitude Median [°]</td>\n",
       "      <td>0.943096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Saccade Amplitude Quantil 25 [°]</td>\n",
       "      <td>0.910914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fixation Duration Min [ms]</td>\n",
       "      <td>0.852951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Features   F_Scores\n",
       "73             Veregence Angles Std [rad]  10.152555\n",
       "38  Saccade Deceleration Peak [°/s²] Mean   8.560988\n",
       "41   Saccade Deceleration Peak [°/s²] Std   8.508311\n",
       "61          Saccade Velocity Peak [%] Std   8.469369\n",
       "7                 Blink Duration Std [ms]   8.180086\n",
       "..                                    ...        ...\n",
       "15      Fixation Dispersion X Median [px]   0.965857\n",
       "53    Saccade Velocity Peak [°/s²] Median   0.948839\n",
       "21           Saccade Amplitude Median [°]   0.943096\n",
       "23       Saccade Amplitude Quantil 25 [°]   0.910914\n",
       "0              Fixation Duration Min [ms]   0.852951\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_features_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>F_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Veregence Angles Std [rad]</td>\n",
       "      <td>10.152555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Mean</td>\n",
       "      <td>8.560988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Std</td>\n",
       "      <td>8.508311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Saccade Velocity Peak [%] Std</td>\n",
       "      <td>8.469369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blink Duration Std [ms]</td>\n",
       "      <td>8.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Std</td>\n",
       "      <td>7.860550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Saccade Acceleration Average [°/s²] Mean</td>\n",
       "      <td>7.688727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Quantil 25]</td>\n",
       "      <td>7.368572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Mean</td>\n",
       "      <td>7.263204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Saccade Acceleration Average [°/s²] Std</td>\n",
       "      <td>7.167826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Saccade Acceleration Average [°/s²] Quantil 75]</td>\n",
       "      <td>6.378195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Std</td>\n",
       "      <td>6.212499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Quantil 75]</td>\n",
       "      <td>5.961422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Saccade Velocity Peak [%] Quantil 75]</td>\n",
       "      <td>5.863685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Mean</td>\n",
       "      <td>5.733594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Min</td>\n",
       "      <td>5.703454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Quantil 75]</td>\n",
       "      <td>5.555263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Max</td>\n",
       "      <td>5.367087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Saccade Acceleration Peak [°/s²] Mean</td>\n",
       "      <td>4.909186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Saccade Acceleration Peak [°/s²] Quantil 75]</td>\n",
       "      <td>4.846965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Features   F_Scores\n",
       "73                       Veregence Angles Std [rad]  10.152555\n",
       "38            Saccade Deceleration Peak [°/s²] Mean   8.560988\n",
       "41             Saccade Deceleration Peak [°/s²] Std   8.508311\n",
       "61                    Saccade Velocity Peak [%] Std   8.469369\n",
       "7                           Blink Duration Std [ms]   8.180086\n",
       "54                 Saccade Velocity Peak [°/s²] Std   7.860550\n",
       "25         Saccade Acceleration Average [°/s²] Mean   7.688727\n",
       "43     Saccade Deceleration Peak [°/s²] Quantil 25]   7.368572\n",
       "50                Saccade Velocity Peak [°/s²] Mean   7.263204\n",
       "29          Saccade Acceleration Average [°/s²] Std   7.167826\n",
       "31  Saccade Acceleration Average [°/s²] Quantil 75]   6.378195\n",
       "48              Saccade Velocity Average [°/s²] Std   6.212499\n",
       "56         Saccade Velocity Peak [°/s²] Quantil 75]   5.961422\n",
       "62            Saccade Velocity Peak [%] Quantil 75]   5.863685\n",
       "44             Saccade Velocity Average [°/s²] Mean   5.733594\n",
       "39             Saccade Deceleration Peak [°/s²] Min   5.703454\n",
       "49      Saccade Velocity Average [°/s²] Quantil 75]   5.555263\n",
       "51                 Saccade Velocity Peak [°/s²] Max   5.367087\n",
       "32            Saccade Acceleration Peak [°/s²] Mean   4.909186\n",
       "37     Saccade Acceleration Peak [°/s²] Quantil 75]   4.846965"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_features_with_score.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat_names</th>\n",
       "      <th>F_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Saccade Velocity Average [°/s²] Median</td>\n",
       "      <td>1.337471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blink Duration Min [ms]</td>\n",
       "      <td>1.315676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fixation Duration Kurtosis [ms]</td>\n",
       "      <td>1.264215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Saccade Acceleration Peak [°/s²] Skew]</td>\n",
       "      <td>1.260970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Saccade Deceleration Peak [°/s²] Kurtosis</td>\n",
       "      <td>1.258899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blink Number</td>\n",
       "      <td>1.245705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Saccade Velocity Peak [%] Kurtosis</td>\n",
       "      <td>1.201339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fixation Duration Skew [ms]</td>\n",
       "      <td>1.192515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Fixation Average Pupil Diameter [mm] Quantil75</td>\n",
       "      <td>1.135945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Saccade Amplitude Quantil 75 [°]</td>\n",
       "      <td>1.112870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saccade Duration Std [ms]</td>\n",
       "      <td>1.022469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Saccade Acceleration Average [°/s²] Min</td>\n",
       "      <td>1.017311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fixation Dispersion Y Skew [px]</td>\n",
       "      <td>1.008745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fixation Duration Std [ms]</td>\n",
       "      <td>1.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Kurtosis</td>\n",
       "      <td>0.973287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fixation Dispersion X Median [px]</td>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Saccade Velocity Peak [°/s²] Median</td>\n",
       "      <td>0.948839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Saccade Amplitude Median [°]</td>\n",
       "      <td>0.943096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Saccade Amplitude Quantil 25 [°]</td>\n",
       "      <td>0.910914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fixation Duration Min [ms]</td>\n",
       "      <td>0.852951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Feat_names  F_Scores\n",
       "47          Saccade Velocity Average [°/s²] Median  1.337471\n",
       "6                          Blink Duration Min [ms]  1.315676\n",
       "9                  Fixation Duration Kurtosis [ms]  1.264215\n",
       "36          Saccade Acceleration Peak [°/s²] Skew]  1.260970\n",
       "63       Saccade Deceleration Peak [°/s²] Kurtosis  1.258899\n",
       "14                                    Blink Number  1.245705\n",
       "65              Saccade Velocity Peak [%] Kurtosis  1.201339\n",
       "2                      Fixation Duration Skew [ms]  1.192515\n",
       "72  Fixation Average Pupil Diameter [mm] Quantil75  1.135945\n",
       "24                Saccade Amplitude Quantil 75 [°]  1.112870\n",
       "4                        Saccade Duration Std [ms]  1.022469\n",
       "27         Saccade Acceleration Average [°/s²] Min  1.017311\n",
       "17                 Fixation Dispersion Y Skew [px]  1.008745\n",
       "1                       Fixation Duration Std [ms]  1.000014\n",
       "64           Saccade Velocity Peak [°/s²] Kurtosis  0.973287\n",
       "15               Fixation Dispersion X Median [px]  0.965857\n",
       "53             Saccade Velocity Peak [°/s²] Median  0.948839\n",
       "21                    Saccade Amplitude Median [°]  0.943096\n",
       "23                Saccade Amplitude Quantil 25 [°]  0.910914\n",
       "0                       Fixation Duration Min [ms]  0.852951"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_features_with_score.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a166e61b3f1e7b9ccc9f59f78d7cc3087a9ccbb0b1a7cff444b301613a633a54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
