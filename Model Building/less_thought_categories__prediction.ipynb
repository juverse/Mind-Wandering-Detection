{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## can we decide between different thought categories? ############################\n",
    "## Dependencies\n",
    "\n",
    "# Import package/module for data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules for feature engineering and modelling\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# cross validation and hyperparameter tuning\n",
    "from sklearn.model_selection import StratifiedGroupKFold,  GridSearchCV\n",
    "\n",
    "# balancing\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "#feature selection\n",
    "from sklearn import set_config\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = r\"W:\\WCT\\04_Mind-Wandering-Labstudy\\04_Daten\\04_Prepared_data\\00_Julia\\Model Building\\features_with_labels.csv\"\n",
    "df = pd.read_csv(read_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Probe</th>\n",
       "      <th>Tracking Ratio [%] Mean</th>\n",
       "      <th>Fixation Duration Mean [ms]</th>\n",
       "      <th>Fixation Duration Max [ms]</th>\n",
       "      <th>Fixation Duration Min [ms]</th>\n",
       "      <th>Fixation Duration Median [ms]</th>\n",
       "      <th>Fixation Duration Std [ms]</th>\n",
       "      <th>Fixation Duration Skew [ms]</th>\n",
       "      <th>...</th>\n",
       "      <th>Fixation Average Pupil Diameter [mm] Kurtosis</th>\n",
       "      <th>Veregence Angles Mean [rad]</th>\n",
       "      <th>Veregence Angles Std [rad]</th>\n",
       "      <th>Pupil Distance Mean [px]</th>\n",
       "      <th>Pupil Distance Std [px]</th>\n",
       "      <th>Awareness_all</th>\n",
       "      <th>Content_cat</th>\n",
       "      <th>Content_text</th>\n",
       "      <th>Content_Probe</th>\n",
       "      <th>Awareness_all_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85.268</td>\n",
       "      <td>259.893077</td>\n",
       "      <td>668.0035</td>\n",
       "      <td>79.9605</td>\n",
       "      <td>246.01250</td>\n",
       "      <td>148.837048</td>\n",
       "      <td>1.275655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397839</td>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>219.578560</td>\n",
       "      <td>126.804463</td>\n",
       "      <td>task-related</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lecture Comprehension (TRI)</td>\n",
       "      <td>TRI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>81.388</td>\n",
       "      <td>195.289221</td>\n",
       "      <td>738.0090</td>\n",
       "      <td>59.9435</td>\n",
       "      <td>144.00400</td>\n",
       "      <td>139.321063</td>\n",
       "      <td>2.273614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369095</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>220.563184</td>\n",
       "      <td>106.613971</td>\n",
       "      <td>task-related</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On task</td>\n",
       "      <td>On Task</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>83.450</td>\n",
       "      <td>204.240667</td>\n",
       "      <td>749.8700</td>\n",
       "      <td>63.9685</td>\n",
       "      <td>165.05425</td>\n",
       "      <td>136.716801</td>\n",
       "      <td>2.419750</td>\n",
       "      <td>...</td>\n",
       "      <td>18.112139</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>209.008402</td>\n",
       "      <td>109.885864</td>\n",
       "      <td>task-related</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lecture Comprehension (TRI)</td>\n",
       "      <td>TRI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>83.736</td>\n",
       "      <td>311.880068</td>\n",
       "      <td>1004.0200</td>\n",
       "      <td>65.9780</td>\n",
       "      <td>206.00375</td>\n",
       "      <td>266.756308</td>\n",
       "      <td>1.735261</td>\n",
       "      <td>...</td>\n",
       "      <td>13.587151</td>\n",
       "      <td>0.030035</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>227.466912</td>\n",
       "      <td>125.311414</td>\n",
       "      <td>task-related</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lecture Comprehension (TRI)</td>\n",
       "      <td>TRI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>87.020</td>\n",
       "      <td>483.836531</td>\n",
       "      <td>1203.8275</td>\n",
       "      <td>111.9665</td>\n",
       "      <td>311.97925</td>\n",
       "      <td>384.029087</td>\n",
       "      <td>1.091558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213811</td>\n",
       "      <td>0.024829</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>218.641919</td>\n",
       "      <td>111.928529</td>\n",
       "      <td>task-related</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ideas about lecture (TRT)</td>\n",
       "      <td>On Task</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1022</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>91.360</td>\n",
       "      <td>563.403233</td>\n",
       "      <td>2699.5470</td>\n",
       "      <td>107.9430</td>\n",
       "      <td>208.01900</td>\n",
       "      <td>868.559968</td>\n",
       "      <td>2.276932</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.417532</td>\n",
       "      <td>0.019285</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>259.802260</td>\n",
       "      <td>70.026819</td>\n",
       "      <td>aware</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Personal matters (TUT)</td>\n",
       "      <td>TUT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1023</td>\n",
       "      <td>97</td>\n",
       "      <td>6</td>\n",
       "      <td>96.044</td>\n",
       "      <td>689.920744</td>\n",
       "      <td>3299.6905</td>\n",
       "      <td>85.9770</td>\n",
       "      <td>254.93450</td>\n",
       "      <td>961.214162</td>\n",
       "      <td>2.220278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>0.019262</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>262.876279</td>\n",
       "      <td>58.771618</td>\n",
       "      <td>task-related</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On task</td>\n",
       "      <td>On Task</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1024</td>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>86.734</td>\n",
       "      <td>358.844061</td>\n",
       "      <td>929.7645</td>\n",
       "      <td>101.9995</td>\n",
       "      <td>246.88975</td>\n",
       "      <td>248.337427</td>\n",
       "      <td>1.136750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>0.027485</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>248.013878</td>\n",
       "      <td>88.994922</td>\n",
       "      <td>task-related</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lecture Comprehension (TRI)</td>\n",
       "      <td>TRI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1025</td>\n",
       "      <td>97</td>\n",
       "      <td>8</td>\n",
       "      <td>87.880</td>\n",
       "      <td>347.362106</td>\n",
       "      <td>905.9330</td>\n",
       "      <td>98.0240</td>\n",
       "      <td>256.97750</td>\n",
       "      <td>223.867392</td>\n",
       "      <td>1.267630</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078778</td>\n",
       "      <td>0.019740</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>264.238181</td>\n",
       "      <td>36.298896</td>\n",
       "      <td>aware</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Personal matters (TUT)</td>\n",
       "      <td>TUT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1026</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>84.449</td>\n",
       "      <td>438.488124</td>\n",
       "      <td>1584.0745</td>\n",
       "      <td>59.9540</td>\n",
       "      <td>234.02500</td>\n",
       "      <td>443.232896</td>\n",
       "      <td>1.790886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>260.640314</td>\n",
       "      <td>78.084723</td>\n",
       "      <td>task-related</td>\n",
       "      <td>1.0</td>\n",
       "      <td>On task</td>\n",
       "      <td>On Task</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Participant  Probe  Tracking Ratio [%] Mean  \\\n",
       "0              0            1      1                   85.268   \n",
       "1              1            1     10                   81.388   \n",
       "2              2            1     11                   83.450   \n",
       "3              3            1     12                   83.736   \n",
       "4              4            1     13                   87.020   \n",
       "...          ...          ...    ...                      ...   \n",
       "1013        1022           97      5                   91.360   \n",
       "1014        1023           97      6                   96.044   \n",
       "1015        1024           97      7                   86.734   \n",
       "1016        1025           97      8                   87.880   \n",
       "1017        1026           97      9                   84.449   \n",
       "\n",
       "      Fixation Duration Mean [ms]  Fixation Duration Max [ms]  \\\n",
       "0                      259.893077                    668.0035   \n",
       "1                      195.289221                    738.0090   \n",
       "2                      204.240667                    749.8700   \n",
       "3                      311.880068                   1004.0200   \n",
       "4                      483.836531                   1203.8275   \n",
       "...                           ...                         ...   \n",
       "1013                   563.403233                   2699.5470   \n",
       "1014                   689.920744                   3299.6905   \n",
       "1015                   358.844061                    929.7645   \n",
       "1016                   347.362106                    905.9330   \n",
       "1017                   438.488124                   1584.0745   \n",
       "\n",
       "      Fixation Duration Min [ms]  Fixation Duration Median [ms]  \\\n",
       "0                        79.9605                      246.01250   \n",
       "1                        59.9435                      144.00400   \n",
       "2                        63.9685                      165.05425   \n",
       "3                        65.9780                      206.00375   \n",
       "4                       111.9665                      311.97925   \n",
       "...                          ...                            ...   \n",
       "1013                    107.9430                      208.01900   \n",
       "1014                     85.9770                      254.93450   \n",
       "1015                    101.9995                      246.88975   \n",
       "1016                     98.0240                      256.97750   \n",
       "1017                     59.9540                      234.02500   \n",
       "\n",
       "      Fixation Duration Std [ms]  Fixation Duration Skew [ms]  ...  \\\n",
       "0                     148.837048                     1.275655  ...   \n",
       "1                     139.321063                     2.273614  ...   \n",
       "2                     136.716801                     2.419750  ...   \n",
       "3                     266.756308                     1.735261  ...   \n",
       "4                     384.029087                     1.091558  ...   \n",
       "...                          ...                          ...  ...   \n",
       "1013                  868.559968                     2.276932  ...   \n",
       "1014                  961.214162                     2.220278  ...   \n",
       "1015                  248.337427                     1.136750  ...   \n",
       "1016                  223.867392                     1.267630  ...   \n",
       "1017                  443.232896                     1.790886  ...   \n",
       "\n",
       "      Fixation Average Pupil Diameter [mm] Kurtosis  \\\n",
       "0                                         -0.397839   \n",
       "1                                         -0.369095   \n",
       "2                                         18.112139   \n",
       "3                                         13.587151   \n",
       "4                                         -0.213811   \n",
       "...                                             ...   \n",
       "1013                                      -1.417532   \n",
       "1014                                       0.946158   \n",
       "1015                                       0.018713   \n",
       "1016                                      -1.078778   \n",
       "1017                                      -0.328504   \n",
       "\n",
       "      Veregence Angles Mean [rad]  Veregence Angles Std [rad]  \\\n",
       "0                        0.024544                    0.008193   \n",
       "1                        0.016063                    0.008325   \n",
       "2                        0.033338                    0.023195   \n",
       "3                        0.030035                    0.018617   \n",
       "4                        0.024829                    0.006304   \n",
       "...                           ...                         ...   \n",
       "1013                     0.019285                    0.006715   \n",
       "1014                     0.019262                    0.005560   \n",
       "1015                     0.027485                    0.008152   \n",
       "1016                     0.019740                    0.008049   \n",
       "1017                     0.026633                    0.008470   \n",
       "\n",
       "      Pupil Distance Mean [px]  Pupil Distance Std [px]  Awareness_all  \\\n",
       "0                   219.578560               126.804463   task-related   \n",
       "1                   220.563184               106.613971   task-related   \n",
       "2                   209.008402               109.885864   task-related   \n",
       "3                   227.466912               125.311414   task-related   \n",
       "4                   218.641919               111.928529   task-related   \n",
       "...                        ...                      ...            ...   \n",
       "1013                259.802260                70.026819          aware   \n",
       "1014                262.876279                58.771618   task-related   \n",
       "1015                248.013878                88.994922   task-related   \n",
       "1016                264.238181                36.298896          aware   \n",
       "1017                260.640314                78.084723   task-related   \n",
       "\n",
       "      Content_cat                 Content_text  Content_Probe  \\\n",
       "0             3.0  Lecture Comprehension (TRI)            TRI   \n",
       "1             1.0                      On task        On Task   \n",
       "2             3.0  Lecture Comprehension (TRI)            TRI   \n",
       "3             3.0  Lecture Comprehension (TRI)            TRI   \n",
       "4             2.0    Ideas about lecture (TRT)        On Task   \n",
       "...           ...                          ...            ...   \n",
       "1013          4.0       Personal matters (TUT)            TUT   \n",
       "1014          1.0                      On task        On Task   \n",
       "1015          3.0  Lecture Comprehension (TRI)            TRI   \n",
       "1016          4.0       Personal matters (TUT)            TUT   \n",
       "1017          1.0                      On task        On Task   \n",
       "\n",
       "      Awareness_all_cat  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "...                 ...  \n",
       "1013                  2  \n",
       "1014                  1  \n",
       "1015                  1  \n",
       "1016                  2  \n",
       "1017                  1  \n",
       "\n",
       "[1018 rows x 148 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge categories\n",
    "# delte Category Others, becasue its not predictible\n",
    "df = df.loc[df[\"Content_cat\"] != 14]\n",
    "# merge task- related thoughts to On-task, to get bigger classes\n",
    "df[\"Content_Probe\"] = df[\"Content_Probe\"].replace(\"TRT\", \"On Task\")\n",
    "\n",
    "df = df.reset_index(drop = True)#.drop(['Unnamed: 0'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452\n",
       "2    396\n",
       "1    170\n",
       "Name: Content_probe_categories, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoder for content probe\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "df[\"Content_probe_categories\"] = labelencoder.fit_transform(df[\"Content_Probe\"])\n",
    "df[\"Content_probe_categories\"].unique()\n",
    "df[\"Content_probe_categories\"].value_counts()\n",
    "\n",
    "# Categories not so speficic: \n",
    "#0    452 On-Task & TRT: 44,4007858546169\n",
    "#2   396 TUT 38,89980353634578\n",
    "#1    170 TRI 16,69941060903733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        'Fixation Duration Mean [ms]', 'Fixation Duration Max [ms]', 'Fixation Duration Min [ms]', 'Fixation Duration Median [ms]', 'Fixation Duration Std [ms]', 'Fixation Duration Skew [ms]', 'Fixation Duration Quantil 25 [ms]', 'Fixation Duration Quantil 75 [ms]',\n",
    "        'Saccade Duration Mean [ms]', 'Saccade Duration Max [ms]', 'Saccade Duration Min [ms]', 'Saccade Duration Median [ms]', 'Saccade Duration Std [ms]', 'Saccade Duration Skew [ms]', 'Saccade Duration Quantil 25 [ms]', 'Saccade Duration Quantil 75 [ms]', \n",
    "        'Blink Duration Mean [ms]', 'Blink Duration Max [ms]', 'Blink Duration Min [ms]', 'Blink Duration Median [ms]', 'Blink Duration Std [ms]', 'Blink Duration Skew [ms]', 'Blink Duration Quantil 25 [ms]', 'Blink Duration Quantil 75 [ms]', 'Fixation Duration Kurtosis [ms]',\n",
    "        'Saccade Duration Kurtosis [ms]',\n",
    "        'Blink Duration Kurtosis [ms]', \n",
    "        'Fixation Saccade Ratio Mean', 'Fixation Saccade Ratio Max', 'Fixation Saccade Ratio Min', 'Fixation Saccade Ratio Median', 'Fixation Saccade Ratio Std', 'Fixation Saccade Ratio Skew', 'Fixation Saccade Ratio Kurtosis', \n",
    "        'Fixation Number', 'Blink Number', \n",
    "        'Fixation Dispersion X Mean [px]', 'Fixation Dispersion X Max [px]', 'Fixation Dispersion X Min [px]', 'Fixation Dispersion X Median [px]', 'Fixation Dispersion X Std [px]', 'Fixation Dispersion X Skew [px]', 'Fixation Dispersion X Quantil 25 [px]', 'Fixation Dispersion X Quantil 75 [px]', \n",
    "        'Fixation Dispersion Y Mean [px]', 'Fixation Dispersion Y Max [px]', 'Fixation Dispersion Y Min [px]', 'Fixation Dispersion Y Median [px]', 'Fixation Dispersion Y Std [px]', 'Fixation Dispersion Y Skew [px]', 'Fixation Dispersion Y Quantil 25 [px]', 'Fixation Dispersion Y Quantil 75 [px]', 'Fixation Dispersion X Kurtosis [px]', 'Fixation Dispersion Y Kurtosis [px]', \n",
    "        'Saccade Amplitude Mean [°]', 'Saccade Amplitude Max [°]', 'Saccade Amplitude Min [°]', 'Saccade Amplitude Median [°]', 'Saccade Amplitude Std [°]', 'Saccade Amplitude Skew [°]', 'Saccade Amplitude Quantil 25 [°]', 'Saccade Amplitude Quantil 75 [°]', 'Saccade Amplitude Kurtosis [°]',\n",
    "        'Saccade Acceleration Average [°/s²] Mean', 'Saccade Acceleration Average [°/s²] Max', 'Saccade Acceleration Average [°/s²] Min', 'Saccade Acceleration Average [°/s²] Median', 'Saccade Acceleration Average [°/s²] Std', 'Saccade Acceleration Average [°/s²] Skew]', 'Saccade Acceleration Average [°/s²] Quantil 25]', 'Saccade Acceleration Average [°/s²] Quantil 75]',\n",
    "        'Saccade Acceleration Peak [°/s²] Mean', 'Saccade Acceleration Peak [°/s²] Max', 'Saccade Acceleration Peak [°/s²] Min', 'Saccade Acceleration Peak [°/s²] Median', 'Saccade Acceleration Peak [°/s²] Std', 'Saccade Acceleration Peak [°/s²] Skew]', 'Saccade Acceleration Peak [°/s²] Quantil 25]', 'Saccade Acceleration Peak [°/s²] Quantil 75]', 'Saccade Deceleration Peak [°/s²] Mean', \n",
    "        'Saccade Deceleration Peak [°/s²] Max', 'Saccade Deceleration Peak [°/s²] Min', 'Saccade Deceleration Peak [°/s²] Median', 'Saccade Deceleration Peak [°/s²] Std', 'Saccade Deceleration Peak [°/s²] Skew]', 'Saccade Deceleration Peak [°/s²] Quantil 25]', 'Saccade Deceleration Peak [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Average [°/s²] Mean', 'Saccade Velocity Average [°/s²] Max', 'Saccade Velocity Average [°/s²] Min', 'Saccade Velocity Average [°/s²] Median', 'Saccade Velocity Average [°/s²] Std', 'Saccade Velocity Average [°/s²] Skew]', 'Saccade Velocity Average [°/s²] Quantil 25]', 'Saccade Velocity Average [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Peak [°/s²] Mean', 'Saccade Velocity Peak [°/s²] Max', 'Saccade Velocity Peak [°/s²] Min', 'Saccade Velocity Peak [°/s²] Median', 'Saccade Velocity Peak [°/s²] Std', 'Saccade Velocity Peak [°/s²] Skew]', 'Saccade Velocity Peak [°/s²] Quantil 25]', 'Saccade Velocity Peak [°/s²] Quantil 75]', \n",
    "        'Saccade Velocity Peak [%] Mean', 'Saccade Velocity Peak [%] Max', 'Saccade Velocity Peak [%] Min', 'Saccade Velocity Peak [%] Median', 'Saccade Velocity Peak [%] Std', 'Saccade Velocity Peak [%] Skew]', 'Saccade Velocity Peak [%] Quantil 25]', 'Saccade Velocity Peak [%] Quantil 75]', \n",
    "        'Saccade Acceleration Average [°/s²] Kurtosis', 'Saccade Acceleration Peak [°/s²] Kurtosis', 'Saccade Deceleration Peak [°/s²] Kurtosis', 'Saccade Velocity Average [°/s²] Kurtosis', 'Saccade Velocity Peak [°/s²] Kurtosis', 'Saccade Velocity Peak [%] Kurtosis', \n",
    "        'Saccade Length Mean [px]', 'Saccade Length Max [px]', 'Saccade Length Min [px]', 'Saccade Length Median [px]', 'Saccade Length Std [px]', 'Saccade Length Skew [px]]', 'Saccade Length Quantil 25 [px]]', 'Saccade Length Quantil 75 [px]]', 'Saccade Length Kurtosis [px]', \n",
    "        'Fixation Average Pupil Diameter [mm] Mean', 'Fixation Average Pupil Diameter [mm] Max', 'Fixation Average Pupil Diameter [mm] Min', 'Fixation Average Pupil Diameter [mm] Median', 'Fixation Average Pupil Diameter [mm] Std', 'Fixation Average Pupil Diameter [mm] Skew', 'Fixation Average Pupil Diameter [mm] Quantil25', 'Fixation Average Pupil Diameter [mm] Quantil75',\n",
    "        'Fixation Average Pupil Diameter [mm] Kurtosis', \n",
    "        'Veregence Angles Mean [rad]', 'Veregence Angles Std [rad]', \n",
    "        'Pupil Distance Mean [px]', 'Pupil Distance Std [px]'\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"Participant\"\n",
    "\n",
    "    TARGET_THOUGHT_CAT = \"Content_probe_categories\"\n",
    "    \n",
    "    X = train[FEATURES]\n",
    "    y_thoughts_cat = train[TARGET_THOUGHT_CAT]\n",
    "\n",
    "    groups = train[GROUPS]\n",
    "\n",
    "    return X, y_thoughts_cat, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_thoughts_cat, groups = get_X_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Thought Categories not specific\n",
    "## Pipleline\n",
    "imputer =  SimpleImputer(fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "over = SMOTE(random_state= 27) \n",
    "\n",
    "# neu tunen für neue Kategorien\n",
    "#model = MLPClassifier()\n",
    "#model = RandomForestClassifier(random_state=0,bootstrap= True, max_depth = 50, max_features=\"auto\", min_samples_leaf = 10, min_samples_split= 1, n_estimators = 50)\n",
    "#model = SVC(C = 0.1, gamma = 0.5, kernel = \"linear\")\n",
    "#model = xgb.XGBClassifier(objective=\"objective=multi:softmax\", random_state=42, colsample_bytree = 1, max_depth = 3, n_estimators = 100, subsample = 1)\n",
    "model = GaussianNB()\n",
    "\n",
    "steps = [('imputer', imputer), ('scaler',scaler),('over', over), ('model', model)]\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 with labels  score for fold 0:  {0: 0.22764227642276424, 1: 0.3191489361702127, 2: 0.18691588785046728}\n",
      "recall with labels  score for fold 0:  {0: 0.14893617021276595, 1: 0.8571428571428571, 2: 0.125}\n",
      "precision with labels  score for fold 0:  {0: 0.4827586206896552, 1: 0.19607843137254902, 2: 0.37037037037037035}\n",
      "f1 with labels  score for fold 1:  {0: 0.273972602739726, 1: 0.21052631578947367, 2: 0.15730337078651682}\n",
      "recall with labels  score for fold 1:  {0: 0.18691588785046728, 1: 0.6923076923076923, 2: 0.1}\n",
      "precision with labels  score for fold 1:  {0: 0.5128205128205128, 1: 0.12413793103448276, 2: 0.3684210526315789}\n",
      "f1 with labels  score for fold 2:  {0: 0.24390243902439024, 1: 0.28415300546448086, 2: 0.12500000000000003}\n",
      "recall with labels  score for fold 2:  {0: 0.20270270270270271, 1: 0.6666666666666666, 2: 0.07291666666666667}\n",
      "precision with labels  score for fold 2:  {0: 0.30612244897959184, 1: 0.18055555555555555, 2: 0.4375}\n",
      "f1 with labels  score for fold 3:  {0: 0.3007518796992481, 1: 0.26666666666666666, 2: 0.10526315789473684}\n",
      "recall with labels  score for fold 3:  {0: 0.21739130434782608, 1: 0.8275862068965517, 2: 0.060240963855421686}\n",
      "precision with labels  score for fold 3:  {0: 0.4878048780487805, 1: 0.15894039735099338, 2: 0.4166666666666667}\n",
      "f1 with labels  score for fold 4:  {0: 0.2807017543859649, 1: 0.3052631578947368, 2: 0.0}\n",
      "recall with labels  score for fold 4:  {0: 0.18823529411764706, 1: 0.7073170731707317, 2: 0.0}\n",
      "precision with labels  score for fold 4:  {0: 0.5517241379310345, 1: 0.19463087248322147, 2: 0.0}\n"
     ]
    }
   ],
   "source": [
    "##################### prediction without baseline #####################\n",
    "import random\n",
    "from sklearn import metrics\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "f1_scores ={\"0\": [], \"2\": [], \"1\": []}\n",
    "precision_scores = {\"0\": [], \"2\": [], \"1\": []}\n",
    "recall_scores ={\"0\": [], \"2\": [], \"1\": []}\n",
    "\n",
    "# stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y_thoughts_cat, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y_thoughts_cat.loc[train_index], y_thoughts_cat.loc[test_index]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    labels = [0, 1, 2]\n",
    "    f1 = f1_score(y_test, y_pred, average=None, labels=labels)\n",
    "    f1_scores[\"0\"].append(f1[0])\n",
    "    f1_scores[\"2\"].append(f1[2])\n",
    "    f1_scores[\"1\"].append(f1[1])\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, average=None, labels=labels)\n",
    "    recall_scores[\"0\"].append(recall[0])\n",
    "    recall_scores[\"2\"].append(recall[2])\n",
    "    recall_scores[\"1\"].append(recall[1])\n",
    "\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average=None, labels=labels)\n",
    "    precision_scores[\"0\"].append(precision[0])\n",
    "    precision_scores[\"2\"].append(precision[2])\n",
    "    precision_scores[\"1\"].append(precision[1])\n",
    "\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "    #auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    #print(f\"f1 with labels  score for fold {fold}: \", auc)\n",
    "    print(f\"f1 with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, f1)})\n",
    "    print(f\"recall with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, recall)})\n",
    "    print(f\"precision with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, precision)})\n",
    "    \n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: [('0', 0.2653941904544187), ('2', 0.1148964833063442), ('1', 0.27715161639711416)]\n",
      "precision: [('0', 0.46824611969391494), ('2', 0.3185916179337232), ('1', 0.17086863755936044)]\n",
      "recall: [('0', 0.18883627184628182), ('2', 0.07163152610441767), ('1', 0.7502040992368999)]\n"
     ]
    }
   ],
   "source": [
    "#results\n",
    "# Categories not so speficic: \n",
    "#0    452 On-Task & TRT\n",
    "#2   396 TUT\n",
    "#1    170 TRI\n",
    "f1_averages = [(k, sum(v)/len(v)) for k, v in f1_scores.items()]\n",
    "print(\"f1 score:\",f1_averages)\n",
    "\n",
    "\n",
    "precision_averages = [(k, sum(v)/len(v)) for k, v in precision_scores.items()]\n",
    "print(\"precision:\", precision_averages)\n",
    "\n",
    "recall_averages = [(k, sum(v)/len(v)) for k, v in recall_scores.items()]\n",
    "print(\"recall:\", recall_averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k_neighbors': 5,\n",
       " 'n_jobs': None,\n",
       " 'random_state': 27,\n",
       " 'sampling_strategy': 'auto'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SMOTE(random_state=27)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=27)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SMOTE(random_state=27)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "pipe[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean fold f1 score is 0.2191\n",
      "Our mean fold recall is 0.3369\n",
      "Our mean fold precision is 0.3192\n"
     ]
    }
   ],
   "source": [
    "##################### prediction without baseline with macro f1 score #####################\n",
    "import random\n",
    "from sklearn import metrics\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "\n",
    "f1_scores =[]\n",
    "precision_scores = []\n",
    "recall_scores =[]\n",
    "\n",
    "### stratifies group k fold\n",
    "for train_index, test_index in sgk.split(X, y_thoughts_cat, groups):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y_thoughts_cat.loc[train_index], y_thoughts_cat.loc[test_index]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    labels = [0, 1, 2]\n",
    "    f1 = f1_score(y_test, y_pred, average= \"macro\", labels=labels)\n",
    "    f1_scores.append(f1)\n",
    "  \n",
    "    #print(f1)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, average= \"macro\", labels=labels)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    #print(recall)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", labels=labels)\n",
    "    precision_scores.append(precision)\n",
    "\n",
    "    #print(recall)\n",
    "\n",
    "    #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "    #auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "\n",
    "print(f'Our mean fold f1 score is {mean_f1:0.4f}')\n",
    "print(f'Our mean fold recall is {mean_recall:0.4f}')\n",
    "print(f'Our mean fold precision is {mean_precision:0.4f}')\n",
    "\n",
    "\n",
    "#Our mean fold f1 score is 0.3877\n",
    "#Our mean fold recall is 0.3905\n",
    "#Our mean fold precision is 0.3951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### prediction with baseline #####################\n",
    "# distribution:\n",
    "#0    452 On-Task & TRT\n",
    "#2   396 TUT\n",
    "#1    170 TRI \n",
    "\n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "fold = 0\n",
    "f1_scores ={\"0\": [], \"1\": [], \"2\": []}\n",
    "precision_scores = {\"0\": [], \"1\": [], \"2\": []}\n",
    "recall_scores ={\"0\": [], \"1\": [], \"2\": []}\n",
    "\n",
    "### stratifies group k fold\n",
    "for i in range(10):\n",
    "    for train_index, test_index in sgk.split(X, y_thoughts_cat, groups):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y_thoughts_cat.loc[train_index], y_thoughts_cat.loc[test_index]\n",
    "    \n",
    "        # Fit Model on Train\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = pipe.predict(X_test)\n",
    "    \n",
    "        # create baseline\n",
    "        data_size = 1018\n",
    "        baseline = np.ones(len(y_pred))\n",
    "        TUT_size = 396/data_size * len(y_pred)\n",
    "        baseline[: int(TUT_size)] = 2\n",
    "\n",
    "        On_Task_size =  452/data_size * len(y_pred)\n",
    "        baseline[int(TUT_size):int(TUT_size) +int(On_Task_size)] = 0\n",
    "\n",
    "        np.random.shuffle(baseline)\n",
    "        baseline = baseline.astype(int)\n",
    "        labels = [0, 1, 2]\n",
    "        f1 = f1_score(y_test, baseline, average=None, labels=labels)\n",
    "        f1_scores[\"0\"].append(f1[0])\n",
    "        f1_scores[\"1\"].append(f1[1])\n",
    "        f1_scores[\"2\"].append(f1[2])\n",
    "\n",
    "        recall = recall_score(y_test, baseline, average=None, labels=labels)\n",
    "        recall_scores[\"0\"].append(recall[0])\n",
    "        recall_scores[\"1\"].append(recall[1])\n",
    "        recall_scores[\"2\"].append(recall[2])\n",
    "\n",
    "        precision = precision_score(y_test, baseline, average=None, labels=labels)\n",
    "        precision_scores[\"0\"].append(precision[0])\n",
    "        precision_scores[\"1\"].append(precision[1])\n",
    "        precision_scores[\"2\"].append(precision[2])\n",
    "\n",
    "        #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "        #auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "        #print(f\"f1 with labels  score for fold {fold}: \", auc)\n",
    "        print(f\"f1 with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, f1)})\n",
    "        print(f\"recall with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, recall)})\n",
    "        print(f\"precision with labels  score for fold {fold}: \", {label:score for label,score in zip(labels, precision)})\n",
    "        \n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: [('0', 0.4449827047557848), ('1', 0.1858383753934031), ('2', 0.37648062566786905)]\n",
      "precision: [('0', 0.4480190394998578), ('1', 0.18493362193362195), ('2', 0.37791232283890513)]\n",
      "recall: [('0', 0.445312200998912), ('1', 0.18993991318465672), ('2', 0.37715488606879544)]\n"
     ]
    }
   ],
   "source": [
    "#results\n",
    "# Categories not so speficic: \n",
    "#0    452 On-Task & TRT\n",
    "#2   396 TUT\n",
    "#1    170 TRI\n",
    "f1_averages = [(k, sum(v)/len(v)) for k, v in f1_scores.items()]\n",
    "print(\"f1 score:\",f1_averages)\n",
    "\n",
    "\n",
    "precision_averages = [(k, sum(v)/len(v)) for k, v in precision_scores.items()]\n",
    "print(\"precision:\", precision_averages)\n",
    "\n",
    "recall_averages = [(k, sum(v)/len(v)) for k, v in recall_scores.items()]\n",
    "print(\"recall:\", recall_averages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### prediction with baseline #####################\n",
    "# distribution:\n",
    "        # 4    396\n",
    "        # 0    374\n",
    "        # 2    170\n",
    "        # 3     78\n",
    "        # 1      9\n",
    "\n",
    "# 1. not so speficic: \n",
    "        # 0: on-Task, \n",
    "        # 1: Others\n",
    "        # 2: TRI\n",
    "        # 3: TRT, \n",
    "        # 4: TUT,  \n",
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "fold = 0\n",
    "f1_scores =[]\n",
    "precision_scores = []\n",
    "recall_scores =[]\n",
    "\n",
    "### stratifies group k fold\n",
    "for i in range(10):\n",
    "    for train_index, test_index in sgk.split(X, y_thoughts_cat, groups):\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y_thoughts_cat.loc[train_index], y_thoughts_cat.loc[test_index]\n",
    "    \n",
    "        # Fit Model on Train\n",
    "        pipe.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = pipe.predict(X_test)\n",
    "    \n",
    "        # create baseline\n",
    "        data_size = 1018\n",
    "        baseline = np.ones(len(y_pred))\n",
    "        TUT_size = 396/data_size * len(y_pred)\n",
    "        baseline[: int(TUT_size)] = 2\n",
    "\n",
    "        On_Task_size =  452/data_size * len(y_pred)\n",
    "        baseline[int(TUT_size):int(TUT_size) +int(On_Task_size)] = 0\n",
    "\n",
    "        np.random.shuffle(baseline)\n",
    "        baseline = baseline.astype(int)\n",
    "    \n",
    "    \n",
    "        labels = [0, 1, 2]\n",
    "        f1 = f1_score(y_test, baseline, average= \"macro\", labels=labels)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "\n",
    "        recall = recall_score(y_test, baseline, average= \"macro\", labels=labels)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "\n",
    "        precision = precision_score(y_test, baseline, average=\"macro\", labels=labels)\n",
    "        precision_scores.append(precision)\n",
    "\n",
    "\n",
    "        #fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "        #auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "        print(f\"f1  score for fold {fold}: \", f1)\n",
    "        print(f\"recall for fold {fold}: \", recall)\n",
    "        print(f\"precision for fold {fold}: \", precision)\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "\n",
    "print(f'Our mean fold f1 score is {mean_f1:0.4f}')\n",
    "print(f'Our mean fold recall is {mean_recall:0.4f}')\n",
    "print(f'Our mean fold precision is {mean_precision:0.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
